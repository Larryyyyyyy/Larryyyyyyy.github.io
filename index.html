<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Larry's garden</title>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js" async></script>
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/5.1.0/github-markdown-dark.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']]
            },
            svg: {
                fontCache: 'global'
            }
        };
    </script>
    <style>
        :root {
            --bg-color: #0d1117;
            --card-bg: rgba(22, 27, 34, 0.7);
            --accent-color: #79c0ff;
            --text-main: #c9d1d9;
            --text-dim: #8b949e;
            --glass-border: rgba(255, 255, 255, 0.1);
        }

        body {
            background-color: var(--bg-color);
            background-image: radial-gradient(circle at 50% -20%, #161b22, #0d1117);
            color: var(--text-main);
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            display: flex;
        }

        nav {
            width: 260px;
            height: 100vh;
            position: fixed;
            border-right: 1px solid var(--glass-border);
            padding: 2rem;
            display: flex;
            flex-direction: column;
            backdrop-filter: blur(10px);
        }

        .logo {
            font-size: 1.5rem;
            font-weight: 800;
            background: linear-gradient(45deg, #79c0ff, #d2a8ff);
            background-clip: border-box;
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            margin-bottom: 3rem;
        }

        .nav-links a {
            display: block;
            color: var(--text-dim);
            text-decoration: none;
            margin-bottom: 1.5rem;
            transition: 0.3s;
            font-size: 0.95rem;
        }

        .nav-links a:hover, .nav-links a.active {
            color: var(--accent-color);
            padding-left: 5px;
        }

        main {
            margin-left: 260px;
            padding: 3rem 10%;
            width: 100%;
        }

        .markdown-body {
            background: var(--card-bg);
            padding: 2.5rem;
            border-radius: 16px;
            border: 1px solid var(--glass-border);
            box-shadow: 0 8px 32px rgba(0,0,0,0.3);
            margin-bottom: 3rem;
        }

        h1, h2 { color: #ffffff; border-bottom: 1px solid var(--glass-border); padding-bottom: 0.5rem; }
        code { background: rgba(110, 118, 129, 0.4); padding: 0.2rem 0.4rem; border-radius: 6px; font-size: 85%; }
        
        .download-grid {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(280px, 1fr));
            gap: 1.5rem;
        }

        .download-card {
            background: rgba(255, 255, 255, 0.03);
            border: 1px solid var(--glass-border);
            padding: 1.5rem;
            border-radius: 12px;
            transition: transform 0.2s, background 0.2s;
            display: flex;
            align-items: center;
            justify-content: space-between;
        }

        .download-card:hover {
            transform: translateY(-5px);
            background: rgba(255, 255, 255, 0.06);
            border-color: var(--accent-color);
        }

        .file-info i { margin-right: 12px; color: var(--accent-color); }
        .btn-download {
            color: var(--accent-color);
            text-decoration: none;
            font-size: 0.8rem;
            border: 1px solid var(--accent-color);
            padding: 4px 12px;
            border-radius: 20px;
        }

        .btn-download:hover { background: var(--accent-color); color: var(--bg-color); }

        .subject-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(240px, 1fr));
            gap: 1.5rem;
            margin-top: 2rem;
        }

        .subject-card {
            text-decoration: none;
            color: inherit;
            background: rgba(255, 255, 255, 0.05);
            border: 1px solid var(--glass-border);
            border-radius: 12px;
            padding: 1.5rem;
            display: flex;
            align-items: flex-start;
            transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
        }

        .subject-card:hover {
            background: rgba(121, 192, 255, 0.08);
            border-color: var(--accent-color);
            transform: translateY(-4px);
            box-shadow: 0 10px 20px rgba(0, 0, 0, 0.2);
        }

        .subject-icon {
            font-size: 1.5rem;
            color: var(--accent-color);
            margin-right: 1rem;
            margin-top: 0.2rem;
        }

        .subject-info h3 {
            margin: 0 0 0.5rem 0;
            font-size: 1.1rem;
            border: none;
            color: #fff;
        }

        .subject-info p {
            margin: 0;
            font-size: 0.85rem;
            color: var(--text-dim);
            line-height: 1.4;
        }

        .question-card {
            position: relative;
            display: flex;
            width: 100%;
            max-width: 450px;
            background: rgba(255, 255, 255, 0.05);
            border-radius: 16px;
            overflow: hidden;
            margin: 15px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.05);
            border: 1px solid rgba(0, 0, 0, 0.03);
            transition: all 0.3s cubic-bezier(0.25, 0.8, 0.25, 1);
            cursor: pointer;
        }

        .question-card:hover {
            background: rgba(121, 192, 255, 0.08);
            border-color: var(--accent-color);
            transform: translateY(-4px);
            box-shadow: 0 10px 20px rgba(0, 0, 0, 0.2);
        }

        .card-status-accent {
            width: 6px;
            background: #4285F4;
            flex-shrink: 0;
        }

        .card-body {
            padding: 20px;
            flex-grow: 1;
            display: flex;
            flex-direction: column;
        }

        .card-header {
            display: flex;
            align-items: center;
            gap: 8px;
            margin-bottom: 12px;
        }

        .tag {
            font-size: 11px;
            padding: 2px 8px;
            border-radius: 4px;
            font-weight: 600;
        }

        .tag-difficulty {
            font-size: 11px;
            padding: 2px 8px;
            border-radius: 4px;
            font-weight: 600;
        }

        .tag-difficulty[data-level="Easy"] {
            background: rgba(52, 168, 83, 0.1);
            color: #34A853;
        }

        .tag-difficulty[data-level="Medium"] {
            background: rgba(251, 188, 5, 0.1);
            color: #FBBC05;
        }

        .tag-difficulty[data-level="Hard"] {
            background: rgba(234, 67, 53, 0.1);
            color: #EA4335;
        }

        .tag-category { background: rgba(66, 133, 244, 0.1); color: #4285F4; }

        .question-id {
            margin-left: auto;
            font-size: 12px;
            color: #BDC1C6;
            font-family: 'Inter', sans-serif;
        }

        .question-title {
            font-family: 'Inter', sans-serif;
            font-size: 1.1rem;
            color: #7289d2;
            margin: 0 0 8px 0;
            line-height: 1.4;
        }

        .question-preview {
            font-size: 13px;
            color: #5F6368;
            line-height: 1.6;
            display: -webkit-box;
            line-clamp: 2;
            -webkit-line-clamp: 2;
            -webkit-box-orient: vertical;
            overflow: hidden;
            margin-bottom: 16px;
        }

        /* 底部功能区 */
        .card-footer {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-top: auto;
        }

        .stats {
            font-size: 12px;
            color: #9AA0A6;
        }

        .action-btn {
            background: none;
            border: none;
            color: #4285F4;
            font-weight: 600;
            font-size: 14px;
            cursor: pointer;
            transition: transform 0.2s;
        }

        .question-card:hover .action-btn {
            transform: translateX(5px);
        }

        .chapter-list {
            display: flex;
            flex-direction: column;
            gap: 12px;
            margin-top: 2rem;
            width: 100%;
        }

        .chapter-item {
            background: rgba(255, 255, 255, 0.03);
            border: 1px solid var(--glass-border);
            border-radius: 12px;
            padding: 1.2rem 2rem;
            cursor: pointer;
            display: flex;
            justify-content: space-between;
            align-items: center;
            transition: all 0.3s ease;
            width: 100%;
            box-sizing: border-box;
        }

        .chapter-item:hover {
            background: rgba(121, 192, 255, 0.08);
            border-color: var(--accent-color);
            transform: translateX(8px);
        }

        .chapter-number {
            background: rgba(121, 192, 255, 0.15);
            color: var(--accent-color);
            padding: 2px 10px;
            border-radius: 6px;
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.8rem;
            margin-right: 15px;
            font-weight: 600;
        }

        .chapter-title {
            font-size: 1.05rem;
            font-weight: 500;
            color: #e6edf3;
        }

        .chapter-info p {
            margin: 0;
            font-size: 0.85rem;
            color: var(--text-dim);
            line-height: 1.4;
        }

        @media (max-width: 768px) {
            body { flex-direction: column; }
            nav { width: 100%; height: auto; position: relative; border-right: none; border-bottom: 1px solid var(--glass-border); }
            main { margin-left: 0; padding: 1.5rem; }
        }

        section {
            animation: fadeIn 0.4s ease;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .download-card {
            display: flex;
            align-items: center;
            justify-content: space-between;
            gap: 15px;
            min-width: 0;
        }

        .file-info {
            display: flex;
            align-items: center;
            flex: 1;
            min-width: 0;
        }

        .file-info span {
            white-space: nowrap;
            overflow: hidden;
            text-overflow: ellipsis;
            display: inline-block;
            flex: 1;
        }

        .btn-download {
            flex-shrink: 0;
            white-space: nowrap;
        }

    </style>
</head>

<body>
    <nav>
        <div class="logo">Larryyyyyyy</div>
        <div class="nav-links">
            <a href="#" class="active" data-section="notes"><i class="fas fa-book-open"></i> 学习笔记</a>
            <a href="#" data-section="downloads"><i class="fas fa-download"></i> 资料下载</a>
            <a href="#" data-section="questions"><i class="fas fa-archive"></i> 思考题</a>
            <a href="#" data-section="about"><i class="fas fa-user"></i> 关于我</a>
        </div>
    </nav>

    <main>
        <section id="section-notes">
            <div id="back-btn-container" style="display: none; margin-bottom: 1rem;">
                <a href="javascript:void(0)" onclick="goBack()" style="color: var(--accent-color); text-decoration: none; font-size: 0.9rem;">
                    <i class="fas fa-arrow-left"></i> 返回上一级
                </a>
            </div>
            <h2 style="margin-bottom: 1.5rem;">学习笔记</h2>
            <div class="subject-grid" id="content-display"></div>
        </section>

        <section id="section-downloads" style="display: none;">
            <h2 style="margin-bottom: 1.5rem;">资料下载</h2>
            <div class="download-grid">
                <div class="download-card">
                    <div class="file-info">
                        <i class="fas fa-calculator"></i>
                        <span>高等数学A1</span>
                    </div>
                    <a href="./static/res/advanced_mathA1.zip" class="btn-download">下载</a>
                </div>
                <div class="download-card">
                    <div class="file-info">
                        <i class="fas fa-square-root-variable"></i>
                        <span>高等数学A2</span>
                    </div>
                    <a href="./static/res/advanced_mathA2.zip" class="btn-download">下载</a>
                </div>
                <div class="download-card">
                    <div class="file-info">
                        <i class="fas fa-infinity"></i>
                        <span>高等数学B2</span>
                    </div>
                    <a href="./static/res/advanced_mathB2.zip" class="btn-download">下载</a>
                </div>
                <div class="download-card">
                    <div class="file-info">
                        <i class="fas fa-th"></i>
                        <span>线性代数A</span>
                    </div>
                    <a href="./static/res/algebraA.zip" class="btn-download">下载</a>
                </div>
                <div class="download-card">
                    <div class="file-info">
                        <i class="fas fa-dice"></i>
                        <span>概率论与数理统计A</span>
                    </div>
                    <a href="./static/res/probability_theory_and_mathematical_statistics.zip" class="btn-download">下载</a>
                </div>
                <div class="download-card">
                    <div class="file-info">
                        <i class="fas fa-atom"></i>
                        <span>大学物理B2</span>
                    </div>
                    <a href="./static/res/university_physicsB2.zip" class="btn-download">下载</a>
                </div>
                <div class="download-card">
                    <div class="file-info">
                        <i class="fas fa-vial"></i>
                        <span>大学物理实验</span>
                    </div>
                    <a href="./static/res/university_physics_experiment.zip" class="btn-download">下载</a>
                </div>
                <div class="download-card">
                    <div class="file-info">
                        <i class="fas fa-code-branch"></i>
                        <span>数据结构参考源码</span>
                    </div>
                    <a href="./static/res/structure.zip" class="btn-download">下载</a>
                </div>
                <div class="download-card">
                    <div class="file-info">
                        <i class="fas fa-monument"></i>
                        <span>马克思主义基本原理</span>
                    </div>
                    <a href="./static/res/principles_of_marxism.zip" class="btn-download">下载</a>
                </div>
                <div class="download-card">
                    <div class="file-info">
                        <i class="fas fa-landmark"></i>
                        <span>中国近现代史纲要</span>
                    </div>
                    <a href="./static/res/outline_of_modern_and_contemporary_history.zip" class="btn-download">下载</a>
                </div>
                <div class="download-card">
                    <div class="file-info">
                        <i class="fas fa-star"></i>
                        <span>毛泽东思想和中国特色社会主义理论体系概论</span>
                    </div>
                    <a href="./static/res/introduction_to_Mao_Zedong_thought_and_the_theoretical_system_of_socialism_with_chinese_characteristics.zip" class="btn-download">下载</a>
                </div>
            </div>
        </section>

        <section id="section-questions" style="display: none;">
            <h2>思考题</h2>
            <div id="back-btn-container-question" style="display: none; margin-bottom: 1rem;">
                <a href="javascript:void(0)" onclick="goBack()" style="color: var(--accent-color); text-decoration: none; font-size: 0.9rem;">
                    <i class="fas fa-arrow-left"></i> 返回上一级
                </a>
            </div>
            <div class="subject-grid" id="question-display"></div>
        </section>

        <section id="section-about" style="display: none;">
            <h2>关于我</h2>
            <div class="markdown-body">
                <p>这里是 Larry 的个人空间...</p>
            </div>
        </section>
    </main>
    <!--负责展示笔记-->
    <script>
        const database = {
            subjects: [
                { id: 'advanced_programming', title: '高级语言程序设计A', icon: 'fas fa-hashtag', desc: '<p>C++: 从入门到入土。</p><p>如果你的大一很开心，说明C艹学少了。</p>', 
                  chapters: [
                      { id: 'advanced_programming-1', 
                        title: '4、类与对象', 
                        desc: '', 
                        content: '# 第四章-类与对象\n## 面向对象程序设计的基本特点\n### 抽象\n数据抽象：描述某类对象的属性或状态。\n```C++\nstring name, birth_date;\n```\n行为抽象： 描述某类对象的共同行为和功能特征。\n```C++\nmap<int, string> nameList; // map 是一种实现映射的 stl 数据结构，底层是红黑树，非常强大\nmap<string, string> birthDatelist;\nstring getname(int num) {\n    return nameList[num];\n}\nstring getbirth_date(string name) {\n    return birthDatelist[name];\n}\n```\n\n### 封装\n\n将抽象得到的数据或行为相结合，形成一个有机的整体。\n\n```C++\nclass point {\nprivate:\n    int x, y;\npublic:\n    point(int x, int y): x(x),y(y) {} // 构造函数\n    point(const point& p): x(p.x), y(p.y) {} // 委托构造函数\n    ~point() {} // 析构函数\n};\n```\n\n### 继承\n\nC++语言提供了类的继承机制，允许在保持原有类特性的基础上，进行更具体、更详细的说明。\n\n```C++\nclass point {\nprivate:\n    int x, y;\npublic:\n    point(int x, int y): x(x), y(y) {}\n    point(const point& p): x(p.x), y(p.y) {}\n    ~point() {}\n    int getx() {return x;}\n    int gety() {return y;}\n    int definex(int pos) {x = pos;}\n};\nclass line: public point {\nprivate:\n    int x1, y1, x2, y2;\npublic:\n    // 如果不定义构造函数，c++会内置初始构造函数（包括析构函数）\n    // 但point类中定义了构造函数，这里不会内置默认构造函数\n    // 可见line类继承了point类的部分特性\n    line(int a, int b, int c, int d)：point(a, b), x1(a), y1(b), x2(c), y2(d) {}\n}\nint main() {\n    line x(1, 1, 4, 5);\n    cout<<x.getx()<<endl; // 可以调用 point 类中 public 的函数, 这个会在后面详细介绍\n    x.define(114514);\n    cout<<x.getx(); // 输出114514\n    return 0;\n}\n```\n\n### 多态\n一段程序能够处理多种类型对象的能力。可以通过强制多态、重载多态、类型参数化多态、包含多态 4 种形式来实现。\n\n## 类和对象\n\n### 类的定义\n\n```C++\nclass Clock {\npublic:\n    // 公有成员\n    // 外部只能访问类的公有成员\nprivate:\n    // 私有成员\n    // 私有成员只能被本类的成员函数访问\n    // 不能被类外部访问\nprotected:\n    // 保护成员\n    // 与私有成员的区别在于：相比私有成员还可以被派生类访问\n};\n```\n\n习惯： 一般将数据成员设为私有成员，函数成员设为公有成员，这样内部数据结构就不会对该类以外的其余部分造成影响，程序模块之间的相互作用就被降低到最小。\n\n此外，通常按 `public`, `private`, `protected` 依次定义，以便于阅读。\n\n### 对象\n\n声明对象\n\n```C++\nClock myClock; // 具体可能根据需求进行初始化\n```\n\n访问数据成员和函数成员\n\n```C++\nclass Clock {\npublic:\n    int hour;\n    void set_minute(int x) {\n        minute = x;\n    }\nprivate:\n    int minute;\n};\nClock myClock;\nmyClock.hour = 114514; // 直接调用公有数据成员\nmyClock.set_minute(114514); // 通过调用公有函数成员调用私有数据成员\n// 此外还可以通过友元函数，友元类访问私有数据成员，但是会破坏了类的封装性。\n// 如果滥用友元类，可能导致代码难以维护，增加耦合度。\n// 还有指针和引用的方法，这个以后再说\n```\n\n### 类的成员函数\n\n通常成员函数在类内部声明，在类外部实现，以下为例子：\n\n```C++\nclass Clock {\npublic:\n    void showtime(); // 类内声明\n    void settime(int x1 = 114514) { // 可以提供默认形参值，为方便\n        hour = x1;\n    }\nprivate: \n    int hour, minute, second;\n};\nvoid Clock::showtime() { // 类外实现\n    printf("%d %d %d", hour, minute, second);\n}\nClock x;\nx.settime(); // 这样不输入值，settime函数也能正常执行\n```\n\n## 构造函数和析构函数\n\n### 构造函数\n\n在类对象被创建时利用特定的值构造对象，将对象初始化，\n\n在没有显式定义构造函数时，系统会生成隐含的默认构造函数，确保参数的初始化（通常为垃圾值）\n\n### 默认构造函数\n\n通常需要定义默认构造函数，但是这不是必须的：\n\n如果创建了一个类的对象数组或放在某些容器中（如 `vector`），则需要调用默认构造函数。\n\n许多标准库模板类（如 `map` 和 `vector`）要求元素类型有默认构造函数，以便在扩展容器或初始化时使用。\n\n如果类 B 继承了类 A，并且 B 的构造函数没有显式调用 A 的其他构造函数，则编译器会尝试调用 A 的默认构造函数来初始化基类部分。\n\n其它情况不一定要写默认构造函数。**但是，我们应当养成习惯写默认构造函数和其它构造函数的习惯**。\n\n```C++\nclass point {\npublic:\n    point() {} // <-定义默认构造函数\nprivate:\n    // ...\n};\n```\n\n### 委托构造函数\n\n```C++\nclass point {\npublic:\n    point(int a, int b): x(a), y(b) {}\n    point():point(2, 3) {} // <-委托构造函数，委托其它构造函数完成初始化，通常在派生类中使用\nprivate:\n    // ...\n};\n```\n\n### 复制构造函数\n\n顾名思义，复制构造函数作用是依赖先前的类完成构造，\n\n通常在以下情况下被调用：\n\n1.**当用类的一个对象初始化该类的另一个对象时**。\n\n2.**调用形参是类的对象的函数的函数时**。\n\n3.**函数返回的是一个类的对象时。**\n\n```C++\nclass point {\npublic:\n    point(int a, int b): x(a), y(b) {}\n    point(point &p) { // 自定义的复制构造函数\n        x = p.x, y = p.y;\n    }\n};\n```\n\n### 析构函数\n\n用来完成对象被删除前的一些清理工作。\n\n通常在对象的生存期即将结束的时刻被自动调用。\n\n函数体本身不接受任何参数。\n\n```C++\n~point() {}\n```\n\n### 移动构造函数\n\n基于右值引用的设定，类似于复制构造函数。但是不同于复制构造函数的是，它主要利用 move 函数将变量转化为右值使用，直到被引用的变量被重新赋值或销毁为止，**不再通过除 rr_n 右值引用以外的方式引用，避免了冗余复制对象的代价**。\n\n```C++\nclass point {\npublic:\n    string s;\n    point(point&& str) noexcept:s(std::move(str.s)) {} // 其中 noexcept 是编译器不抛出异常的命令\n};\n```\n\n参考下列例子：\n\n```c++\nclass point {\npublic:\n    string s;\n    point() = delete;\n    point(string t):s(t) {}\n    point(point&& p):s(move(p.s)) {\n        puts("wtf");\n    }\n};\nint main() {\n    point x("114514"),  y("1919810");\n    point z = move(y);\n    cout << z.s << " " << y.s << " " << x.s;\n    return 0;\n}\n```\n\n输出：\n\n```\nwtf\n114514 1919810\n```\n\n## default 和 delete 函数\n\n### default\n\ndefault 函数可以使编译器自动生成默认或复制构造函数。\n\n可以起到简化代码的作用。\n\n```C++\n// ...\npoint() = default;\npoint(point &&p) = default;\n// ...\n```\n\n### delete\n\n当不希望定义的类存在复制的时候，可以用 delete 函数将复制构造函数删除。\n\n不同于 default，delete 可以把除了析构函数的所有构造函数删除。\n\n```C++\n// ...\npoint() = default;\npoint(point &&p) = delete;\n// ...\n```\n\n## 类的组合\n\n**当一个类的定义包含另一个类的时候，采取类似于栈的构造和析构顺序**\n\n**当类之间采取循环依赖的时候，需要前向引用声明，类似于函数**\n\n## 结构体，联合体和枚举类型\n\n### 结构体(struct)\n\n**结构体和类的唯一区别在于，结构体和类具有不同的默认访问控制属性：在类中，对于未指定访问控制属性的成员，其访问控制属性为私有类型(private)；在结构体中，对于未指定任何访问控制属性的成员，其访问控制属性为共有类型(public)**\n\n```C++\nstruct name {\n    public_member\nprotected\n    protected_member\nprivate\n    private_member\n};\n```\n\n引入结构体的意义是保持和 C 程序的兼容性。\n\n### 联合体(union)\n\n联合体是一种特殊形态的类，由 C 语言继承而来。\n\n联合体的全部数据成员 **共享同一组内存单元**。\n\n```C++\nunion name {\n    public_member\nprotected\n    protected_member\nprivate\n    private_member\n};\n```\n\n因为联合体共用相同内存单元的特性：\n\n**联合体的所有对象成员，不能有自定义的构造函数、析构函数和重载运算符。**\n\n**联合体不能继承，也不支持包含多态**。\n\n所以通常只用联合体存储一些公有的数据，而不为它定义函数成员。\n\n**无名联合体：**\n\n没有标记名，只是声明一个成员项的集合。\n\n```C++\nunion {\n    public_member\nprotected\n    protected_member\nprivate\n    private_member\n};\n```\n\n### 枚举类型(enum)\n\nenum 类型的作用主要是为保证选用数据的合法性。枚举类型可以将一组整型常量组织在一起。\n\n例如：\n\n```C++\nenum Weekday{SUN, MON, TUE, WED, THU, FRI, SAT};\nenum class week1{a, b, c};\nenum struct week2{a, b, c};\n// 或者\nenum{a, b, c}week1, week2;\n```\n\nenum 也可以进行前向声明，但是必须指定其成员类型，例如：\n\n```C++\nenum unscopedEnum：long long; // 不限定作用域的，必须指定成员类型\nenum scopedEnum; // 限定作用域的，可使用默认成员类型\n```' 
                      },
                      { id: 'advanced_programming-2', 
                        title: '5、数据的共享与保护', 
                        desc: '', 
                        content: '# 第五章-数据的共享与保护\n\n## 1、标识符与作用域\n\n### 作用域\n\n#### 函数原型作用域\n\n在函数原型声明时形式参数的作用范围就是函数原型作用域。\n\n#### 局部作用域\n\n直观来说就是”大括号“里作用域。\n\n#### 类作用域\n\n类`X`的成员`m`具有类作用域，对`m`的访问方式包括：\n\n1. 如果在类X中没有声明同名的局部作用域标识符，那么可以直接访问成员`m`\n2. 通过`X.m`或`X::m`访问\n3. 通过指针，如`ptr->m`\n\n#### 文件作用域\n\n不在前述各个作用域中出现的声明，具有文件作用域（可以理解为全局变量/函数）\n\n#### 命名空间作用域\n\n命名空间声明方式：\n\n```C++\nnamespace namespace_name {\n    // 狠狠声明\n}\n```\n\n使用某个命名空间的函数、变量，需要使用**命名空间::实体名称**或`using namespace namespace_name`方式。\n\n#### 限定作用域的enum枚举类\n\n如果以`enum class{...}`方式定义枚举类型，其在枚举类型的作用域外是不可访问的\n\n### 可见性\n\n- 标识符要声明在前，引用在后。\n- 在同一作用域中，不能声明同名的标识符。\n- 在没有互相包含关系的不同的作用域中声明的同名标识符，互不影响。\n- 如果在两个或多个具有包含关系的作用域中声明了同名标识符，则外层标识符在内层不可见。\n\n## 2、生存期\n\n### 静态生存期\n\n如果对象的生存期与程序的运行期相同，则认为对象具有静态生存期。\n\n在文件作用域中声明的对象都具有静态生存期。\n\n函数内部的对象需要具有静态生存期，需要使用关键字`static`。\n\n### 动态生存期\n\n动态（局部）生存期对象诞生于生命点，结束于声明所在的块执行完毕之时。\n\n## 3、类的静态成员\n\n### 静态数据成员\n\n类的静态数据成员具有**静态生存期**，不属于任何一个对象，可以通过**类名::标识符**访问，当用常量表达式类型修饰（`constexpr`或`const`）的静态常量在类内初始化，此时仍可以在类外定义该静态成员，但不能做再次初始化操作。\n\n```C++\nclass Point {\npublic:\n    Point(int x=0, int y=0): x(x), y(y) {\n        ++count;\n    }\n    ~Point() {\n        --count;\n    }\nprivate:\n    int x, y;\n    static int count;\n    constexpr static int origin = 0; // 常量静态成员类内初始化\n};\nint Point::count = 0; // 定义和初始化使用类名限定\nconstexpr int Point::origin; // 类外定义常量静态成员，但不可二次初始化\n```\n\n### 静态函数成员\n\n输出静态成员`count`需要通过`Point`类的静态函数成员来调用`showCount`，这个静态函数的访问不能通过对象。\n\n通常用如下方式访问静态函数成员：\n\n```C++\nPoint::showCount();\n```\n\n静态成员函数可以**直接访问该类的静态数据和函数成员**，而访问非静态成员，**必须通过对象名**。\n\n```C++\nclass A {\npublic:\n    static void f(A a);\nprivate:\n    int x;\n};\nvoid A::f(A a) {\n    cout<<a.x;\n}\n```\n\n## 4、类的友元\n\n友元关系提供了不同类或对象的成员函数之间，类的成员函数与一般函数之间进行数据共享的机制。\n\n### 友元函数\n\n友元函数是在类中用关键字`friend`修饰的非成员函数。在该函数体中可以通过对象名访问类的私有和保护成员。\n\n```C++\nclass Point {\npublic:\n    Point(int x = 0, int y = 0): x(x), y(y) {}\n    friend float dist(Point &p1, Point &p2);\nprivate:\n    int x, y;\n};\nfloat dist(Point &p1, Point &p2) { // 类外函数\n    double x = p1.x - p2.x;\n    double y = p1.y - p2.y;\n    return sqrt(x * x + y * y);\n}\n```\n\n### 友元类\n\n若A类为B类的友元类，则A类的所有成员函数都是B类的友元函数，都可以访问B类的私有和保护成员。\n\n```C++\nclass B {\n    friend class A;\n    // ...\n};\n```\n\n## 5、共享数据的保护\n\n### 常对象\n\n常对象必须进行初始化，而且不能被更新，常对象声明语法：\n\n```C++\nconst int x;\n```\n\n常对象**既不能被对象名访问赋值**，**也不能在类的成员函数被当作数据成员改变**。\n\n常整型对象可以用于指定数组内存。\n\n### 常成员函数\n\n使用`const`关键字修饰的函数，声明格式如下：\n\n```C++\nint f(...) const;\n```\n\n**如果将一个对象声明为常对象，则通过常对象只能调用它的常成员函数**。\n\n**常成员函数不能更新数据成员，也不能调用未经`const`修饰的成员函数**。\n\n**`const`关键字可以用于对重载函数区分**。\n\n### 常数据成员\n\n类中的常数据成员不能被函数赋值，仅能通过构造函数的初始化列表进行初始化。\n\n### 常引用\n\n常饮用引用的对象不能被更新，包括普通对象和常对象，声明格式如下：\n\n```C++\nconst int &x;\n```\n\n### mutable关键字\n\n**由`mutable`修饰的成员对象在任何时候都不会被视为常对象**。\n\n这样常成员函数就可以更新该数据成员。\n\n## 6、多文件结构和编译预处理命令\n\n### 外部变量与外部函数\n\n当一个变量既可以被所在文件使用，也可以被其它文件使用，则这个变量被称为**外部变量**。\n\n文件作用域中的变量通常都是外部变量，如需使用，需要用`extern`关键字声明。\n\n所有类之外声明的函数都具有文件作用域。\n\n若无特殊说明，只要在调用前进行引用性声明即可。\n\n当然，也可以提前用`extern`关键字声明。\n\n### 将变量和函数限制在编译单元内\n\n出于**安全**和**避免文字冲突**的目的，可以采用`static`关键字使被修饰的对象不能被其它编译单元引用。\n\n当然，也可以使用匿名空间：\n\n```C++\nnamespace {\n    int n;\n    void f() {\n        /* ... */\n    }\n}\n```\n\n### 标准C++库\n\nC++中加入了大量的预定义模板和类。\n\n标准C++类与组件在逻辑上分为如下6种类型：\n\n- **输入输出类**\n- **容器类与`ADT`（抽象数据类型）**\n- **存储管理类**\n- **算法**\n- **错误处理**\n- **运行环境支持**\n\n当包含了必要的头文件，就可以使用预定义的内容：\n\n```C++\nusing namespace std;\n```\n\n通常使用这条将指定命名空间的名称引入当前作用域。\n\n否则要使用`std::`标识。\n\n### 编译预处理\n\n#### #include\n\n```C++\n#include <cstdio>\n#include "function.h"\n```\n\n第一种按标准方式搜索，文件位于系统目录`include`下。\n\n第二种现在当前目录搜索，若没有，再按标准方式搜索。\n\n可以嵌套使用。\n\n#### #define和#undef\n\n`#define`可以定义符号常量，带参数宏，也可以如下定义空符号：\n\n```C++\n#define MYHEAD_H\n```\n\n用以表示该头文件已经定义过。\n\n```C++\n#undef MYHEAD_H\n```\n\n用以删除由`#define`定义的宏。\n\n#### 条件编译指令\n\n可以限定程序中某些内容要在满足一定条件的情况下才参与编译。\n\n常见有如下形式:\n\n**1)**\n\n```C++\n#if /* 常量表达式 */\n    /* ... */\n#endif\n```\n\n**2)**\n\n```C++\n#if /* 常量表达式 */\n    /* ... */\n#else\n    /* ... */\n#endif\n```\n\n**3)**\n\n```C++\n#if /* 常量表达式 */\n    /* ... */\n#elif /* 常量表达式 */\n    /* ... */\n    .\n    .\n    .\n#elif /* 常量表达式 */\n    /* ... */\n#else\n    /* ... */\n#endif\n```\n\n**4)**\n\n```C++\n#ifdef /* 常量表达式 */\n    /* ... */\n#endif\n```\n\n**5)**\n\n```C++\n#ifndef /* 标识符 */\n    /* ... */\n#else\n    /* ... */\n#endif\n```\n\n#### defined操作符\n\n`defined`是一个预处理操作符，不是指令，使用形式为：\n\ndefined（标识符）\n\n若该标识符已由`#define`定义过，且未由`#undef`删除，则表达式为非0，否则为0\n\n例如：\n\n```C++\n#ifndef MYHEAD_H\n/* 与 */\n#if !defined(MYHEAD_H)\n```\n\n是等价的\n\n**这种写法通常写在头文件开头，用以防止重复包含头文件**。' 
                      },
                      { id: 'advanced_programming-3', 
                        title: '6、数组、指针与字符串', 
                        desc: '', 
                        content: '# 第六章-数组、指针与字符串\n\n## 1、数组\n\n### 声明与使用\n\n略\n\n### 存储与初始化\n\n**数组元素在内存中是顺序、连续存储的**。\n\n初始化方面值得注意的是：\n\n```C++\nint a[2][3] = {1, 1, 4, 5, 1, 4};\n/* 与 */\nint a[][3] = {1, 1, 4, 5, 1, 4};\n/* 与 */\nint a[2][3] = {(1, 1, 4), (5, 1, 4)};\n```\n\n是完全等效的。\n\n### 作为函数参数\n\n**使用数组名传递数据时，传递的是地址**，因此形参数组和实参数组的首地址重合，进而对应元素使用相同的数据存储地址，因此实参数组的元素个数不应该少于形参数组的元素个数。\n\n**所以被调函数中对形参数组元素值改变，主调函数中实参数组的相应元素值也会改变**。\n\n传参格式如下：\n\n```C++\nvoid rowSum(int a[][4], int nRow) {\n    /* ... */\n}\nint main() {\n    int table[3][4] = {/* ... */};\n    rowSum(table, 3);\n    return 0;\n}\n```\n\n### 对象数组\n\n声明一个一维对象数组的形式例为：\n\n```C++\nclass location {\n    /* ... */\n};\nint main() {\n    location a[2] = {location(1, 2)};\n    return 0;\n}\n```\n\n在这个例子中，会先调用带形参的构造函数初始化`a[0]`，再调用默认构造函数初始化`a[1]`。\n\n## 2、指针\n\nC++程序可以通过变量名和地址利用内存单元读取数据。\n\n利用地址读取数据的优点是：\n\n- **有时候变量名不够方便，或者无变量名可用，如此可以提高方便性**。\n- **减小系统开销，提高效率**。\n- **动态分配的内存单元没有名称，只能通过地址访问**。\n\n指针就是专门用来存放内存单元地址的变量类型。\n\n### 指针变量的声明\n\n数据类型`*`标识符：\n\n如：\n\n```C++\nint *ptr;\n```\n\n### 与地址相关的运算\n\n`*`是指针运算符，也称解析，表示获取指针所指向的变量的值。\n\n`&`是取地址运算符，用来得到一个对象的地址。\n\n### 指针的赋值\n\n通过将对象地址赋给指针变量完成赋值。\n\n值得注意的是：\n\n1. **数组名称实际上就是一个不能被赋值的指针，即指针常量**。\n\n2. **可以声明指向常量的指针**。\n\n3. **可以声明指针类型的常量，这时指针本身的值不能被改变**。\n   例如：\n\n   ```c++\n   int* const p2 = &a;\n   p2 = &b; // 不合法\n   ```\n\n4. **`void`类型指针可以存储任何类型对象地址，经过类型显式转换，`void`类型指针可以访问任何类型数据**。\n\n```C++\nvoid* p;\nint i = 5;\np = &i;\nint* pint = static_cast<int *>(p);\n```\n\n### 指针运算\n\n**指针与整型的相加减即指针指向地址向前或向后移若干位**。\n\n**其中`0`专用于表示空指针，也就是一个不指向任何有效地址的指针**。\n\n在这里，`0`也可以由`NULL`或`nullptr`代替。\n\n### 用指针处理数组元素\n\n```C++\nint a[10] = {1, 1, 4,5 , 1, 4};\nint* beg = begin(a); //返回数组a首元素的指针\nint* last = end(a); //返回数组a尾元素下一位置的指针\n```\n\n### 指针数组\n\n指针数组必须先赋值，后引用。\n\n其中对于二维数组的使用如下：\n\n```C++\nint a[2][3] = {(1, 1, 4), (5, 1, 4), (1, 9, 1)};\nfor(int i = 0; i < 3; ++i) {\n    for(int j = 0; j < 3; ++j)cout<<*(*(a + i)+j)<<" ";\n    cout<<endl;\n}\n```\n\n这里`*(a + i)`返回的是`a[i]`的首地址。\n\n### 指针作为函数参数\n\n形式上如下例：\n\n```C++\nvoid f(int* x, float* y) {\n    *x = 114514;\n    *y = 1919810;\n}\nint main() {\n    int x, y;\n    f(&x, &y);\n    return 0;\n}\n```\n\n### 指针型函数\n\n当一个函数的返回值是指针类型，这个函数就是指针型函数。\n\n稍为复杂的就是**函数返回数组指针**：\n\n```C++\ntypedef int arr[10]; // 或 using arr = int[10];\narr* foo(int i); // foo 返回一个指向含有 10 个整数的数组的指针\n```\n\n或者\n\n```C++\nint (*foo(int i))[10];\n// 函数 foo 返回了一个数组指针但没有使用类型别名\n```\n\n或者\n\n```C++\nauto foo(int i)->int(*)[10];\n// 函数 foo 返回了一个指向 10 个 int 类型的数组的指针\n```\n\n如果知道函数返回的指针将指向哪个数组，那也可以用这种方法：\n\n```C++\nint a[]={0, 1, 2, 3, 4};\nint b[]={5, 6, 7, 8, 9};\ndecltype(a) *func(int i) {\n    return (i % 2) ? &a : &b;\n}\n// decltype 表示指针所指对象与 a 类型一致\n// 函数 func 返回了一个指向 5 个 int 类型的数组指针\n```\n\n### 指向函数的指针\n\n函数指针就是专门用来存放函数代码首地址的变量。可以像使用函数名一样使用指向函数的指针来调用函数：\n\n```C++\nvoid f(int x) {\n    puts("114514");\n}\nvoid (*funcptr)(float); // 一个有 float 形参，返回类型为 void 的函数的指针\ntypedef int (*dif)(double);\n// 这声明了 dif 为有一个 double 形参，返回类型为 int 的函数的指针类型\nfuncptr = f;\nfuncptr(114514); // 调用 f\n```\n\n### 对象指针\n\n#### 对象指针的一般语法示例\n\n```C++\nPoint *ptr;\nPoint p1;\nptr = &p1;\nptr->show();\n```\n\n对象指针在使用之前，一定要进行初始化。\n\n#### this指针\n\n`this`指针是一个隐含于每一个类懂得非静态成员函数中的特殊指针，用于指向正在被成员函数操作的对象。\n\n例如:\n\n```C++\nreturn x;\n/* 其实是 */\nreturn this->x;\n```\n\n成员函数对对象的数据成员操作时，就隐含使用了`this`指针。\n\n#### 指向类的非静态成员的指针\n\n```C++\nint main(){\n    Point a(4,5);\n    Point *p1 = &a;\n    int Point::*dataPtr;\n    // 指向数据成员的指针\n    int (Point::*funcPtr)(/* 参数表 */)const = &Point::getx;\n    // 指向函数成员的指针\n    cout<<(a.*funcPtr)()<<endl;\n    cout<<(p1->*funcPtr)()<<endl;\n    // 两种调用方式\n    return 0;\n}\n```\n\n#### 指向类的静态成员的指针\n\n因为对类的静态成员的访问不依赖于对象，可以用普通指针指向和访问静态成员。\n\n## 3、动态内存分配\n\n### new和delete\n\n`new`用于申请分配用于存放指定类型数据的内存空间，并根据初始化参数列表进行初始化。\n\n若内存申请成功，`new`运算便返回一个指向新分配内存首地址的类型的指针,可以通过这个指针对堆对象进行访问。\n\n若内存申请失败，会抛出异常。\n\n使用例：\n\n```C++\nint *point;\npoint=new int(2); // 动态分配了用于存放 int 类型数据的内存空间\n//并把初值 2 存入该空间，再将首地址赋给 point\nint *point = new int; // 不赋初值\nint *point = new int(); // 以 0 作为初值\n```\n\n`delete`用来删除由`new`建立的对象，释放指针所指向的内存空间：\n\n```c++\ndelete point;\n```\n\n值得注意的是：\n\n**如果被删除的是对象，则调用该对象的析构函数**。\n\n**对同一内存空间多次使用`delete`将会导致运行错误**。\n\n### assert\n\n`assert`是标准C++的<cassert>头文件中定义的一个宏，用来判断表达式是否为`true`，如果为`false`，则程序终止，报告错误。其只在调试`debug`模式下生效。\n\n## 4、深层复制与浅层复制\n\n浅层复制只复制对象的基本成员（如值或指针地址），而不复制指针所指向的实际数据。这意味着多个对象共享相同的动态内存资源。\n\n- **对象间共享动态内存资源**。\n- **若一个对象释放了动态内存，其他对象会因为指针悬挂（dangling pointer）导致程序崩溃**。\n- **默认的拷贝构造函数和赋值运算符都是浅层复制**。\n\n深层复制会为每个对象单独分配一块新的动态内存，并复制指针所指向的数据内容。这样，两个对象互不干扰，能安全地管理各自的资源。\n\n- **为每个对象独立分配资源**。\n- **避免了共享资源导致的问题**。\n- **需要手动实现拷贝构造函数和赋值运算符**。\n\n## 5、字符串\n\n熟能生巧~\n\n## 6、指针和引用\n\n| **特性**             | **指针**                                   | **引用**                       |\n| -------------------- | ------------------------------------------ | ------------------------------ |\n| **定义**             | 保存变量地址的变量，可以指向其他变量或内存 | 变量的别名，直接绑定到某个变量 |\n| **是否必须初始化**   | 可以声明后初始化，未初始化指针为`nullptr`  | 必须在定义时初始化             |\n| **是否可以更改指向** | 可以更改指向的地址                         | 一旦绑定到变量，不能更改绑定   |\n| **是否可以为空**     | 可以为空（`nullptr`或未初始化）            | 不存在空引用                   |\n\n## 7、reinterpret_cast和const_cast\n\n`reinterpret_cast`是一种底层，具有很大危险性和不确定性的数据类型转换。\n\n```C++\nint i;\nfloat *p = reinterpret_cast<float *>(&i);\n```\n\n通过`p`访问整型变量`i`，所执行的操作只能是针对浮点型的。\n\n会出大问题，少用。\n\n`const_cast`可以用来将数据类型中的`const`属性去除，可以将常指针转换为普通指针，将常引用转换为普通引用。' 
                      },
                      { id: 'advanced_programming-4', 
                        title: '7、类的继承', 
                        desc: '', 
                        content: '# 第七章-类的继承\n\n**类的继承，是新的类从已有类那里得到已有的特性**。\n\n**从已有类产生新类的过程就是类的派生**。\n\n**原有的类成为基类或父类**。\n\n**产生的类称为派生类或子类**。\n\n## 1、基类与派生类\n\n### 派生类的定义\n\n```C++\nclass derived: public base1, private base2 {\npublic:\n    derived();\n    ~derived();\n};\n```\n\n一个派生类，可以同时有多个基类，这种情况称为**多继承**。\n\n一个派生类只有一个直接基类的情况，称为**单继承**。\n\n直接参与派生出某类的基类称为**直接基类**。\n\n基类的基类甚至更高层的基类称为**间接基类**。\n\n**继承方式**规定了如何访问从基类继承的成员，如`public`、`protected`、`private`。\n\n**派生类成员**是指除了从基类继承来的所有成员外，新增加的数据和函数成员。\n\n### 派生类生成过程\n\n- **吸收基类成员**\n\n派生类包含全部基类中除构造和析构函数之外的所有成员。\n\n- **改造基类成员**\n\n一方面，依靠派生类定义时的继承方式来控制。\n\n另一方面，进行对基类数据或函数成员的覆盖或隐藏。\n\n如果派生类声明了一个和某基类成员同名的新成员，派生的新成员就隐藏了外层同名成员，这叫做**同名隐藏**。\n\n- **添加新的成员**\n\n派生类要实现一些特别的初始化和扫尾清理工作，就需要在派生类中加入新的构造和析构函数。\n\n## 2、访问控制\n\n### 公有继承\n\n基类的公有和保护成员的访问属性在派生类中不变，而基类的私有成员不可直接访问。\n\n### 私有继承\n\n基类的公有和保护成员的都以私有成员身份出现在派生类中，而基类的私有成员不可直接访问。\n\n### 保护继承\n\n基类的公有和保护成员都以保护成员的身份出现在派生类中，而基类的私有成员不可直接访问。\n\n## 3、类型兼容规则\n\n**类型兼容规则是指在需要基类对象的任何地方，都可以使用公有派生类的对象来替代**。\n\n这个替代包括:\n\n```C++\nclass B {/* ... */};\nclass D: public B {/* ... */};\nB b, *bp;\nD d;\n```\n\n- **派生类的对象可以隐含转换为基类对象**。\n\n```C++\nb = d;\n```\n\n- **派生类的对象可以初始化基类的引用**。\n\n```C++\nB &rb = d;\n```\n\n- **派生类的指针可以隐含转换为基类的指针**。\n\n```C++\nbp = &d;\n```\n\n在替代之后，派生类对象就可以作为基类的对象使用，但只能使用从基类继承的成员。\n\n## 4、派生类的构造和析构函数\n\n### 构造函数\n\n派生类在创建过程中，就会调用基类的构造函数，以确保派生类构造函数执行时，基类已经被初始化。\n\n如果需要调用基类的带有形参表的构造函数，派生类就必须声明构造函数。\n\n派生类构造函数执行的一般顺序如下：\n\n1. **调用基类构造函数，调用顺序按照它们被继承时声明的顺序（从左向右）**\n2. **对派生类新增的成员初始化，初始化顺序按照它们在类中声明的顺序**\n3. **执行派生类的构造函数体中的内容**\n\n```C++\nclass base1 {\npublic:\n    base1(int x) {cout<<"base1 constructed "<<x<<endl;}\n};\nclass base2 {\npublic:\n    base2(int x) {cout<<"base2 constructed "<<x<<endl;}\n};\nclass base3 {\npublic:\n    base3() {cout<<"base3 constructed "<<"#"<<endl;}\n};\nclass derived: public base2, public base1, public base3 {\npublic:\n    derived(int x, int y, int z, int w): base1(x), member2(y), member1(z), base2(w) {}\n    // 事实上，这个构造顺序无关紧要\nprivate:\n    base1 member1;\n    base2 member2;\n    base3 member3;\n};\nint main() {\n    derived obj(1, 2, 3, 4);\n    return 0;\n}\n```\n\n输出结果将会是：\n\n```C++\nbase2 constructed 4\nbase1 constructed 1\nbase3 constructed #\nbase1 constructed 3\nbase2 constructed 2\nbase3 constructed #\n```\n\n### 复制构造函数\n\n派生类的复制构造函数，一般需要为基类相应的复制构造函数传递参数，例：\n\n```C++\nderived::derived(const derived&v): base(v) {/* ... */}\n```\n\n### 析构函数\n\n可以认为，析构函数执行的次序与构造函数执行时严格相反。\n\n```C++\nclass base1 {\npublic:\n    base1(int x) {cout<<"base1 constructed "<<x<<endl;}\n    ~base1() {cout<<"base1 destructed"<<endl;}\n};\nclass base2 {\npublic:\n    base2(int x) {cout<<"base2 constructed "<<x<<endl;}\n    ~base2() {cout<<"base2 destructed"<<endl;}\n};\nclass base3 {\npublic:\n    base3() {cout<<"base3 constructed "<<"#"<<endl;}\n    ~base3() {cout<<"base3 destructed"<<endl;}\n};\nclass derived: public base2, public base1, public base3 {\npublic:\n    derived(int x, int y, int z, int w): base1(x), member2(y), member1(z), base2(w) {}\n    //事实上，这个构造顺序无关紧要\nprivate:\n    base1 member1;\n    base2 member2;\n    base3 member3;\n};\nint main() {\n    derived obj(1, 2, 3, 4);\n    return 0;\n}\n```\n\n输出结果将会是:\n\n```C++\nbase2 constructed 4\nbase1 constructed 1\nbase3 constructed #\nbase1 constructed 3\nbase2 constructed 2\nbase3 constructed #\nbase3 destructed\nbase2 destructed\nbase1 destructed\nbase3 destructed\nbase1 destructed\nbase2 destructed\n```\n\n### 删除构造函数\n\n如果基类中的默认构造函数、复制构造函数、移动构造函数是删除或者不可访问的，则派生类中对应的成员函数将是被删除的。\n\n因为编译器无法执行派生类对象中基类部分的构造或赋值操作。\n\n```C++\nclass base {\npublic:\n    base() = default;\n    base(string _info): info(move(_info)) {}\n    base(base &) = delete;\n    base(base &&) = delete;\nprivate:\n    string info;\n};\nclass derived: public base {\n};\nderived d; // 可以\nderived _d(d); // 不行\nderived __d(move(d)); // 不行\n```\n\n## 5、派生类成员的标识与访问\n\n### 作用域分辨符\n\n首先在不同的作用域声明的标识符，可见性原则是:如果存在两个或多个具有包含关系的作用域，若内层声明了同名标识符，则外层标识符在内层不可见，实现了标识符之间的**隐藏**。\n\n因此：\n\n**如果派生类中声明了与基类成员函数同名的新函数，即使函数的参数表不同，从基类继承的同名函数的所有重载形式也都会被隐藏**。\n\n另一方面：\n\n**如果派生类的多个基类拥有同名的成员，即使派生类没有同名成员，也不能访问基类成员**。\n\n但是可以使用作用域分辨符**`::`**，\n\n使用例：\n\n```C++\nclass base1 {\npublic:\n    int var;\n    void fun() {cout<<"m1"<<endl;}\n};\nclass base2 {\npublic:\n    int var;\n    void fun() {cout<<"m2"<<endl;}\n};\nclass derived: public base1, public base2 {\npublic:\n    int var;\n    void fun() {cout<<"d1"<<endl;}\n};\nint main() {\n    derived d;\n    derived *p = &d;\n    d.var = 1;\n    d.fun();\n    d.base1::var = 2;\n    d.base1::fun();\n    p->base2::var = 3;\n    p->base2::fun();\n    return 0;\n}\n```\n\n如果去掉`derived`中同名变量和函数的定义，会出现错误。\n\n可以使用`using`关键字加以澄清。\n\n例：\n\n```C++\nclass base1 {\npublic:\n    int var;\n    void fun() {cout<<"m1"<<endl;}\n};\nclass base2 {\npublic:\n    int var;\n    void fun() {cout<<"m2"<<endl;}\n};\nclass derived: public base1, public base2 {\npublic:\n    using base1::var;\n    using base1::fun;\n};\nint main() {\n    derived d;\n    derived *p = &d;\n    d.var = 1; // 经过澄清\n    d.fun(); // 可以访问\n    p->base2::var = 3;\n    p->base2::fun();\n    return 0;\n}\n```\n\n### 虚基类\n\n派生类从不同路径继承过来同名数据成员，这可能会导致冗余、冲突、甚至逻辑错误。\n\n通过虚基类，可以确保最终的派生类只会有一个基类的副本。\n\n```C++\nclass A {\npublic:\n    A() {\n        cout<<"A constructor"<<endl;\n    }\n    void show() {\n        cout<<"A class"<<endl;\n    }\n};\nclass B: virtual public A { // 声明虚基类 A\npublic:\n    B() {\n        cout<<"B constructor"<<endl;\n    }\n};\nclass C: virtual public A { // 声明虚基类 A\npublic:\n    C() {\n        cout<<"C constructor"<<endl;\n    }\n};\nclass D: public B, public C {\npublic:\n    D() {\n        cout<<"D constructor"<<endl;\n    }\n};\nint main() {\n    D d;\n    d.show(); // 调用 A 的成员函数\n    return 0;\n}\n```\n\n### 虚基类及其派生类构造函数\n\n建立一个对象时，如果这个对象中含有从虚基类继承来的成员，则虚基类的成员是由最远派生类的构造函数通过调用虚基类的构造函数进行初始化的。而且，只有最远派生类的构造函数会调用虚基类的构造函数。\n\n例如，如果上个代码中类B，C，D都调用A的构造函数，那么只有D会调用虚基类的构造函数。\n\n## 6、派生类对象的内存布局\n\n### 单继承\n\n派生类继承基类的时候，派生类新增的数据成员放在基类数据成员之后，一起组成派生类对象：\n\n<img src="./pictures/image-20241228150139342.png">  \n\n`pd`赋给`pbb`的过程中，指针值不需要改变。\n\n`pba`和`pbb`指针，虽然指向不同类型，但是任何一个`Base`数据成员到该对象首地址都具有相同的偏移量。\n\n所以二者可以采用相同的方式访问`Base`类中定义的数据成员。\n\n#### 多继承\n\n以下是`Derived`类依次继承`Base1`类，`Base2`类：\n\n<img src="./pictures/image-20241228151453512.png">\n\n#### 虚拟继承\n\n以下是等同于上文介绍虚基类的代码中继承关系：\n\n<img src="./pictures/image-20241228151544510.png">\n\n<img src="./pictures/image-20241228151628612.png">\n\n## 7、基类向派生类的转换及其安全性问题\n\n派生类指针要想转换为基类指针，则转换一定要显示地进行，如：\n\n```C++\nBase* pb = new Derived();\nDerived* pd = static_cast<Derived *>(pd);\n```\n\n同`void`指针与其它指针的关系一样，从一般指针转换到特殊指针是不安全的，只能显示地转换。\n\n引用亦然：\n\n```C++\nDerived d;\nBase &rb = d;\nDerived &rb = static_cast<Derived &>(rb);\n```\n\n值得注意的是：\n\n- **基类对象一般无法被显示转换为派生类对象**，因为这不涉及创建新的对象。\n- 执行基类向派生类的转换时，一定要确保被转换的指针和引用所指向或引用的对象符合转换的目的类型。\n- 在多重继承情况下，执行基类指针到派生类指针的显式转换时，通常需要将指针所存储的地址值进行调整后才能得到新指针的值。\n- 如果转换中间涉及void指针，只要最初和最后的类型不完全相同，转换的结果就可能是不正确的。' 
                      },
                      { id: 'advanced_programming-5', 
                        title: '8、类的多态', 
                        desc: '', 
                        content: '# 第八章-类的多态\n\n## 1、多态性概述\n\n### 多态的类型\n\n面向对象的多态性可分为**重载多态**、**强制多态**、**包含多态**、**参数多态**。\n\n前两者统称为专用多态，后两者统称为通用多态。\n\n- **函数重载属于重载多态**。\n- **强制类型转换属于强制多态**。\n- **虚函数实现的不同类中同名成员函数的多态行为是包含多态**。\n- **类模板涉及参数多态**。\n\n### 多态的实现\n\n**编译时多态**:在编译时确定具体调用的函数版本，通常通过**函数重载**和**运算符重载**和**静态绑定**实现。\n\n**运行时多态**:在程序运行时根据实际对象的类型动态选择函数的实现，通常通过**虚函数**和**动态绑定**实现。\n\n其中绑定是指计算机程序自身彼此关联的过程。\n\n## 2、运算符重载\n\n运算符重载是对已有的运算符赋予多重含义，使同一个运算符作用于不同类型的数据时导致不同的行为。\n\n### 运算符重载的规则\n\n1. 只能重载已经存在的运算符。\n2. 运算符的优先级和结合性都不会改变。\n3. 不能改变原运算符的操作对象个数，至少要有一个操作对象是自定义类型。\n4. `.` `.*` `::` `?:` `sizeof`不能重载。\n5. 既可以重载为非成员函数，也可以重载为成员函数。\n\n### 运算符重载为成员函数\n\n```C++\nclass Complex {\nprivate:\n    int real, imag;\npublic:\n    Complex(int r, int i): real(r), imag(i) {}\n    Complex operator +(const Complex& other) {\n        return Complex(real + other.real, imag + other.imag);\n    }\n    Complex& operator +=(const Complex& other) {\n        real += other.real;\n        imag += other.imag;\n        return *this;\n    }\n    Complex& operator++() {\n        ++real;\n        return *this;\n    }\n    Complex operator++(int) {\n        return ++(*this);\n    }\n    void display() {\n        cout<<real<<" + "<<imag<<"i"<<endl;\n    }\n};\n\nint main() {\n    Complex c1(1, 14), c2(5, 14);\n    Complex c3 = c1 + c2;\n    c3 += c1;\n    c3++;\n    ++c3;\n    c3.display();\n    return 0;\n}\n```\n\n### 运算符重载为非成员函数\n\n运算符重载作为非成员函数时，可以像普通函数一样定义，并且可以通过参数来访问运算符的左侧和右侧对象。\n\n不能重载`=`，`->`，`[]`，`()`\n\n非成员函数通常有两种情况:\n\n**友元函数**：将运算符重载函数声明为类的友元函数，使其可以访问类的私有成员。\n\n**全局函数**：在类外部定义的运算符重载函数。\n\n非成员函数（如果不是友元函数）无法直接访问类的私有成员，因此需要通过公共接口（如`getter`）来间接访问类成员。\n\n```C++\nclass Complex {\nprivate:\n    double real, imag;\npublic:\n    Complex(double r = 0, double i = 0): real(r), imag(i) {}\n    void display() const {\n        cout<<real<<" + "<<imag<<"i"<<endl;\n    }\n    friend Complex operator+(const Complex& c1, const Complex& c2);\n    friend ostream& operator<<(ostream& out, const Complex& c);\n    friend istream& operator>>(istream& in, Complex& c);\n};\nComplex operator+(const Complex& c1, const Complex& c2) {\n    return Complex(c1.real + c2.real, c1.imag + c2.imag);\n}\nostream& operator<<(ostream& out, const Complex& c) {\n    out<<c.real<<" + "<<c.imag<<"i";\n    return out;\n}\nistream& operator>>(istream& in, Complex& c) {\n    in >> c.real >> c.imag;\n    return in;\n}\nint main() {\n    Complex c1(11.0, 4.0);\n    Complex c2(5.0, 14.0);\n    Complex c3 = c1 + c2;\n    c3.display();\n    return 0;\n}\n```\n\n## 3、虚函数\n\n**虚函数声明只能出现在类定义中的函数原型声明中，而不能在成员函数实现的时候**。\n\n### 虚函数的基本概念\n\n- **虚函数**是基类中声明的函数，允许在派生类中进行重写。\n- 使用关键字`virtual`来声明虚函数。\n- 虚函数实现了**动态多态**，即程序在运行时决定调用哪个版本的函数。\n\n### 虚函数的工作原理\n\n- 当你使用基类的指针或引用来调用虚函数时，程序会根据实际指向的对象的类型来调用合适的函数，而不是在编译时决定。这个过程称为**动态绑定**或**运行时多态**。\n- 虚函数的调用通过虚函数表（`vtable`）实现。每个包含虚函数的类都有一个虚函数表，该表包含指向虚函数的指针。当你通过基类指针调用虚函数时，程序会查找该指针所指向对象的虚函数表，从而确定实际调用的函数。\n\n### 一般虚成员函数\n\n```C++\nclass Base {\npublic:\n    virtual void show() {\n        cout<<"Base class show function"<<endl;\n    }\n};\nclass Derived: public Base {\npublic:\n    void show() override {\n        cout<<"Derived class show function"<<endl;\n    }\n};\nint main() {\n    Base* basePtr;\n    Derived derivedObj;\n    basePtr = &derivedObj;\n    basePtr->show();\n    return 0;\n}\n```\n\n上述代码将会调用派生类中的`show`函数。\n\n其中`override`关键字用来说明派生类中的虚函数。\n\n还存在`final`关键字可以标记某成员函数不能被覆盖，用法和`override`一样。\n\n### 虚析构函数\n\n基类的析构函数应该是虚函数，以确保当派生类对象通过基类指针删除时，派生类的析构函数能够被正确调用。如果没有虚析构函数，派生类的析构函数可能不会被调用，从而导致资源泄漏。\n\n```C++\nclass Base {\npublic:\n    virtual ~Base() {\n        cout<<"Base Destructor"<<endl;\n    }\n};\nclass Derived:public Base {\npublic:\n    ~Derived() {\n        cout<<"Derived Destructor"<<endl;\n    }\n};\nint main() {\n    Base* basePtr = new Derived();\n    delete basePtr;\n    return 0;\n}\n```\n\n## 4、纯虚函数与抽象类\n\n### 纯虚函数\n\n纯虚函数是在基类中声明的虚函数，但不提供函数的具体实现。纯虚函数以`=0`结尾，它的目的是强制派生类实现该函数。这使得基类成为一个抽象类。\n\n声明为纯虚函数之后，基类中就可以不再给出函数的实现部分。\n\n### 抽象类\n\n抽象类是包含至少一个纯虚函数的类。抽象类不能被实例化。它的目的是为派生类提供一个共同的接口，而不需要具体实现。抽象类可以包含:\n\n纯虚函数：没有函数实现，强制派生类提供实现。\n\n普通函数：可以包含已实现的函数，供派生类使用或覆盖。\n\n数据成员：存储类的状态。\n\n**抽象类的特点：**\n\n1. **不能实例化**：抽象类不能直接创建对象，只能通过指向派生类的指针或引用来使用。派生类只有实现了基抽象类的所有纯虚函数才可以实例化。\n2. **提供接口**：抽象类通常用于定义派生类必须实现的接口。\n3. **可以包含已实现的函数**：虽然抽象类包含纯虚函数，但它也可以包含已实现的函数，供派生类继承或调用。\n\n```C++\nclass Animal {\npublic:\n    virtual void speak() = 0;\n    void sleep() {\n        cout<<"Animal is sleeping."<<endl;\n    }\n};\nclass Dog: public Animal {\npublic:\n    void speak() override {\n        cout<<"Woof!"<<endl;\n    }\n};\nclass Cat: public Animal {\npublic:\n    void speak() override {\n        cout<<"Meow!"<<endl;\n    }\n};\nint main() {\n    Animal* dog = new Dog();\n    Animal* cat = new Cat();\n    dog->speak();\n    dog->sleep();\n    cat->speak();\n    cat->sleep();\n    delete dog;\n    delete cat;\n    return 0;\n}\n```\n\n## 5、多态类型与非多态类型\n\n多态类型是指有虚函数的类类型，非多态类型是指所有的其他类型。\n\n**对非多态类的公有继承，应当慎重，而且一般没有太大必要**。\n\n## 6、运行时类型识别\n\n### 用dynamic_cast执行基类向派生类的转换\n\n`dynamic_cast`可以将基类的指针显式转换为派生类的指针，或将基类的引用转换为派生类的引用。\n\n会检查前后类型是否兼容，若不兼容：\n\n**指针类型：得到空指针**。\n\n**引用类型：抛出异常**。\n\n且转换前类型必须是指向多态类型的指针或引用。\n\n```c++\nBase* q = new Base;\nDerived* p = dynamic_cast<Derived*>(q);\n```\n\n### 用typeid获取运行时类型信息\n\n```C++\nconst type_info &p = typeid(114 + 514), &q = typeid(int)\n```\n\n通过`typeid`得到的是一个`type_info`类型的常引用。\n\n其中`type_info`是定义在`<typeinfo>`头文件中的类类型。\n\n### 虚函数动态绑定的实现原理\n\n#### 虚函数的工作机制\n\n当一个类声明了虚函数时，编译器会为该类创建一个虚表。虚表是一个函数指针数组，其中每个元素指向该类的虚函数的实现。对于派生类，它会继承基类的虚表，并且会替换虚表中的虚函数指针，以指向该派生类中重写的函数。\n\n**虚表（`vtable`）**：每个类（包含虚函数的类）会有一个虚表，虚表是一个函数指针数组，每个指针指向类中的虚函数的实现。\n\n**虚指针（`vptr`）**：每个对象（如果类中有虚函数）都会有一个指向虚表的指针，称为虚指针。每个对象在构造时会初始化该指针指向类的虚表。\n\n#### 虚表的实现过程\n\n**编译阶段**\n\n编译器会为每个包含虚函数的类生成一个虚表。这个表中存储了类中虚函数的地址。\n\n如果类中有虚函数，编译器会在该类的每个对象中添加一个虚指针（`vptr`），指向该类的虚表。\n\n**对象创建阶段**\n\n当创建一个对象时，编译器会初始化该对象的`vptr`，使它指向正确的虚表（根据对象的实际类型，可能是基类或派生类的虚表）。\n\n**运行时阶段**\n\n当通过基类指针或引用调用虚函数时，程序会通过该指针或引用中的`vptr`查找虚表。然后，虚表中的函数指针会指向相应的虚函数实现（基类或派生类的实现）。'
                      },
                      { id: 'advanced_programming-6', 
                        title: '9、模板与群体数据', 
                        desc: '', 
                        content: '# 第九章-模板与群体数据\n\n## 1、函数模板与类模板\n\n通过模板可以实现参数化多态性，即**将程序所处理的对象的类型参数化，使得一段程序可以用于处理多种不同类型的对象**。\n\n### 函数模板\n\n```C++\ntemplate <typename T>\nT abs(T x) {\n    return x < 0 ? -x : x;\n}\n// typename 也可以使用 class 标识符，接收类型可以是任意的\n```\n\n在调用`abs()`时，编译器会根据实参的类型推导出函数模板的类型参数，并根据函数模板生成一个函数并执行，这叫作**函数模板的实例化**。\n\n**注意：**\n\n- 只有生成的示例会生成目标代码。\n- 模板的函数体也应当放在头文件中。\n- 函数指针只能指向模板生成的实例。\n\n### 类模板\n\n**使用类模板可以为类定义一种模式，使得类中的某些数据成员、某些成员函数的参数、返回值或局部变量能取不同类型**。\n\n#### 类模板的定义\n\n```C++\ntemplate <typename T> // 或者使用 class 替代 typename\nclass ClassName {\nprivate:\n    T data;\npublic:\n    ClassName(T value): data(value){} // 构造函数\n    T getData() {return data;} // 成员函数，返回模板类型的数据\n};\n```\n\n1. `template <typename T>`是模板声明，其中`T`是占位符，表示在使用该模板时将指定的具体类型替代它。\n2. `ClassName`是类模板的名字，`T`是模板参数，可以在类中作为数据类型来使用。\n\n类模板在定义时并没有生成具体的类，而是在实例化时根据传入的类型创建具体的类。\n\n**实例化类模板**时，可以传入不同的类型：\n\n```C++\nClassName<int> obj1(114514);\nClassName<double> obj2(1919.810);\n```\n\n**类模板也可以支持多个类型参数**，比如`STL`模板里的`pair`。\n\n**默认模板参数**\n\n```C++\ntemplate <typename T = int>\nclass Box {\nprivate:\n    T value;\npublic:\n    Box(T val): value(val) {}\n    T getValue() {return value;}\n};\n```\n\n在这里，`T`默认被定义为`int`，如果在实例化时不指定类型参数，编译器会默认使用`int`类型。\n\n**模板类中友元声明类型参数**\n\n```C++\ntemplate <typename T>\nclass MyClass {\n    friend T; // 类型参数 T 是友元，可以访问私有成员\nprivate:\n    int data = 42;\npublic:\n    MyClass() = default;\n};\nclass FriendClass {\npublic:\n    void showPrivateData(const MyClass<FriendClass>& obj) {\n        cout<<"Accessing private data: "<<obj.data<<endl;\n    }\n};\nint main() {\n    MyClass<FriendClass> obj;\n    FriendClass friendObj;\n    friendObj.showPrivateData(obj); // 类型参数作为友元\n    return 0;\n}\n```\n\n使得`T`在被用来实例化模板类的基础上，拥有对`ClassName`的成员的访问权限。\n\n`typedef`和`using`为模板类定义别名：\n\n```C++\n// 为模板实例化定义别名\ntypedef ClassName<int> intClassName;\nusing intClassName = ClassName<int>;\n// 为模板非实例化定义别名\ntemplate <typename T>using AliasDemo = ClassName<T>;\ntemplate <typename T>using IntPair = pair<T, int>;\n```\n\n## 2、线性群体\n\n对可直接访问的线性群体，可以直接访问群体中的任何一个元素。\n\n对顺序访问的线性群体，只能按元素的排列顺序从头开始依次访问各个元素。\n\n后简单，略。\n\n## 3、为模板定义特殊的实现\n\n### 完全特化\n\n```C++\n// 通用模板\ntemplate <typename T>\nclass MyClass {\npublic:\n    void print() {\n        cout<<"Generic Template"<<endl;\n    }\n};\n// 完全特化：针对 int 类型的特化\ntemplate <>\nclass MyClass<int> {\npublic:\n    void print() {\n        cout<<"Specialized Template for int"<<endl;\n    }\n};\nint main() {\n    MyClass<float> obj1;\n    obj1.print(); // 输出:Generic Template\n    MyClass<int> obj2;\n    obj2.print(); // 输出:Specialized Template for int\n    return 0;\n}\n```\n\n### 偏特化\n\n```C++\n// 通用模板\ntemplate <typename T>\nclass MyClass {\npublic:\n    void print() {\n        cout<<"Generic Template"<<endl;\n    }\n};\n// 偏特化：当模板参数是指针类型时\ntemplate <typename T>\nclass MyClass<T*> {\npublic:\n    void print() {\n        cout<<"Specialized Template for Pointer"<<endl;\n    }\n};\nint main() {\n    MyClass<int> obj1;\n    obj1.print(); // 输出: Generic Template\n    MyClass<int*> obj2;\n    obj2.print(); // 输出: Specialized Template for Pointer\n    return 0;\n}\n```\n\n### 函数模板重载\n\n允许为不同参数类型定义多个函数模板，可以根据参数的不同类型来选择不同的重载版本。\n\n```C++\n// 函数模板重载\ntemplate <typename T>\nvoid print(T val) {\n    cout<<"Generic Template: "<<val<<endl;\n}\n//重载版本：针对 const char* 类型的特化\ntemplate <>\nvoid print<const char*>(const char* val) {\n    cout<<"Specialized Template for const char*: "<<val<<endl;\n}\nint main() {\n    print(10); // 输出: Generic Template: 10\n    print("Hello, World!"); // 输出: Specialized Template for const char*: Hello, World!\n    return 0;\n}\n```\n\n### 类模板的默认实参\n\n类模板可以为模板参数提供默认值，调用时可以不显式指定模板参数。\n\n```C++\ntemplate <typename T = int>\nclass MyClass {\npublic:\n    T value;\n    MyClass(T val): value(val) {}\n    void print() {\n        cout<<"Value: "<<value<<endl;\n    }\n};\nint main() {\n    MyClass<> obj1(42); // 使用默认模板参数 int\n    obj1.print(); // 输出: Value:42\n    MyClass<double> obj2(3.14); // 显式指定模板参数为 double\n    obj2.print(); // 输出: Value:3.14\n    return 0;\n}\n```\n\n### 函数模板的默认实参\n\n函数模板也可以为模板参数提供默认值。若调用时未指定模板参数，则会使用默认值。\n\n```C++\ntemplate <typename T = int>\nT add(T a, T b) {\n    return a + b;\n}\nint main() {\n    cout<<add(3, 4)<<endl; // 使用默认类型 int, 输出: 7\n    cout<<add<double>(3.14, 2.71)<<endl; // 显式指定模板类型 double, 输出: 5.85\n    return 0;\n}\n```\n\n## 4、模板元编程\n\n一种利用C++模板机制在编译期间执行计算的编程技巧。它允许在编译时计算出常量值、生成类型和实现算法，而不是在程序运行时进行计算。通过模板递归、模板特化等技术，程序员可以编写高效的代码，并通过编译时计算提高性能。\n\n```C++\ntemplate <int N>\nstruct Factorial {\n    static const int value = N * Factorial<N - 1>::value;\n};\n// 基本情况，阶乘 0 的结果是 1\ntemplate <>\nstruct Factorial<0> {\n    static const int value = 1;\n};\nint main() {\n    cout<<"Factorial of 5: "<<Factorial<5>::value<<endl; // 输出: 120\n    return 0;\n}\n```\n\n`Factorial`模板使用递归来计算阶乘。在编译时，`Factorial<5>::value`会被替换为`5 * Factorial<4>::value`，依此类推，直到递归到`Factorial<0>::value`。\n\n这个计算发生在编译阶段，因此可以避免在程序运行时进行计算。\n\n## 5、可变参数模板\n\n`C++11`引入的一种特性，使得模板能够接受任意数量的模板参数。传统的模板只能接受固定数量的参数，而可变参数模板允许模板接受零个或多个参数，非常适合处理不定数量的参数。\n\n语法：\n\n```C++\ntemplate <typename...Args>\nvoid func(Args...args);\n```\n\n**展开方式**\n\n左折叠：\n\n```c++\ntemplate<typename... Args>\nvoid sum(Args... args) {\n    cout<<"Sum: "<<(args+...)<<endl; // 从左到右依次求和\n}\nint main() {\n    sum(1, 2, 3, 4); // 输出：Sum:10\n    return 0;\n}\n```\n\n右折叠：\n\n```c++\ntemplate<typename... Args>\nvoid printInReverse(Args... args) {\n    (cout<<...<<args)<<endl; // 从右到左展开\n}\n```\n\n递归展开：\n\n```C++\n// 基础情况：递归终止条件\nvoid print() {\n    cout<<endl;\n}\n// 可变参数模板函数：递归打印每个参数\ntemplate <typename T,typename... Args>\nvoid print(T first,Args...args) {\n    cout<<first<<" ";\n    print(args...); // 递归调用，展开剩余的参数\n}\nint main() {\n    print(1, 2.5, "Hello", "A"); // 输出：1 2.5 Hello A\n    return 0;\n}\n```\n\n初始列表展开：\n\n```c++\ntemplate<typename... Args>\nvoid print(Args... args) {\n    initializer_list<int> {(cout<<args<<" ",0)...}; // 参数包展开到初始列表中\n    cout<<endl;\n}\nint main() {\n    print(1, 2.5, "Hello", "A"); // 输出：1 2.5 Hello A\n    return 0;\n}\n```\n\n**解释**\n\n`print`是一个可变参数模板函数。`Args...`表示一个参数包，可以匹配任意数量的参数。\n\n在递归函数调用中，通过 `print(args...)` 展开参数包，并逐个打印每个参数。\n\n**应用**\n\n构造多参数类\n\n```c++\ntemplate<typename... Args>\nclass MyClass {\npublic:\n    MyClass(Args... args) {\n        print(args...);\n    }\n    void print(Args... args) {\n        (cout<<...<<args)<<endl;\n    }\n};\nint main() {\n    MyClass<int, double, string> obj(1, 3.14, "Hello");\n    return 0;\n}\n```\n\n**转发参数到另一个函数**\n\n```c++\ntemplate<typename... Args>\nvoid wrapper(void (*func)(Args...), Args... args) {\n    func(args...); // 参数转发\n}\nvoid printArgs(int a, double b, const char* c) {\n    cout<<a<<" "<<b<<" "<<c<<endl;\n}\nint main() {\n    wrapper(printArgs, 42, 3.14, "Hello");\n    return 0;\n}\n```\n\n**可变参数模板与继承**\n\n实现模板类的多层继承，类似于`tuple`的功能。\n\n```c++\ntemplate<typename... Args>\nclass MyTuple; // 前向声明\ntemplate<>\nclass MyTuple<> {}; // 空模板的特化，递归终止\ntemplate<typename T,typename... Rest>\nclass MyTuple<T,Rest...>: private MyTuple<Rest...> {\npublic:\n    MyTuple(T first,Rest... rest): MyTuple<Rest...> (rest...), value(first) {}\n    T getValue()const {return value;}\nprivate:\n    T value;\n};\nint main() {\n    MyTuple<int, double, string> tuple(42, 3.14, "Hello");\n    cout<<tuple.getValue()<<endl; // 输出 42（第一个元素的值）\n    return 0;\n}\n```\n\n**进一步理解**\n\n**递归展开**：在编译时，编译器通过递归展开参数包来处理每个参数。\n\n`sizeof...(Args)`：可以获取模板参数包中参数的数量。\n\n`std::forward<Args>(args)`：可以转发参数（通过完美转发传递到其他函数）。'
                      },
                      { id: 'advanced_programming-7', 
                        title: '10、泛型程序设计与STL', 
                        desc: '', 
                        content: '# 第十章-泛型程序设计与STL\n\n## 1、基本概念\n\n### 泛型程序设计\n\n就是**编写不依赖于具体数据类型的程序**。\n\n主要思想是**将算法从特定的数据结构中抽象出来，使算法成为通用的、可以作用于各种不同的数据结构**。\n\n为什么需要泛型程序设计：\n\n在软件的复用中，被复用和复用双方需要遵守一定的协议。\n\n例如：\n\n1. 调用函数时除了需要提供正确的函数名，也要提供正确的参数。\n2. 模板中类型参数T需要具备相应的功能如能比较大小，大于号有相应的重载等。\n\n### 概念\n\n用概念来描述泛型程序设计中作为参数的数据类型所需具备的功能。\n\n**其内涵是这些功能**。\n\n**其外延是具备这些功能的所有数据类型**。\n\n例如将可以比大小，具有公有的复制构造函数并可用=赋值的所有数据类型记作`Sortable`概念。\n\n**概念之间存在包含与被包含的关系**。\n\n### 模型\n\n具备一个概念所需要功能的数据类型称为这一概念的一个模型。\n\n例如`int`数据类型就是`Sortable`概念的一个模型。\n\n## 2、STL\n\n伟大，无需多言！\n\n### 容器(container)\n\n容器是容纳、包含一组元素的对象。\n\n例如：`priority_queue`。\n\n### 迭代器(iterator)\n\n迭代器提供了顺序访问容器中每个元素的方法：\n\n```C++\nvector<int> v;\nvector<int>::iterator it = v.begin();\n++it; // 指向 v 第二个元素\n*it = 114514; // 访问所指向的元素\n--it; // 指向 v 第一个元素\n```\n\n若迭代器指向的是类或结构体，还可以用`->`直接访问该元素的一个成员。\n\n**迭代器是泛化的指针**。\n\n各种容器的迭代器与不同的迭代器将在后面介绍。\n\n### 函数对象(function object)\n\n一个行为类似函数的对象，对它可以像调用函数一样调用。\n\n函数对象是泛化的函数。\n\n### 算法(algorithm)\n\n这些算法都具有统一性，可以广泛用于不同的对象和内置的数据类型。\n\n## 3、迭代器\n\n`cin`是输入流的一个实例，`cout`是输出流的一个实例。\n\n### 输入流迭代器\n\n输入流迭代器用来从一个输入流中连续地输入某种类型的数据，它是一个类模板，例如：\n\n```C++\ntemplate <class T> istream_iterator<T>;\n```\n\n其中，`T`类型要满足两个条件：\n\n1. 有默认构造函数。\n2. 可以用`>>`从输入流输入。\n\n一个输入流迭代器的实例需要由下面的构造函数来构造：\n\n```C++\nistream_iterator(istream& in);\n```\n\n**其中**`in`**表示将数据输入到的输入流**。\n\n`istream_iterator`类模板有一个默认构造函数，该函数构造出的迭代器指向的就是输入流的结束位置。\n\n### 输出流迭代器\n\n输出流迭代器用来向一个输出流中连续地输出某种类型的数据，它是一个类模板，例如：\n\n```C++\ntemplate <class T> ostream_iterator<T>;\n```\n\n其中，`T`需要具有一个功能：可以用`<<`向输出流输出。\n\n一个输出流迭代器可以用下面两个构造函数来构造：\n\n```C++\nostream_iterator(ostream& out);\nostream_iterator(ostream& out, const char* delimiter);\n```\n\n**其中**`out`**表示将数据输出到的输出流**。\n\n`delimiter`**表示两个输出数据之间的分隔符**。\n\n输出流迭代器可以使用，`it=x`相当于`out<<x`或`out<<x<<delimiter`。\n\n输出流迭代器可以使用`++`但意义不大。\n\n总使用例：\n\n```C++\ntransform(istream_iterator<double>(cin), istream_iterator<double>(), ostream_iterator<double>(cout,"\t"), a_function);\n```\n\n### 迭代器的分类\n\n<img src="./pictures/image-20241228151815560.png"> \n\n接下来所有概念都是`Assignable`概念的子概念：\n\n即都有公有的复制构造函数和赋值运算符。\n\n`++p`为使迭代器`p`指向下一个元素，返回`p`自身的引用。\n\n`p++`为使迭代器`p`指向下一个元素，根据`p`的类型不同，返回不同。\n\n#### 输入迭代器\n\n输入迭代器可以用来从序列中读取数据，但是不一定能够向其中写入数据。\n\n输入迭代器支持对序列进行不可重复的单向遍历。\n\n值得注意的是:即使`p==q`，`++p==++q`和`(++p)==(++q)`是不一定成立的，具体原因有些复杂，涉及每个`range`对应迭代器唯一性问题。\n\n#### 输出迭代器\n\n输出迭代器允许向序列中写入数据，但是并不保证可以从其中读取数据。\n\n输出迭代器支持对序列进行单向遍历。\n\n使用输出迭代器，写入元素操作和`++`自增操作需要交替进行，否则行为不确定（就是可能会出现难以理解的bug）。\n\n#### 前向迭代器\n\n前向迭代器是输入迭代器和输出迭代器的子概念，既支持数据读取，也支持数据写入，支持对序列进行可重复的单向遍历。\n\n前向迭代器的操作是确定的，不受输出迭代器的限制。\n\n#### 双向迭代器\n\n双向迭代器是单向迭代器的子概念，额外支持迭代器反向移动，即如对应`++`的`--`操作。\n\n#### 随机访问迭代器\n\n随机访问迭代器是双向迭代器的子概念，额外支持将迭代器向前或向后移动`n`个元素，几乎和指针一样。\n\n### 迭代器的区间\n\n`STL`算法的形参中常包括一对输入迭代器，它们构成的区间表示输入数据的序列。\n\n设`p1`，`p2`是两个输入迭代器，当且仅当对`p1`执行`n`次`++`运算后，表达式`p1==p2`为真，则`[p1,p2)`是一个合法的区间。\n\n```C++\ntemplate <class T, class InputIt, class OutputIt>\nvoid mySort(InputIt first, InputIt last, OutputIt result) {\n    vector<T> s;\n    for(; first != last; ++first) s.push_back(*first);\n    sort(s.begin(), s.end());\n    copy(s.begin(), s.end(), result);\n}\nint main() {\n    double a[5]={1.1, 4.5, 1.4, 19.19, 8.10};\n    mySort<double>(a, a + 5, ostream_iterator<double>(cout, " "));\n    puts("");\n    return 0;\n}\n```\n\n### 迭代器的辅助函数\n\n`STL`为迭代器提供了两个辅助函数模板。\n\n#### advance\n\n```C++\ntemplate <class InputIt, class Distance>\nvoid advance(InputIt& iter, Distance n);\n```\n\n它用来使迭代器`iter`前进`n`个元素。\n\n对于双向迭代器或随机访问迭代器，`n`可以取负值，表示让`iter`后退`n`个元素。\n\n#### distance\n\n```C++\ntemplate <class InputIt>\nunsigned distance(InputIt first, InputIt last);\n```\n\n用来计算`first`经过多少次`++`运算可以到达`last`。\n\n## 4.容器的基本功能与分类\n\n每种容器都支持的基本功能有下，以`set`为例：\n\n```C++\nset<int> s, t;\ns=t, s>t, s<t;\ns.begin();\ns.end();\ns.clear();\ns.empty();\ns.size();\ns.swap(t);\n```\n\n不同类型相关的迭代器有不同表示：\n\n```C++\nset<int>::iterator\nset<int>::const_iterator\n```\n\n对于常迭代器，指向元素的类型为`const T`，只能通过迭代器读取元素，不能改写元素。\n\n<img src="./pictures/image-20241228152239826.png">\n\n一般`STL`标准容器都至少是可逆容器，其`begin()`或`end()`成员函数所得到的通常是双向迭代器。\n\n也可以使用逆向迭代器：\n\n容器的`rbegin()`或`rend()`成员函数返回的是逆向迭代器，它的表示如下：\n\n```C++\nset<int>::iterator s1;\nset<int>::reverse_iterator p1 = set<int>::reverse_iterator(s1);\n// 得到与 s1 对应的逆向迭代器，p1 指向 s1 - 1 所指向的元素\np1.base();\n// 返回的是 s1\nset<int>::const_reverse_iterator p2;\n```\n\n事实上：\n\n```C++\ns1.rbegin() == set<int>::reverse_iterator(s1.end()), s1.rbegin().base() == s1.end();\ns1.rend() == set<int>::reverse_iterator(s1.begin()), s1.rend().base() == s1.begin();\n```\n\n随机访问容器提供的迭代器是随机访问迭代器，可以直接通过一个整数来访问容器中的指定元素：\n\n```C++\nvector<int> v;\nv[114514];\n```\n\n<img src="./pictures/image-20241228152349038.png">\n\n## 5.顺序容器\n\n每种类型的容器都是一个类模板，都具有一个模板参数，表示容器的元素类型，该类型必须符合`Assignable`概念，即具有公有的复制构造函数并可以用`=`赋值。\n\n### 基本功能\n\n#### 构造函数\n\n<img src="./pictures/image-20241228152418078.png">\n\n#### 赋值函数\n\n<img src="./pictures/image-20241228152452239.png">\n\n#### 元素插入\n\n<img src="./pictures/image-20241228152517152.png">\n\n#### 元素删除\n\n<img src="./pictures/image-20241228152538874.png">\n\n#### 改变容器的大小\n\n<img src="./pictures/image-20241228152605189.png">\n\n#### 首尾元素的直接访问\n\n<img src="./pictures/image-20241228152626321.png">\n\n#### 在容器尾部插入、删除元素\n\n<img src="./pictures/image-20241228152651053.png">\n\n#### 在容器头部插入、删除元素\n\n`list`或`deque`能支持的操作，具有前插顺序容器这一概念的容器可以完成操作。\n\n<img src="./pictures/image-20241228152719427.png">\n\n#### 容器的列表初始化\n\n示例如下:\n\n<img src="./pictures/image-20241228152749517.png">\n\n### 5种顺序容器的特性\n\n####  向量(vector)\n\n主要介绍动态内存分配：\n\n当数组的空间不够时，`vector`会自动用 `new`分配一块更大的空间，将原有的数据分别复制到新的空间中，再将原有的空间释放，向量的容量为申请的空间总数。\n\n<img src="./pictures/image-20241228152820650.png">\n\n值得注意的是：\n\n**如果插入操作引起了向量容量的扩展，那么在执行插入之前所获得的一切迭代器、指针和引用都会失效**。\n\n**如果插入操作未引起了向量容量的扩展，那么在执行插入位置之后的一切迭代器、指针和引用都会失效**。\n\n标准库提供了`shrink_to_fit`函数实现将`vector`中未使用的元素空间回收的功能。\n\n#### 双端队列(deque)\n\n<img src="./pictures/image-20241228152850098.png">\n\n1. 当向`deque`两端加入元素时，会使所有迭代器失效，但是不会使已有的指针，引用失效：\n\n   前者是因为插入新元素可能会引起索引数组中已有元素位置的改变，\n\n   后者是因为元素在分段数组中位置不变。\n\n2. 当删除`deque`两端元素时，`O(1)`效率，只会使被删除元素的迭代器、指针或引用失效，而不会影响其他元素的迭代器、指针或引用。\n\n3. 当在`deque`中间插入新元素时，类似`vector`中头部插入元素，效率偏低，且所有迭代器、指针和引用失效。\n\n4. 删除情况类似3。\n\n#### 列表(list)\n\n基本原理按指针链表理解即可。\n\n列表之间支持接合操作：\n\n<img src="./pictures/image-20241228152912430.png">\n\n#### 单向链表(forward_list)和数组(array)\n\n`forward_list`的设计目标是达到与手写的单向链表数据结构相当的性能。\n\n`array`提供了更安全，更方便地使用数组的方式。\n\n#### 5种顺序容器的比较\n\n<img src="./pictures/image-20241228153006886.png">\n\n<img src="./pictures/image-20241228153028707.png">\n\n### 顺序容器的插入迭代器**(Insertion Iterator)**\n\n插入迭代器是`STL`中的一种特殊迭代器，它允许我们在容器的特定位置插入元素，而不仅仅是替换已有的元素。插入迭代器通常用于需要在容器中动态插入元素的场景。\n\n插入迭代器通常与`STL`容器的`insert()`操作配合使用，它允许我们通过迭代器将一个值插入到容器中。\n\n##### 1. `insert_iterator`\n\n- **作用**：它允许在容器的指定位置插入元素。可以在容器中的任意位置插入元素，而不仅限于容器的末尾。\n- **用法**：通过`insert_iterator`插入元素时，我们通常使用`insert()`方法，它会将元素插入到指定位置。\n\n```C++\nint main() {\n    vector<int> v = {1, 2, 3, 4};\n    insert_iterator<vector<int>> insert_it(v, v.begin() + 2);\n    *insert_it = 114514; // 在位置 2 插入 114514\n    v.insert(v.begin() + 2, 88); // 可以直接使用 insert\n    for(int i:v) {\n        cout<<i<<" ";\n    }\n    return 0;\n}\n```\n\n##### 2.`front_insert_iterator`\n\n- **作用**：它仅适用于支持在容器前端插入元素的容器（例如`deque`或`list`）。通过它插入元素会将元素插入到容器的开头。\n- **用法**：用于将元素插入容器的前端。例如，当我们使用`front_insert_iterator`时，元素会被插入到容器的开头(即使我们在容器的迭代器上前进)。\n\n```C++\nint main(){\n    deque<int> dq={1,2,3,4};\n    front_insert_iterator<deque<int>> front_it(dq);\n    *front_it=99;//在deque前端插入99\n    for(int i:dq){\n        cout<<i<<" ";\n    }\n    return 0;\n}\n```\n\n##### 3.`back_insert_iterator`\n\n- **作用**:它专门用于容器的尾部插入元素。它支持将元素插入到容器的末尾。`back_insert_iterator` 是最常用的插入迭代器，因为许多容器（如`vector`,`deque`和`list`）都支持尾部插入。\n- **用法**:通过`back_insert_iterator`进行插入时，元素会自动被追加到容器的末尾。\n\n```C++\nint main() {\n    vector<int> v = {1, 2, 3, 4};\n    back_insert_iterator<vector<int>> back_it(v);\n    *back_it = 99; // 在 vector 末尾插入 99\n    for(int i:v) {\n        cout<<i<<" ";\n    }\n    return 0;\n}\n```\n\n### 顺序容器的适配器\n\n#### 容器适配器(Container Adapters)\n\n容器适配器本质上是对底层容器的包装，它提供了一种不同的接口来操作容器。`C++`标准库中有三种容器适配器：\n\n- **栈(stack)**\n- **队列(queue)**\n- **优先队列(priority_queue)**\n\n#### 功能适配器(Function Adapters)\n\n功能适配器提供了一些函数对象(`functors`)来封装操作，使得容器操作更加灵活和简洁。\n\n`greater` **和** `less`：\n\n`greater`和`less`是两种常用的比较函数对象，分别用于表示**大于**关系和**小于**关系。\n\n```C++\n#include <iostream>\n#include <queue>\n#include <functional> //for greater, less\nusing namespace std;\nint main() {\n    priority_queue<int, vector<int>, greater<int>> pq;\n    // 使用 greater 使优先队列变成最小堆\n    pq.push(10);\n    pq.push(20);\n    pq.push(5);\n    cout<<"Top element: "<<pq.top()<<endl; // 输出 5\n    pq.pop();\n    cout<<"Top element after pop: "<<pq.top()<<endl; // 输出 10\n    return 0;\n}\n```\n\n## 6.关联容器\n\n关联容器的每个元素都有一个键`key`，容器中元素的顺序不能被随意决定，而是按照键的取值升序排列。\n\n**关联容器可分为单重关联容器和多重关联容器**：\n\n#### 单重关联容器\n\n键值唯一，不允许重复。\n\n#### 多重关联容器\n\n相同的键值允许重复出现。\n\n**关联容器也可分为简单关联容器和二元关联容器**：\n\n#### 简单关联容器\n\n以元素本身作为键。\n\n#### 二元关联容器\n\n由键和某种类型的附加数据共同构成。\n\n<img src="./pictures/image-20241228153111346.png">\n\n- **简单关联容器只有一个类型参数**。\n- **二元关联容器有两个类型参数，前一个是键类型，后一个是附加数据的类型**。\n- **后者的组合类型可以用**`pair`**表示**。\n- **关联容器的键之间必须能够使用**`<`**比较大小，否则需要重载**`<`**运算符**。\n\n### 关联容器支持的操作\n\n#### 构造函数\n\n<img src="./pictures/image-20241228153136591.png">\n\n#### 元素的插入\n\n<img src="./pictures/image-20241228153200232.png">\n\n#### 元素的删除\n\n<img src="./pictures/image-20241228153222281.png">\n\n#### 基于键的查找和计数\n\n<img src="./pictures/image-20241228153243310.png">\n\n#### 关联容器的列表初始化\n\n<img src="./pictures/image-20241228153317856.png">\n\n### 8种关联容器的特性\n\n#### 集合(set)\n\n几乎是数学上的集合，只是元素个数有限。\n\n集合的第一个元素一定是最小的元素。\n\n集合的最后一个元素一定是最大的元素。\n\n#### 映射(map)\n\n底层是红黑树。\n\n伟大，无需多言。\n\n#### 多重集合(multiset)和多重映射(multimap)\n\n相比`set`和`map`，一个键可以对应多个元素。\n\n使用`find()`将得到某一个不确定的元素位置。\n\n通常使用`equal_range()`和`count()`。\n\n使用例：\n\n```C++\nmultimap<string,string>courses;\n/*...*/\nauto range=courses.equal_range("math");\nfor(multimap<string,string>::iterator it = range.first; it != range.second; ++iter)\n    cout<<iter->second<<" ";\n```\n\n#### 无序容器\n\n包括`unordered_set`，`unordered_map`，`unordered_multiset`，`unordered_multimap`。\n\n它们是通过哈希函数和键类型的`==`运算符组织元素的。\n\n在不考虑序的情况下，无序函数非常有用。\n\n哈希函数的使用能够获得更好的平均性能。\n\n## 7.函数对象\n\n**函数对象是一个行为类似函数的对象，对参数数目没有要求，功能是获取一个值，或者改变操作的状态**。\n\n**任何普通的函数、函数指针、**`lambda`**表达式和任何重载了调用运算符**`operator()`**的类的对象都满足函数对象的特征**。\n\n<img src="./pictures/image-20241228153355192.png">\n\n#### 自定义函数对象\n\n使用例：\n\n```C++\nbool cmp(int x, int y) return x > y;\nint main() {\n    sort(a, a + n + 1, cmp);\n    return 0;\n}\n```\n\n### 标准的函数对象\n\n#### 产生器(generator)、一元函数(unary function)和二元函数(binary function)\n\n分别是具有0个、1个和2个传入参数的函数对象：\n\n<img src="./pictures/image-20241228153418170.png">\n\n需要调用`<functional>`，标准函数对象是内联函数。\n\n使用例：\n\n```C++\nint a[]={1, 1, 4, 5, 1, 4}, n = 6;\naccumulate(a, a + n, 1, multiplies<int>());\n```\n\n#### 一元谓词(unary predicate)和二元谓词(binary predicate)函数对象\n\n要求返回为`bool`型，并具有一个或两个参数。\n\n<img src="./pictures/image-20241228153440976.png">\n\n使用例：\n\n```C++\nint a[] = {1, 1, 4, 5, 1, 4};\nsort(a, a + 6, greater<int>());\n```\n\n### lambda表达式\n\n可以理解为一个未命名的内联函数，包含一个返回类型，一个参数列表和一个函数体，可能定义在函数内部。\n\n**基本语法**\n\n```C++\n[capture](parameter_list)->return_type{function_body}\n```\n\n其中：\n\n- **capture**：捕获外部变量的方式（可以是值捕获、引用捕获等）。\n- **parameter_list**：与普通函数相同，可以定义输入参数。\n- **return_type**：返回值类型（可以省略，编译器自动推断）。\n- **function_body**：函数的具体实现。\n\n#### 捕获的方式：capture\n\n**按值捕获（默认捕获方式）**：通过`[]`捕获外部变量的副本：\n\n```C++\nint x = 10;\nauto lambda = [x]() {return x * 2;};\ncout<<lambda()<<endl; // 输出 20\n```\n\n**按引用捕获**：通过`[&]`捕获外部变量的引用。这样，Lambda内部可以修改外部变量：\n\n```C++\nint x = 10;\nauto lambda = [&x]() {x *= 2;};\nlambda();\ncout<<x<<endl; // 输出 20\n```\n\n**指定捕获**：可以指定捕获哪些变量，以及是按值还是按引用捕获：\n\n```C++\nint x = 10, y = 20;\nauto lambda = [x,&y]() {return x + y;};\ny = 50;\ncout<<lambda()<<endl; // 输出 60 (x 按值捕获，y 按引用捕获)\n```\n\n**捕获所有变量**：\n\n1. `[=]`按值捕获所有外部变量。\n2. `[&]`按引用捕获所有外部变量。\n3. `[this]`捕获当前对象的指针，可以在`Lambda`中使用类成员：\n\n```C++\nauto lambda1 = [=]() {return x + y;}; // 按值捕获所有外部变量\nauto lambda2 = [&]() {return x + y;}; // 按引用捕获所有外部变量\n```\n\n**捕获列表与this指针**：\n\n```C++\nclass MyClass {\npublic:\n    int x;\n    MyClass(): x(10) {}\n    void foo() {\n        auto lambda = [this]() {return this->x;};\n        cout<<lambda()<<endl; // 输出 10\n    }\n};\n```\n\n#### 参数列表：parameter_list\n\n参数列表与普通函数一样，可以定义`Lambda`的输入参数。`Lambda`参数可以省略，也可以显式地定义。\n\n#### 返回类型：return_type\n\n`Lambda`表达式的返回类型可以显式指定，也可以由编译器自动推断。如果没有返回类型，则返回类型会默认推导为`void`，或者由返回语句自动推导。\n\n- **显式返回类型**：\n\n```C++\nauto lambda = [](int a, int b)->int {return a + b;};\ncout<<lambda(3,4)<<endl; // 输出 7\n```\n\n- **隐式返回类型**：编译器会根据返回值类型推导出`Lambda`的返回类型\n\n```C++\nauto lambda = [](int a, int b) {return a + b;}; // 返回类型会自动推导为 int\ncout<<lambda(3,4)<<endl; // 输出 7\n```\n\n`Lambda`表达式还可以作为`STL`中的回调函数，如：\n\n```C++\nvector<int> vec = {1, 2, 3, 4, 5};\nfor_each(vec.begin(), vec.end(), [](int x) {cout<<x<<" ";});\n```\n\n由于`Lambda`能捕获外部变量，它还可以充当闭包(`Closure`)，可以将外部数据封装在内部的函数中。\n\n### 函数对象参数绑定\n\n指将一个函数对象的某些参数与固定的值绑定，使得生成一个新的函数对象，该函数对象具有固定的参数。\n\n使用例：\n\n```C++\nauto p = find_if(a.begin(), a.end(), bind(greater<>(), placeholders::_1,40));\n```\n\n这里`bind<>`相当于一个函数，占位符`_1`接收了`find_if`提供的参数。\n\n## 8.算法\n\n**算法本身就是一种函数模板**。\n\n`STL`算法可以分为4大类：\n\n### 不可变序列算法(Non-mutating algorithms)\n\n指不直接修改所操作的容器内容的算法，包括：\n\n1. 在序列中查找元素的算法。\n2. 执行相等检查的算法。\n3. 对序列元素进行计数的算法。\n\n<img src="./pictures/image-20241228153508601.png">\n\n### 可变序列算法(Mutating algorithms)\n\n可以修改它们所操作的容器的元素，包括：\n\n复制(`copy`)，生成(`generate`)，删除(`remove`)，替换(`replace`)，倒序(`reverse`)，旋转(`rotate`)，交换(`swap`)，变换(`transform`)，分割(`partition`)，去重(`unique`)，填充(`fill`)，洗牌(`shuffle`)\n\n<img src="./pictures/image-20241228153532001.png">\n\n<img src="./pictures/image-20241228153557784.png">\n\n### 排序和搜索算法\n\n<img src="./pictures/image-20241228153626961.png">\n\n<img src="./pictures/image-20241228153706798.png">\n\n### 数值算法\n\n需要包含头文件`<numeric>`\n\n<img src="./pictures/image-20241228153732024.png">\n\n## 9.迭代器的类型特征\n\n<img src="./pictures/image-20241228153800753.png">\n\n## 10.Boost\n\n喜欢可以去玩玩这个库！'
                      },
                      { id: 'advanced_programming-8', 
                        title: '11、流类库与输入输出', 
                        desc: '', 
                        content: '# 第十一章-流类库与输入输出\n\n`C++`标准库中一个面向对象的输入输出软件包。\n\n## 1、基本概念\n\n### 流\n\n**流是一种抽象，它负责在数据的生产者和数据的消费者之间建立联系，并管理数据的流动**。\n\n程序操作流对象，流对象通过文件系统对所连接的文件对象产生作用。\n\n**程序将流对象看作是文件对象的化身**。\n\n### I/O流类库\n\nI/O流类库的基础是一组类模板，类模板提供了库中的大多数功能，而且可以作用于不同类型的元素。\n\n流的基本单位的数据类型就是模板的参数。\n\n`<iostream>`中声明了4个预定义的流对象用来完成在标准设备上的输入输出操作:`cin`、`cout`、`cerr`、`clog`。\n\n<img src="./pictures/image-20241228153955467.png">\n\n<img src="./pictures/image-20241228154120072.png">\n\n## 2、输出流\n\n最重要的3个输出流是`ostream`、`ofstream`、`ostringstream`。\n\n预先定义的`ostream`类对象用来完成向标准设备的输出：\n\n- `cout`是标准输出流。\n- `cerr`是标准错误输出流，没有缓冲，发送给它的内容立即被输出。\n- `clog`类似于`cerr`，但是有缓冲，缓冲区满时被输出。\n\n`ofstream`类支持磁盘文件输出。\n\n如果在构造函数中指定一个文件名，当构造这个文件时该文件是自动打开的。\n\n### 构造输出流对象\n\n如果要使用文件流将信息输出到文件，需要使用构造函数来建立流对象：\n\n使用默认构造函数，调用`open`成员函数\n\n```C++\nofstream myFile;\nmyFile.open("114514.txt");\n```\n\n在调用构造函数时指定文件名\n\n```C++\nofstream myFile("114514.txt");\n```\n\n使用同一个流先后打开不同的文件\n\n```C++\nofstream myFile("114514.txt");\nmyFile.open("1919810.txt");\n```\n\n可以用字符串作为文件名。\n\n### 使用插入运算符和操纵符\n\n很多操纵符定义在`<iomanip>`\n\n#### 输出宽度\n\n```C++\ncout.width(10); // 设定以至少 10 个字符宽按右对齐方式输出\ncout.fill(\'*\'); // 设定以 * 填充\ncout<<setw(10)<</* ... */; // 指定宽度\n```\n\n#### 对齐方式\n\n```C++\ncout<<setiosflags(ios_base::left)<</* ... */<<resetiosflags(ios_base::left);\n// 设置左对齐和解除左对齐\n```\n\n<img src="./pictures/image-20241228154149865.png">\n\n#### 精度\n\n```C++\ncout<<setprecision(1)<<114.514;\n// 输出 1e+002\ncout<<setiosflags(ios_base::fixed)<<setprecision(1)<<114.514;\n// 输出 114.5\ncout<<setiosflags(ios_base::scientific)<<setprecision(1)<<114.514;\n// 输出 1.1e+002\n```\n\n#### 进制\n\n```C++\ncout<<dec<<114514; // 输出 337522\ncout<<oct<<114514; // 输出 114514\ncout<<hex<<114514; // 输出 1BF52\ncout<<setbase(16)<<114514; // 输出 1BF52\n```\n\n### 文件输出流成员函数\n\n<img src="./pictures/image-20241228154220513.png">\n\n#### 输出流的open函数\n\n```C++\nofstream file("filename", ios_base::out | ios_base::binary);\n```\n\n<img src="./pictures/image-20241228154238123.png">\n\n对于`ios_base:app`，若文件不存在，则新建一个同名文件。\n\n#### 输出流的close函数\n\n如果需要在同一流对象上打开另外的文件，需要使用`close`函数。\n\n#### put函数\n\n```C++\ncout.put(\'A\'); // 精确输出一个字符\ncout<<\'A\'; // 同上，但是此前设置的宽度和填充方式在此起作用\n```\n\n#### write函数\n\n`write`函数把一个内存中的一块内容写到一个文件输出流中，长度参数指出写的字节数。\n\n```C++\nstruct date {\n    int a, b, c;\n}\nint main() {\n    date x = {11, 45, 14};\n    ofstream file("date.dat", ios_base::binary);\n    file.write(reinterpret_cast<char *>(&x), sizeof(x));\n    file.close();\n    return 0;\n}\n```\n\n`write`函数带两个参数:一个`char`指针（指向内存数据的起始地址）和一个所写的字节数。\n\n#### seekp和tellp函数\n\n一个文件输出流保存一个内部指针指出下一次写数据的位置。\n\n`seekp`函数设置这个指针，因此可以以随机方式向磁盘文件输出。\n\n`tellp`函数返回该文件位置指针值。\n\n```c++\nfile.seekp(20,ios::beg); // 从文件头开始计算偏移量，这里是读取第 21 个字节\nfile.seekp(-1,ios::end); // 从文件末尾开始计算偏移量，这里是读取最后一个字节\nfile.seekp(20,ios::cur); // 从当前位置开始计算偏移量\nstreampos sp=in.tellp(); // 指示当前指针位置\n```\n\n#### 错误处理函数\n\n<img src="./pictures/image-20241228154258486.png">\n\n### 二进制输出文件\n\n在以文本模式输出时，每输出一个换行符`\\n`都会将当前操作系统下的行分隔符写入文件中，这意味着在`Windows`下输出换行符后还会被自动扩充一个回车符。\n\n想要避免这一问题，就要采用二进制模式输出到文件。\n\n```C++\nofstream os("test.dat", ios_base::out | ios_base::binary);\n```\n\n### 字符串输出流\n\n字符串输出流可以用于生成字符串。\n\n`ostringstream`类就用来表示一个字符串输出流。\n\n`ostringstream`具有`ofstream`类大部分功能，还具有一个特有函数`str()`，返回`string`对象。\n\n需要头文件`<sstream>`\n\n```C++\ntemplate<class T>\ninline string toString(const T &v) {\n    ostringstream os;\n    os<<v;\n    return os.str();\n}\nint main() {\n    cout<<toString(114.514);\n    return 0;\n}\n```\n\n## 3、输入流\n\n最重要的3个输入流是`istream`、`ifstream`、`istringstream`。\n\n- `istream`类最适合用于顺序文本模式输入。\n- `ifstream`类支持磁盘文件输入。\n- `istream`的所有功能都包括在`ifstream`中。\n\n### 构造输入流对象\n\n如果要使用文件流从文件中读取数据，就必须构造一个输入流对象：\n\n使用默认构造函数，调用`open`成员函数：\n\n```C++\nifstream myFile;\nmyFile.open("114514.txt");\n```\n\n在调用构造函数时指定文件名：\n\n```C++\nifstream myFile("114514.txt");\n```\n\n使用同一个流先后打开不同的文件：\n\n```C++\nifstream myFile("114514.txt");\nmyFile.open("1919810.txt");\n```\n\n可以用字符串作为文件名。\n\n### 使用提取运算符\n\n提取运算符（`>>`）对于所有标准`C++`数据类型都预先设计好，是从一个输入流对象获取字节最容易方法。\n\n### 输入流操纵符\n\n<img src="./pictures/image-20241228154341485.png">\n\n### 输入流相关函数\n\n#### 输入流的open函数\n\n```C++\nifstream file("filename", ios_base::in | ios_base::binary);\n```\n\n<img src="./pictures/image-20241228154325154.png">\n\n#### 输入流的close函数\n\n如果需要在同一流对象上打开另外的文件，需要使用`close`函数。\n\n#### get函数\n\n相比`>>`还接受空白字符。\n\n```C++\nchar ch;\nwhile((ch=cin.get())!=EOF)cout.put(ch);\n```\n\n#### getline函数\n\n`getline`函数允许从输入流中读取多个字符，并且允许指定输入终止字符。\n\n```C++\nstring line;\ngetline(cin,line, \'t\'); // 属于 string 流\nchar line_[10];\ncin.getline(line_, 5, \'t\'); // 属于 istream 流\n```\n\n#### read函数\n\n`read`函数从一个文件读字节到一个指定的存储器区域，由长度参数确定要读的字节数。\n\n```C++\nifstream file("filename", ios_base::in | ios_base::binary);\nfile.read(reinterpret_cast<char *>(&file), sizeof(file));\n```\n\n#### seekg和tellg函数\n\n一个文件输入流保存一个内部指针指向文件中下一个将读数据的位置。\n\n`seekg`函数设置这个指针。\n\n`tellp`函数返回该文件位置指针值，是`streampos`类型。\n\n使用例：\n\n```c++\nfile.seekg(20, ios::beg); // 从文件头开始计算偏移量，这里是读取第 21 个字节\nfile.seekg(-1, ios::end); // 从文件末尾开始计算偏移量，这里是读取最后一个字节\nfile.seekg(20, ios::cur); // 从当前位置开始计算偏移量\nstreampos sp = in.tellg(); // 指示当前指针位置\n```\n\n#### 错误处理函数\n\n<img src="./pictures/image-20241228154403471.png">\n\n### 字符串输入流\n\n字符串输入流可以用于从一个字符串中读取数据：\n\n`istringstream`类就用来表示一个字符串输入流。\n\n`istringstream`具有`ifstream`类大部分功能，只有专用于文件操作的`open`函数和`close`函数不具有。\n\n需要头文件`<sstream>`\n\n```C++\ntemplate<class T>\ninline T fromString(const string &str) {\n    istringstream is(str);\n    T v;\n    is>>v;\n    return v;\n}\nint main() {\n    cout<<fromString("114.514");\n    return 0;\n}\n```\n\n## 4.宽字符、宽字符串与宽流\n\n### 普通字符和字符串的缺陷\n\n计算机需要处理的字符有些是在`ASCII`码表之外。\n\n一个汉字需要用两个连续的`char`数据来表示。\n\n字符串处理汉字就会存在相关问题：\n\n- 字符串长度将会比汉字数目多。\n- 截取子串的时候，会出现问题。\n- 查找子串也会有问题。\n\n### 宽字符\n\n列宽字符（`WideCharacter`）是指用于表示较大字符集的字符类型，通常比传统的字符类型（如`char`）占用更多的内存空间。`C++`中的宽字符类型为`wchar_t`，它通常用于存储`Unicode`字符：\n\n- `wchar_t`类型用于表示宽字符。\n- 它的大小通常为2或4字节（取决于平台和编译器），以支持表示多字节字符集（如`UTF-16`或`UTF-32`）。\n- 在`Windows`上，`wchar_t`是2字节，而在一些`Unix`系统上，`wchar_t`是4字节。\n- `wchar_t`支持`Unicode`字符集，使其能够表示几乎所有语言的字符。\n\n```C++\nint main() {\n    wchar_t wide_char = L\'你\'; // 使用 L 前缀表示宽字符\n    wcout<<L"Wide character:"<<wide_char<<endl;\n    return 0;\n}\n```\n\n### 宽字符串\n\n宽字符串是由宽字符（`wchar_t`）构成的字符串，通常用`wchar_t`数组或`std::wstring`类型表示。宽字符串用于存储由多个`Unicode`字符组成的字符串：\n\n- 宽字符串使用`wchar_t`数组或`wstring`来存储。\n- `wstring`是`C++`标准库中专门为宽字符串设计的容器类，具有与`string`类似的接口。\n- 宽字符串使用`L`前缀，例如`L"hello"`。\n\n```C++\nint main() {\n    wstring wide_str = L"你好，世界！"; // 宽字符串\n    wcout<<L"Wide string: "<<wide_str<<endl;\n    return 0;\n}\n```\n\n### 宽流\n\n宽流是用于处理宽字符（`wchar_t`）的流类型。C++提供了宽流`wcin`、`wcout`、`wcerr`和`wclog`，分别用于标准输入、标准输出、标准错误输出和日志输出：\n\n- 宽流基于`C++`的流机制，支持宽字符类型的数据输入和输出。\n- `wcin`是宽字符版的`cin`，用于从标准输入读取宽字符。\n- `wcout`是宽字符版的`cout`，用于向标准输出写入宽字符。\n- `wclog`和`wcerr`类似于`wcout`和`wcerr`，但用于日志输出和错误输出。\n\n```C++\nint main() {\n    wcout<<L"请输入一个宽字符字符串："<<endl;\n    wstring input;\n    wcin>>input; // 从标准输入读取宽字符字符串\n    wcout<<L"你输入的字符串是："<<input<<endl;\n    return 0;\n}\n```\n\n### C++ 中的宽字符与多字节字符转换\n\n`C++`标准库提供了一些工具来进行宽字符和多字节字符（如`char`）之间的转换。常用的转换函数包括：\n\n- `mbstowcs()`：将多字节字符数组转换为宽字符数组。\n- `wcstombs()`：将宽字符数组转换为多字节字符数组。\n- `wstring_convert`：C++11提供的类，用于在宽字符和多字节字符之间进行转换。\n\n## 5.对象的串行化\n\n对象的串行化（或序列化）是指将对象的状态转换为一种可存储或传输的格式，通常是字节流。这使得对象可以在不同的程序、不同的计算机或不同的进程间进行传递，并且可以在稍后的时间反序列化（`deserialize`）为原始对象。\n\n对象串行化的常见用途包括：\n\n- 存储对象（如将对象保存到文件或数据库中）。\n- 在网络上传输对象（如通过`HTTP`、`TCP/IP`协议传输数据）。\n- 跨平台传输（确保对象在不同的操作系统或硬件架构间传递时能够正确还原）。\n\n### 序列化的常见方法\n\n1. 使用`ostream`和`istream`进行流序列化：\n   最常见的对象串行化方式是通过C++标准流（`ostream`和`istream`）来操作数据。可以将对象的每个成员变量按顺序写入输出流，再通过输入流读取并还原对象。\n\n2. 手动序列化与反序列化：\n\n   在简单情况下，可以手动编写函数，将对象的每个成员变量以一种特定的格式（如二进制格式或文本格式）写入流中。反序列化时，再从流中读取数据并恢复成原对象。'
                      },
                      { id: 'advanced_programming-9', 
                        title: '12、异常处理', 
                        desc: '', 
                        content: '\n# 第十二章-异常处理\n\n## 1.异常处理的基本思想\n\n<img src="./pictures/image-20241228154507354.png">\n\n## 2.C++异常处理的实现\n\n### 异常处理的语法\n\n`try`语句块用于包围可能抛出异常的代码。如果代码中的某个部分发生了异常，控制流会跳到相应的`catch`语句中。\n\n`catch`用于捕获并处理`try`语句块抛出的异常。每个`catch`语句块都可以指定一个特定的异常类型，程序会依照异常类型跳转到相应的`catch`语句块中进行处理。\n\n```C++\ntry {\n    // 可能发生异常的代码\n    // 例如：除数为零、数组越界、空指针解引用等\n}catch(exception_type1 &e) {\n    // 处理 exception_type1 类型的异常\n}catch(exception_type2 &e) {\n    // 处理 exception_type2 类型的异常\n}\n```\n\n`throw`用于抛出一个异常。当程序检测到错误或特殊情况时，可以通过`throw`语句将异常抛出，并跳转到与之匹配的`catch`语句。\n\n```C++\nthrow SomeException("An error occurred");\n```\n\n在`C++`中，异常通常是通过类对象传递的，因此大多数异常对象都是`exception`类或其派生类的实例。通过继承`exception`类，可以创建自定义异常类型。\n\n```C++\nclass MyException: public exception {\npublic:\n    const char* what() const noexcept override {\n        return "My custom exception";\n    }\n};\ntry {\n    throw MyException();\n}catch(const MyException &e) {\n    cout<<e.what()<<endl; // 输出：My custom exception\n}\n```\n\n### 异常接口声明\n\n使用`noexcept`声明一个函数时，表示该函数不会抛出异常。`noexcept`还可以用于表达式。\n\n`exception`类定义了一个`what()`成员函数，它返回异常的描述信息。\n\n可以通过`is_nothrow_invocable`来检查一个函数是否会抛出异常。\n\n```C++\nvoid func() noexcept; // 函数不抛出异常\nvoid func2() noexcept(false){ // 函数可能抛出异常\n    throw runtime_error("An error occurred");\n}\nint main() {\n    f();\n    try {\n        g(); // 可能抛出异常\n    }catch(const exception& e) {\n        cout<<e.what()<<endl;\n    }\n    cout<<is_nothrow_invocable_v<decltype(func)><<endl; // 输出 1\n    cout<<is_nothrow_invocable_v<decltype(func2)><<endl; // 输出 0\n    return 0;\n}\n```\n\n可以通过继承`exception`类来自定义异常类型。在自定义的异常类中，可以重载 `what()`函数以提供更多的信息。\n\n```C++\nclass MyException: public exception {\npublic:\n    const char* what()const noexcept override {\n        return "My custom exception";\n    }\n};\ntry {\n    throw MyException();\n}catch(const MyException& e) {\n    cout<<"Caught custom exception: "<<e.what()<<endl;\n}\n```\n\n<img src="./pictures/image-20241228154622058.png">\n\n## 3.异常处理中的构造与析构\n\n找到一个匹配的`catch`异常处理后：\n\n- 如果`catch`子句的异常声明是一个值参数，则其初始化方式是复制被抛出的异常对象。\n- 如果`catch`子句的异常声明是一个引用，则其初始化方式是使该引用指向异常对象。\n\n异常被抛出后，栈的展开过程开始。\n\n从进入`try`块(与截获异常的`catch`子句相对应的那个`try`块)起，到异常被抛出前，这期间在栈上构造（且尚未析构）的所有对象都会被自动析构，析构的顺序与构造的顺序相反。'
                      },
                  ]
                },
                { id: 'data_structure', title: '数据结构A', icon: 'fas fa-braille', desc: '<p>前排提示: 本人没正式修过这门课，请谨慎使用。</p><p>3.5学分上出11.4学分的感觉。</p>',
                  chapters: [
                      { id: 'data_structure-1', 
                        title: '1、基本概念', 
                        desc: '', 
                        content: '# 1.基本概念\n\n## 1.1数据结构的定义\n\n用计算机解决一个具体问题的步骤：\n\n1. 分析问题，确定数据模型。\n2. 设计相应的算法。\n3. 编写程序，运行并调试程序，直至得到正确的结果。\n\n**数据（data）**：描述客观事物的数和字符的集合。\n\n**数据项（data item）**：具有独立含义的数据最小单位，也称为字段或域。\n\n**数据对象（data object）**：指性质相同的数据元素的集合，它是数据的一个子集。\n\n**数据结构（data structure）**：指所有数据元素以及数据元素之间的关系，可以看作是相互之间存在着某种特定关系的数据元素的集合。\n\n**数据结构=数据+结构**\n\n数据的结构通常包括：\n\n1. **数据的逻辑结构（logical structure）**：由数据元素之间的逻辑关系构成。\n2. **数据的存储结构（storage structure）**：数据元素及其关系在计算机存储器中的存储表示，也称为数据的物理结构（physical structure）。\n3. **数据的运算（operation）**：施加在该数据上的操作。\n\n### 1.1.1逻辑结构\n\n**数据的逻辑结构是从数据元素的逻辑关系上描述数据的，是指数据元素之间的逻辑关系的整体，通常是从求解问题中提炼出来的**。\n\n#### 逻辑结构的表示\n\n1. 图表表示\n2. 二元组表示：`<x,y>`表示元素`x`和`y`之间是相邻的，`x`为`y`的直接前驱元素，`y`为`x`的直接后继元素。\n\n#### 逻辑结构的类型\n\n1. 集合\n2. 线性结构\n3. 树形结构\n4. 图形结构\n\n### 1.1.2存储结构\n\n**数据逻辑结构在计算存储器中的存储表示称为数据的存储结构（也称为映像），也就是逻辑结构在计算机中的存储实现**。\n\n#### 顺序存储结构\n\n是采用一组连续的存储单元存放所有的数据元素，**所有数据元素在存储器中占有一整块存储空间**，**两个逻辑上相邻的元素在存储器中的存储位置也相邻**。\n\n优点：\n\n1. 存储效率高，存储单元全用于存放数据元素，元素之间的逻辑关系没有占用额外的存储空间。\n2. 可实现元素的随机存取。\n\n缺点：\n\n1. 不便于数据修改。\n\n#### 链式存储结构\n\n每个逻辑元素用一个内存结点存储，每个结点是单独分配的，所有的结点地址不一定是连续的，**所以无须占用一整块存储空间**。**给每个结点附加指针域**，**用于存放相邻结点的存储地址**。\n\n优点：\n\n1. 便于数据修改。\n\n缺点：\n\n1. 空间的利用率较低。\n2. 不能对元素进行随机存取。\n\n#### 索引存储结构\n\n存储数据元素信息的同时还建立附加的索引表。**存储所有数据元素信息的表称为主数据表**，**每个数据元素有一个关键字和对应的存储地址**。\n\n索引项一般是**关键字→地址**。通常，索引表中的所有索引项是按关键字有序排列的，利用这个性质，可以快速根据关键字查找到主数据表中的对应元素。\n\n优点：\n\n1. 查找效率高。\n\n缺点：\n\n1. 增加了索引表的空间开销。\n\n#### 哈希（或散列）存储结构\n\n根据元素的关键字通过哈希（或散列）函数直接计算出一个值，并将这个值作为该元素的存储地址。\n\n优点：\n\n1. 查找速度快\n\n### 1.1.3数据运算\n\n**数据运算是指对数据实施的操作**。\n\n包括：**检索**、**插入**、**删除**、**更新**和**排序**等。\n\n#### 运算定义\n\n运算功能的描述，是抽象的，是基于逻辑结构的。\n\n#### 运算实现\n\n完成运算的实现方法，是具体的，是基于存储结构的。\n\n**逻辑结构（运算定义）--映射->存储结构（运算实现）**\n\n对于一种数据结构，其逻辑结构总是唯一的，但它可能对应多种存储结构，并且在不同的存储结构中同一运算的实现过程可能不同。\n\n### 1.1.4数据类型和抽象数据类型\n\n#### 数据类型\n\n**一组性质相同的值的集合和定义在此集合上的一组操作的总称，是某种程序设计语言中已实现的数据结构**。\n\n1. **基本数据类型（也被称为自动变量）**：系统自动为变量分配一个固定长度的存储空间，当超出其作用范围时系统自动释放其内存空间。\n2. **指针类型**\n3. **数组类型**\n4. **结构体类型**\n5. **共用体类型**\n6. **自定义类型**\n\n#### 存储空间的分配\n\n1. **静态存储空间分配方式**：在程序编译期间分配固定的存储空间的方式：在变量定义时就分配存储单元并一直保持不变，直至整个程序结束。\n\n2. **动态存储空间分配方式**：在程序运行期间根据需要动态地分配存储空间的方式：可以用`malloc()/free()`函数分配和释放空间。\n\n   ```c++\n   char* p;\n   p=(char &)malloc(10*sizeof(char));\n   strcpy(p,"China");\n   free(p);\n   ```\n\n   一定要用`free()`释放内存，否则动态分配的空间对于程序而言就丢失了，可能造成内存泄露。\n\n#### 抽象数据类型\n\n**指用户进行软件系统设计时从问题的数学模型中抽象出来的逻辑数据结构和逻辑数据结构上的运算，而不考虑计算机的具体存储结构和运算的具体实现算法**。\n\n一个抽象数据类型可用$(D,S,P)$三元组表示。其中，$D$是数据对象，$S$是$D$上的关系集，$P$是$D$中数据运算的基本运算集。\n\n例如，一个复数的抽象数据类型`Complex`定义如下：\n$$\\begin{align}&ADT~Complex\\\\{\\\\\\\\\n&数据对象:\\\\\\\\\n&\\\\quad\\\\quad D=\\\\{e_1,e_2|e_1,e_2均为实数\\\\}\\\\\\\\\n&数据关系:\\\\\\\\\n&\\\\quad\\\\quad R=\\\\{<e_1,e_2>|e_1是复数的实数部分，e_2是复数的虚数部分\\\\}\\\\\\\\\n&基本运算:\\\\\\\\\n&\\\\quad\\\\quad AssignComplex(\\\\&z,v_1,v_2):构造复数z，其实部和虚部分别为参数v_1和v_2的值。\\\\\\\\\n&\\\\quad\\\\quad DestroyComplex(\\\\&z):销毁复数z。\\\\\\\\\n&\\\\quad\\\\quad GetReal(z,\\\\&real):用real返回复数z的实部值。\\\\\\\\\n&\\\\quad\\\\quad GetImag(z,\\\\&imag):用imag返回复数z的虚部值。\\\\\\\\\n&\\\\quad\\\\quad Add(z_1,z_2,\\\\&sum):用sum返回两个复数z_1、z_2相加的结果。\\\\\\\\\n&\\\\}\n\\end{align}\n$$\n**重要特征**\n\n1. 数据抽象：指用`ADT`描述程序处理的实体时强调的是其本质的特征、其所能完成的功能以及它和外部用户的接口（即外界使用它的方法）。\n2. 数据封装：指将实体的外部特性和其内部实现细节分离，并且对外部用户隐藏其内部实现细节。\n\n抽象数据类型需要通过固有数据类型来实现。\n\n## 1.2算法及其描述\n\n### 1.2.1算法\n\n**算法是对特定问题求解步骤的一种描述，它是指令的有限序列**。\n\n**算法的特性**：\n\n1. **有穷性**：有穷步和有穷时间。\n2. **确定性**：不能有二义性。\n3. **可行性**：所有操作都必须足够基本。\n4. **有输入**：有零个或多个输入。\n5. **有输出**：有与输入对应关系的量值。有一个或者多个输出。\n\n### 1.2.2算法设计的目标\n\n1. **正确性**：最重要且最基本。\n2. **可使用性**：用户友好性。\n3. **可读性**：清晰，简单，结构化。\n4. **健壮性**：容错性高。\n5. **高效率与低存储量需求**：一定程度上取决于问题的规模。\n\n### 1.2.3算法描述\n\n这里采用`C/C++`语言来描述算法，通常是`C/C++`函数。\n\n## 1.3算法分析\n\n### 1.3.1算法分析概述\n\n分析算法占用计算机资源的多少，即占用`CPU`时间（时间性能分析）和内存空间（空间性能分析）。\n\n### 1.3.2算法时间性能分析\n\n#### 两种算法时间性能分析方法\n\n- **事后统计法**\n  统计实际执行时间，必须执行程序，存在很多因素掩盖算法本质。\n- **事前估算法**\n  依赖问题的规模，或者说算法的执行时间是问题规模的函数。主要采用这种方法分析时间性能。\n\n#### 算法时间复杂度分析\n\n1. **计算算法的频度$T(n)$**\n\n   一个算法是由控制结构（顺序、分支和循环3种）和原操作（指固有数据类型的操作）构成的。\n\n   ```c++\n   void fun(int a[], int n) {\n       int i;                  // p1\n       for(i = 0; i < n; ++i)  // p2\n       a[i] = 2 * i;           // p3\n       for(i = 0; i < n; ++i)  // p4\n       printf("%d", a[i]);     // p5\n       puts("");               // p6\n   }\n   ```\n\n   上述语句中`p1`，`p3`，`p5`，`p6`就是原操作。\n\n   **一个算法的执行时间可以由其中原操作的执行次数来计量**。\n\n   算法时间分析的就是求出算法所有原操作的执行次数（也称为频度），它是问题规模$n$的函数，用$T(n)$表示。\n\n   算法执行时间大致等于原操作所需的时间$\\times T(n)$。\n\n2. **$T(n)$用$O$表示**\n\n   算法时间复杂度就是用$T(n)$的数量级来表示，记作$T(n)=O(f(n))$。\n   严格数学定义是$T(n)$的数量级表示为$O(f(n))$，是指存在着正常量$c$和$n_0$(一个足够大的正整数)，使得$\\lim_{x \\to n_0} \\frac{|T(n)|}{|f(n)|} =c\\neq0$\n   通常\n   $$\n   O(1)<O(log_2n)<O(n)<O(nlog_2n)<O(n^2)<O(n^3)<O(2^n)<O(n!)\n   $$\n   $O(log_2n)、O(n)、O(nlog_2n)、O(n^2)、O(n^3)$称为**多项式时间复杂度**，$O(2^n)、O(n!)$称为**指数时间复杂度**。\n\n   一个问题可以通过**多项式时间复杂度**求解，则称为`P`问题，可以通过**指数时间复杂度**求解，则称为`NP`问题。\n\n3. **简化的算法时间复杂度分析**\n\n   即仅仅考虑算法中的基本操作，也就是最深层循环内的原操作。算法执行时间大致等于基本操作所需的时间$\\times$其运算次数。\n\n4. **时间复杂度定理**\n\n   **求和定理**：设$T_1(n)=O(f(n)),T_2(n)=O(g(n))$，那么先执行第一部分再执行第二部分的总执行时间是$T_1(n)+T_2(n)=O(MAX(f(n),g(n)))$，例如多个并列循环就属于这种情况。\n\n   **求积定理**：设$T_1(n)=O(f(n)),T_2(n)=O(g(n))$，那么$T_1(n)\\times T_2(n)=O(f(n)\\times g(n))$，例如多层嵌套循环就属于这种情况。\n\n#### 算法的最好、最坏和平均时间复杂度\n\n- **平均时间复杂度**\n  设$I$是所有输入的集合$D_n$中的一个，$P(I)$是$I$出现的频率，$T(I)$是算法在输入$I$下所执行的基本操作次数，则该算法的平均时间复杂度定义为\n  $$\n  E(n)=\\\\sum_{I\\\\in D_n}P(I)\\\\times T(I)\n  $$\n\n- **最好时间复杂度**\n  $B(n)=MIN_{I\\\\in D_n}\\\\{T(n)\\\\}$\n\n- **最坏时间复杂度**\n  $W(n)=MAX_{I\\\\in D_n}\\\\{T(n)\\\\}$\n\n#### 递归算法时间复杂度分析\n\n参考如下例：\n\n```c++\nvoid fun(int a[], int n, int k) {\n    int i;\n    if(k == n - 1) {\n        for(i = 0; i < n; ++i) printf("%d", a[i]);\n    }\n    else {\n        for(i = k; i < n; ++i)a[i] = a[i] + i * i;\n        fun(a, n, k + 1);\n    }\n}\n```\n\n设$fun(a,n,k)$的执行时间为$T(n,k)$，$T(n)=T(n,0)$，且令$T(n,n)=n$，则当$k<n-1$时：\n$$\nT(n,k)=(n-k)+T(n,k+1)\n$$\n易得：\n$$\nT(n)=\\\\frac{n^2}{2}+\\\\frac{3n}{2}-1=O(n^2)\n$$\n\n### 1.3.3算法空间性能分析\n\n#### 算法空间复杂度分析\n\n**算法空间复杂度**是对一个算法在运行过程中临时占用得存储空间大小的量度，一般只考察临时变量所占的空间。一般也作为问题规模$n$的函数，以数量级形式给出，记作：\n$$\nS(n)=O(g(n))\n$$\n其中$O$的含义与时间复杂度中的含义相同。\n\n若所需临时空间相对于问题规模来说是常数，则称此算法为**原地工作**算法或**就地工作**算法。\n\n#### 递归算法空间复杂度分析\n\n分析方法与时间复杂度分析类似。\n\n## 1.4数据结构+算法=程序\n\n略' 
                      },
                      { id: 'data_structure-2', 
                        title: '2、线性表及其逻辑结构', 
                        desc: '', 
                        content: '# 2.线性表\n\n## 2.1线性表及其逻辑结构\n\n### 2.1.1线性表的定义\n\n**线性表**是具有相同特性的数据元素的一个有限序列。一般表示为$(a_1,a_2,...,a_i,...,a_n)$。\n\n线性表用二元组表示为$L=(D,R)$，其中：\n$$\nD=\\\\{a_i|1\\\\le i\\\\le n,n\\\\ge 0,a_i为ElemType类型\\\\}$$$$\nR=\\\\{r\\\\}$$$$\nr=\\\\{<a_i,a_{i+1}>|1\\\\le i \\\\le n-1\\\\}\\\\\\\\\n$$\n特性：\n\n1. **有穷性**：一个线性表中的元素个数是有限的。\n2. **一致性**：一个线性表中所有元素的性质相同。从实现的角度看，所有元素具有相同的数据类型。\n3. **序列性**：一个线性表中所有元素之间的相对位置是线性的，即存在唯一的开始元素和终端元素，除此之外，每个元素只有唯一的前驱元素和后继元素。各元素在线性表中的位置只取决于它们的序号，所以在一个线性表中可以存在两个值相同的元素。\n\n### 2.1.2线性表的抽象数据类型描述\n\n$$\n\\begin{align}\n&ADT~List\\\\{\\\\\\\\\n&数据对象:\\\\\\\\\n&\\\\quad\\\\quad D=\\\\{a_i|1\\\\le i\\\\le n,n\\\\ge0,a_i为ElemType类型\\\\}\\\\\\\\\n&数据关系:\\\\\\\\\n&\\\\quad\\\\quad R=\\\\{<a_i,a_{i+1}>|a_i、a_{i+1}\\\\in D,i=1,\\\\ldots ,n-1\\\\}\\\\\\\\\n&基本运算:\\\\\\\\\n&\\\\quad\\\\quad InitList(\\\\&L):初始化线性表，构造一个空的线性表L。\\\\\\\\\n&\\\\quad\\\\quad DestroyList(\\\\&L):销毁线性表，释放线性表L占用的内存空间。\\\\\\\\\n&\\\\quad\\\\quad ListEmpty(L):判断线性表是否为空表，若L为空表，则返回真，否则返回假。\\\\\\\\\n&\\\\quad\\\\quad ListLength(L):求线性表的长度，返回L中元素的个数。\\\\\\\\\n&\\\\quad\\\\quad DispList(L):输出线性表，当线性表L不为空时顺序显示L中各结点的值域。\\\\\\\\\n&\\\\quad\\\\quad //余下略\\\\\\\\\n&\\\\}\\\\\\\\\n\\end{align}\n$$\n\n## 2.2线性表的顺序存储结构\n\n**存储密度**：**指结点中数据元素本身所占的存储量和整个结点占用的存储量之比**。顺序表的存储密度比较高，通常为$1$。而链表的存储密度小于$1$，单链表的存储密度为$50\%$。\n\n### 2.2.1线性表的顺序存储结构——顺序表\n\n参考`seqList.cpp`\n\n## 2.3线性表的链式存储结构\n\n### 2.3.1线性表的链式存储结构——链表\n\n参考`doublyLinkedList.cpp`\n\n## 2.4线性表的应用\n\n书中给出的例子是两个表的**自然连接**，这里只介绍**自然连接**的定义。\n$$\n\\\\boldsymbol A=\\\\begin{array}{l}\n1&2&3\\\\\\\\\n2&3&3\\\\\\\\\n1&1&1\\\\\\\\\n\\\\end{array}\n\\\\quad\\\\quad\\\\quad\n\\\\boldsymbol B=\\begin{array}{l}\n3&5\\\\\\\\\n1&6\\\\\\\\\n3&4\\\\\\\\\n\\end{array}\n$$\n$\\boldsymbol A$的第三列和$\\boldsymbol B$的第一列实现自然连接，实现为$\\boldsymbol A$的第一行分别与$\\boldsymbol B$的第一行、第三行连接；$\\boldsymbol A$的第二行分别与$\\boldsymbol B$的第一行、第三行连接，以此类推。\n\n得到的表是：\n$$\n\\\\boldsymbol C=\\begin{array}{l}\n1&2&3&3&5\\\\\\\\\n1&2&3&3&4\\\\\\\\\n2&3&3&3&5\\\\\\\\\n2&3&3&3&4\\\\\\\\\n1&1&1&1&6\\\\\\\\\n\\end{array}\n$$\n\n## 2.5有序表\n\n**有序表**是所有元素递增或递减有序排列的线性表。\n\n#### 2.5.1有序表的抽象数据类型描述\n\n$$\n\\begin{align}\n&ADT~List\\\\{\\\\\\\\\n&数据对象:\\\\\\\\\n&\\\\quad\\\\quad D=\\\\{a_i|1\\\\le i\\\\le n,n\\\\ge0,a_i为ElemType类型\\\\}\\\\\\\\\n&数据关系:\\\\\\\\\n&\\\\quad\\\\quad R=\\\\{<a_i,a_{i+1}>|a_i、a_{i+1}\\\\in D且a_i\\\\le a_{i+1},i=1,\\\\ldots ,n-1\\\\}\\\\\\\\\n&基本运算:\\\\\\\\\n&\\\\quad\\\\quad InitList(\\\\&L):初始化线性表，构造一个空的线性表L。\\\\\\\\\n&\\\\quad\\\\quad DestroyList(\\\\&L):销毁线性表，释放线性表L占用的内存空间。\\\\\\\\\n&\\\\quad\\\\quad ListEmpty(L):判断线性表是否为空表，若L为空表，则返回真，否则返回假。\\\\\\\\\n&\\\\quad\\\\quad ListLength(L):求线性表的长度，返回L中元素的个数。\\\\\\\\\n&\\\\quad\\\\quad DispList(L):输出线性表，当线性表L不为空时顺序显示L中各结点的值域。\\\\\\\\\n&\\\\quad\\\\quad //余下略\\\\\\\\\n&\\\\}\\\\\\\\\n\\end{align}\n$$\n\n#### 2.5.2有序表的存储结构及其基本运算方法\n\n在插入元素方法上，是从头扫描顺序表$L$，通过比较插入位置$i$，实现插入元素，具体不介绍。\n\n#### 2.5.3有序表的归并算法\n\n**二路归并**\n\n即同时遍历两个有序表，将其中较小值放入一个新的线性表，实现比较简单。\n\n#### 2.5.4有序表的应用\n\n略。' 
                      },
                      { id: 'data_structure-3', 
                        title: '3、栈和队列', 
                        desc: '', 
                        content: '# 3.栈和队列\n\n## 3.1栈\n\n### 3.1.1栈的定义\n\n**栈是一种只能在一端进行插入或删除操作的线性表**。\n\n### 3.1.2栈的顺序存储结构及其基本运算的实现\n\n参考`seqStack.cpp`\n\n### 3.1.3栈的链式存储结构及其基本运算的实现\n\n参考`linkedStack.cpp`\n\n### 3.1.4栈的应用\n\n- 中、后缀表达式求值。\n- 深度优先搜索。\n\n## 3.2队列\n\n### 3.2.1队列的定义\n\n**队列是一种操作受限的线性表，仅允许在表的一端进行插入操作，而在表的另一端进行删除操作**。\n\n### 3.2.2队列的顺序存储结构及其基本运算的实现\n\n- 顺序队列\n\n  参考`seqQueue.cpp`\n\n- 环形队列。\n\n  参考`seqCircleQueue.cpp`\n\n### 3.2.3队列的链式存储结构及其基本运算的实现\n\n参考`linkedQueue.cpp`\n\n### 3.2.4队列的应用\n\n- 求解报数问题。\n- 广度优先搜索。\n\n### 3.2.5双端队列\n\n参考`deque.cpp`' 
                      },
                      { id: 'data_structure-4', 
                        title: '4、串', 
                        desc: '', 
                        content: '# 4.串\n\n## 4.1串的基本概念\n\n**串是由零个或多个字符组成的有限序列**。\n\n含零个字符的串称为**空串**。\n\n**两个串相等**当且仅当长度相等且各个位置上字符都相同。\n\n一个串中任意个连续字符组成的序列称为该串的**子串**。\n\n\n## 4.2串的存储结构\n\n和线性表一样，串也有顺序存储结构和链式存储结构。前者叫**顺序串**，后者叫**链串**。\n\n### 4.2.1串的顺序存储结构——顺序串\n\n顺序串中的字符被依次存放在一组连续的存储单元里。一般一个字节表示一个字符。而计算机内存是按字编址的，即以字为存储单位，一个字包含的字节数随机器而异。\n\n顺序串的存储方式有两种：\n\n1. **非紧缩格式**（其存储密度小）：每个字只存一个字符。\n   比较浪费存储空间，但处理单个字符或者一组连续字符方便。\n2. **紧缩格式**（其存储密度大）：每个字存放多个字符。\n   节省存储空间，但处理单个字符不太方便，运算效率低，需要花费时间从同一个字中分离字符。\n\n我们主要讨论**非紧缩格式**。\n\n参考`seqString.cpp`\n\n### 4.2.2串的链式存储结构——链串\n\n串采用链式存储结构存储时称为**链串**。\n\n链串的组织形式与一般的单链表类似，主要区别在于链串中的一个结点可以存储多个字符。\n\n通常将链串中每个结点所存储的字符个数称为**结点大小**。\n\n当结点大小大于$1$时，会在链串尾结点未占满的数据域里补上不属于字符集的特殊符号（例如`#`）\n\n1. 结点大小较大：存储密度较大，但一些基本操作(如插入、删除、替换)有所不便。\n\n   适合串很少修改的情况。\n\n2. 结点大小较小：相关操作的实现方便，但存储密度下降。\n\n我们主要讨论链串结点大小为$1$。\n\n参考`listedString.cpp`\n\n## 4.3串的模式匹配\n\n### 4.3.1Brute-Force算法\n\n暴力，无需多言。\n\n### 4.3.2KMP算法\n\n通过分析模式串$t$从中提取出加速匹配的有用信息，这种信息是对于$t$的每个字符$t_j(0\\le j\\le m-1)$存在一个整数$k(k<j)$，使得模式串$t$中开头的$k$个字符$(t_0t_1\\dots t_{k-1})$依次与$t_j$的前面$k$个字符$(t_{j-k}t_{j-k+1}\\dots t_{j-1})$相同。如果有多个这样的$k$则取较大的$k$。\n\n模式串$t$中每个位置$j$的字符都有这种信息，记为$nxt[j]$。\n\n**$nxt$数组的求解过程**：\n\n1. $nxt[0]=-1,nxt[1]=0(j=0)$\n2. 如果$nxt[j]==k$，表示有"$t_0t_1\\dots t_{k-1}$"$=$"$t_{j-k}t_{j-k+1}\\dots t_{j-1}$"。\n   若$k==-1$或$t_k==t_j$，也就是"$t_0t_1\\dots t_{k-1}t_{k}$"$=$"$t_{j-k}t_{j-k+1}\\dots t_{j-1}t_{j}$"，于是$nxt[++j]=++k$。\n   若$t_k\\ne t_j$，应当试图匹配一个较短的子串，则$k=nxt[k]$。\n\n**$KMP$算法的匹配过程**：\n\n设目标串$s=$"$s_0s_1\\dots s_{n-1}$"，模式串$t=$"$t_0t_1\\dots t_{m-1}$"，在进行第$i-j+1$趟匹配(从$s_{i-j}$开始)时出现失配情况($s_i\\ne t_j$)。\n\n这时的部分匹配是"$t_0t_1\\dots t_{j-1}$"$=$"$s_{i-j}s_{i-j+1}\\dots s_{i-1}$"，又有$nxt[j]=k$，说明"$t_0t_1\\dots t_{k-1}$"$=$"$t_{j-k}t_{j-k+1}\\dots t_{j-1}$"，因此"$t_0t_1\\dots t_{k-1}$"$=$"$s_{i-k}s_{i-k+1}\\dots s_{i-1}$"。下一趟就不再从$s_{i-j+1}$开始匹配，而是$s_{i-k}$开始匹配，并且将$s_i$和$t_k$比较，这样就可以把第$i-j+1$趟比较适配时的模式串$t$从当前位置直接右滑$j-k$个字符。\n\n从而执行过程如下：\n\n1. $j=-1或s[i]==t[j]$，则$++i,++j$。\n2. 否则$j=nxt[j]$。\n3. 直至$j>=t.length()$，匹配位置就是$i-t.length()$。\n\n我们发现，若按照前面求$nxt$的步骤，得到$nxt[j]=k$，在模式串中有$t_j=t_k$，当目标串中的字符$s_i$和模式串中的字符$t_j$比较不相同时，$s_i$一定和$t_k$也不相同，所以没必要再将$s_i$和$t_k$进行比较，而是直接将$s_i$和$t_{nxt[k]}$比较，为此将$nxt[j]$修正为$nxtval[j]$。\n\n**$nxtval$数组的求解过程**：\n\n1. $nxtval[0]=-1,nxtval[1]=0(j=0)$\n2. 若$k==-1$或$t_k==t_j$，则$++j,++k$，如果$t_j\\ne t_k$，则$nxtval[j]=k$，否则$nxtval[j]=nxtval[k]$。\n   若$t_k\\ne t_j$，应当试图匹配一个较短的子串，则$k=nxtval[k]$。\n\n**时间复杂度**：$O(n+m)$' 
                      },
                      { id: 'data_structure-5', 
                        title: '5、递归', 
                        desc: '', 
                        content: '# 5.递归\n\n## 5.1什么是递归\n\n### 5.1.1递归的定义\n\n**一个过程或函数调用自身**。\n\n### 5.1.2何时使用递归\n\n1. 定义是递归的：将递归定义转化为递归算法。\n2. 数据结构是递归的：例如结点数据结构中指向下一个结点的指针。\n3. 问题求解方法是递归的：无需多言。\n\n### 5.1.3递归模型\n\n可以用树的模型阐释。\n\n### 5.1.4递归与数学归纳法\n\n数学归纳法是递归求解问题的理论基础。\n\n## 5.2栈和递归\n\n### 5.2.1函数调用栈\n\n大多数`CPU`上的程序实现使用栈来支持函数调用操作，**单个函数调用操作所使用的函数调用栈被称为栈帧结构**，每次函数调用时都会相应地创建一帧，保存返回地址、函数实参和局部变量值等，并将该帧压入调用栈。在函数返回前发生新调用，则把新函数对应的一帧进栈，成为栈顶。函数执行完毕，对应的帧便出栈，控制权交还给该函数的上层调用函数。\n\n### 5.2.2递归调用的实现\n\n递归调用在内部实现时并不是每次调用真正去复制一个复制件存放到内存中，而是采用**代码共享**的方式。系统为每一次调用开辟一组**存储单元**，用来存放本次调用的返回地址以及被中断的函数的参数值。这些单元以**栈**的形式存放，每调用一次进栈一次，当返回时执行出栈操作，把当前栈顶保留的值送回相应的参数中进行恢复，并按栈顶中的返回地址从断点继续执行。\n\n*如果习惯断点调试，就很容易理解这个过程*。\n\n### 5.2.3递归到非递归的转换\n\n1. **减少栈溢出**：递归深度过大时，可能会导致栈溢出。对于深递归，使用非递归方法可以避免这个问题。\n2. **提高效率**：递归往往会有额外的函数调用开销，非递归实现可以通过显式的数据结构避免这种开销。\n3. **优化**：某些递归实现效率较低，可以通过非递归的方式优化性能。\n\n通常的做法是显式模拟递归函数的调用过程。这可以通过栈来完成。\n\n## 5.3递归算法的设计\n\n### 5.3.1递归算法设计的步骤\n\n做熟练了哪要记什么步骤呢？\n\n### 5.3.2基于递归数据结构的递归算法设计\n\n这种类型侧重于处理具有树形或类似结构的问题，利用递归来解决。关键点在于数据结构本身支持递归操作，比如树、链表等。\n\n- 特点：\n  - 数据结构本身具有层次性，如树形结构。\n  - 递归用于遍历和处理每个节点或子问题。\n- 例子：\n  - **快速排序**：利用二叉搜索树结构，递归地将数组分成两部分，分别排序后合并。\n  - **归并排序**：通过递归地比较子列表并将它们合并，最终得到有序的列表。\n\n### 5.3.3基于递归求解方法的递归算法设计\n\n这种类型更注重如何利用递归来分解问题，寻找答案，而不论数据结构复杂性。这适用于所有类型的问题，不一定涉及复杂的数据结构。\n\n- 特点：\n  - 递归用于分解问题到更小的子问题，逐步解决。\n- 例子：\n  - **计算阶乘**：递归地将$n$分解为$n\\times (n-1)\\times...\\times 1$。\n  - **斐波那契数列**：递归地将问题分解为更小的两个问题，然后合并结果。' 
                      },
                      { id: 'data_structure-6', 
                        title: '6、数组和广义表', 
                        desc: '', 
                        content: '# 6.数组和广义表\n\n## 6.1数组\n\n### 6.1.1数组的基本概念\n\n从逻辑结构上看，一维数组$A$是$n(n>1)$个相同类型数据元素$a_1,a_2,\\dots ,a_n$构成的有限序列，其逻辑表示如下：\n$$\nA=(a_1,a_2,\\\\dots,a_n)\n$$\n其中，$a_i(1\\le i\\le n)$表示数组$A$的第$i$个元素。\n\n多维数组可以看作一个由$d-1$维数组作为数据元素的线性表。\n\n$d$维数组的抽象数据类型：\n$$\n\\begin{align}\n&ADT~Array\\\\{\\\\\\\\\n&数据对象:\\\\\\\\\n&\\\\quad\\\\quad D=\\\\{a_{j_1,j_2,\\\\dots,j_d}|j_i=1,\\\\dots,b_i,i=1,2,\\\\dots,d\\\\}\\\\\\\\\n&数据关系:\\\\\\\\\n&\\quad\\quad R=\\\\{r_1,r_2,\\\\dots,r_d\\\\}\\\\\\\\\n&\\quad\\quad r_i=\\\\{<a_{j_1\\\\dots j_i\\\\dots j_d},a_{j_1\\\\dots j_i+1\\\\dots j_d}>|1\\\\le j_k\\\\le b_k,1\\\\le k\\\\le d且k\\\\ne i,1\\\\le j_i\\\\le b_i-1,i=2,\\\\dots,d\\\\}\\\\\\\\\n&基本运算:\\\\\\\\\n&\\quad\\quad initarray(\\\\&A):初始化数组，即为数组A分配存储空间\\\\\\\\\n&\\quad\\quad Destroyarray(\\\\&A):销毁数组，即释放数组A的存储空间\\\\\\\\\n&\\quad\\quad Value(A,index_1,index_2,\\\\dots ,index_d):A是已存在的d维数组，index_1,index_2,\\\\dots ,index_d是指定的d维下标，这些下\\\\\\\\&\\quad\\quad 标均在有效范围内.其运算结果是返回由该下标指定的A中的对应元素的值\\\\\\\\\n&\\quad\\quad Assign(A,e,index_1,index_2,\\\\dots ,index_d):A是已存在的d维数组，e为元素变量,index_1、index_2、\\\\dots 、index_d是指\\\\\\\\&\\quad\\quad定的d维下标，这些下标均在有效范围内.其运算结果是将e的值赋给A中由该下标指定的元素\\\\\\\\\n&\\\\}\\\\\\\\\n\\end{align}\n$$\n数组具有以下性质：\n\n1. 元素数目固定。\n2. 元素具有相同数据类型。\n3. 每个数据元素都和一组唯一的下标对应。\n4. 随机存储结构，可随机存取数组中的任意数据元素。\n\n### 6.1.2数组的存储结构\n\n有**按行优先存放**和**按列优先存放**，对应的下标可以由公式推出。\n\n### 6.1.3特殊矩阵的压缩存储\n\n包括**对称矩阵**、**上下三角矩阵**和**对角矩阵**的压缩存储。\n\n相当于把元素映射到一个一维数组上，注意具体下标推导。\n\n## 6.2稀疏矩阵\n\n当一个矩阵非零元素数量远小于矩阵元素总数时，称该矩阵为**稀疏矩阵**。\n\n### 6.2.1稀疏矩阵的三元组表示\n\n通常由一个三元组$(i,j,a_{i,j})$唯一确定，稀疏矩阵中的所有非零元素构成三元组线性表。\n\n一定程度上节省存储空间，但是会丧失随机存取特性。\n\n### 6.2.2稀疏矩阵的十字链表表示\n\n**十字链表**是稀疏矩阵的一种链式存储结构。\n\n我们需要给每个非零元素建立一个数据结点，包含行、列、值，行指针，列指针的信息。\n\n再给每一行，每一列建立一个带头结点的单链表，头结点包括行、列、指向其它头结点的指针，指向行或者列数据的指针。看似第$i$行的头结点和第$i$列的头指针不同，事实上可以把它们合为一个头指针。\n\n最后建立一个总头结点，包含矩阵行列数和指向头结点$h[0]$。\n\n<img src="./pictures/image-20250202155810834.png">\n\n## 6.3广义表\n\n### 6.3.1广义表的定义\n\n**广义表**是线性表的推广，是有限个元素的序列，$GL=(a_1,a_2,\\dots,a_i,\\dots,a_n)$\n\n其中$a_i$可以是**原子**，也可以是**子表**。\n\n定义广义表的**长度**为最外层包含元素的个数，**深度**为层数。\n\n例：$A((a,(a,b),((a,b),c)))$的长度为1，深度为4。\n\n值得注意的是：一个广义表可以是自己的子表，这种广义表称为递归表。递归表的深度是无穷值，而长度是有限值。\n\n### 6.3.2广义表的存储结构\n\n采用链式存储结构。\n\n采用以下结构：\n\n| `tag` | `sublist/data` | `link` |\n| ----- | -------------- | ------ |\n\n1. 若`tag=0`，表示该结点为原子结点，则第2个域为`data`，存放相应原子元素的信息；\n2. 若`tag=1`，表示该结点为表/子表结点，则第2个域为`sublist`，存放相应表/子表中第一个元素对应结点的地址。\n\n当没有兄弟结点时，其`link`域为`NULL`。\n\n### 6.3.3广义表的运算\n\n参考`generalizedTable.cpp`' 
                      },
                      { id: 'data_structure-7', 
                        title: '7、树和二叉树', 
                        desc: '', 
                        content: '# 7.树和二叉树\n\n## 7.1树的基本概念\n\n### 7.1.1树的定义\n\n**树是由$n(n\\ge 0)$个结点(或元素)组成的有限集合(记为T)**。\n\n树的抽象数据类型：\n$$\n\\begin{align}\n&ADT~Tree\\\\{\\\\\\\\\n&数据对象:\\\\\\\\\n&\\quad\\quad D=\\\\{a_{i}|1\\\\le i\\\\le n,n\\\\ge 0,a_i为ElemType类型\\\\}\\\\\\\\\n&数据关系:\\\\\\\\\n&\\quad\\quad R=\\\\{<a_i,a_j>|a_i,a_j\\\\in D,1\\\\le i,j\\\\le n\\\\}\\\\\\\\\n&基本运算:\\\\\\\\\n&\\quad\\quad 略\\\\\\\\\n&\\\\}\\\\\\\\\n\\end{align}\n$$\n\n\n### 7.1.2树的逻辑表示方法\n\n1. **树形表示法**：画图。\n2. **文氏图表示法**：画圈圈。\n3. **凹入表示法**：画条形图，长的为父亲结点。\n4. **括号表示法**：画括号，类似广义表。\n\n### 7.1.3树的基本术语\n\n1. **结点的度与树的度**：分别是某个结点子树的个数和数中所有结点的度的最大值。\n2. **分支结点与叶子结点**：分别是度不为零的结点和度为零的结点。\n3. **路径与路径长度**：分别是任意两个结点连接的结点序列和这个序列长度。\n4. **孩子结点、双亲结点、兄弟结点、子孙结点和祖先结点**：分别是顾名思义。\n5. **结点层次和树的高度**：相当于深度。\n6. **有序树和无序树**：若各结点子树按照一定次序排，则称为有序树，否则为无序树。\n7. **森林**：$n$个互不相交的树的集合称为森林。\n\n### 7.1.4树的性质\n\n1. **数中结点数等于所有结点度数之和加1**。\n2. **度为$m$的树中第$i$层上最多有$m^{i-1}$个结点$(i\\ge 1)$**。\n3. **高度为$h$的$m$次树最多有$\\frac{m^h-1}{m-1}$个结点**。\n4. **具有$n$个结点的$m$次树的最小高度为$\\log_m(n(m-1)+1)$**。\n\n### 7.1.5树的基本运算\n\n1. **寻找满足某种特定条件的结点**。\n2. **插入或删除某个结点**。\n3. **遍历树中的所有结点**：其中**层次遍历**为从上到下、从左到右的次序。\n\n### 7.1.6树的存储结构\n\n1. **双亲存储结构**：每个结点存储值和双亲位置。\n2. **孩子链存储结构**：每个结点存储值和孩子位置。\n3. **孩子兄弟链存储结构**：每个结点存储值和长子位置和下一个兄弟位置。\n\n## 7.2二叉树的概念和性质\n\n### 7.2.1二叉树的定义\n\n无需多言。\n\n### 7.2.2二叉树的性质\n\n1. **非空二叉树上的叶子结点数等于双分支结点数加1**。\n2. **非空二叉树的第$i$层上最多有$2^{i-1}$个结点$(i\\ge 1)$**。\n3. **高度为$h$的二叉树最多有$2^h-1$个结点$(h\\ge 1)$**。\n4. **完全二叉树具有些简单性质**。\n\n### 7.2.3二叉树与树、森林之间的转换\n\n1. **森林、树转换为二叉树**：相邻兄弟之间连线、删除非长子与双亲结点之间的连线。如果是森林，再将每个二叉树根节点相连。\n2. **二叉树还原为树/森林**：逆过程。\n\n## 7.3二叉树的存储结构\n\n### 7.3.1二叉树的顺序存储结构\n\n参考`seqBinaryTree.cpp`。\n\n### 7.3.2二叉树的链式存储结构\n\n参考`linkedBinaryTree.cpp`。\n\n## 7.4二叉树的基本运算及其实现\n\n略。\n\n## 7.5二叉树的遍历\n\n略。\n\n## 7.6二叉树的构造\n\n**任何$n(n\\ge 0)$个不同结点的二叉树，都可由它的中序序列和先序序列唯一地确定**。\n\n示例`createBinaryTree1.cpp`\n\n**任何$n(n\\ge 0)$个不同结点的二叉树，都可由它的中序序列和后序序列唯一地确定**。\n\n示例`createBinaryTree2.cpp`\n\n## 7.7线索二叉树\n\n### 7.7.1线索二叉树的概念\n\n**当某个结点左指针为空时，令该指针指向遍历序列中的前驱结点；当某个结点右指针为空时，令该指针指向遍历序列中的后继结点**。\n\n### 7.7.2线索化二叉树\n\n参考`threadedBinaryTree.cpp`\n\n### 7.7.3遍历线索化二叉树\n\n参考`threadedBinaryTree.cpp`\n\n## 7.8哈夫曼树\n\n### 7.8.1哈夫曼树概述\n\n**带权路径长度(WPL)**：从根结点到该结点之间的路径长度与该结点上权的乘积\n$$\nWPL=\\sum_{i=1}^{n_0}w_il_i\n$$\n**在$n_0$个带权叶子结点构成的所有二叉树中，带权路径长度WPL最小的二叉树称为哈夫曼树或最优二叉树**。\n\n### 7.8.2哈夫曼树的构造算法\n\n如图所示：\n\n<img src="./pictures/image-20250204140123216.png">\n\n**对于具有$n_0$个叶子结点的哈夫曼树，共有$2n_0-1$个结点**。\n\n### 7.8.3哈夫曼编码\n\n参考`haffmanTree.cpp`\n\n## 7.9用并查集求解等价问题\n\n### 7.9.1什么叫并查集\n\n有"关系"的元素被分为一组，这一组可以用树的结构表示，这一组就是**并查集**。\n\n### 7.9.2并查集的算法实现\n\n略，烂熟于心。' 
                      },
                      { id: 'data_structure-8', 
                        title: '8、图', 
                        desc: '', 
                        content: '\n# 8.图\n\n## 8.1图的基本概念\n\n### 8.1.1图的定义\n\n图$G$由两个集合$V$和$E$组成，记为$G=(V,E)$，其中$V$是顶点的有限集合，记为$V(G)$，$E$是连接$V$中两个不同顶点(顶点对)的边的有限集合，记为$E(G)$。\n\n包括**有向图**、**无向图**。\n\n图的抽象数据类型：\n$$\n\\begin{align}\n&ADT~Graph\\\\{\\\\\\\\\n&数据对象:\\\\\\\\\n&\\\\quad\\\\quad D=\\\\{a_{i}|1\\\\le i\\\\le n,n\\\\ge 0,a_i为ElemType类型\\\\}\\\\\\\\\n&数据关系:\\\\\\\\\n&\\\\quad\\\\quad R=\\\\{<a_i,a_j>|a_i,a_j\\\\in D,1\\\\le i,j\\\\le n\\\\}\\\\\\\\\n&基本运算:\\\\\\\\\n&\\\\quad\\\\quad略\\\\\\\\\n&\\\\}\\\\\\\\\n\\\\end{align}\n$$\n\n### 8.1.2图的基本术语\n\n1. **端点和邻接点**：无向图中若存在一条边$(i,j)$，则顶点$i$和$j$为该边的两个**端点**，互为**邻接点**。而在有向图中若存在一条有向边$<i,j>$，则$i$为**起始端点**，$j$为**终止端点**，$j$是$i$的**出边邻接点**，$i$是$j$的**入边邻接点**。\n2. **顶点的度、入度和出度**：略。\n3. **完全图**：无向图每两个顶点之间都存在着一条边或有向图每两个顶点之间都存在方向相反的两条边。\n4. **稠密图和稀疏图**：接近完全图的图和含有较少的边数的图。\n5. **子图**：图$A$是图$B$的子图当且仅当$V_A\\in V_B且E_A\\in E_B$。\n6. **路径和路径长度**：无需多言，只需注意若一条路径除开始点和结束点相同以外其余顶点均不相同，则此路径为**简单路径**。\n7. **回路或环**：一条路径的开始点与结束点为同一个顶点。若这条路径为简单路径则这个回路或环也叫**简单回路**或**简单环**。\n8. **连通、连通图和连通分量**：对于无向图：两个顶点连通当且仅当它们存在路径。若任意两个顶点连通，则这个图是**连通图**。无向图$G$中的极大连通子图称为$G$的**连通分量**。\n9. **强连通图和强连通分量**：对于有向图：若顶点$i$到顶点$j$有路径，则$i$到$j$连通。若有向图中任意两顶点都互相连通，则有向图是**强连通图**。有向图$G$中的极大强连通子图为$G$的强连通分量。\n   在非强连通图中找强连通分量(~~不如 tarjan~~)：\n   1. 找有向环。\n   2. 扩展：如果某顶点到该环一点有路径且该环中任一顶点到这个顶点也有路径，则加入这个顶点。\n10. **权和网**：边上带有权的图称为**带权图**，也称作**网**。\n\n## 8.2图的存储结构和基本运算算法\n\n### 8.2.1邻接矩阵存储方法\n\n无需多言。\n\n### 8.2.2邻接表存储方法\n\n储存每个结点的出度，无需多言。\n\n### 8.2.3图基本运算算法设计\n\n略。\n\n### 8.2.4其他存储方法\n\n1. **十字链表**：（没怎么用过）\n\n   <img src="./pictures/image-20250204163340403.png">\n\n   十字链表是一种用于表示有向图的存储结构。它的基本思想是将图的每条边表示为一个链表节点，同时在每个节点中维护两个链表指针：一个指向该边的起点，另一个指向该边的终点。这种结构适合处理具有有向边的图。\n\n   **十字链表的特点**\n\n   - 十字链表适用于有向图的表示，尤其是在有大量**弯曲的边**和**边的反向遍历**操作时。\n   - 该结构的优点是能同时高效地表示**从某顶点出发的所有边**和**指向某顶点的所有边**。\n   - 它通过交叉链表的方式，避免了对边进行重复存储。\n\n   **十字链表的结构**\n\n   1. **顶点链表**：每个顶点都有一个指向它的出边的链表（**出度链表**）和一个指向它的入边的链表（**入度链表**）。\n   2. **边结点**：每个边结点包含两个指针，一个指向该边的**起点**，另一个指向该边的**终点**。\n\n   ```c++\n   struct EdgeNode {\n       int vertex; // 该边的终点\n       EdgeNode* next; // 下一条边\n   };\n   struct VertexNode {\n       EdgeNode* firstOut; // 出度链表的头指针\n       EdgeNode* firstIn; // 入度链表的头指针\n   };\n   class Graph {\n   public:\n       vector<VertexNode> adjList; // 图的邻接表\n       int vertexCount,edgeCount; // 顶点数和边数\n       Graph(int v) {\n           vertexCount = v;\n           adjList.resize(v);\n           edgeCount = 0;\n       }\n       void addEdge(int start, int end) {\n           EdgeNode* edge1 = new EdgeNode{end, adjList[start].firstOut};\n           adjList[start].firstOut = edge1;\n           EdgeNode* edge2 = new EdgeNode{start, adjList[end].firstIn};\n           adjList[end].firstIn = edge2;\n           edgeCount++;\n       }\n   };\n   ```\n\n2. **邻接多重表**：\n\n<img src="./pictures/image-20250204164203164.png">\n\n邻接多重表（也称为多重邻接表）是一种扩展的邻接表结构，用于表示包含**多重边**或**自环**的图。在普通的邻接表中，每个顶点的邻接表仅包含指向该顶点的**一条边**，而在邻接多重表中，邻接表每个节点会包含多条边。\n\n**邻接多重表的特点**\n\n- 适用于**有重边**和**有自环**的图。\n- 每个顶点的邻接表不仅仅存储指向邻居顶点的单一边，而是存储指向所有邻居顶点的边（如果图中存在多条边，或者一个顶点和其自身之间有边）。\n- 该结构可以有效地表示多重边（即相同顶点之间有多条边）和自环（即一个顶点和自己之间的边）。\n\n**邻接多重表的结构**\n\n1. **邻接表的链表结构**：每个顶点在邻接多重表中有一个链表，这个链表包含多个边节点。\n2. **每个边节点**：边节点包含两个部分：\n   - **目标顶点**（即边的另一个端点）\n   - **边的权值**（如果是加权图）\n\n```c++\nstruct EdgeNode {\n    int vertex;\n    EdgeNode* next;\n    int weight;\n};\nstruct VertexNode {\n    EdgeNode* firstEdge;\n};\nclass Graph {\npublic:\n    vector<VertexNode> adjList;\n    int vertexCount, edgeCount;\n    Graph(int v) {\n        vertexCount = v;\n        adjList.resize(v);\n        edgeCount = 0;\n    }\n    void addEdge(int start, int end, int weight = 0) {\n        EdgeNode* edge = new EdgeNode{end, adjList[start].firstEdge,weight};\n        adjList[start].firstEdge = edge;\n        edgeCount++;\n    }\n    void addUndirectedEdge(int start, int end, int weight = 0) {\n        addEdge(start, end, weight);\n        addEdge(end, start, weight);\n    }\n};\n```\n\n## 8.3图的遍历\n\n### 8.3.1图的遍历的概念\n\n从任意顶点开始每个顶点仅访问一次的遍历。\n\n### 8.3.2深度优先遍历\n\n栈，无需多言。\n\n### 8.3.3广度优先遍历\n\n队列，无需多言。\n\n### 8.3.4非连通图的遍历\n\n对于各个连通分量分别选择初始点进行遍历。其中有向图中可能要再选择初始点。\n\n### 8.3.5图遍历算法的应用\n\n随机应变。\n\n## 8.4生成树和最小生成树\n\n### 8.4.1生成树的概念\n\n一个连通图的**生成树**是一个极小连通子图，其中含有图中的全部顶点和构成一棵树的$n-1$条边。\n\n如果在一棵生成树上添加任何一条边，必定构成一个环。\n\n**图的所有生成树中具有边上的权值之和最小的树称为图的最小生成树**。\n\n### 8.4.2无向图的连通分量和生成树\n\n事实上，如果记录一次合法的**深度优先遍历**经过的边和结点，可以得到一棵生成树，称为**深度优先生成树**，相应地，如果记录一次合法的**广度优先遍历**经过的边和结点，可以得到一棵生成树，称为**广度优先生成树**。\n\n对于非连通图，各个连通分量的生成树组成非连通图的**生成森林**。\n\n### 8.4.3Prim算法\n\n设$G=(V,E)$是一个具有$n$个顶点的带权连通图，$T=(U,TE)$是$G$的最小生成树，其中$U$是$T$的顶点集，$TE$是$T$的边集，则由$G$构造从起始点$v$出发的最小生成树$T$的步骤如下：\n\n1. 初始化$U=\{v\}$，以$v$到其他顶点的所有边为侯选边。\n2. 重复以下步骤$(n-1)$ 次，使得其他$(n-1)$个顶点被加入到$U$中。\n   ①从侯选边中挑选权值最小的边加入$TE$，设该边在$V-U$中的顶点是$k$，将$k$加入$U$中；\n   ②考查当前$V-U$中的所有顶点$j$，修改侯选边，若$(k,j)$的权值小于原来和顶点$j$关联的侯选边，则用$(k,j)$取代后者作为侯选边。\n\n参考`prim.cpp`(使用优先队列优化)\n\n使用邻接矩阵且不加优化的时间复杂度为$O(n^2)$\n\n使用邻接表且加堆优化时间复杂度为$O(mlogn)$\n\n### 8.4.4Kruskal算法\n\n设$G=(V,E)$是一个具有$n$个顶点的带权连通无向图，$T=(U,TE)$是$G$的最小生成树，则构造最小生成树的步骤如下：\n\n1. 置$U$的初值为$V$(即包含有$G$中的全部顶点)，$TE$的初值为空集(即图$T$中的每一个顶点都构成一个分量)。\n2. 将图$G$中的边按权值从小到大的顺序依次选取，若选取的边未使生成树$T$形成回路，则加入$TE$，否则舍弃，直到$TE$中包含$(n-1)$条边为止。\n\n参考`kruskal.cpp`(使用优先队列优化)\n\n未经优化的算法时间复杂度为$O(m^2)$\n\n使用堆优化的算法时间复杂度为$O(mlogm)$\n\n## 8.5最短路径\n\n### 8.5.1路径的概念\n\n不妨把不带权图看作边权都为1的带权图，则对于带权图，从一个顶点到另一个顶点所有路径长度最短的那条路径就是**最短路径**。\n\n### 8.5.2从一个顶点到其余各顶点的最短路径\n\n**$Dijkstra$算法**：\n\n1. 初始时$S$只包含源点，即$S=\{v\}$，源点$v$到自己的距离为$0$。$U$包含除源点$v$以外的其他顶点，源点$v$到$U$中任一顶点$i$的最短路径长度为边上的权(若源点$v\\rightarrow i$有边$<v,i>$或$\\infty$(若源点$v\\rightarrow i$没有边)。\n1. 从$U$中选取一个顶点$u$，使源点$v\\rightarrow u$的最短路径长度为最小，然后把顶点$u$加入$S$中。\n1. 以顶点$u$为新考虑的中间点，修改源点$v$到$U$中所有顶点的最短路径长度，称之为路径调整(松弛)。\n1. 重复2和3，直至$S$包含所有的顶点。\n\n参考`dijkstra.cpp`\n\n$Dijkstra$不适合处理负权图。\n\n不加优化的$Dijkstra$时间复杂度为$O(n^2+m)=O(n^2)$。\n\n堆优化的$Dijkstra$时间复杂度为$O(mlogn)$。\n\n**$Bellman-Ford$算法**：\n\n不断尝试对图上每一条边进行松弛。我们每进行一轮循环，就对图上所有的边都尝试进行一次松弛操作，当一次循环中没有成功的松弛操作时，算法停止。\n\n$Bellman-Ford$适用于处理负权图并可以对最短路不存在的情况进行判断。\n\n参考`bellman-ford.cpp`\n\n常规时间复杂度为$O(nm)$。\n\n**$SPFA$算法**：\n\n很多时候我们并不需要那么多无用的松弛操作。\n\n很显然，只有上一次被松弛的结点，所连接的边，才有可能引起下一次的松弛操作。\n\n那么我们用队列来维护哪些结点可能会引起松弛操作，就能只访问必要的边了。\n\n参考`SPFA.cpp`\n\n大多数情况下$SPFA$跑得很快，但其最坏情况下的时间复杂度为$O(nm)$。\n\n### 8.5.3每对顶点之间的最短路径\n\n**$Floyd$算法**：\n\n设有向图$G=(V,E)$采用邻接矩阵$g$表示，另外设置一个二维数组$A$用于存放当前顶点之间的最短路径长度，即分量$A[i][j]$表示当前$i\\rightarrow j$的最短路径长度。$Floyd$算法的基本思想是递推产生一个矩阵序列$\\boldsymbol A_0,\\boldsymbol A_1,\\dots,\\boldsymbol A_k,\\dots,\\boldsymbol A_{n-1}$，其中$\\boldsymbol A_k[i][j]$表示$i\\rightarrow j$的路径上所经过的顶点编号不大于$k$的最短路径长度。\n\n初始时有$\\boldsymbol A_{-1}[i][j]=g.edges[i][j]$。若$\\boldsymbol A_{k-1}[i][j]$已求出，现在考查顶点$k$，求$i\\rightarrow j$的路径上所经过的顶点编号不大于$k$的最短路径长度$\\boldsymbol A_k[i][j]$，此时$i\\rightarrow j$的路径有两条。\n\n1. 在考查顶点$k$之前求出其最短路径长度为$\\boldsymbol A_{k-1}[i][j]$(若没有这样的路径，则取为$\\infty$)。\n2. 考查顶点$k,i\\rightarrow j$存在一条经过顶点$k$的路径，分为两段，即$i\\rightarrow k$和$k\\rightarrow j$，其长度为$\\boldsymbol A_{k-1}[i][k]+\\boldsymbol A_{k-1}[k][j]$，(若没有这样的路径，则取为$\\infty$)。\n\n选择较短的那一条。\n\n$Floyd$适合负权图但不能有负权回路。\n\n参考`floyd.cpp`\n\n时间复杂度为$O(n^3)$。\n\n## 8.6拓补排序\n\n**在一个有向图中找一个拓补序列的过程称为拓补排序**。\n\n比较简单，每次将入度为零的点入队，减少其指向的点的入度即可。\n\n## 8.7AOE网与关键路径\n\n### 8.7.1相关概念\n\n若用$DAG$(有向无环图)描述工程的预计进度，以顶点表示事件，有向边表示活动，边权表示时间。图中入度为0的顶点表示工程的**开始事件**，出度为0的顶点表示工程**结束事件**，这样的有向图就是边表示活动的网($AOE$网)。\n\n$AOE$网中入度为0的点称为**源点**，出度为0的顶点称为**汇点**。必要时可以添加虚拟源点和虚拟汇点。\n\n**在$AOE$网中，从源点到汇点的所有路径中具有最大路径长度的路径称为关键路径**。\n\n**关键路径上的活动称为关键活动**。\n\n### 8.7.2求AOE网的关键活动\n\n1. 通过拓补排序求得每个点的$ve$值。顺便通过拓补排序判断是否存在环。求$ve$值的方法如下：\n   设$S$为指向点$j$的所有点的集合，对于所有$i\\in S$，$D_{i,j}$为点$i$到点$j$的边权大小。\n   则$ve(j)=max(ve(i)+D_{i,j}),i\\in S$。\n   特别地，$ve(源点)=0$\n2. 通逆拓补序求得每个点的$vl$值。求$vl$值的方法如下：\n   设$S$为点$j$指向的所有点的集合，对于所有$i\\in S$，$D_{j,i}$为点$j$到点$i$的边权大小。\n   则$vl(i)=min(vl(j)+D_{j,i}),i\\in S$。\n   特别地，$vl(汇点)=ve(汇点)$。\n3. 其中满足$ve$值等于$vl$值的点就是关键活动点。\n' 
                      },
                      { id: 'data_structure-9', 
                        title: '9、查找', 
                        desc: '', 
                        content: '\n# 9.查找\n\n## 9.1查找的基本概念\n\n在查找表的定义下：**查找**的定义是给定一个值$k$，在含有$n$个元素的表中找出关键字等于$k$的元素。\n\n若在查找的同时对表做修改操作（如插入和删除），则相应的查找表称为**动态查找表**。若在查找中不涉及表的修改操作，则相应的查找表称为**静态查找表**。\n若整个查找过程都在内存中进行，则称之为**内查找**；反之，若查找过程的需要访问外存，则称之为**外查找**。\n在查找运算中时间主要花费在关键字的比较上，把平均需要和给定值*k*进行比较的关键字次数称为**平均查找长度**，其定义如下：\n$$\nASL=\\sum_{i=1}^np_ic_i\n$$\n$n$是查找表中元素的个数。$p_i$是查找第$i$个元素的概率，通常假设$p_i=\\frac{1}{n}(1\\le i\\le n)$，$c_i$是找到第$i$个元素所需的关键字比较次数。\n\n$ASL$分为$ASL_{成功}$和$ASL_{不成功}$。\n\n对于$ASL_{成功}$，有\n$$\n\\sum_{i-1}^np_i=1\n$$\n对于$ASL_{不成功}$，假设共有$m$种查找失败情况，则\n$$\n\\sum_{i=1}^mq_i=1\n$$\n$ASL$越大，则算法的时间性能越差，反之则反之。\n\n## 9.2线性表的查找\n\n### 9.2.1顺序查找\n\n无需多言。\n\n$$\nASL_{成功}=\\frac{n\\times (n+1)}{2\\times n}=\\frac{n+1}{2}\n$$\n\n### 9.2.2折半查找\n\n 无需多言。\n\n$$\nASL_{成功}=\\log_2(n+1)-1\n$$\n\n### 9.2.3索引存储结构和分块查找\n\n**索引存储结构**：\n\n在存储数据的同时还建立附加的索引表。\n\n**分块查找**：\n\n要求整个表是分块有序的。\n\n用二分查找查询所在块，再用顺序查找查询块中元素。\n\n通常取块的长度为$\\sqrt{n}$最佳\n\n$$\nASL_{成功}=\\log_2(\\sqrt{n}+1)+\\frac{n+1}{2}-1\n$$\n\n## 9.3树表的查找\n\n### 9.3.1二叉排序树\n\n**二叉排序树**又称二叉搜索树，其定义为二叉排序树或者是空树，或者是满足以下性质的二叉树。\n\n1. 若根结点的左子树非空，则左子树上的所有结点关键字均小于根结点关键字。\n2. 若根结点的右子树非空，则右子树上的所有结点关键字均大于根结点关键字。\n3. 根结点的左、右子树本身又各是一棵二叉排序树。\n\n上述性质简称二叉排序树性质（`BST`性质），故二叉排序树实际上是满足`BST`性质的二叉树。也就是说，二叉排序树是在二叉树基础上增加了结点值的约束。\n\n**二叉排序树的插入和创建**：\n\n这个比较简单。\n\n**二叉排序树的查找**：\n\n这个也比较简单。\n\n**二叉排序树的删除**：\n\n1. 叶子结点：直接删。\n2. 只有左子树或右子树：让唯一子树代替之。\n3. 同时存在左右子树：让左子树中值最大的结点值与该结点值交换，删除左子树那个结点。\n\n参考`BST.cpp`\n\n### 9.3.2平衡二叉树\n\n本书主要指$AVL$树。\n\n若一棵二叉树中每个结点的左、右子树高度最多相差1，则称此二叉树为**平衡二叉树**。\n\n通过**平衡因子**来具体实现上述平衡二叉树的定义。\n\n一个结点的平衡因子是该结点左子树的高度减去右子树的高度。\n\n一个结点是平衡的当且仅当其平衡因子的取值为-1或0或1。\n\n**若一棵二叉树的所有结点都是平衡的，称之为平衡二叉树**。\n\n**平衡二叉树中插入结点的过程**：\n\n1. **LL型调整**：当在$A$结点的左孩子(设为$B$结点)的左子树上插入结点，使得$A$结点的平衡因子由1变为2而引起不平衡。\n   <img src="./pictures/image-20250206173411641.png">\n\n2. **RR型调整**：当在$A$结点的右孩子(设为$B$结点)的右子树上插入结点，使得$A$结点的平衡因子由-1变为-2而引起不平衡。\n   <img src="./pictures/image-20250206173613302.png">\n\n3. **LR型调整**：当在$A$结点的左孩子(设为$B$结点)的右子树上插入结点，使得$A$结点的平衡因子由1变为2而引起不平衡。\n\n   <img src="./pictures/image-20250206173954771.png">\n\n4. **RL型调整**：当在$A$结点的右孩子(设为$B$结点)的左子树上插入结点，使得$A$结点的平衡因子由-1变为-2而引起不平衡。\n\n   <img src="./pictures/image-20250206174202252.png">\n\n**平衡二叉树中删除结点的过程**：\n\n删除过程与二叉查找树一样，只是在最后增加一个**调整**步骤：\n\n从被删除的结点向根结点方向查找，查找到失去平衡的结点时进行与插入相同的调整。\n\n**平衡二叉树的查找**：\n\n与二叉查找树完全相同。\n\n最坏情况下，普通二叉查找树的查找性能为$O(n)$。\n\n$AVL$树的平均查找长度为$O(\\log_2n)$，对应查找算法的时间复杂度为$O(\\log_2n)$。\n\n实际上，折半查找对应的判断树就是一棵平衡的二叉排序树。\n\n参考`AVL.cpp`\n\n### 9.3.3B_树\n\n$B$树是一种自平衡的搜索树，能够保持数据有序。这种数据结构能够让查找数据、顺序访问、插入数据及删除的动作，都在对数时间内完成。$B$树的每个结点可以拥有两个以上的子结点，因此$B$树是一种多路搜索树。\n\n假设数据量达到亿级别，主存存储不下，是能以块的形式从磁盘读取数据。$B$树的主要目的就是减少磁盘的$I/O$操作。\n\n在$B$树中，有两种结点：\n\n1. 内部结点：存储了数据以及指向其子结点的指针。\n2. 叶子(外部)结点：与内部结点不同的是，叶子结点只存储数据，并没有子结点。\n\n一棵$m$阶$B$树或者是一棵空树，或者是满足下列要求的$m$叉树：\n\n1. 每个结点最多有$m$个子结点。\n2. 每一个非叶子结点（除根结点）最少有$\\lceil\\frac{m}{2}\\rceil$个子结点。\n3. 如果根结点不是叶子结点，那么它至少有两个子结点。\n4. 有$k$个子结点的非叶子结点拥有$k-1$个元素，且升序排列，满足$k[i]<k[i+1]$。\n5. 所有的叶子结点在同一层。\n\n**$B$树的查找**：\n\n$B$树中的结点包含有多个元素。假设需要查找的是$k$，那么从根结点开始，从上到下递归的遍历树。在每一层上，搜索的范围被减小到包含了搜索值的子树中。子树值的范围被它的父结点的元素确定。采用二分查找。\n\n**$B$树的插入**：\n\n1. 查找到关键字$k$的插入结点。\n2. 若插入结点的关键字个数$<m-1$，把关键字$k$插入到该结点的合适位置上。\n   若插入结点的关键字个数$=m-1$，把结点分裂，即创建一个新结点，将原结点中较大的一半关键字插入到新结点，中间位置关键字插入到双亲结点。\n\n**B树的删除**：\n\n**第一种策略**：定位并删除元素，然后调整树使它满足约束条件。\n\n首先，查找$B$树中需删除的元素，如果该元素在$B$树中存在，则将该元素在其结点中进行删除；删除该元素后，首先判断该元素是否有左右孩子结点。如果有，则上移孩子结点中的某相近元素（左孩子最右边的结点或右孩子最左边的结点）到父结点中，然后是移动之后的情况；如果没有，直接删除。\n\n1. 某结点中元素数目小于$\\lceil m/2\\rceil-1$，则需要看其某相邻兄弟结点是否丰满。\n2. 如果丰满(结点中元素个数大于$\\lceil m/2\\rceil -1$)，则向父结点借一个元素来满足条件。\n3. 如果其相邻兄弟都不丰满，即其结点数目等于$\\lceil m/2\\rceil -1$，则该结点与其相邻的某一兄弟结点进行合并成一个结点。\n\n**第二种策略**：从上到下处理这棵树，在进入一个结点之前，调整树使得之后一旦遇到了要删除的元素，它可以被直接删除而不需要再进行调整。\n\n代码中采用第一种策略。\n\n参考`BT.cpp`\n\n### 9.3.4B+树\n\n作为$B$树的一种变形，一棵$m$阶$B+$树满足：\n\n1. 每个分支结点最多有$m$棵子树。\n2. 根节点或者没有子树，或者最少有两棵子树。\n3. 除根结点以外，其它每个分支结点最少有$\\lceil m/2\\rceil$棵子树。\n4. 有$n$棵子树的结点有$n$个关键字。\n5. 所有叶子结点包含全部关键字及指向相应记录的指针，而且叶子结点按关键字大小顺序链接。\n6. 所有分支结点中仅包含它的各个子结点中的最大关键字及指向子结点的指针。\n\n**$B+$树的查找**\n\n1. 直接从最小关键字开始进行顺序査找(通过`sqt`指针查找)。\n2. 从$B+$树的根结点开始进行随机査找(通过`root`指针查找)。这种查找方式与$B$树的查找方法相似，只是在分支结点上的关键字与查找值相等时查找并不结束，要继续查到叶子结点为止，此时若查找成功，则按所给指针取出对应元素即可。因此,在$B+$树中不管查找成功与否，每次查找都是经过了一条从根结点到叶子结点的路径。\n\n**$B+$树的插入**\n\n$B+$树的插入与$B$树的插入操作相似，$B+$树的插入也是在叶子结点中进行的，当插入后结点中的关键字个数大于$m$时要分裂成两个结点，它们所含的键值个数分别为$\\lceil (m+1)/2\\rceil$和$\\lfloor (m+1)/2\\rfloor$，同时要使得它们的双亲结点中包含有这两个结点的最大关键字和指向它们的指针。若双亲结点的关键字个数大于$m$，应继续分裂，依此类推。\n\n**$B+$树的删除**\n$B+$树的删除也是在叶子结点中进行的，当叶子结点中的最大关键字被删除时，分支结点中的值可以作为“分界关键字”存在。若因删除操作而使结点中的关键字个数少于$\\lceil m/2\\rceil$，则从兄弟结点中调剂关键字或和兄弟结点合并，其过程和$B$树相似。\n\n有点难搓，略。\n\n## 9.4哈希表的查找\n\n### 9.4.1哈希表的基本概念\n\n又称散列表，设要存储的元素个数为$n$，设置一个长度为$m(m\\ge n)$的连续内存单元，以每个元素的关键字$k_i(0\\le i\\le n-1)$为自变量，通过一个称为**哈希函数**的函数$h(k_i)$把$k_i$映射为内存单元的地址（或下标）$h(k_i)$，并把该元素存储在这个内存单元中，$h(k_i)$也称为**哈希地址**。这样的线性表称为哈希表。\n\n当出现$k_i\\ne k_j$且$h(k_i)=h(k_j)$的情况时认为出现**哈希冲突**。通常把这种具有不同关键字而具有相同哈希地址的元素称为**同义词**。\n\n哈希查找性能主要与3个因素有关：\n\n1. 与装填因子$\\alpha$有关。所谓**装填因子**是指哈希表中已存入的元素数$n$与哈希地址空间大小$m$的比值,即$\\alpha=n/m$。$α$越小，冲突的可能性就越小；$α$越大(最大可取1)，冲突的可能性就越大。另一方面，$α$越小，存储空间的利用率就越低；反之，存储空间的利用率也就越高。为了既兼顾减少冲突的发生，又兼顾提高存储空间的利用率这两个方面，通常使最终的$α$控制在$0.6\\sim0.9$的范围内。\n2. 与所采用的哈希函数有关。若哈希函数选择得当，就可以使哈希地址尽可能均会地分布在哈希地址空间上，从而减少冲突的发生；否则，若哈希函数选择不当，就可能使哈希地址集中于某些区域，从而加大冲突的发生。\n3. 当出现哈希冲突时需要采取解决哈希冲突的方法，所以哈希查找性能也与解决冲突的方法有关。对于预先知道且规模不大的关键字集合，通常可以找到不发生冲突的哈希函数，从而避免出现冲突，使查找时间复杂度为$O(1)$，提高了查找效率，因此对频繁进行查找的关键字集应尽力设计一个完美的哈希数。\n\n### 9.4.2哈希函数的构造方法\n\n1. 直接定址法：$h(k)=k+c$\n2. 除留余数法：$h(k)=k\\mod p$\n3. 数字分析法：例如取一组数的后两位作为哈希地址，或者取关键字平方后分布均匀的几位作为哈希地址，或者把关键字中的若干段作为一小组，把各小组折叠相加后分布均匀的几位作为哈希地址。\n\n### 9.4.3哈希冲突的解决方法\n\n1. 开放定址法：在冲突地址前后找空闲位置。\n\n   **线性探测**：\n   $$\n   d_0=h(k)$$$$d_i=(d_{i-1}+1)\\mod m\\quad(1\\le i\\le m-1)\n   $$\n   **平方探测**：\n\n   $$\n   d_0=h(k)$$$$d_i=(d_0\\pm i^2)\\mod m\\quad(1\\le i\\le m-1)\n   $$\n\n   **伪随机序列**：略。\n\n   **双哈希函数**：略。\n   \n2. 拉链法：在冲突地址生成一个链表储存同义词。\n\n- 拉链法处理冲突简单，无堆积现象，平均查找长度较短。\n- 适合造表前无法确定表长的情况。\n- 节省空间\n- 更易删除结点。\n\n### 9.4.4哈希表的运算算法\n\n**开放定址法**：参考`hash1.cpp`\n\n**拉链法**：参考`hash2.cpp`\n' 
                      },
                      { id: 'data_structure-10', 
                        title: '10、排序', 
                        desc: '', 
                        content: '\n# 10.内排序\n\n## 10.1排序的基本概念\n\n1. **什么是排序**：\n\n   就是排序。\n\n2. **排序的稳定性**：\n   经过排序后这些具有相同关键字的元素之间的相对次序保持不变，则称这种排序方法是稳定的。\n\n3. **内排序和外排序**：\n\n   在排序过程中，若整个表都放在内存中处理，排序时不涉及数据的内、外存交换，则称之为内排序；反之，若在排序过程中要进行数据的内、外存交换,则称之为外排序。\n\n   内排序适用于元素个数不是很多的小表，外排序则适用于元素个数很多，不能一次将其全部元素放入内存的大表。内排序是外排序的基础，本章只讨论内排序。\n\n   按所用的策略不同，内排序方法可以分为需要关键字比较和不需要关键字比较两类。需要关键字比较的排序方法有插入排序、选择排序、交换排序和归并排序等；不需要关键字比较的排序方法有基数排序等。\n\n4. **基于比较的排序算法的性能**：\n   对于$n$个元素排序结果有$n!$种情况，对应得判定树是一棵有$n!$个叶子结点的高度最小的二叉树，结点总数$=n_0+n_2=2n!-1$，则其高度为$h=\\lceil \\log_22n!\\rceil=\\lceil \\log_2n!\\rceil+1$，对应的关键字比较次数最多为$h-1=\\lceil \\log_2n!\\rceil$，又$\\lceil \\log_2n!\\rceil\\approx n\\log_2n$。\n   所以排序的平均时间复杂度为$O(n\\log_2n)$，即基于比较的排序算法最好的平均时间复杂度为$O(n\\log_2n)$。\n\n5. **排序数据的组织**：\n   略。\n\n## 10.2插入排序\n\n### 10.2.1直接插入排序\n\n无需多言。\n\n稳定排序。\n\n最快时间复杂度为$O(n)$\n\n最坏时间复杂度为$O(n^2)$\n\n平均时间复杂度为$O(n^2)$\n\n### 10.2.2折半插入排序\n\n无需多言。\n\n在直接插入排序基础上使用二分查找。\n\n稳定排序。\n\n平均时间复杂度为：\n$$\n\\sum_{i=1}^{n-1}(\\log_2(i+1)-1+\\frac{i}{2}+2)=O(n^2)\n$$\n\n### 10.2.3希尔排序\n\n 考虑小于$n$的增量$d_t$，把表的元素分成$d_t$个组，将所有距离为$d_t$的倍数的元素放同一个组中，在同一个组中进行直接插入排序，再选取$d_{t+1},d_{t+1}<d_t$直至$d_m=1$。\n\n不稳定排序。\n\n平均时间复杂度有点难算，参考`OIwiki`的结果：\n\n若间距序列为$H=\\\\{2^k-1|k=1,2,\\dots ,\\lfloor\\log_2n\\rfloor\\\\}$（从大到小），则希尔排序算法的时间复杂度为$O(n^{3/2})$。\n\n若间距序列为$H=\\\\{k=2^p·3^q|p,q\\in\\mathbb N,k\\le n\\\\}$（从大到小），则希尔排序算法的时间复杂度为$O(n\\log_2n)$。\n\n## 10.3交换排序\n\n### 10.3.1冒泡排序\n\n无需多言。\n\n稳定排序。\n\n最快时间复杂度为$O(n)$\n\n最坏时间复杂度为$O(n^2)$\n\n平均时间复杂度为$O(n^2)$\n\n### 10.3.2快速排序\n\n选取数组中一个关键字(或者随机取一个关键字)，将不大于该关键字的元素和大于该关键字的元素分成两个子区间。对于每个子区间，又进行同样的排序，直到该子区间只有一个元素或不存在元素为止。\n\n不稳定排序。\n\n当初始序列比较有序，则算法的时间复杂度比较大，可能达到$O(n^2)$。\n\n平均时间复杂度$O(n\\log_2n)$。\n\n## 10.4选择排序\n\n### 10.4.1简单选择排序\n\n无需多言。\n\n不稳定排序。\n\n平均时间复杂度为$O(n^2)$。\n\n### 10.4.2堆排序\n\n用堆结构排序。\n\n堆嘛，如果是大根堆：\n\n建立堆就是先塞成一棵完全二叉树，然后中序遍历把儿子结点中较大的关键字与当前结点交换。\n\n取出堆顶元素后，把最后的元素移至堆顶，再进行建立时候的调整。\n\n不稳定排序。\n\n最好、最坏和平均时间复杂度都是$O(n\\log_2n)$。\n\n## 10.5归并排序\n\n无需多言。\n\n就是把排序表细分为多段，各自排序后合在一起。通常是二路合并。\n\n稳定排序算法。\n\n平均时间复杂度为$O(n\\log_2n)$\n\n三路归并可以是$O(n\\log_3n)$，不过实现远远复杂。\n\n## 10.6基数排序\n\n无需多言。\n\n就是按个位比较，十位比较...以此类推。\n\n时间复杂度为$O(d(n+r))$，其中$d=\\lfloor lg{最大元素}\\rfloor+1$，$r$通常是10。\n\n## 10.7各种内排序方法的比较和选择\n\n<img src="./pictures/image-20250207141451249.png">' 
                      },
                      { id: 'data_structure-11', 
                        title: '11、外排序', 
                        desc: '', 
                        content: '\n# 11.外排序\n\n## 11.1外排序概述\n\n外存设备分为**顺序存取设备**和**直接存取设备**。\n\n**磁带**是典型的顺序存取设备，通过读写头读写数据。检索和修改很不方便，主要用于处理很少需要修改的且进行顺序存取的信息。\n\n**磁盘**是直接存取的外存设备，不仅能进行顺序存取，还能直接存取任何记录。存取速度比磁带快得多。\n\n磁盘分为硬盘和软盘两种，硬盘的容量比软盘大得多，而且存取速度也比软盘快得多。\n\n*目前磁盘多使用带有可移动式的磁头，整个磁盘由多个盘片组成，固定在同一轴上沿一个固定方向高速旋转，每个盘片包括上、下两个盘面，每个盘面用于存储信息，每个盘面有一个读写头，所有读写头是固定在一起同时同步移动的。在一个盘面上读写头的轨迹称为磁道，磁道就是磁面上的圆环。各个磁面上半径相同的磁道总和称为一个柱面。在一个磁道内又分为若干个扇面。一般情况下,把一次向磁盘写人或读出的数据称为一个物理块，一个物理块通常由若干个记录组成。对于磁盘而言，影响存取时间的因素有3个*：\n\n1. ***搜索时间**（磁头定位到指定柱面所需要的时间）。*\n2. ***等待时间**（磁头定位到磁道的指定扇区所需要的时间）。*\n3. ***传送时间**（从磁盘或向碳盘传送一个物理块的数据所需要的时间）。*\n\n外排序的基本方法是**归并排序**法：\n\n1. **生成若干初始归并段（顺串）**：将一个文件（含待排序的数据）中的数据分段读人内存，在内存中对其进行内排序，并将经过排序的数据段（有序段）写到多个外存文件上。\n2. **多路归并**：对这些初始归并段进行多遍归并，使得有序的归并段逐渐扩大，最后在外存上形成整个文件的单一归并段，也就完成了这个文件的外排序。\n\n外排序的时间主要花费在内，外存数据的交换（对应存取时间）和内排序上。\n\n## 11.2磁盘排序\n\n### 11.2.1磁盘排序概述\n\n对存放在磁盘中的文件进行排序属于典型的外排序称为**磁盘排序**。\n\n可以通过读写数据块的次数来衡量存取时间。\n\n磁盘中$F_{in}$文件包含待排序的数据，我们这样做：\n\n1. 把$F_{in}$文件分块调入内存，产生若干个文件$F_1\\sim F_n$，称为**顺串**。\n2. 再次将$F_1\\sim F_n$文件中的记录调入内存，通过相关归并算法产生一个有序文件$F_{out}$，从而达到数据排序的目的。\n\n影响磁盘排序时间性能的主要因素：\n\n1. 读写记录次数。\n2. 关键字比较次数。\n\n不同于内排序，磁盘排序中元素移动的次数相对上述两个因素可以忽略。\n\n大致认为**磁盘排序时间=读写记录次数+关键字比较次数**。\n\n### 11.2.2生成初始归并段\n\n**置换-选择排序算法**：\n\n1. 从待排序文件$F_{in}$中按内存工作区$WA$的容量(设为$w$)读入$w$个记录。设归并段编号$i=1$。\n2. 从$WA$中选出关键字最小的记录$R_{min}$。\n3. 将$R_{min}$记录输出到文件$F_i$中，作为当前归并段的一个记录。\n4. 若$F_{in}$不空，则从$F_{in}$中读入下一个记录到$WA$中代替刚输出的记录。\n5. 在$WA$工作区中所有大于或等于$R_{min}$的记录中选择出最小记录作为新的$R_{min}$，转第3步，直到选不出这样的$R_{min}$。\n6. 置$i=i+1$，开始一个新的归并段。\n7. 若$WA$工作区已空，则初始归并段已全部产生，算法结束；否则转第2步。\n\n如下例：\n\n<img src="./pictures/image-20250209165510222.png">\n\n可以证明，如果输入文件中的记录按关键字随机排列，所得到的初始归并段的平均长度为内存工作区大小的两倍。\n\n算法的时间复杂度为$O(nw)$。\n\n这种操作可以使用败者树来实现，使得该算法时间复杂度优化到$O(n\\log_2w)$。\n\n### 11.2.3多路平衡归并\n\n 在$k$路归并中，如果基于简单选择排序方法，需要进行$k-1$次关键字比较。每趟归并$u$个记录需要做$(u-1)\\times (k-1)$次关键字比较，则$s$趟归并总共需要的关键字比较次数为：\n$$\n\\lceil\\log_2m\\rceil\\times(u-1)\\times(k-1)/\\lceil\\log_2k\\rceil\n$$\n所以对$k$的选择有待斟酌。\n\n**利用败者树的$k$路平衡归并**\n\n**败者树**是一棵有$k$个叶子结点的完全二叉树(可将大根堆看成胜者树)，其中叶子结点存储参与归并的记录，分支结点存放关键字对应的段号。所谓败者是两个记录比较时关键字较大者，胜者是两个记录比较时关键字较小者。\n\n**建立败者树**是采用类似于堆调整的方法实现的，初始时令所有的分支结点指向一个含最小关键字($MINKEY$)的叶子结点，然后从各叶子结点出发调整分支结点为新的败者即可。\n\n对$k$个有序段进行**k路平衡归并**的方法如下：\n\n1. 取每个输入有序段的第一个记录作为败者树的叶子结点，建立初始败者树：两两叶子结点进行比较，在双亲结点中存放比较的败者（关键字较大者），而让胜者去参加更高一层的比赛，如此在根结点之上胜出的**冠军**是关键字最小者。\n2. 将胜出的记录写至输出归并段，在对应的叶子结点处补充其输入有序段的下一个记录，若该有序段变空，则补充一个大关键字（比所有记录关键字都大，设为$k_{max}$）的虚记录。\n3. 调整败者树，选择新的关键字最小的记录：从补充记录的叶子结点向上和双亲结点的关键字比较，败者留在该双亲结点，胜者继续向上，直到树的根结点，最后将胜者放在根结点的双亲结点中。\n4. 若胜出的记录关键字等于$k_{max}$，则归并结束；否则转第2步继续。\n\n参考`loserTree.cpp`\n\n**初始化时间复杂度**：$O(k)$，初始化树结构并填充初始数据。\n\n**更新时间复杂度**：每次更新最多需要$O(\\log k)$的时间来更新败者树。\n\n**查找最小值**：$O(1)$，直接访问根节点即可。\n\n**弹出最小值**：$O(\\log k)$​，需要更新败者树。\n\n关键字比较次数与$k$无关，总的内部归并时间不会随$k$的增大而增大。但$k$越大，归并树的高度较小，读写磁盘的次数也较少。\n\n因此，当采用败者树实现多路平衡归并时，只要内存空间允许，增大归并路数$k$会有效地减少归并树的高度，从而减少读写磁盘次数，提高外排序的速度。\n\n### 11.2.4最佳归并树\n\n为了提高归并的时间效率，我们有必要对各归并段进行合理的搭配组合。按照最佳归并树的设计可以使归并过程中对外的读写次数最少。\n\n归并树是描述归并过程的$k$次树。因为每一次做$k$路归并都需要有$k$个归并段参加因此归并树是只包含度为$0$和度为$k$的结点的标准$k$次树。\n\n所有归并树中最小带权路径长度$WPL$的归并树称为**最佳归并树**。\n\n为了使归并树成为一棵标准$k$次树，可能需要补入**虚段**(记录个数为$0$的归并段)。\n\n补虚段的原则为：设参加归并的初始归并段有$m$个，做$k$路平衡归并。因为归并树是只有度为0和度为$k$的结点的正则$k$次树，设度为0的结点有$m$个(因为初始归并段有$m$个,对应归并树的叶子结点就有$m$个)，度为$k$的结点有$m_k$个，则有$m=(k-1)m_k+1$。因此，可以得出$m_k=(m-1)/(k-1)$。如果该除式能整除，即$(m-1)\\text{ mod }(k-1)=0$，则说明这$m$个叶子结点正好可以构造$k$次归并树，不需加虚段，此时分支结点有$m_k$个。如果$(m-1)\\text{ mod }(k-1)=u≠0$，则需要补入$k-u-1$个虚段，这样就可以建立归并树了。\n\n因此,最佳归并树构造步骤如下：\n\n1. 若$(m-1)\\text{ mod }(k-1)≠0$，则需附加$(k-1)-(m-1)\\text{ mod }(k-1)$个长度为0的**虚段**，以使每次归并都可以对应$k$个段。\n2. 按照哈夫曼树的构造原则(权值越小的结点离根结点越远)构造最佳归并树。\n\n对应的读写记录次数为$WPL\times 2$。\n\n参考`optimalMergeTree.cpp`\n\n## 11.3磁带排序\n\n### 11.3.1多路平衡归并排序\n\n**与磁盘的多路平衡归并排序过程基本上相同**。\n\n不同之处在于：磁盘排序要充分考虑归并段的分布状况，因为磁带是顺序存取的。\n\n1. 把输入文件分段读入内存并进行内排序，生成初始归并段，然后将这些归并段轮流写到磁带$T_1$ 和$T_2$上。\n2. 采用二路归并，把$T_1$上的各归并段与$T_2$上的各归并段归并(之后$T_1$和$T_2$上的记录仍存在，但不再有用，可将它们看成空磁带)，并把所产生的较大归并段轮流分布到$T_3$和$T_4$上(若输入文件带需要保留，则在第1步完成后把输人文件带从$T_4$上卸下来，换上工作带)。其中$T_3$上的归并段1是$T_1$上的归并段1和$T_2$上的归并段2归并的结果，$T_3$上的归并段3是$T_1$上的归并段5和$T_2$上的归并段6归并的结果，$T_4$上的归并段2是$T_1$上的归并段3和$T_2$上的归并段4归并的结果。\n3. 把$T_3$上的归并段1和$T_4$上的归并段2进行归并，并将结果放到$T_1$上。\n4. 把$T_1$上的归并段1和$T_3$上的归并段3归并，并把结果放到$T_2$，这就是排好序的文件。\n\n**排序的时间主要取决于对数据的扫描遍数**。\n\n$k$路归并至少需要$k+1$台磁带，其中$k$台作为输入带，另一台为归并后输出之用。但是这样需要对输出带再做一遍扫描，把输出带上的各归并段重新分配到$k$台磁带上，以便作为下一级归并使用。\n\n若使用$2k$台磁带，则可避免这种再分配扫描。把k台作为输入带，其余k台作为输出带。在下一级归并时输入带与输出带的作用互相对换。\n\n### 11.3.2多阶段归并排序\n\n**多阶段归并排序**实际上是**多路非平衡归并排序**，即各条带上的归并段不再保持平衡分布，它在$k$路归并中仅使用$k+1$条磁带就可避免在多路平衡归并排序法中遇到的重新分布有序段的问题。\n\n1. 开始时,初始归并段不平衡地分配在前$k$条磁带上,第$k+1$条磁带作为输出带，开始为空。\n2. 每一步归并只是部分记录参加，归并段最少的带在本步归并完成后便成为空带，作为下一步归并的输出带。这样$k+1$条磁带将轮流成为输出带，直到整个文件为一个排序文件为止。\n\n**为使归并躺数最少，必须合理分配各磁带上初始归并段段数**。\n\n分析得到：利用$(k+1)$台磁带机做$k$路多阶段归并时，总段数$T$满足(其中$F_i^{(k)}$为$k$阶$Fibonacci$序列中的第$i$项)：\n$$\nT_1=F_i^{(k)}+F_{i-1}^{(k)}+\\dots +F_{i-(k-2)}^{(k)}+F_{i-(k-1)}^{(k)}$$$$\nT_2=F_i^{(k)}+F_{i-1}^{(k)}+\\dots +F_{i-(k-2)}^{(k)}$$$$\n\\dots$$$$\nT_{k-1}=F_i^{(k)}+F_{i-1}^{(k)}$$$$\nT_k=F_i^{(k)}$$$$\nT=T_1+T_2+\\dots T_k=[kF_i^{(k)}+(k-1)F_{i-1}^{(k)}+\\dots +2F_{i-(k-2)}^{(k)}+F_{i-(k-1)}^{(k)}]\n$$\n枚举求得$i$，一共需要进行$i-k+2$个阶段的归并。\n\n每个阶段每个磁带机上的段数减去除空的磁带机外最少的磁带段数，空的磁带机加上该段数。' 
                      },
                      { id: 'data_structure-12', 
                        title: '12、文件', 
                        desc: '', 
                        content: '\n# 12.文件\n\n## 12.1文件的基本概念\n\n### 12.1.1什么是文件\n\n**文件**是性质相同的记录的集合，数据量通常很大，被放置在外存上。\n\n数据结构中所讨论的文件主要是数据库意义上的文件，而不是操作系统意义上的文件。是有结构的记录集合。\n\n**记录**是文件中存取的基本单位，**数据项**是文件可使用的最小单位。\n\n数据项有时也称为字段，其值能唯一标识一个记录的数据项或数据项的组合称为**主关键字**，其他不能唯一标识一个记录的数据项则称为**次关键字**。\n\n文件可以分为单关键字文件和多关键字文件。\n\n也可以分为定长文件和不定长文件，取决于文件中记录含有的信息长度相同与否。\n\n文件结构也包括**逻辑结构**、**存储结构**以及在**文件上的各种操作（运算）**。文件的操作定义在逻辑结构上，操作的具体实现要在存储结构上。\n\n### 12.1.2文件的逻辑结构及操作\n\n文件各个记录之间存在着逻辑关系，形成了一种**线性结构**。\n\n文件上的操作包括：**检索**和**维护**。\n\n**文件检索**就是在文件中查找满足给定条件的记录，它既可以按记录的逻辑号（即记录存入文件时的顺序编号）查找，也可以按关键字查找。\n\n**文件维护**主要是指对文件进行记录的插入、删除及修改等更新操作。此外，为了提高文件的效率，还要进行再组织操作、文件被破坏后的恢复操作，以及文件中数据的安全保护等。\n\n### 12.1.3文件的存储结构\n\n指文件在外存上的组织方式。采用不同的组织方式就得到了不同的存储结构。\n\n基本的组织方式有：**顺序组织**、**索引组织**、**哈希组织**和**链式组织**。\n\n## 12.2顺序文件\n\n**顺序文件**是指按记录进入文件的先后顺序存放、其逻辑顺序跟物理顺序一致的文件。若顺序文件中的记录按其主关键字有序，则称此顺序文件为**顺序有序文件**。否则称为**顺序无序文件**。为了提高检索效率，经常将顺序文件组织成有序文件。\n\n存储在顺序存取存储器上的文件都只能是**顺序文件**，这类顺序文件只能按**顺序查找法**存取。\n\n存储在直接存取存储器上的顺序文件还可以用**分块查找法**或**二分查找法**进行存取。其中后者只适合较小的文件，否则磁头来回移动增加寻查时间。\n\n顺序文件不能按顺序表那样的方法进行插入、删除和修改。因此数据库系统总会产生很多临时文件\n\n顺序文件的主要优点是**连续存取的速度较快**。多路存储设备上其他用户可能驱使磁头移向其他柱面，因此顺序文件多用于磁带。\n\n## 12.3索引文件\n\n指明逻辑记录和物理记录之间的一一对应关系的表称为**索引表**，它和主文件一起构成的文件称为**索引文件**。\n\n索引表必须按主关键字有序，而主文件本身可以有序或无序。有序则称为**索引顺序文件**，无序则称为**索引非顺序文件**。\n\n在**索引非顺序文件**中，建立的索引表称为**稠密索引**。而在**索引顺序文件**中则称为**稀疏索引**。\n\n索引表和主文件一起形成**索引文件**。\n\n**检索**：\n\n1. 将外存上含有索引区的物理块送入内存，查找所需记录的物理地址。\n2. 再将含有该记录的物理块送入内存。\n\n**更新**：\n\n- 在插入时将插入记录置于数据区的末尾，并在索引表中插入索引项。\n- 在删除时删去相应的索引项。\n- 若修改主关键字，则同时修改索引表。\n\n当索引表太大以至于一个物理块容纳不下，可以为索引表建立一个索引，称为**查找表**。 \n\n### 12.3.1ISAM文件\n\nISAM是**索引顺序存取方法**。ISAM文件是一种采用静态索引结构的磁盘存取文件，包括：\n\n1. **基本数据区**：由一个或多个柱面组成,文件的记录按关键字有序存放于柱面的每个磁道上。\n\n2. **溢出区**：每个柱面都开一个溢出区，为插入记录而设。\n\n   当一个磁道存满记录以后，如果要在该磁道插入记录，就将该磁道的最后一个记录移至溢出区，再将新记录插在此磁道的适当位置。\n\n   每个磁道的溢出数据在溢出区中组成链表。\n\n3. **多级索引**：\n\n   1)**磁道索引**：包括**基本索引项**（本磁道的最大关键字及起始地址）和**溢出索引项**（本磁道溢出记录的最大关键字及本磁道溢出区首地址）。\n\n   2)**柱面索引**：索引项包含柱面中的最大关键字和该柱面磁道索引的起始地址。\n\n   3)**主索引**：主索引是柱面索引的索引。每个索引项包含柱面索引中一组记录的最大关键字及该柱面索引组的起始地址。检索时由高级索引到低级索引逐级查找，找到待查记录所在的磁道后再到此磁道中查找待查记录。\n\n4. **柱面**：包括**磁道索引区**、**基本区**和**溢出区**。\n\n   磁道索引区存放该柱面的磁道索引，通常记为$T_0$。\n\n   基本区存放主文件的记录，通常从$T_1$开始记若干项。\n\n   溢出区由该柱面基本区的各个磁道共享。\n\n5. **磁道索引项**：包括**基本索引项关键字**、**基本索引项指针**、**溢出索引项关键字**和**溢出索引项指针**。\n\n   基本索引项关键字$\\rightarrow$磁道在基本区中最末一个记录的关键字（即该磁道的最大关键字）。\n\n   基本索引项指针$\\rightarrow$磁道中第一个记录在基本区中的位置。\n\n   溢出索引项关键字$\\rightarrow$对应溢出链表的最大关键字。\n\n   溢出索引项指针$\\rightarrow$溢出链表的头指针。\n\n6. **柱面索引项**：包括**关键字**和**指针**。\n\n   关键字$\\rightarrow$柱面（即对应磁道索引块）中最后一个记录的关键字（即该柱面的最大关键字）。\n\n   指针$\\rightarrow$柱面上的磁道索引首地址。\n\n<img src="./pictures/image-20250210132559686.png">\n\n当有新的记录插入时需要重组某个磁道的记录，并将该磁道最后一个记录移入该柱面的溢出链表中,同时修改对应磁道索引的基本索引项和溢出索引项内容。\n\n<img src="./pictures/image-20250210133320173.png">\n\n删除记录的操作只要找到待删除的记录，在其存储位置上加一个删除标志即可。\n\n查询记录只需按照索引依次顺序查询即可。\n\nISAM文件多次增删后大量记录进入溢出区，在基本区又浪费了很多空间，需要周期性整理：\n\n把记录读入内存重新排列复制成一个新的ISAM文件，填满基本区而空出溢出区。\n\n### 12.3.2VSAM文件\n\nVSAM是**虚拟存储存取方法**。VSAM文件是一种采用虚拟存取方法的文件，其存储单位是控制区间和控制区域，这是一些逻辑存储单位，与柱面、磁道等存储单位无必然联系。\n\n也采用**索引顺序文件组织方式**。且VSAM采用$B+$树的动态索引结构。\n\n1. **数据集**：一个结点称为一个控制区间,它是`I/0`操作的一个基本单位。文件的记录存放于数据集中。一个控制区间除存放一个或多个记录以外，还包含有记录的控制信息和区间的控制信息，且每个控制区间留有空间，为插入记录时备用。\n2. **顺序集**：存放每个控制区间的索引项，一个索引项包含该控制区间的最大关键字和指向区间的指针。若于个控制区间的索引项组成顺序集中的一个结点，结点之间用指针链接，使整个顺序集形成一个链表。顺序集中一个结点和与之对应的控制区间组成一个控制区域。\n3. **索引集**：每个顺序集的结点又在其上一层的结点中建立索引，且逐层向上建立索引，每个索引项都是由下层若干个结点的最大关键字和指向这些结点的指针组成。这些上层的索引组成了索引集。它们是$B+$树的非终端结点，与顺序集共同构成一棵 B+树，作为文件的索引部分。\n\n<img src="./pictures/image-20250210140728318.png">\n\n- VSAM文件记录都存放在数据集中（其中的一个结点就是一个控制区间）。\n\n- 控制区间大小视文件大小而定，但同一文件中大小需相同。\n\n- 顺序集和索引集构成一棵$B+$树。\n\n- 每个控制区间在顺序集中都有一个**索引项**，其关键字为控制区间中记录的最大关键字，其指针为该控制区间的首地址。顺序集中的一个结点和对应的若干个控制区间组成的部分称为**控制区域**。每个控制区间可看作一个逻辑磁道，每个控制区域可看作一个逻辑柱面，而控制区间相当于一个磁道。\n\n- 记录插入：不填满控制区间或者留有一些全空的备用区间，插入时：\n  \n  1)可能要修改顺序集中索引项。\n  \n  2)可能要进行后移使得区间元素有序。\n  \n  3)元素已满，要进行区间的分裂，并修改索引。\n  \n  4)控制区域要分裂，对应的顺序集中结点也分裂。\n\n相比ISAM，VSAM有优点：\n\n1. 动态地分配和释放存储空间。\n2. 不需要对文件进行重组。\n3. 插入新记录后对新记录的查找时间和对原有记录的查找时间相同。\n\n## 12.4哈希文件\n\n类似于哈希表。\n\n磁盘上的若干个文件记录组成一个存储单位，称为**桶**。\n\n处理溢出主要采用**链地址法**：将溢出文件放入溢出桶中。\n\n通常希望溢出桶和基桶最好在同一柱面上。\n\n**查找**：顺序查找记录。\n\n**删除**：对被删记录做删除标记。\n\n优点：\n\n1. 文件随机存放。\n2. 记录不需进行排序。\n3. 插入、删除方便。\n4. 存取速度快。\n5. 不需要索引区，节省存储空间。\n\n缺点：\n\n1. 只能按关键字随机存取。\n2. 仅限于简单询问，并且在经过多次插入、删除后文件结构可能不合理，需要重新组织文件。\n\n## 12.5多关键字文件\n\n### 12.5.1多重表文件\n\n一个顺序文件，把具有相同次关键字的记录链接成一个链表，并将此链表的头指针、链表长度及此关键字作为索引表的一个索引项。\n\n**查找**：先查询索引表，再在主文件中读出待查记录信息。\n\n**插入**：将新纪录插在链表头指针之后。\n\n**删除**：需要在每个次关键字的链表中删去该记录。\n\n### 12.5.2倒排文件\n\n与多重表文件的区别是直接列出记录的物理地址或记录号。\n\n相比之下检索更快，但难以维护。' 
                      },
                      { id: 'data_structure-13',
                        title: '13、采用面向对象的方法描述算法',
                        desc: '',
                        content: '参考附赠源文件。'
                      }
                  ]
                },
                { id: 'computer_basic', title: '计算机系统基础', icon: 'fas fa-industry', desc: '<p>这门课的学分数变化无常，小心4学分的那种。</p><p>能啃完黑皮书的可以请高人了。</p>',
                  chapters: [
                      { id: 'computer_basic-1', 
                        title: '2、信息的表示和处理', 
                        desc: '', 
                        content: '# 2.信息的表示和处理\n\n## 2.1信息存储\n\n**概念**：\n\n- 大多数计算机使用**8**位的**块**，或者**字节（byte）**，作为最小的可寻址的内存单位。\n\n- 机器级程序将内存视为一个非常大的字节数组，称为**虚拟内存（virtual memory）** 。\n\n- 内存的每个字节都由一个唯一的数字来标识，称为它的**地址（address）** 。\n\n- 所有可能地址的集合就称为**虚拟地址空间（virtual address space）** 。\n  \n  顾名思义，这个虚拟地址空间只是一个展现给机器级程序的概念性映像。\n\n> 实际的实现是将动态随机访问存储器（DRAM）、闪存、磁盘存储器、特殊硬件和操作系统软件结合起来，为程序提供一个看上去统一的字节数组。\n\n**每个程序对象可以简单地视为一个字节块，而程序本身就是一个字节序列**。\n\n### 2.1.1*十六进制表示法\n\n略。\n\n### 2.1.2字数据大小\n\n每台计算机都有一个**字长（word size）**，指明指针数据的**标称大小（nominal size）**。 \n\n因为虚拟地址是以这样的一个字来编码的，所以字长决定的最重要的系统参数就是**虚拟地址空间**的最大大小。\n\n也就是说，对于一个字长为$w$位的机器而言，虚拟地址的范围为$0\\sim 2^w-1$，程序最多访问$2^w$​个字节。\n\n------\n\n大多数64位机器也可以运行为32位机器编译的程序，这是一种向后兼容。\n\n因此，当程序`prog.c`用如下伪指令编译后\n\n```bash\nlinux> gcc -m32 prog.c\n```\n\n该程序就可以在32位或64位机器上正确运行。\n\n当程序用下述伪指令编译\n\n```bash\nlinux> gcc -m64 prog.c\n```\n\n那就只能在64位机器上运行。\n\n> [!IMPORTANT]\n>\n> 将程序称为**32位程序或64位程序**时，区别在于**该程序是如何编译的， 而不是其运行的机器类型**。\n\nC声明下32位与64位的不同：\n\n- `long`在32位下是4字节，64位下是8字节。\n- `char *`在32位下是4字节，64位下是8字节。\n\n> 为了**避免由于依赖典型大小和不同编译器设置带来的奇怪行为**，`ISO C99`引入了一类数据类型，其数据大小是固定的，不随编译器和机器设置而变化。其中就有数据类型`int32_t`和`int64_t`, 它们分别为4个字节和8个字节。 \n\n------\n\n程序对`char`是否有符号通常不敏感。\n\n### 2.1.3**寻址和字节顺序\n\n在几乎所有的机器上，多字节对象都被存储为连续的字节序列，对象的地址为所使用字节中最小的地址。\n\n以`0x1234567`为例：\n\n- **小端法**：最小地址存储`0x67`，最大地址存储`0x01`。\n- **大端法**：最小地址存储`0x01`，最大地址存储`0x67`。\n\n大多数`Intel`兼容机都只用小端模式。 另一方面，`IBM`和`Oracle`（从其2010年收购`Sun Microsystems`开始）的大多数机器则是按大端模式操作。\n\n许多比较新的微处理器是**双端法（bi-endian）**，也就是说可以把它们配置成作为大端或者小端的机器运行。\n\n> 实际情况是：一旦选择了特定操作系统，字节顺序也就固定下来。如许多移动电话的 `ARM` 微处理 器，其硬件可以按小端或大端两种模式操作，但是这些芯片上最常见的两种操作系统 `Android` 和 `IOS` 却只能运行于小端模式。\n\n字节顺序很重要：\n\n1. **网络应用程序的代码编写必须遵守已建立的关于字节顺序的规则**，以确保发送方机器将它的内部表示转换成网络标准，而接收方机器则将网络标准转换为它的内部表示。\n2. **反汇编器**：反汇编器是一种确定可执行程序文件所表示的指令序列的工具。\n3. **编写规避正常的类型系统的程序**：如涉及强制类型转换的程序。\n\n### 2.1.4表示字符串\n\nC语言中字符串被编码为一个以`null`（其值为0）字符结尾的字符数组。 每个字符都由某个标准编码来表示，最常见的是`ASCII`字符码。\n\n**文本数据比二进制数据具有更强的平台独立性**。\n\n### 2.1.5表示代码\n\n在机器上编译时，会生成字节表示的机器代码，如：`55 89 e5 8b 45 Oc 03 45 08 5d c3`（Windows）。\n\n第三章我们会再做了解。\n\n**二进制代码是不兼容的，很少能在不同机器和操作系统组合之间移植**。\n\n### 2.1.6布尔代数简介\n\n当考虑长度为$w$的位向量上的＾、＆和～运算时，会得到一种不同的数学形式，称为**布尔环**（$Boolean\\ \\ ring$）。\n\n**位向量**是一种固定长度为$w$、由0和1组成的串。\n\n一个很有用的应用是表示有限集合。我们可以用位向量$[a_{w-1},\\dots,a_1,a_0]$编码任何子集A。比如：\n\n$a=[01101001]表示集合A=\\lbrace 0,3,5,6\\rbrace$。\n\n### 2.1.7C语言中的位级运算\n\n略。\n\n### 2.1.8C语言中的逻辑运算\n\n略。\n\n### 2.1.9C语言中的移位运算\n\n略。\n\n- **逻辑右移**：在左端补$k$个0。\n- **算术右移**：在左端补$k$个最高有效位的值。\n\n实际上，几乎所有的编译器/机器组合都对**有符号数**使用**算术右移**，且许多程序员也都假设机器会使用这种右移。另一方面，对于**无符号数**，**右移必须是逻辑的**。\n\n与C相比，Java对于如何进行右移有明确的定义。表达式`x>>k`会对`x`算术右移，而`x>>>k`会对`x`做逻辑右移。\n\n> 当位移量很大的时候：在许多机器上，当移动一个$w$位的值时，移位指令只考虑位移量的低$\\log_2w$位，因此实际上位移量就是通过计算$k\\text{ mod }w$得到的。事实上未必能保证发生这种行为，还是注意别乱搞。\n\n## 2.2*整数表示\n\n### 2.2.1整型数据类型\n\n略。\n\n### 2.2.2无符号数的编码\n\n**定义**：\n\n对向量$\\overrightarrow x=[x_{w-1},x_{w-2},\\dots,x_0]:$\n$$\nB2U_w(\\overrightarrow x)\\overset{.}{=}\\sum_{i=0}^{w-1}x_i2^i\n$$\n无符号数的二进制表示有一个很重要的属性，也就是每个介于$0\\sim 2^w-1$之间的数都有唯一一个$w$位的值编码。\n\n此外：$B2U_w$是一个双射，即映射双方互相唯一对应。\n\n### 2.2.3补码编码\n\n**定义**：\n\n对向量$\\overrightarrow x=[x_{w-1},x_{w-2},\\dots,x_0]:$\n$$\nB2T_w(\\overrightarrow x)\\overset{.}{=}-x_{w-1}2^{w-1}+\\sum_{i=0}^{w-2}x_i2^i\n$$\n同无符号表示一样，在可表示的取值范围内的每个数字都有一个唯一的$w$位的补码编码。\n\n此外：$B2T_w$是一个双射。\n\n**C语言标准并没有要求要用补码形式来表示有符号整数，但是几乎所有的机器都是这么做的**。\n\n> 宏与格式字符串：\n>\n> 例：宏PRId32编译为64位程序时，展开为字符串d，而宏PRIu64展开成字符串lu。\n>\n> 使用宏能保证：不论代码是如何被编译的，都能生成正确的格式字符串。根据平台的需要自动选择适当的格式符，使得这个宏在不同的系统上更加灵活和安全。\n\n**反码和原码**：\n\n- **反码**：\n  $$\n  B2O_w(\\overrightarrow x)\\overset{.}{=}-x_{w-1}(2^{w-1}-1)+\\sum_{i=0}^{w-2}x_i2^i\n  $$\n\n- **原码**：\n  $$\n  B2S_w(\\overrightarrow x)\\overset{.}{=}(-1)^{x_{w-1}}·\\sum_{i=0}^{w-2}x_i2^i\n  $$\n\n> 虽然过去生产过基于反码表示的机器，但是几乎所有的现代机器都使用补码。我们将看到在浮点数中有使用原码编码。\n\n### 2.2.4有符号数和无符号数之间的转换\n\n对于大多数C语言的实现，处理同样字长的有符号数和无符号数之间相互转换的一般规则是：**数值可能会改变，但是位模式不变**。\n\n道理大家都懂，值得注意的是**有符号数和无符号数的右移规则不同**。\n\n### 2.2.5C语言中的有符号数与无符号数\n\n通常， 大多数数字都默认为是有符号的。\n\n要创建一个无符号常扯，必须加上后缀字符`U`或者`u`。\n\n**强制类型转换**：\n\n1. 显式强制类型转换如：\n\n   ```c++\n   y = (int)x;\n   ```\n\n2. 隐式强制类型转换如：\n\n   ```c++\n   y = x;\n   ```\n\n3. 格式字符串。\n\n**当执行一个运算时，如果它的一个运算数是有符号的而另一个是无符号的，那么C语言会隐式地将有符号参数强制类型转换为无符号数，并假设这两个数都是非负的，来执行这个运算**。\n\n### 2.2.6扩展一个数字的位表示\n\n**零扩展**：要将一个无符号数转换为一个更大的数据类型，只需简单地在表示的开头添加0。\n\n**符号扩展**：要将一个补码数字转换为一个更大的数据类型，可以在表示中添加最高有效位的值。事实上：\n$$\nB2T_{w+k}([x_{w-1},\\dots,x_{w-1},x_{w-1},x_{w-2},\\dots,x_0])=B2T_{w}([x_{w-1},x_{w-2},\\dots,x_0])\n$$\n值得一提的是，从一个数据大小到另一个数据大小的转换，以及无符号和有符号数字之间的转换的相对顺序能够影响一个程序的行为。\n\n通常是**先改变大小，再完成从有符号到无符号的转化**。这个规则是C语言标准要求的。\n\n### 2.2.7截断数字\n\n**截断无符号数**：直接截断\n$$\nB2U_w([x_{w-1},x_{w-2},\\dots,x_0])\\text{ mod }\ 2^k=B2U_k([x_{k-1},x_{k-2},\\dots,x_0])\n$$\n**截断补码数据**：截断后注意符号位\n$$\nB2T_k([x_{k-1},x_{k-2},\\dots,x_0])=U2T_k(B2U_w([x_{w-1},x_{w-2},\\dots,x_0])\\text{ mod }~2^k)\n$$\n\n### 2.2.8关于有符号数与无符号数的建议\n\n许多无符号运算的细微特性，尤其是有符号数到无符号数的隐式转换，会导致错误或者漏洞的方式。避免这类错误的一种方法就是**绝不使用无符号数**。 实际上，除了C以外很少有语言支持无符号整数。\n\n## 2.3**整数运算\n\n### 2.3.1无符号加法\n\n对满足$0\\le x,y<2^w$的$x$和$y$有：（这里的$x+y$特指无符号数的加法）\n$$\nx+y=\n\\begin{cases}\nx+y,&x+y<2^w&正常\\\\\\\\\nx+y-2^w,&2^w\\le x+y<2^{w+1}&溢出\n\\end{cases}\n$$\n当且仅当$x+y<x或x+y<y$时，发生了溢出。\n\n### 2.3.2补码加法\n\n对满足$-2^{w-1}\\le x,y<2^{w-1}-1$的$x$和$y$有：（这里的$x+y$特指补码的加法）\n$$\nx+y=\n\\begin{cases}\nx+y-2^w,&2^{w-1}\\le x+y&正溢出\\\\\\\\\nx+y,&-2^{w-1}\\le x+y<2^{w-1}&正常\\\\\\\\\nx+y+2^w,&x+y<-2^{w-1}&负溢出\n\\end{cases}\n$$\n当且仅当$x>0,y>0但x+y\\le 0$时，发生了正溢出。\n\n当且仅当$x<0,y<0但x+y\\ge 0$时，发生了负溢出。\n\n### 2.3.3补码的非\n\n对满足$TMin_w\\le x\\le TMax_w$的$x$，其补码的非为：\n$$\n-x=\n\\begin{cases}\nTMin_w,&x=TMin_w\\\\\\\\\n-x,&x>TMin_w\n\\end{cases}\n$$\n执行位级补码非的笫一种方法是对每一位求补，再对结果加1，即：$-x=\\sim x+1$。\n\n### 2.3.4无符号乘法\n\n对满足$0\\le x,y\\le UMax_w$的$x$和$y$有：\n$$\nx*y=(x·y)\\text{ mod }2^w\n$$\n\n### 2.3.5补码乘法\n\n对满足$TMin_w\\le x,y\\le TMax_w$的$x$和$y$有：\n$$\nx*y=U2T_w((x·y)\\text{ mod }2^w)\n$$\n值得注意的是，同样的两个数，作为无符号数和补码相乘的时候，其乘积的位级表示不同，但是截断后乘积的位级表示相同。\n\n### 2.3.6乘以常数\n\n整数乘法指令通常很慢，大约是而其他整数运算（例如加法、 减法、位级运算和移位）的10倍左右。\n\n因此，编译器使用了一项重要的优化，试着**用移位、加法和减法运算的组合来代替乘以常数因子的乘法**。\n\n包括：考虑生成$\\dots00\\underbrace{11\\dots11}_{第m位到第n位}000\\dots$\n\n- $(x<<n)+(x<<(n-1))+\\dots+(x<<m)$\n- $(x<<(n+1))-(x<<m)$\n\n大多数编译器只在需要少量移位、加法和减法就足够的时候才使用这种优化。\n\n### 2.3.7除以2的幂\n\n在大多数机器上，整数除法要比整数乘法更慢，大概需要其他整数运算的30倍左右。\n\n**除以2的幂也可以用移位运算来实现**。\n\n值得注意的是，舍去小数位的时候：\n\n- 正数：**向下取整**。\n- 负数：**向上取整**。\n\n编译器会通过符号位判断取整方式。\n\n## 2.4***浮点数\n\n### 2.4.1二进制小数\n\n如用$(0.111111)_2$表示$\\frac{63}{64}$。\n\n对于$\\frac{1}{5}$这种只能近似地表示它，增加二进制表示的长度可以提高表示的精度：\n$$\n(0.2)_{10}=(0.001100110011\\dots)_2\n$$\n\n### 2.4.2IEEE浮点表示\n\nIEEE浮点标准用$V=(-1)^s\\times M\\times 2^E$的形式来表示一个数：\n\n- **符号（sign）**：$s$决定这数是负数$(s=1)$还是正数$(s=0)$，而对于数值$0$的符号位解释作为特殊情况处理。\n- **尾数（significand）**：$M$是一个二进制小数，它的范围作为规格化数时是$[1,2)$，作为非规格化数时是$[0,1)$。\n- **阶码（exponent）**：$E$的作用是对浮点数加权，这个权重是$2$的$E$次幂（$E$可能是负数）。\n\n将浮点数的位表示划分为三个字段，分别对这些值进行编码：\n\n- 一个单独的符号位$s$直接编码符号$s$。\n- $k$位的阶码字段${\\text{exp}}=e_{k-1}\\dots e_1e_0$编码阶码$E$。\n- $n$位小数字段${\\text{frac}}=f_{n-1}\\dots f_1f_0$编码尾数$M$，但是编码出来的值也依赖于阶码字段的值是否等于0。\n\n**float**：在封装到32位字中，其$k=8$，$n=23$。\n\n**double**：在封装到64位字中，其$k=11$，$n=52$。\n\n根据$\\text{exp}$的值，被编码的值可以分成三种情况：\n\n1. **规格化的值**：\n   当$\\text{exp}$既不全为$0$也不全为$1$时：$E=\\text{exp}-Bias$，其中$Bias=2^{k-1}-1$。\n   尾数定义为$M=1+\\text{frac}$。\n\n2. **非规格化的值**：\n   当$\\text{exp}$全为$0$时，$E=1-Bias$，$M=f$。\n\n   此时当$M=f=0$时，可以取到$0$，而根据符号位不同，分为$+0.0$和$-0.0$。\n\n   根据$\\text{IEEE}$的浮点格式，值$+0.0$和$-0.0$在某些方面被认为是不同的。\n\n3. **无穷**：\n   当$\\text{exp}$全为$1$时，$\\text{frac}$全为$0$时，取为无穷，正负无穷取决于符号位。\n\n   无穷可以由两个大数相乘或除以零得到。\n\n4. **$\\text{NaN}$**:\n\n   当$\\text{exp}$全为$1$时，$\\text{frac}$不全为$0$时，取为$\\text{NaN}$。\n\n   一些运算结果不能是实数或无穷时，就会得到这个结果。（例如$\\infty-\\infty,\\frac{1.0}{0}$）。\n\n### 2.4.3示例\n\n2.4.2都是教科书式的介绍，有些晦涩难懂。而浮点数的表示是考试的**必考点**和**较难点**，以下是本人从做题角度总结的学习方法。\n\n以**float**的表示为例：\n\n- 死记三个数：\n\n  - `x_11111111_00000000000000000000000`：正负无穷。\n  - `x_11111111_xxxxxxxxxxxxxxxxxxxxxxx`：$\\text{NaN}$。\n  - `0_01111111_00000000000000000000000`：$1.0$。\n\n- 其它规格化数和非规格化数的表示全部由$1.0$的表示推导：\n\n  - 阶码的`01111111`代表$2^0$，对于其它阶码，只需要与`01111111`相减即可得到幂次，特别地，对于`00000000`需要把相减结果加$1$。例如：\n\n    `0_10110110_00000000000000000000000`：用`10110110`减去`01111111`得到$55$，所以`0_10110110_00000000000000000000000`表示$2^{55}\\times 1.0$。\n\n  - 对于规格化数（阶码不全为$0$）：把尾数$x$处理为$1.x$，再乘上刚刚计算的二次幂。\n\n  - 对于非规格化数（阶码全为$0$）：把尾数$x$处理为$0.x$，再乘上刚刚计算的二次幂。\n\n- 实操演示：\n\n  - 给出`1_10110110_01010000000000000000000`的十进制表示：\n\n    阶码对应的幂次为$2^{55}$，尾数处理为$1+\\frac{1}{4}+\\frac{1}{16}=1.3125$，其表示为$-1.3125\\times 2^{55}$。\n\n  - 给出**float**能表示的除了无穷外最大正数和最小正数：\n\n    最大正数是`0_11111110_11111111111111111111111`，阶码对应的幂次为$2^{127}$，尾数处理为$1+\\frac{1}{2}+\\dots+\\frac{1}{2^{23}}=2-\\frac{1}{2^{23}}$，其表示为$(2-\\frac{1}{2^{23}})\\times 2^{127}=2^{128}-2^{104}$。\n\n    最小正数是`0_00000000_00000000000000000000001`，阶码对应的幂次为$2^{-126}$，尾数处理为$\\frac{1}{2^{23}}$，其表示为$\\frac{1}{2^{23}}\\times 2^{-126}=2^{-149}$。\n\n  - 给出**float**能表示的除了无穷和$\\text{NaN}$外的数的个数:\n\n    阶码不全为$1$的数都被计入：总共有$2^{32}-2^{24}$个。\n\n### 2.4.4舍入\n\nIEEE浮点格式定义了四种不同的舍入方式。默认的方法是找到最接近的匹配，而其他三种可用于计算上界和下界。\n\n四种舍入方式：\n\n- **向偶数舍入（round-to-even）**：是默认的方式，试图找到一个最接近的匹配值。当在可能结果的中间数值：它将数字向上或者向下舍入，使得结果的最低有效数字是偶数。例如，$1.5$和$2. 5$都舍入成$2$。\n- **向零舍入**：把正数向下舍入，把负数向上舍入。\n- **向下舍入**：把正数和负数都向下舍入。\n- **向上舍入**：把正数和负数都向上舍入。\n\n提供一个float类型采取**向偶数舍入**的例子：\n\n```c++\n// temp 是一个 32 位数，现在将其右移 9 位。f 取为 1 时尾数要加 1\nf = 0;\nif((temp & 0x1ff) > 0x100) f = 1;\nif((temp & 0x3ff) == 0x300) f = 1;\n```\n\n### 2.4.5浮点运算\n\n把浮点值$x$和$y$看成实数，而某个运算$\\bullet$定义在实数上，计算将产生$Round(x\\bullet y)$，这是进行舍入后的结果。在实际中，浮点单元的设计者使用一些聪明的小技巧来避免执行这种精确的计算，因为计算只要精确到能够保证得到一个正确的舍入结果就可以了。\n\n**浮点加法**：\n\n- 浮点加法不具有结合性，这是缺少的最重要的群属性。\n- 浮点加法满足单调性：如果$a\\ge b$，那么对于任何$a、b$以及$x$的值，除了$\\text{NaN}$，都有$x+a\\ge x+b$。无符号或补码加法不具有这个实数（和整数）加法的属性。\n\n**浮点乘法**：\n\n- 浮点乘法不具有结合性。\n\n- 浮点乘法不具备分配性。\n\n- 浮点乘法满足单调性：不考虑$\\text{NaN}$，都有\n  - $a\\ge b\\land c\\ge 0\\Rightarrow a\\times c\\ge b\\times c$\n  - $a\\ge b\\land c\\le 0\\Rightarrow a\\times c\\le b\\times c$\n\n### 2.4.6C语言中的浮点数\n\n所有的C语言版本提供了两种不同的浮点数据类型：`float`和`double`。通常都使用向偶数舍入的舍入方式。\n\n不幸的是，因为C语言标准不要求机器使用IEEE浮点，所以没有标准的方法来改变舍入方式或者得到诸如$-0$、$+\\infty$、$-\\infty$或者$\\text{NaN}$之类的特殊值。\n\n通常在包含`math.h`库中：GNU编译器GCC会定义程序常数`INFINITY`（表示$+\\infty$)和`NAN`（表示$\\text{NaN}$)。' 
                      }, 
                      { id: 'computer_basic-2', 
                        title: '3、程序的机器级表示', 
                        desc: '', 
                        content: '# 3.程序的机器级表示\n\n> 本章基于x86-64，一种现在笔记本电脑和台式机中最常见处理器的机器语言，也是驱动大型数据中心和超级计算机的最常见处理器的机器语言。\n\n> IA32是x86-64的32位前身。\n\n## 3.1历史观点\n\n略。\n\n## 3.2*程序编码\n\n从一段代码开始：\n\n```bash\n# 有两个文件 p1.c 和 p2.c，用 Unix 命令行编译这些代码：\ngcc -Og -o p p1.c p2.c\n```\n\n- 命令`gcc`（也可以是`cc`）是`GCC`编译器，这是Linux上默认的编译器。\n\n- 编译选项`-Og`告诉编译器使用**会生成符合原始C代码整体结构的机器代码的优化等级**。较高级别优化产生的代码会严重变形，难以理解。\n  \n  实际中，从得到的程序的性能考虑，较高级别的优化（例如`-O2`或`-O3`）更好。\n  \n- 实际上`gcc`命令调用了一整套的程序，将源代码转化成可执行代码。\n  - C预处理器扩展源代码，插入所有用`#include`命令指定的文件，并扩展所有用`#define`声明指定的宏。\n  - 编译器产生两个源文件的汇编代码，名字分别为`p1.s`和`p2.s`。接下来，汇编器会将汇编代码转化成二进制目标代码文件`p1.o`和`p2.o`。目标代码是机器代码的一种形式，它包含所有指令的二进制表示，但是还没有填入全局值的地址。\n  - 链接器将两个目标代码文件与实现库函数的代码合并， 并产生最终的可执行代码文件`p`（由命令行指示符`-op`指定的）。可执行代码是我们要考虑的机器代码的第二种形式，也就是处理器执行的代码格式。\n\n### 3.2.1机器级代码\n\n对千机器级编程来说，其中两种抽象尤为重要：\n\n1. **指令集体系结构或指令集架构（Instruction Set Architecture，ISA）**：\n\n   它定义了处理器状态、指令的格式，以及每条指令对状态的影响。\n\n2. 机器级程序使用的内存地址是**虚拟地址**，提供的内存模型看上去是一个非常大的字节数组。\n\n**一些隐藏的处理器状态**：\n\n- 程序计数器（通常称为**PC**，在x86-64中用`％rip`表示）给出将要执行的下一条指令在内存中的地址。\n- 整数寄存器文件**包含16个命名的位置，分别存储64位的值**。 这些寄存器可以存储**地址**（对应于C语言的指针）或**整数数据**。有的寄存器被用来记录某些**重要的程序状态**，而其他的寄存器用来保存**临时数据**，例如过程的参数和局部变量，以及函数的返回值。\n- 条件码寄存器保存着最近执行的**算术或逻辑指令的状态信息**。它们用来实现控制或数据流中的条件变化，比如说用来实现`if`和`while`语句。\n- 一组向量寄存器可以存放**一个或多个整数或浮点数值**。\n\n**程序内存**：\n\n- 程序的可执行机器代码。\n- 操作系统需要的一些信息。\n- 用来管理过程调用和返回的**运行时栈**，以及用户分配的**内存块**。\n\n程序内存用虚拟地址来寻址。\n\n在任意时刻，**只有有限的一部分虚拟地址被认为是合法的**。例如，x86-64的虚拟地址由64位的字表示。在目前的实现中， 这些地址的高16位必须设置为0，所以一个地址实际上能够指定的是$2^{48}$或$64TB$范围内的一个字节。\n\n较为典型的程序只会访问几兆字节或几千兆字节的数据。\n\n**操作系统负责管理虚拟地址空间**，将虚拟地址翻译成**实际处理器内存中的物理地址**。\n\n**一条机器指令只执行一个非常基本的操作**，机器指令可以由编译器产生。\n\n### 3.2.2代码示例\n\n使用`-S`选项编译文件，就可以仅得到编译器产生的汇编文件`test.s`：`gcc -Og -S test.c`。\n\n`test.s`示例：\n\n```bash\ntest:\n  pushq %rbx\n  movq %rdx, %rbx\n  call mult2\n  movq %rax, (%rbx)\n  popq %rbx\n  ret\n```\n\n使用`-c`选项编译文件，就可以编译并汇编代码产生二进制文件`test.o`：`gcc -Og -c test.c`。\n\n1368字节的文件`test.o`中有一段14字节的序列，它的十六进制表示为：`53 48 89 d3 e8 00 00 00 00 48 89 03 5b c3`。它的含义我们会在第四章讲。\n\n**反汇编器**\n\n**反汇编器程序**根据机器代码产生一种类似于汇编代码的格式。在Linux，带`-d`命令行标志的程序OBJDUMP可以充当这个角色：\n\n`objdump -d test.o`\n\n我们得到的结果为\n\n```bash\n0000000000000000 <multstore>:\n0: 53               push   %rbx\n1: 48 89 d3         mov    %rdx, %rbx\n4: e8 00 00 00 00   callq  9 <multstore+0x9>\n9: 48 89 03         mov    %rax, (%rbx)\nc: 5b               pop    %rbx\nd: c3               retq\n```\n\n> 要展示程序的二进制目标代码，可以用反汇编器确定该过程的代码长度。然后，在 `.o` 文件上运行GNU调试工具GDB，输入命令： `(gdb) x/14xb multstore` 这条命令告诉GDB显示从函数`multstore`所处地址开始的14个十六进制格式表示的字节。\n>\n\n**值得注意的是**：\n\n- x86-64的指令长度**从1到15个字节**不等。\n  \n  常用的指令以及操作数较少的指令所需的字节数少。\n\n  不太常用或操作数较多的指令所需字节数较多。\n  \n- 设计指令格式的方式是，从某个给定位置开始，可以将字节**唯一地**解码成机器指令。\n  \n  例如，只有指令`pushq %rbx`是以字节值53开头的。\n  \n- 反汇编器只是基于机器代码文件中的字节序列来确定汇编代码。它不需要访问该程序的源代码或汇编代码。\n\n- 反汇编器使用的指令命名规则与GCC生成的汇编代码使用的有些细微的差别。\n\n  它省略了很多指令结尾的`q`。\n  \n  这些后缀是大小指示符，在大多数情况中可以省略。\n  \n  反汇编器给`call`和`ret`指令添加了`q`后缀，同样，省略这些后缀也没有问题。\n\n生成实际可执行的代码需要对一组目标代码文件运行链接器，而这一组目标代码文件中必须含有一个`main`函数，这样会使生成文件包含**启动和终止程序的代码和用来与操作系统交互的代码**。\n\n有时候会插入如`e: 90 nop`这样的指令，**无特殊意义，仅为补充为16字节**。\n\n### 3.2.3关于格式的注解\n\n例：\n\n```bash\ntest:\n	pushq %rbx                #Save %rbx\n	movq %rdx, %rbx           #Copy dest to %rbx\n	call mult2                #Call mult2(x,y)\n	movq %rax, (%rbx)         #Store result at *dest\n	popq %rbx                 #Restore %rbx\n	ret                       #Return\n```\n\n通常给出与讨论内容相关的代码行。每一行的**左边都有编号供引用**，**右边是注释**，简单地描述指令的效果以及它与原始C语言代码中的计算操作的关系。 \n\n这是一种汇编语言程序员写代码的风格。\n\n对于一些应用程序，程序员必须用汇编代码来访问机器的低级特性。一种方法是**用汇编代码编写整个函数，在链接阶段把它们和C函数组合起来**。另一种方法是**利用GCC的支持，直接在C程序中嵌入汇编代码**。\n\n第二种方法示例：\n\n```c\n#include <stdio.h>\nint main() {\n    int a = 2, b = 3, result;\n    asm ("addl %%ebx, %%eax" \n         : "=a" (result)  // 输出：将 eax 赋值给 result\n         : "a" (a), "b" (b)  // 输入：a 传入 eax, b 传入 ebx\n         : "cc");  // 破坏了条件标志寄存器\n    printf("Result = %d\n", result); // 输出 5\n    return 0;\n}\n```\n\n**使用内联汇编的情景**：\n\n- **优化代码**（虽然现在编译器优化能力也很强）。\n- **访问特殊寄存器**（如`rdtsc`计时）。\n- **直接执行CPU指令**（如`cpuid`获取CPU信息）。\n- **驱动开发**（与硬件通信）。\n\n## 3.3数据格式 \n\nIntel用**字（word）**表示16位数据类型。称32位数为**双字（double words）**，称64位数为**四字（quad words）**。\n\n| C声明  | Intel数据类型 | 汇编代码后缀 | 大小(字节) |\n| ------ | ------------- | ------------ | ---------- |\n| char   | 字节          | b            | 1          |\n| short  | 字            | w            | 2          |\n| int    | 双字          | l            | 4          |\n| long   | 四字          | q            | 8          |\n| char*  | 四字          | q            | 8          |\n| float  | 单精度        | s            | 4          |\n| double | 双精度        | l            | 8          |\n\n- **非浮点数**：b，w，l，q分别对应1，2，4，8字节，后缀会加到汇编代码指令后面。\n- **浮点数**：与非浮点数用的是不同的指令和寄存器，所以后缀会有区别。\n\n## 3.4**访问信息\n\n一个x86-64的中央处理单元(CPU)包含一组16个存储64位值的通用目的**寄存器**。 这些寄存器用来存储整数数据和指针。 它们都以`%r`开头。\n\n1. 在最初的`8086`中是8个16位寄存器。\n2. 扩展到`IA32`架构时扩展成32位寄存器。\n3. 扩展到`x86-64`扩展成64位，且增加了8个寄存器。\n\n| 32-63位 | 16-31位 | 8-15位  | 0-7位   | 用途         |\n| ------- | ------- | ------- | ------- | ------------ |\n| `%rax`  | `%eax`  | `%ax`   | `%al`   | 返回值       |\n| `%rbx`  | `%ebx`  | `%bx`   | `%bl`   | 被调用者保存 |\n| `%rcx`  | `%ecx`  | `%cx`   | `%cl`   | 第4个参数    |\n| `%rdx`  | `%edx`  | `%dx`   | `%dl`   | 第3个参数    |\n| `%rsi`  | `%esi`  | `%si`   | `%sil`  | 第2个参数    |\n| `%rdi`  | `%edi`  | `%di`   | `%dil`  | 第1个参数    |\n| `%rbp`  | `%ebp`  | `%bp`   | `%bpl`  | 被调用者保存 |\n| `%rsp`  | `%esp`  | `%sp`   | `%spl`  | 栈指针       |\n| `%r8`   | `%r8d`  | `%r8w`  | `%r8b`  | 第5个参数    |\n| `%r9`   | `%r9d`  | `%r9w`  | `%r9b`  | 第6个参数    |\n| `%r10`  | `%r10d` | `%r10w` | `%r10b` | 调用者保存   |\n| `%r11`  | `%r11d` | `%r11w` | `%r11b` | 调用者保存   |\n| `%r12`  | `%r12d` | `%r12w` | `%r12b` | 被调用者保存 |\n| `%r13`  | `%r13d` | `%r13w` | `%r13b` | 被调用者保存 |\n| `%r14`  | `%r14d` | `%r14w` | `%r14b` | 被调用者保存 |\n| `%r15`  | `%r15d` | `%r15w` | `%r15b` | 被调用者保存 |\n\n指令可以对这16个寄存器的低位字节中存放的不同大小的数据进行操作。字节级操作可以访问最低的字节，16位操作可以访问最低的2个字节，32位操作可以访问最低的4个字节，而64位操作可以访问整个寄存器。\n\n当指令以这些寄存器为目标时，根据字节数会有所不同：\n\n- 生成1字节和2字节数字的指令会保持剩下的字节不变。\n- 生成4字节数字的指令会把高位4个字节置为0（这么规定是为了从`IA32`架构向`x86-64`扩展）。\n\n### 3.4.1操作数指示符\n\n1. **立即数**：用来表示常数值，如`$-577`，`$0x7f`。\n2. **寄存器**：表示某个寄存器的内容，16个寄存器的低位1字节、2字节、4字节或8字节中的一个作为操作数， 这些字节数分别对应于8位、16位、32位或64位。\n3. **内存引用**：根据计算出来的地址访问某个内存位置，如`%rax`。\n\n**寻址模式**：\n\n| 类型   | 格式             | 操作数值                        | 名称                |\n| ------ | ---------------- | ------------------------------- | ------------------- |\n| 立即数 | $\\\\$Imm$          | $Imm$                           | 立即数寻址          |\n| 寄存器 | $r_a$            | $\\text{R}[r_a]$                 | 寄存器寻址          |\n| 存储器 | $Imm$            | $\\text{M}[Imm]$                 | 绝对寻址            |\n| 存储器 | $(r_a)$          | $\\text{M}[R[r_a]]$              | 间接寻址            |\n| 存储器 | $Imm(r_b)$       | $\\text{M}[Imm+R[r_b]]$          | （基址+偏移量）寻址 |\n| 存储器 | $(r_b,r_i)$      | $\\text{M}[R[r_b]+R[r_i]]$       | 变址寻址            |\n| 存储器 | $Imm(r_b,r_i)$   | $\\text{M}[Imm+R[r_b]+R[r_i]]$   | 变址寻址            |\n| 存储器 | $(,r_i,s)$       | $\\text{M}[R[r_i]· s]$           | 比例变址寻址        |\n| 存储器 | $Imm(,r_i,s)$    | $\\text{M}[Imm+R[r_i]·s]$        | 比例变址寻址        |\n| 存储器 | $(r_b,r_i,s)$    | $\\text{M}[R[r_b]+R[r_i]·s]$     | 比例变址寻址        |\n| 存储器 | $Imm(r_b,r_i,s)$ | $\\text{M}[Imm+R[r_b]+R[r_i]·s]$ | 比例变址寻址        |\n\n### 3.4.2数据传送指令\n\n**MOV类**：\n\n| 指令                                                      | 效果            | 描述                                                         |\n| --------------------------------------------------------- | --------------- | ------------------------------------------------------------ |\n| `MOV S, D`                                                | $D\\leftarrow S$ | 传送                                                         |\n| `movb`<br />`movw`<br />`movl`<br />`movq`<br />`movabsq` |                 | 传送字节<br />传送字<br />传送双字<br />传送四字<br />传送绝对的四字 |\n\n源操作数指定的值是**存储在寄存器中或者内存中的一个立即数**。\n\n目的操作数指定**一个寄存器或者一个内存地址的位置**。\n\n> `movl`指令会把目的寄存器的高位4字节设置为0。\n\n在将较小的源值复制到较大的目的时使用MOVZ类或MOVS类。其中后者会做符号位扩展。\n\n| 指令                                                         | 效果                     | 描述                                                         |\n| ------------------------------------------------------------ | ------------------------ | ------------------------------------------------------------ |\n| `MOVZ S, R`                                                  | $R\\leftarrow$零扩展$(S)$ | 以零扩展进行传送                                             |\n| `movzbw`<br />`movzbl`<br />`movzwl`<br />`movzbq`<br />`movzwq` |                          | 将做了零扩展的字节传送到字<br />将做了零扩展的字节传送到双字<br />将做了零扩展的字传送到双字<br />将做了零扩展的字节传送到四字<br />将做了零扩展的字传送到四字 |\n\n| 指令                                                         | 效果                                                         | 描述                                                         |\n| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| `MOVS S, R`                                                  | $R\\leftarrow$符号扩展$(S)$                                   | 传送符号扩展的字节                                           |\n| `movsbw`<br />`movsbl`<br />`movswl`<br />`movsbq`<br />`movswq`<br />`movslq`<br />`cltq` | <br /><br /><br /><br /><br /><br />`%rax`$\\leftarrow$符号扩展(`%eax`) | 将做了符号扩展的字节传送到字<br />将做了符号扩展的字节传送到双字<br />将做了符号扩展的字传送到双字<br />将做了符号扩展的字节传送到四字<br />将做了符号扩展的字传送到四字<br />将做了符号扩展的双字传送到四字<br />把`%eax`符号扩展到`%rax` |\n\n### 3.4.4压入和弹出栈数据\n\n**栈顶元素的地址通常是所有栈中元素地址中最低的**。\n\n| 指令                                | 效果                                                         | 描述                                       |\n| ----------------------------------- | ------------------------------------------------------------ | ------------------------------------------ |\n| `pushq S`<br /><br />`popq D`<br /> | $R[\\\\%\\text{rsp}]\\leftarrow R[\\\\%\\text{rsp}]-8$;<br/>$M[R[\\\\%\\text{rsp}]]\\leftarrow S$<br/>$D\\leftarrow M[R[\\\\%\\text{rsp}]]$;<br/>$R[\\\\%\\text{rsp}]\\leftarrow R[\\\\%\\text{rsp}]+8$ | 将四字压入栈<br /><br />将四字弹出栈<br /> |\n\n`pushq`相当于\n\n```bash\nsubq $8, %rsp\nmovq %rbp, (%rsp)\n```\n\n`popq`相当于\n\n```bash\nmovq (%rsp), %rax\naddq $8, %rsp\n```\n\n**栈中被写过的内存位置直到被覆盖前不会被更改**。\n\n**程序可以用标准的内存寻址方法访问栈内的任意位置**。\n\n## 3.5**算术和逻辑操作\n\n| 指令        | 效果             | 描述         |\n| ----------- | ---------------- | ------------ |\n| `leaq S, D` | $D\\leftarrow\\\\&S$ | 加载有效地址 |\n\n| 指令    | 效果                 | 描述 |\n| ------- | -------------------- | ---- |\n| `INC D` | $D\\leftarrow D+1$    | 加1  |\n| `DEC D` | $D\\leftarrow D-1$    | 减1  |\n| `NEG D` | $D\\leftarrow -D$     | 取负 |\n| `NOT D` | $D\\leftarrow \\sim D$ | 取补 |\n\n| 指令        | 效果                      | 描述 |\n| ----------- | ------------------------- | ---- |\n| `ADD S, D`  | $D\\leftarrow D+S$         | 加   |\n| `SUB S, D`  | $D\\leftarrow D-S$         | 减   |\n| `IMUL S, D` | $D\\leftarrow D*S$         | 乘   |\n| `XOR S, D`  | $D\\leftarrow D\\oplus S$   | 异或 |\n| `OR S, D`   | $D\\leftarrow D\ \\vert\ S$ | 或   |\n| `AND S, D`  | $D\\leftarrow D\\\\&S$        | 与   |\n\n| 指令       | 效果                  | 描述     |\n| ---------- | --------------------- | -------- |\n| `SAL S, D` | $D\\leftarrow D<<S$    | 左移     |\n| `SHL S, D` | $D\\leftarrow D<<S$    | 同上     |\n| `SAR S, D` | $D\\leftarrow D>>_AS$  | 算术右移 |\n| `SHR S, D` | $D\\leftarrow D>>_L k$ | 逻辑右移 |\n\n### 3.5.1加载有效地址\n\n`leaq`实际上是`movq`指令的变形，它的指令形式是从内存读数据到寄存器，但实际上它根本就没有引用内存，是**将有效地址写入到目的操作数**（**必须是寄存器**）。\n\n其几乎等效于C语言中的`&`取址符。\n\n### 3.5.2一元和二元操作\n\n见上方表格，第二个即一元操作。\n\n- 一元操作的操作数**可以是一个寄存器，也可以是一个内存位置**。\n\n- 二元操作中，**当第二个操作数为内存地址时，处理器必须从内存读出值，执行操作，再把结果写回内存**。\n\n  内存操作需要显式指定大小\n\n  - 如`BYTE`（1字节）、`WORD`（2字节）、`DWORD`（4字节）、`QWORD`（8字节）。\n\n    ```bash\n    mov  DWORD PTR [eax], 123  将 123 写入 eax 指向的地址，以双字（4字节）形式存储\n    inc  BYTE PTR [mem]        对内存地址 mem 处的字节（1字节）进行加1操作\n    neg  WORD PTR [ebx]        对 ebx 指向的地址处的字（2字节）取负\n    ```\n\n\n### 3.5.3移位操作\n\n移位量可以是一个立即数，或者放在单字节寄存器`％cl`中。（这些指令很特别，因为只允许以这个特定的寄存器作为操作数。）\n\n移位操作对$w$位长的数据值进行操作，移位量是由`％cl`寄存器的低$m$位决定的。\n\n### 3.5.5特殊的算术操作\n\nIntel把16字节的数称为**八字（oct word）**。下面描述的是支持产生两个64位数字的全128位乘积以及整数除法的指令。\n\n| 指令                    | 效果                                                         | 描述                           |\n| ----------------------- | ------------------------------------------------------------ | ------------------------------ |\n| `imulq S`<br />`mulq S` | $R[\\\\%\\text{rdx}]:R[\\\\%\text{rax}]\\leftarrow S\times R[\\\\%\\text{rax}]$<br/>$R[\\\\%\\text{rdx}]:R[\\\\%\\text{rax}]\\leftarrow S\times R[\\\\%\\text{rax}]$ | 有符号全乘法<br />无符号全乘法 |\n| `clto`                  | $R[\\\\%\\text{rdx}]:R[\\\\%\\text{rax}]\\leftarrow符号扩展(R[\\\\%\\text{rax}])$ | 转换为八字                     |\n| `idivq S`               | $R[\\\\%\\text{rdx}]\\leftarrow R[\\\\%\\text{rdx}]: R[\\\\%\\text{rax}]\\text{ mod }S$<br />$R[\\\\%\\text{rdx}]\\leftarrow R[\\\\%\\text{rdx}]:R[\\\\%\\text{rax}]÷S$ | 有符号除法                     |\n| `divq S`                | $R[\\\\%\\text{rdx}]\\leftarrow R[\\\\%\\text{rdx}]: R[\\\\%\\text{rax}]\\text{ mod }S$<br />$R[\\\\%\\text{rdx}]\\leftarrow R[\\\\%\\text{rdx}]:R[\\\\%\\text{rax}]÷S$ | 无符号除法                     |\n\n两个64位有符号或无符号整数相乘得到的乘积需要128位来表示。\n\n- `mulq`，`imulq`都要求一个参数必须在寄存器`%rax`中，而另一个作为指令的源操作数给出。然后乘积存放在寄存器`％rdx`（高64位）和`％rax`（低64位）中。\n\n> 注意区分一个和两个操作数的 `mulq` 。\n>\n\n- 有符号除法指令过`idivl`将寄存器`％rdx`（高64位）和`％rax`（低64位）中的128位数作为**被除数**，而**除数**作为指令的操作数给出。指令将**商**存储在寄存器`％rax`中，将**余数**存储在寄存器`％rdx`中。\n  除数通常是一个64位的值，应该存放在`％rax`中，`％rdx`的位应该设置为全0（无符号运算）或者`％rax`的符号位（有符号运算）。\n\n> 后面这个操作可以用指令 `cqto` （有时也是 `cqo` ）来完成。这条指令不需要操作数而是隐含读出 `％rax` 的符号位，并将它复制到 `％rdx` 的所有位。\n\n## 3.6**控制\n\n### 3.6.1条件码\n\n| 条件码 | 标志类型 | 作用                                                       |\n| ------ | -------- | ---------------------------------------------------------- |\n| `CF`   | 进位标志 | 最近的操作使最高位产生了进位。可用来检查无符号操作的溢出。 |\n| `ZF`   | 零标志   | 最近的操作得出的结果为0。                                  |\n| `SF`   | 符号标志 | 最近的操作得到的结果为负数。                               |\n| `OF`   | 溢出标志 | 最近的操作导致一个补码溢出——正溢出或负溢出。               |\n\n**条件码（condition code）寄存器**，它们描述了最近的算术或逻辑操作的属性。可以检测这些寄存器来执行条件分支指令。\n\n| 指令       | 基于  | 描述     |\n| ---------- | ----- | -------- |\n| `CMP S, D` | $D-S$ | 比较     |\n| `cmpb`     |       | 比较字节 |\n| `cmpw`     |       | 比较字   |\n| `cmpl`     |       | 比较双字 |\n| `cmpq`     |       | 比较四字 |\n\n| 指令        | 基于   | 描述     |\n| ----------- | ------ | -------- |\n| `TEST D, S` | $D\\\\&S$ | 测试     |\n| `testb`     |        | 测试字节 |\n| `testw`     |        | 测试字   |\n| `testl`     |        | 测试双字 |\n| `testq`     |        | 测试四字 |\n\n这两类指令（有8、16、32和64位形式），它们只设置条件码而不改变任何其他寄存器。\n\n### 3.6.2访问条件码\n\n条件码通常不会直接读取，常用的使用方法有三种：\n\n1. 可以根据条件码的某种组合， 将一个字节设置为0或者1。\n2. 可以条件跳转到程序的某个其他的部分。\n3. 可以有条件地传送数据。\n\n| 指令      | 同义名   | 效果                                     | 设置条件             |\n| --------- | -------- | ---------------------------------------- | -------------------- |\n| `sete D`  | `setz`   | $D\\leftarrow ZF$                         | 相等/零              |\n| `setne D` | `setnz`  | $D\\leftarrow\\sim ZF$                    | 不等/非零            |\n| `sets D`  |          | $D\\leftarrow SF$                         | 负数                 |\n| `setns D` |          | $D\\leftarrow\\sim SF$                     | 非负数               |\n| `setg D`  | `setnle` | $D\\leftarrow\\sim(SF\\oplus OF)\\\\&\\sim ZF$ | 大于(有符号>)        |\n| `setge D` | `setnl`  | $D\\leftarrow\\sim(SF\\oplus OF)$          | 大于等于(有符号>=)   |\n| `setl D`  | `setnge` | $D\\leftarrow SF\\oplus OF$                | 小于(有符号<)        |\n| `setle D` | `setng`  | $D\\leftarrow (SF\\oplus OF)\\vert ZF$      | 小于等于(有符号<=)   |\n| `seta D`  | `setnbe` | $D\\leftarrow\\sim CF\\\\&\\sim ZF$          | 超过(无符号>)        |\n| `setae D` | `setnb`  | $D\\leftarrow\\sim CF$                    | 超过或相等(无符号>=) |\n| `setb D`  | `setnae` | $D\\leftarrow CF$                         | 低于(无符号<)        |\n| `setbe D` | `setna`  | $D\\leftarrow CF\\vert ZF$                 | 低于或相等(无符号<=) |\n\n该操作会将目标操作数**第一位设置为0或1**。如果需要零扩展，请使用`MOVZ`指令。\n\n### 3.6.3跳转指令\n\n| 指令           | 同义名 | 跳转条件                   | 描述                 |\n| -------------- | ------ | -------------------------- | -------------------- |\n| `jmp Label`    |        | 1                          | 直接跳转             |\n| `jmp *Operand` |        | 1                          | 间接跳转             |\n| `je Label`     | `jz`   | $ZF$                       | 相等/零              |\n| `jne Label`    | `jnz`  | $\\sim ZF$                      | 不相等/非零          |\n| `js Label`     |        | $SF$                       | 负数                 |\n| `jns Label`    |        | $\\sim SF$                      | 非负数               |\n| `jg Label`     | `jnle` | $\\sim(SF\\oplus OF)\\\\&\\sim ZF$ | 大于(有符号>)        |\n| `jge Label`    | `jnl`  | $\\sim(SF\\oplus OF)$           | 大于或等于(有符号>=) |\n| `jl Label`     | `jnge` | $SF\\oplus OF$              | 小于(有符号<)        |\n| `jle Label`    | `jng`  | $(SF\\oplus OF)\\vert ZF$    | 小于或等于(有符号<=) |\n| `ja Label`     | `jnbe` | $\\sim CF\\\\&\\sim ZF$                 | 超过(无符号>)        |\n| `jae Label`    | `jnb`  | $\\sim CF$                      | 超过或相等(无符号>=) |\n| `jb Label`     | `jnae` | $CF$                       | 低于(无符号<)        |\n| `jbe Label`    | `jna`  | $CF\\vert ZF$               | 低于或相等(无符号<=) |\n\n跳转（jump）指令会导致执行切换到程序中一个全新的位置。\n\n`jmp *%rax`会跳转到`%rax`中的值而`jmp *(%rax)`以`%rax`中的值作为读地址，从内存中读出跳转目标。\n\n### 3.6.4跳转指令的编码\n\n跳转指令有几种不同的编码，但是最常用都是**PC相对的（PC-relative）**。\n\n第一种编码方法是：它们会将目标指令的地址与紧跟在跳转指令后面那条指令的地址之间的差作为编码。这些地址偏移量可以编码为1、2或4个字节。\n**目标地址=当前指令的下一条指令地址+偏移量**。\n\n第二种编码方法是：给出绝对地址，用4个字节直接指定目标。汇编器和链接器会选择适当的跳转目的编码。\n\n> `rep` 和 `ret` 指令通常用来实现重复的字符串操作，这里用 `rep` 后面跟 `ret` 的组合来避免使 `ret` 指令成为条件跳转指令的目标，从而使处理器不能预测 `ret` 指令目的（暂时可以无视）。\n\n### 3.6.5用条件控制来实现条件分支\n\n其汇编代码可以用`if`和`goto`的形式去理解。\n\n### 3.6.6用条件传送来实现条件分支\n\n实现条件操作一种策略是使用**数据的条件转移**。这种方法计算一个条件操作的两种结果，然后再根据条件是否满足从中选取一个。\n\n例如：\n\n```bash\ncmpq %rsi, %rdi\ncmovge %rdx, %rax\nret\n```\n\n使用另一种策略即**控制的条件转移**：\n\n**分支条件结果未决时**：处理器无法确定下一条指令的地址，导致流水线暂停（称为**流水线气泡**），性能显著下降。\n\n- **减少流水线停顿**：通过预测分支的方向（跳转/不跳转），提前执行预测路径的指令，保持流水线满载。\n- **提升指令级并行性（ILP）**：避免等待分支条件计算完成，充分利用处理器的执行资源。\n\n**预测失败会导致更多的时钟周期的惩罚**。\n\n| 指令          | 同义名    | 传送条件                | 描述                 |\n| ------------- | --------- | ----------------------- | -------------------- |\n| `cmove S, R`  | `cmovz`   | $ZF$                    | 相等/零              |\n| `cmovne S, R` | `cmovnz`  | $\\sim ZF$                   | 不相等/非零          |\n| `cmovs S, R`  |           | $SF$                    | 负数                 |\n| `cmovns S, R` |           | $\\sim SF$                   | 非负数               |\n| `cmovg S, R`  | `cmovnle` | $\\sim(SF\\oplus OF)\\\\&\\sim ZF$  | 大于(有符号>)        |\n| `cmovge S, R` | `cmovnl`  | $\\sim(SF\\oplus OF)$        | 大于或等于(有符号>=) |\n| `cmovl S, R`  | `cmovnge` | $SF\\oplus OF$           | 小于(有符号<)        |\n| `cmovle S, R` | `cmovng`  | $(SF\\oplus OF)\\vert ZF$ | 小于或等于(有符号<=) |\n| `cmova S, R`  | `cmovnbe` | $\\sim CF\\\\&\\sim ZF$             | 超过(无符号>)        |\n| `cmovae S, R` | `cmovnb`  | $\\sim CF$                   | 超过或相等(无符号>=) |\n| `cmovb S, R`  | `cmovnae` | $CF$                    | 低于(无符号<)        |\n| `cmovbe S, R` | `cmovna`  | $CF\\vert ZF$            | 低于或相等(无符号<=) |\n\n条件传送指令。当传送条件满足时，指令把源值$S$复制到目的$R$。\n\n**实验表明**：只有当两个分支（条件成立/不成立）的代码必须**可安全提前计算**，且不会引发异常或改变程序状态，同时**容易计算**时，例如表达式分别都只是一条加法指令，它才会使用条件传送。即使许多分支预测错误的开销会超过更复杂的计算，GCC还是会使用条件控制转移。\n\n### 3.6.7循环\n\n可以用**条件测试和跳转组合**起来实现循环的效果。GCC和其他汇编器产生的循环代码主要基于两种基本的循环模式。\n\n**让我们从`do-while`开始**：\n\n```c\nint f(int x) {\n    int res = 0;\n    do{\n        res += x;\n    }\n    while(x <= 100);\n    return res;\n}\n```\n\n这个形式可以翻译成：\n\n```c\nint f(int x) {\n    int res = 0;\n    loop:\n    if(x <= 100) {\n        res += x;\n        goto loop;\n    }\n    return res;\n}\n```\n\n所以对应的汇编代码可以是：\n\n```bash\n	movl	$0, %eax\n.L2:\n	addl	%ecx, %eax\n	cmpl	$100, %ecx\n	jle	.L2\n	ret\n```\n\n**`while`循环**：\n\n第一种翻译方法：`jump to middle`\n\n```c\nint f(int n) {\n    int res = 1;\n    while(n > 1) {\n        res *= n;\n        n = n - 1;\n    }\n    return res;\n}\n```\n\n我们把它翻译成：\n\n```c\nint f(int n) {\n    int res = 1;\n    goto test;\nloop:\n    res *= n;\n    n = n - 1;\ntest:\n    if(n > 1) goto loop;\n    return res;\n}\n```\n\n对应的汇编代码可以是：\n\n```bash\n	movl	$1, %eax\n	jmp	.L5\n.L6:\n	imulq	%rdi, %rax\n	subq	$1, %rdi\n.L5:\n	cmpq	$1, %rdi\n	jg	.L6\n	rep; ret\n```\n\n第二种翻译方法：`guarded-do`\n\n```c\nint f(int n) {\n    int res = 1;\n    while(n > 1) {\n        res *= n;\n        n = n - 1;\n    }\n    return res;\n}\n```\n\n我们把它翻译成：\n\n```c\nint f(int n) {\n    int res = 1;\n    if(n <= 1) goto done;\nloop:\n    res *= n;\n    n = n - 1;\ndone:\n    return res;\n}\n```\n\n对应的汇编代码可以是：\n\n```bash\n	cmpq	$1, %rdi\n	jle	.L7\n	movl	$1, %eax\n.L6:\n	imulq	%rdi, %rax\n	subq	$1, %rdi\n	cmpq	$1, %rdi\n	jne	.L6\n	rep; ret\n.L7:\n	movl	$1, %eax\n	ret\n```\n\n**`for`循环**\n\nGCC为`for`循环产生的代码是`while`循环的两种翻译之一，这取决于优化的等级。\n\n### 3.6.8switch语句\n\n`switch`使用跳转表（jump table）这种数据结构使得实现更加高效。\n\n跳转表是一个数组，表项`t`是一个代码段的地址，这个代码段实现当`case`索引值等于1时程序应该采取的动作。\n\n程序代码用`case`索引值来执行一个跳转表内的数组引用，确定跳转指令的目标。\n\n当`case`情况数量比较多（例如4个以上），并且值的范围跨度比较小时，就会使用跳转表。\n\n **不使用跳转表的情况与条件控制类似**，我们具体讲一下跳转表类型：\n\n源代码：\n\n```c\nint f(int x) {\n    switch(x) {\n        case 100:\n            x += 1;\n            break;\n        case 102:\n            x += 2;\n            break;\n        case 103:\n            x += 3;\n            break;\n        case 104:\n            x <<= 4;\n            break;\n        case 106:\n            x -= 5;\n            break;\n        default:\n            x -= 100;\n    }\n    return x;\n}\n```\n\n对应的汇编代码：\n\n```bash\nf:\n	leal	-100(%rcx), %eax      #减去 100 ，使得方便处理偏移量\n	cmpl	$6, %eax              #大于 6 则进入 default\n	ja	.L2\n	movl	%eax, %eax            #占位符\n	leaq	.L4(%rip), %rdx       #将 .L4 标签的地址加载到 rdx 寄存器中\n	movslq	(%rdx, %rax, 4), %rax #从内存地址%rdx+%rax*4处读取一个32位有符号整数，并将其扩展为64位后存入rax。此时%rax的值是目标地址相对于.L4的偏移量\n	addq	%rdx, %rax            #.L4存储的是相对偏移量，需要加上.L4的基地址rdx，得到目标地址的完整位置\n	jmp	*%rax                 #根据rax中的地址进行间接跳转，执行对应的代码块\n	.section .rdata,"dr"          #声明一个只读数据段，属性为 dr（data, readonly）。\n	.align 4                      #数据按 4 字节对齐。\n.L4:                              #跳转表\n	.long	.L8-.L4\n	.long	.L2-.L4\n	.long	.L7-.L4\n	.long	.L6-.L4\n	.long	.L5-.L4\n	.long	.L2-.L4\n	.long	.L3-.L4\n	.text\n.L8:\n	leal	1(%rcx), %eax\n.L1:\n	ret\n.L7:\n	leal	2(%rcx), %eax\n	jmp	.L1\n.L6:\n	leal	3(%rcx), %eax\n	jmp	.L1\n.L5:\n	movl	%ecx, %eax\n	sall	$4, %eax\n	jmp	.L1\n.L3:\n	leal	-5(%rcx), %eax\n	jmp	.L1\n.L2:\n	leal	-100(%rcx), %eax\n	jmp	.L1\n```\n\n比较难理解的是跳转表部分：\n\n假设：\n\n- `.L4`的地址是`0x1000`\n- `.L8`的地址是`0x1020`\n\n那么：\n\n`leaq	.L4(%rip), %rdx`后`%rdx`是`0x1000`\n`movslq	(%rdx, %rax, 4), %rax`后`%rax`是`0x20`\n`addq	%rdx, %rax`后`rax`是`0x1020`\n\n## 3.7*过程\n\n过程提供了一种封装代码的方式，用一组指定的参数和一个可选的返回值实现了某种功能。\n\n假设过程`P`调用过程`Q`，`Q`执行后返回到`P`。这些动作包括下面一个或多个机制：\n\n**传递控制**：在进入过程`Q`的时候，程序计数器必须被设置为`Q`的代码的起始地址，然后在返回时，要把程序计数器设置为`P`中调用`Q`后面那条指令的地址。\n\n**传递数据**：`P`必须能够向`Q`提供一个或多个参数，`Q`必须能够向`P`返回一个值。\n\n**分配和释放内存**：在开始时，`Q`可能需要为局部变量分配空间，而在返回前，又必须释放这些存储空间。 \n\nx86-64 的过程实现包括一组特殊的指令和一些对机器资源（例如寄存器和程序内存）使用的约定规则。它遵循了被认为是最低要求策略的方法，只实现上述机制中每个过程所必需的那些。\n\n### 3.7.1运行时栈\n\n过程`P`调用过程`Q`：\n\n- 当`Q`在执行时，`P`以及所有在向上追溯到`P`的询用链中的过程，都是**暂时被挂起**的。\n- 当`Q`运行时，它只需要为局部变量分配新的存储空间，或者设置到另一个过程的调用。\n- 当`Q`返回时，任何它所分配的局部存储空间都可以**被释放**。\n\n因此，程序可以用栈来管理它的过程所需要的**存储空间**，栈和程序寄存器存放着传递控制和数据、分配内存所需要的信息。 当`P`调用`Q`时，控制和数据信息添加到栈尾。当`P`返回时，这些信息会释放掉。\n\n*x86-64的栈向低地址方向增长*。\n\n栈指针`%rsp`指向栈顶（更低的地址）元素。\n\n`pushq`：**将数据存入栈中**，将栈指针减小一个适当的量可以为没有指定初始值的数据在栈上分配空间。\n\n`popq`：**将数据从栈中取出**，通过增加栈指针来释放空间。\n\n**栈帧**：\n\n当x86-64过程需要的存储空间超出寄存器能够存放的大小时，就会在栈上分配空间（栈帧）。\n\n栈帧的部分包括：\n\n- **函数参数**：\n\n  在函数调用时，参数通常通过寄存器传递，但为了确保函数调用的独立性，栈中也会保留一份参数的副本。\n\n- **局部变量**：\n\n  - 函数内部声明的局部变量存储在栈帧中，以确保不同函数调用之间的局部变量互不干扰。\n  - 局部变量的大小和数量决定了栈帧中用于存储局部变量的空间大小。\n\n- **返回地址**：\n\n  在函数调用时，返回地址被压入栈中，函数执行完毕后，通过弹出返回地址来恢复执行流程。\n\n- **保存的寄存器**：\n\n  - 函数通常会将需要使用的寄存器的值保存在栈帧中。\n  - 这些保存的寄存器值在函数返回前被恢复，以确保调用函数的寄存器状态不受影响。\n\n- **栈帧基址指针（Base Pointer, RBP）**：\n\n  - 栈帧基址指针是一个寄存器，用于指向当前栈帧的基地址。\n\n**大多数过程的栈帧都是定长的，在过程的开始就分配好了。但是有些过程需要变长的帧**。\n\n**当所有的局部变量都可以保存在寄存器中，而且该函数不会调用任何其他函数时，并不需要栈帧**。\n\n### 3.7.2转移控制\n\n将控制从函数`P`转移到函数`Q`只需要简单地把程序计数器(PC)设置为`Q`的代码的起始位置。 \n\n返回过程要通过`call`指令调用过程`Q`来记录。\n\n| 指令            | 描述             |\n| --------------- | ---------------- |\n| `call Label`    | 过程调用         |\n| `call ·Operand` | 过程调用         |\n| `ret`           | 从过程调用中返回 |\n\n`call Q`会把`P`的地址`A`压入栈中，将`PC`设置为`Q`的起始地址。\n\n`ret`会从栈中弹出地址`A`，并把`PC`设置为`A`。\n\n### 3.7.3数据传送\n\nx86-64中，大部分过程间的数据传送是通过寄存器实现的。\n\n寄存器的使用具有特殊顺序（详见前表），可以通过64位寄存器适当的部分访问小于64位的参数。\n\n存储参数的寄存器只有6个，当函数有大于6个整型参数时，**超出6个的部分就要通过栈来传递**：\n\n1. 要把参数1到6复制到对应的寄存器，为超出6个部分的参数分配空间，把参数7到n放到栈上，而参数7位于栈顶。\n\n   其中通过栈传递参数时，所有的数据大小都向8的倍数对齐。\n\n2. 程序再执行`call`指令将控制转移到过程`Q`。\n\n例：\n\n```c\nvoid f(long a1, long *a1p, int a2, int *a2p, short a3, short *a3p, char a4, char *a4p) {\n    *a1p += a1;\n    *a2p += a2;\n    *a3p += a3;\n    *a4p += a4;\n}\n```\n\n```bash\nf:\n	movq	16(%rsp), %rax  #从栈获取a4p\n	addq	%rdi, (%rsi)\n	addl	%edx, (%rcx)\n	addw	%r8w, (%r9)\n	movl	8(%rsp), %edx   #从栈获取a4\n	addb	%dl, (%rax)\n	ret\n```\n\n> `movl`从内存读入4字节，而`addb`只使用其中的低位一字节以对应char的字节数。\n\n### 3.7.4栈上的局部存储\n\n有些时候局部数据必须存放在内存中，包括：\n\n- 寄存器不足够存放所有的本地数据。\n- 对一个局部变量使用地址运算符&，因此必须能够为它产生一个地址。\n- 某些局部变量是数组或结构，因此必须能够通过数组或结构引用被访问到。\n\n例：\n\n```c\nlong call_f() {\n    long x1 = 1;\n    int x2 = 2;\n    short x3 = 3;\n    char x4 = 4;\n    f(x1, &x1, x2, &x2, x3, &x3, x4, &x4);\n    return (x1 + x2) * (x3 - x4);\n}\n```\n\n```bash\ncall_f:\n	subq	$32, %rsp\n	movq	$1, 24(%rsp)\n	movl	$2, 20(%rsp)\n	movw	$3, 18(%rsp)\n	movb	$4, 17(%rsp)\n	leaq	17(%rsp), %rax\n	movq	%rax, 8(%rsp)\n	movl	%4, (%rsp)\n	leaq	18(%rsp), %r9\n	movl	$3, %r8d\n	leaq	20(%rsp), %r9\n	movl	$3, %r8d\n	leaq	24(%rsp), %rsi\n	movl	$1, %edi\n	call	f\n	movslq	20(%rsp), %rdx\n	addq	24(%rsp), %rdx\n	movswl	18(%rsp), %eax\n	movsbl	17(%rsp), %ecx\n	subl	%ecx, %eax\n	cltq\n	imulq	%rdx, %rax\n	addq	$32, %rsp\n	ret\n```\n\n可以看到代码中第2~15行是为调用函数f做准备。其中包括**为局部变量和函数参数建立栈帧**，**将函数参数加载至寄存器**。\n\n在栈上分配局部变量$x_1\\sim x_4$，它们具有不同的大小：$24\\sim 31(x_1)，20\\sim 23(x_2)，18\\sim19(x_3)和17(x_4)$。用`leaq`指令生成到这些位置的指针（第$7、10、12和14$行）。参数$7$（值为$4$）和参数$8$（指向$x_4$的位置的指针）存放在栈中相对于栈指针偏移量为$0$和$8$的地方(第$8\\sim9$行)。\n\n当调用过程`f`时，参数$7$和参数$8$现在位于相对于栈指针偏移量为$8$和$16$的地方，因为返回地址这时已经被压入栈中了。\n\n下图是`call_f`的栈帧。\n\n<img src="./pictures/image-20250321142208224.png">\n\n在程序结束前，把栈指针加32，释放这个栈帧。\n\n### 3.7.5寄存器中的局部存储空间\n\n寄存器组是唯一被所有过程共享的资源，因此必须确保当一个过程**调用**另一个过程（被调用者）时，被调用者不会**覆盖**调用者稍后会使用的寄存器值。为此，x86-64采用了一组统一的寄存器使用惯例，所有的过程（包括程序库）都必须遵循。\n\n**通常**：`%rbx`、`%rbp`和`%r12~%r15`是**被调用者保存寄存器**。发生P过程调用Q过程的时候，Q必须保存这些寄存器的值，并确保它们在Q返回时的值也是一样的。\n\n- 可以不去改变这些寄存器的值。\n- 也可以把原始值压入栈中，在返回前从栈中弹出旧值，保存回寄存器中。\n\n其它寄存器除了`%rsp`，都是**调用者保存寄存器**。过程P在某个此类寄存器中有局部数据，然后调用过程Q。因为Q可以随意修改这个寄存器，所以P要在调用之前首先保存好这个数据。\n\n执行过程中**值的弹出顺序与压入顺序相反**。\n\n### 3.7.6递归过程\n\n栈规则提供了一种机制，每次函数调用都有它自己**私有的状态信息**（**保存的返回位置**和**被调用者保存寄存器的值**）存储空间。如果需要，它还可以提供局部变量的存储。\n\n栈分配和释放的规则很自然地就与函数调用-返回的顺序匹配。这种实现函数调用和返回的方法甚至对更复杂的情况也适用，包括相互递归调用（例如，过程P调用Q，Q再调用P）。\n\n## 3.8*数组分配和访问\n\nC语言中会产生指向数组中元素的指针，并对这些指针进行运算。\n\n### 3.8.1基本原则\n\n声明`T A[N]`。\n\n- 起始位置表示为$x_A$。它在内存中分配一个`L•N`字节的连续区域，这里`L`是数据类型`T`的大小（单位为字节）。\n- 其次，它引入了标识符`A`，可以用`A`来作为指向数组开头的指针，这个指针的值就是$x_A$。可以用$0\\sim N-1$的整数索引来访问该数组元素。数组元素$i$会被存放在地址为$x_A+L·i$的地方。\n\nx86-64的内存引用指令可以用来简化数组访问。例如，假设`E`是一个int 型的数组，\n而我们想计算`E[i]`，在此，`E`的地址存放在寄存器`%rdx`中，而`i`存放在寄存器`％rcx`中。\n\n```bash\nmovl (rdx,%rcx,4) %eax\n```\n\n\n会执行地址计算$x_E+4i$，读这个内存位置的值，并将结果存放到寄存器`％eax`中。\n\n### 3.8.2指针运算\n\nC语言允许对指针进行运算。也可以用`&`和`*`产生指针和间接引用指针。\n\n| 表达式     | 类型   | 值                  | 汇编代码                        |\n| ---------- | ------ | ------------------- | ------------------------------- |\n| `E`        | `int*` | $x_E$               | `movq %rdx, %rax`               |\n| `E[0]`     | `int`  | $\\text{M}[x_E]$       | `movl (%rdx), %rax`             |\n| `E[i]`     | `int`  | $\\text{M}[x_E+4i]$    | `movl (%rdx, %rcx, 4), %eax`    |\n| `&E[2]`    | `int*` | $x_E+8$             | `leaq 8(%rdx), %rax`            |\n| `E+i-1`    | `int*` | $x_E+4i-4$          | `leaq -4(%rdx, %rcx, 4), %rax`  |\n| `*(E+i-3)` | `int`  | $\\text{M}[x_E+4i-12]$ | `movl -12(%rdx, %rcx, 4), %eax` |\n| `&E[i]-E`  | `long` | $i$                 | `movq %rcx, %rax`               |\n\n### 3.8.3嵌套的数组\n\n以`int A[R][C]`为例：\n\n- 数组的大小为$4\\times R\\times C$字节。\n- 行优先顺序排列，数组元素的内存地址为$\\\\&A[i][j]=x_A+L(C·i+j)$。\n\n可以用下面的代码将数组元素`A[i][j]`复制到寄存器`％eax`中。\n\n```bash\nleaq (%rsi, %rsi, 2), %rax\nleaq (%rdi, %rax, 4), %rax\nmovl (%rax, %rdx, 4), %eax\n```\n\n**更多维的数组**：\n\n以`int A[R][C][D]`为例：\n\n- 数组的大小为$4\\times R\\times C$字节。\n- 行优先顺序排列，数组元素的内存地址为$A[i][j][k]=x_A+L[C·D·i+D·j]$。\n\n### 3.8.4定长数组\n\nC语言编译器能够优化定长多维数组上的操作代码。\n\n例如：\n\n```c\nint fix_prod_ele(fix_matrix A, fix_matrix B, long i, long k) {\n    long j;\n    int result = O;\n    for(j = O; j < N; j++) result += A[i][j] * B[j][k];\n    return result;\n}\n```\n\n会被优化为：\n\n```c\nint fix_prod_ele_opt(fix_matrix A, fix_matrix B, long i, long k) {\n    int *Aptr = &A[i][0];\n    int *Bptr = &B[0][k];\n    int *Bend = &B[N][k];\n    int result = 0;\n    do {\n        result += *Aptr * *Bptr;\n        Aptr++;\n        Bptr += N;\n    } while(Bptr != Bend);\n    return result;\n}\n```\n\n- **减少了索引运算**（如`A[i][j]`→`*Aptr`）。\n- **减少了循环判断**，利用`Bend`作为终止条件。\n- **减少了乘法运算**（`Bptr+=N`直接跳到下一行，而不是计算`B[j][k]`的索引）。\n\n### 3.8.5变长数组\n\nISOC99后我们可以允许数组的维度是**表达式**，**在数组被分配的时候才计算出来**。\n\n例如：\n\n```c++\nint var_ele(long n, int A[n][n], long i, long j) {\n    return A[i][j];\n}\n```\n\nGCC为这个函数产生的代码可能是：\n\n```bash\nvar_ele:\n  imulq  %rdx, %rdi\n  leaq   (%rsi, %rdi, 4), %rax\n  movl   (%rax, %rcx, 4), %eax\nret\n```\n\n这段代码计算元素$i$，$j$的地址为$x_A+4(n·i+j)$，类似于定长数组的地址计算，不同点在于：\n\n1. 由于增加了参数$n$，寄存器的使用变化了。\n2. 用了乘法指令来计算$n·i$，而不是用`leaq`指令来计算$3i$。\n\n因此引用变长数组只需要对定长数组做一点儿概括。动态的版本必须用乘法指令对$i$伸缩$n$倍，而不能用一系列的移位和加法。\n\n**在一个循环中引用变长数组时，编译器常常可以利用访问模式的规律性来优化索引的计算**。\n\n原始C代码：\n\n```c\nint var prod_ele(long n, int A[n][n], int B[n][n], long i, long k) {\n    long j;\n    int result = O;\n    for(j = 0; j < n; j++) result += A[i][j] * B[j][k];\n    return result;\n}\n```\n\n优化后的C代码：\n\n```c\nint var prod_ele_opt(long n, int A[n][n], int B[n][n], long i, long k) {\n    int *Arow = A[i];\n    int *Bptr = &B[0][k];\n    int result = 0;\n    long j;\n    for(j = 0; j < n; j++) {\n        result += Arow[j] * *Bptr;\n        Bptr += n;\n    }\n    return result;\n}\n```\n\n我们看到程序既使用了伸缩过的值$4n$（寄存器`％r9`）来增加`Bptr`，也使用了$n$的值（寄存器`％rdi`中）来检查循环的边界。\n\n因此：**如果允许使用优化，GCC能够识别出程序访问多维数组的元素的步长。然后生成的代码会避免直接应用乘法。不论生成基于指针的代码还是基于数组的代码，这些优化都能显著提高程序的性能。**\n\n## 3.9*异质的数据结构\n\n### 3.9.1结构\n\n结构的所有组成部分都存放在**内存中一段连续的区域内**，而**指向结构的指针就是结构第一个字节的地址**。\n\n编译器维护关于每个结构类型的信息，指示每个字段的字节偏移。它以这些偏移作为内存引用指令中的位移，从而产生对结构元素的引用。\n\n例如：\n\n```c\nstruct rec {  // 下面是变量相对于结构第一个字节地址的偏移\n    int i;    // 0~3\n    int j;    // 4~7\n    int a[2]; // 8~15\n    int *p;   // 16~23\n};\n```\n\n用一个例子展示结构体中编译器的行为：\n\n```c\nr->p = &r->a[r->i + r->j];\n```\n\n开始时$r$在寄存器`%rdi`中。\n\n```bash\nmovl    4(%rdi), %eax\naddl    (%rdi), %eax\ncltq\nleaq    8(%rdi, %rax, 4), %rax\nmovq    %rax, 16(%rdi)\n```\n\n综上所述，结构的各个字段的选取完全是在编译时处理的。机器代码不包含关于字段声明或字段名字的信息。\n\n### 3.9.2联合\n\n联合提供了一种方式，能够规避C语言的类型系统，允许以多种类型来引用一个对象。\n\n联合声明的语法与结构的语法一样，只不过语义相差比较大。它们是**用不同的字段来引用相同的内存块**，也因此：**一个联合的总的大小等于它最大字段的大小**。\n\n一个很好的例子：我们想实现一颗二叉树，若为叶子结点，其左右孩子存储值，否则存储指向左右孩子结点的指针\n\n```c\nstruct node_s {\n    struct node_s *left;\n    struct node_s *right;\n    double data[2];\n};\n```\n\n这种做法显然很浪费空间，我们可以联合！\n\n```c\nunion node_u {\n    struct {\n        union node_u *left;\n        union node_u *right;\n    } internal;\n    double data[2];\n};\n```\n\n这样，每个节点就只需要16个字节。\n\n除了**节省空间**，联合还可以用来**访问不同数据类型的位模式**。\n\n```c\nunsigned long double2bits(double d) {\n    union {\n        double d;\n        unsigned long u;\n    } temp;\n    temp.d = d;\n    return temp.u;\n};\n```\n\n此外，联合意味着**字节顺序问题**也很重要。\n\n```c\ndouble uu2double(unsigned wordO, unsigned word1) {\n    union {\n        double d;\n        unsigned u[2];\n    } temp;\n    temp.u[0] = word0;\n    temp.u[1] = word1;\n    return temp.d;\n}\n```\n\n在小端法机器上，参数`word0`是`d`的低位4个字节，而`word1`是高位4个字节。在大端法机器上，这两个参数的角色刚好相反。\n\n### 3.9.3数据对齐\n\n许多计算机系统对基本数据类型的合法地址做出了一些限制，要求某种类型对象的地址必须是某个值（通常是2、4或8）的倍数。\n\n这种对齐限制**简化了形成处理器和内存系统之间接口的硬件设计**。比如借此我们可以用一个内存操作来读或者写值，否则对象可能被分放在两个8字节内存块，我们需要执行两次内存访问。\n\n- 跳转表的汇编代码声明在第2行可能包含下面这样的命令：\n\n  ```bash\n  .align 8\n  ```\n\n  后面的元素都会遵守8字节对齐的限制。\n\n- 对于包含结构的代码，编译器可能需要在字段的分配中插入间隙，以保证每个结构元素都满足它的对齐要求。而结构本身对它的起始地址也会满足之前的对齐要求，例如：\n\n  ```c\n  struct S {\n      int x;  //0~3\n      char s;  //4~4\n      int j;  //8~11\n  }d[4];\n  ```\n\n  编译器会为结构`S`分配12个字节，\n\n  而结构体的对齐是根据其成员中最大的对齐要求来决定的，所以`d`的元素的地址分别为$x_d,x_d+12,x_d+24,x_d+36$。\n\n## 3.10在机器级程序中将控制与数据结合起来\n\n### 3.10.1理解指针\n\n- **每个指针都对应一个类型**：这个类型表明该指针指向的是哪一类对象。特殊的`void*`类型代表通用指针。指针类型不是机器代码中的一部分，而是C语言提供的一种**抽象**，帮助程序员避免寻址错误。\n\n- **每个指针都有一个值**：这个值是某个指定类型的对象的地址。特殊的`null`（C++引入了`nullptr`）值表示该指针没有指向任何地方。\n\n- **指针用**`&`**运算符创建**：我们已经看到，因为`leaq`指令是设计用来计算内存引用的地址的，＆运算符的机器代码实现常常用这条指令来计算表达式的值。\n\n- `*`**操作符用于间接引用指针**：其结果是一个值，它的类型与该指针的类型一致。\n\n- **数组与指针紧密联系**：一个数组的名字可以像一个指针变量一样引用（但是不能修改）。\n  \n  数组引用（例如`a[3]`）与指针运算和间接引用（例如`＊(a+3)`）有一样的效果。\n  \n- **将指针从一种类型强制转换成另一种类型，只改变它的类型，而不改变它的值**：\n\n  强制类型转换的一个效果是改变指针运算的伸缩。\n\n  例如，如果`p`是一个`char`类型的指针，它的值为$p$，那么表达式`(int*)p+7`计算为$p+28$，而`(int*)(p+7)`计算为$p+7$ 。（~~强制类型转换的优先级高于加法~~。）\n\n- **指针也可以指向函数**：函数指针的值是该函数机器代码表示中第一条指令的地址。\n\n~~用了java可以发现指针的星号是不必要的，毕竟怎么不能用整型储存地址呢？~~\n\n### 3.10.2**应用：使用GDB调试器\n\n这有助于玩$Bomb\\ \\ Lab$。\n\n| 命令                           | 效果                                          |\n| ------------------------------ | --------------------------------------------- |\n| **开始和停止**                 |                                               |\n| `quit`                         | 退出GDB                                       |\n| `run`                          | 运行程序（在此给出命令行参数）                |\n| `kill`                         | 停止程序                                      |\n| **断点**                       |                                               |\n| `break multstore`              | 在函数`multstore`入口处设置断点               |\n| `break *0x400540`              | 在地址`0x400540`处设置断点                    |\n| `delete 1`                     | 删除断点1                                     |\n| `delete`                       | 删除所有断点                                  |\n| **执行**                       |                                               |\n| `stepi`                        | 执行1条命令                                   |\n| `stepi 4`                      | 执行4条命令                                   |\n| `nexti`                        | 类似于`stepi`，但以函数调用为单位             |\n| `continue`                     | 继续执行（到下一个断点）                      |\n| `finish`                       | 运行到当前函数返回                            |\n| **检查代码**                   |                                               |\n| `disas`                        | 反汇编当前函数                                |\n| `disas multstore`              | 反汇编函数`multstore`                         |\n| `disas 0x400544`               | 反汇编位于地址`0x400544`附近的函数            |\n| `disas 0x400540,0x40054d`      | 反汇编指定地址范围内的代码                    |\n| `print /x $rip`                | 以十六进制输出程序计数器的值                  |\n| **检查数据**                   |                                               |\n| `print $rax`                   | 以十进制输出`%rax`的内容                      |\n| `print /x $rax`                | 以十六进制输出`%rax`的内容                    |\n| `print /t $rax`                | 以二进制输出`%rax`的内容                      |\n| `print 0x100`                  | 输出`0x100`的十进制表示                       |\n| `print /x 555`                 | 输出555的十六进制表示                         |\n| `print /x ($rsp+8)`            | 以十六进制输出`%rsp`的内容加上8               |\n| `print*(long *)0x7fffffffe818` | 输出位于地址`0x7fffffffe818`的长整数          |\n| `print*(long *)($rsp+8)`       | 输出位于地址`$rsp+8`处的长整数                |\n| `x/2g 0x7fffffffe818`          | 检查从地址`0x7fffffffe818`开始的双（8字节）字 |\n| `x/20bmultstore`               | 检查函数`multstore`的前20个字节               |\n| **有用的信息**                 |                                               |\n| `info frame`                   | 有关当前栈帧的信息                            |\n| `info registers`               | 所有寄存器的值                                |\n| `help`                         | 获取有关GDB的信息                             |\n\n### 3.10.3*内存越界引用和缓冲区溢出\n\n众所周知，对越界的数组元素的写操作会破坏存储在栈中的状态信息。当程序使用这个被破坏的状态，试图重新加载寄存器或执行`ret`指令时，就会出现很严重的错误。\n\n下面讲一个有趣的例子说明这个问题：\n\n```c\nchar *gets(char *s) {\n    int c;\n    char *dest = s;\n    while((c = getchar()) != \'\n\' && c != EOF) *dest++ = c;\n    if(c == EOF && dest == s) return NULL;\n    *dest++ = \'\0\';\n    return s;\n}\nvoid echo() {\n    char buf[8];\n    gets(buf);\n    puts(buf);\n}\n```\n\n上面我们试图输入一个字符串，并将其复制到参数`s`指明的位置。\n\n```bash\necho:\n  subq    $24, %rsp\n  movq    %rsp, %rdi\n  call    gets\n  movq    %rsp, %rdi\n  call    puts\n  addq    $24, %rsp\n  ret\n```\n\n根据字符串的长度，会出现不同的**被破坏的状态**。\n\n| 输入的字符数量 | 附加的被破坏的状态   |\n| -------------- | -------------------- |\n| 0~7            | 无                   |\n| 9~23           | 未被使用的栈空间     |\n| 24~31          | 返回地址             |\n| 32+            | `caller`中保存的状态 |\n\n达到24个字符后，就会导致程序跳转到一个完全意想不到的位置。\n\n> 一些库函数，如 `strcpy`、`strcat`、`sprintf` ，在目标缓冲区长度小于源字符串时，可能导致缓冲区溢出漏洞。\n>\n\n**缓冲区溢出的一个更加致命的使用就是让程序执行它本来不愿意执行的函数**。\n\n比如输入给程序一个字符串，这个字符串包含一些可执行代码的字节编码，称为**攻击代码**，还有一些字节会用一个指向攻击代码的指针覆盖返回地址。那么，执行`ret`指令的效果就是跳转到攻击代码。\n\n### 3.10.4*对抗缓冲区溢出攻击\n\n1. **栈随机化**\n\n   - 在过去，程序的栈地址非常容易预测。对于所有运行同样程序和操作系统版本的系统来说，在不同的机器之间，栈的位置是相当固定的。\n\n     因此，攻击者可以确定一个常见的Web服务器所使用的栈空间，就可以设计一个在许多机器上都能实施的攻击。这种现象常被称作**安全单一化（security monoculture）**。\n\n   - **栈随机化**的思想使得栈的位置在程序每次运行时都有变化。实现的方式是：\n\n     程序开始时， 在栈上分配一段$0\\sim n$字节之间的随机大小的空间，程序不使用这段空间，但是它会导致程序每次执行时后续的栈位置发生了变化。\n\n     分配的范围**必须足够大**，才能获得足够多的栈地址变化，但是**又要足够小**，不至于浪费程序太多的空间。\n\n   - 在Linux中，**栈随机化**巳经变成了标准行为。它属于**地址空间布局随机化（Address-Space Layout Randomization）**，或者简称**ASLR**技术的一种。\n\n     采用**ASLR**，每次运行时程序的不同部分都会被加载到内存的不同区域，不同机器上相同程序的地址映射会**大相径庭**！\n\n   - 面对**ASLR**，攻击者依然有办法：**空操作雪橇（nop sled）** 是在实际攻击代码前插入一段很长的`nop`指令，只要攻击者能够猜中这段序列中的某个地址， 程序就会经过这个序列，到达攻击代码。\n\n2. **栈破坏检测**\n\n   - 我们能够在发生了越界写的时候，在造成任何有害结果之前，尝试检测到它。\n\n   - **栈保护者（stack protector）机制**：在栈帧中任何局部缓冲区与栈状态之间存储一个特殊的**金丝雀值**，其为每次运行时随机产生。如果某次运行后金丝雀值被改变，则程序异常中止。\n   - 栈保护只会带来很小的性能损失，却能很好地防止缓冲区溢出攻击破坏存储在程序栈上的状态。\n\n3. **限制可执行代码区域**\n\n   - 消除攻击者向系统中插入可执行代码的能力：\n   \n   - **限制哪些内存区域能够存放可执行代码**：\n   \n     许多系统允许控制三种访问形式：读（从内存读数据）、写（存储数据到内存）和执行（将内存的内容看作机器级代码）。\n   \n     在典型的程序中，只有保存编译器产生的代码的那部分内存才需要是可执行的。\n\n### 3.10.5支持变长栈帧\n\n**变长栈帧**指栈帧的大小在运行时才能确定，而非编译时固定。常见于动态内存需求场景。\n\n------\n\n1. **产生变长栈帧的场景**\n\n- 变长数组（VLA）\n\n  ```c\n  void func(int n) {\n      int arr[n]; // 数组长度依赖参数 n，编译时大小未知\n  }\n  ```\n\n- `alloca`动态分配\n\n  ```c\n  void* ptr = alloca(n); // 在栈上动态分配空间（n 运行时确定）\n  ```\n\n- **复杂条件分支**\n  不同分支下使用的局部变量大小不同（需运行时决定）。\n\n------\n\n2. **实现机制**\n\n编译器需在运行时动态调整栈指针（`rsp`），通过以下步骤：\n\n1. **计算所需空间**：根据运行时变量计算总栈空间。\n2. **调整栈指针**：动态修改栈指针。\n3. **维持对齐**：确保调整后的栈指针满足对齐要求。\n\n例如：\n\n```c\nvoid vframe(long n, long idx, long *q) {\n    long i;\n    long *p[n];\n    p[O] = &i;\n    for(i = 1; i < n; i++) p[i] = q;\n    return *p[idx];\n}\n```\n\n```bash\nvframe:\n    pushq %rbp\n    movq  %rsp, %rbp\n    subq  $16, %rsp\n    leaq  22(, %rdi, 8), %rax\n    andq  $-16, %rax\n    subq  %rax, %rsp\n    leaq  7(%rsp), %rax\n    shrq  $3, %rax\n    leaq  0(, %rax, 8), %r8\n    movq  %r8, %rcx\n    \n.L3:\n	movq  %rdx, (%rcx, %rax, 8)\n	addq  $1, %rax\n	movq  %rax, -8(%rdp)\n.L2:\n	movq  -8(%rbp), %rax\n	cmpq  %rdi, %rax\n	jl    .L3\n	\n    leave\n    ret\n```\n\n在函数的整个执行过程中，使`%rbp`指向那个时刻栈的位置，然后用固定长度的局部变量相对于`％rbp`的偏移量来引用它们。\n\n其中`leave`等价于：\n\n```bash\nmovq  %rbp, %rsp\npopq  %rbp\n```\n\n首先把栈指针设置为保存`％rbp`值的位置，然后把该值从栈中弹出到`％rbp` 。这个指令组合具有释放整个栈帧的效果。\n\n------\n\n### 3.11浮点代码\n\n处理器的浮点体系结构包括多个方面，会影响对浮点数据操作的程序如何被映射到机器上，包括：\n\n- 如何存储和访问浮点数值。通常是通过某种寄存器方式来完成。\n- 对浮点数据操作的指令。\n- 向函数传递浮点数参数和从函数返回浮点数结果的规则。\n- 函数调用过程中保存寄存器的规则。例如：一些寄存器被指定为调用者保存，而其他的被指定为被凋用者保存。\n\n本书主要讲**AVX2**，即AVX（Advanced Vector Extension，高级向量扩展）的第二个版本。\n\n**AVX**浮点体系结构允许数据存储在16个`YMM`寄存器中，它们的名字为`%ymm0~%ymm15`。\n\n| 128-255位 | 0-127位  | 用途              |\n| --------- | -------- | ----------------- |\n| `%ymm0`   | `%xmm0`  | 1st FP arg.返回值 |\n| `%ymm1`   | `%xmm1`  | 2nd FP参数        |\n| `%ymm2`   | `%xmm2`  | 3rd FP参数        |\n| `%ymm3`   | `%xmm3`  | 4th FP参数        |\n| `%ymm4`   | `%xmm4`  | 5th FP参数        |\n| `%ymm5`   | `%xmm5`  | 6th FP参数        |\n| `%ymm6`   | `%xmm6`  | 7th FP参数        |\n| `%ymm7`   | `%xmm7`  | 8th FP参数        |\n| `%ymm8`   | `%xmm8`  | 调用者保存        |\n| `%ymm9`   | `%xmm9`  | 调用者保存        |\n| `%ymm10`  | `%xmm10` | 调用者保存        |\n| `%ymm11`  | `%xmm11` | 调用者保存        |\n| `%ymm12`  | `%xmm12` | 调用者保存        |\n| `%ymm13`  | `%xmm13` | 调用者保存        |\n| `%ymm14`  | `%xmm14` | 调用者保存        |\n| `%ymm15`  | `%xmm15` | 调用者保存        |\n\n### 3.11.1浮点传送和转换操作\n\n下面给出一组在内存和XMM寄存器之间以及从一个XMM寄存器到另一个不做任何转换的传送浮点数（$M_{32}$和$M_{64}$）的指令，指令引用内存的指定方式与`MOV`相同。\n\n其中代码优化规则建议32位内存数据满足4字节对齐，64位数据满足8字节对齐。（**$X$是**`XMM`**寄存器，$M_{32}$是32位内存范围，$M_{64}$是64位内存范围**）\n\n| 指令      | 源       | 目的     | 描述                       |\n| --------- | -------- | -------- | -------------------------- |\n| `vmovss`  | $M_{32}$ | $X$      | 传送单精度数               |\n| `vmovss`  | $X$      | $M_{32}$ | 传送单精度数               |\n| `vmovsd`  | $M_{64}$ | $X$      | 传送双精度数               |\n| `vmovsd`  | $X$      | $M_{64}$ | 传送双精度数               |\n| `vmovaps` | $X$      | $X$      | 传送对齐的封装好的单精度数 |\n| `vmovapd` | $X$      | $X$      | 传送对齐的封装好的双精度数 |\n\n把浮点值转换成整数时，指令会执行**截断（truncation）**，把值向$0$进行舍入，这是C和大多数其他编程语言的要求。\n\n**双操作数浮点转换指令。这些操作将浮点数转换成整数**：（**$R_{32}$是32位通用寄存器，$R_{64}$是64位通用寄存器**）\n\n| 指令          | 源         | 目的     | 描述                                 |\n| ------------- | ---------- | -------- | ------------------------------------ |\n| `vcvttss2si`  | $X/M_{32}$ | $R_{32}$ | 用截断的方法把单精度数转换成整数     |\n| `vcvttsd2si`  | $X/M_{64}$ | $R_{32}$ | 用截断的方法把双精度数转换成整数     |\n| `vcvttss2siq` | $X/M_{32}$ | $R_{64}$ | 用截断的方法把单精度数转换成四字整数 |\n| `vcvttsd2siq` | $X/M_{64}$ | $R_{64}$ | 用截断的方法把双精度数转换成四字整数 |\n\n**三操作数浮点转换指令。这些操作将第一个源的数据类型转换成目的的数据类型。第二个源值对结果的低位字节没有影响。**\n\n我们暂且忽略第二个操作数，因为它的值只会影响结果的高位字节。\n\n| 指令         | 源1             | 源2  | 目的 | 描述                     |\n| ------------ | --------------- | ---- | ---- | ------------------------ |\n| `vcvtsi2ss`  | $M_{32}/R_{32}$ | $X$  | $X$  | 把整数转换成单精度数     |\n| `vcvtsi2sd`  | $M_{32}/R_{32}$ | $X$  | $X$  | 把整数转换成双精度数     |\n| `vcvtsi2ssq` | $M_{64}/R_{64}$ | $X$  | $X$  | 把四字整数转换成单精度数 |\n| `vcvtsi2sdq` | $M_{64}/R_{64}$ | $X$  | $X$  | 把四字整数转换成双精度数 |\n\n| 指令        | 源   | 源   | 目的 | 描述                                               |\n| ----------- | ---- | ---- | ---- | -------------------------------------------------- |\n| `vunpcklps` | $X$  | $X$  | $X$  | 交叉放置来自两个源的值，把它们存储到第三个寄存器中 |\n\n这个指令的例子：如果一个源寄存器的内容为字$[s_3,s_2,s_1,s_0]$，另一个源寄存器为字$[d_3,d_2,d_1,d_0]$，那么目的寄存器的值会是$[s_1,d_1,s_0,d_0]$。\n\n### 3.11.2过程中的浮点代码\n\n在x86-64中，`XMM`寄存器用来向函数传递浮点参数，以及从函数返回浮点值。\n\n有如下规则：\n\n- `XMM`寄存器`％xmm0~%xmm7`最多可以传递$8$个浮点参数。按照参数列出的顺序使用这些寄存器。可以通过栈传递额外的浮点参数。\n- 函数使用寄存器`%xmm0`来返回浮点值。\n- 所有的`XMM`寄存器都是调用者保存的。被调用者可以不用保存就覆盖这些寄存器中任意一个。\n\n当函数包含指针、整数和浮点数混合的参数时，指针和整数通过通用寄存器传递，而浮点值通过`XMM`寄存器传递。也就是说，**参数到寄存器的映射取决于它们的类型和排列的顺序**。\n\n比如：\n\n```c\ndouble f(double y, int x, long z);\n```\n\n这个函数会把`x`存放在`％edi`中，`y`放在`％xmm0`中，而`z`放在`％rsi`中。\n\n### 3.11.3浮点运算操作\n\n以下指令每条指令有一个（$S_1$）或两个（$S_1,S_2$）源操作数，和一个目的操作数$D$。\n\n第一个源操作数$S_1$可以是一个`XMM`寄存器或一个内存位置。第二个源操作数和目的操作数都必须是`XMM`寄存器。每个操作都有一条针对单精度的指令和一条针对双精度的指令。结果存放在目的寄存器中。\n\n| 单精度   | 双精度   | 效果                        | 描述         |\n| -------- | -------- | --------------------------- | ------------ |\n| `vaddss` | `vaddsd` | $D\\leftarrow S_2+S_1$       | 浮点数加     |\n| `vsubss` | `vsubsd` | $D\\leftarrow S_2-S_1$       | 浮点数减     |\n| `vmulss` | `vmulsd` | $D\\leftarrow S_2\\times S_1$ | 浮点数乘     |\n| `vdivss` | `vdivsd` | $D\\leftarrow S_2/S_1$       | 浮点数除     |\n| `vmaxss` | `vmaxsd` | $D\\leftarrow \\max(S_2,S_1)$  | 浮点数最大值 |\n| `vminss` | `vminsd` | $D\\leftarrow \\min(S_2,S_1)$  | 浮点数最小值 |\n| `sqrtss` | `sqrtsd` | $D\\leftarrow \\sqrt{S_1}$    | 浮点数平方根 |\n\n### 3.11.4定义和使用浮点常数\n\n和整数运算操作不同， `AVX`浮点操作不能以立即数值作为操作数。相反，编译器必须为所有的常量值分配和初始化存储空间。然后代码在把这些值从内存读入。\n\n例如：\n\n```c\ndouble cel2fahr(double temp) {\n    return 1.8 * temp + 32.0;\n}\n```\n\n对应的汇编代码部分如下：\n\n```bash\ncel2fahr:\n    vmulsd  .LC2(%rip), %xmm0, %xmm0\n	vaddsd  .LC3(%rip), %xmm0, %xmm0\n	ret\n.LC2:\n	.long 3435973837\n	.long 1073532108\n.LC3:\n	.long 0\n	.long 1077936128\n```\n\n### 3.11.5在浮点代码中使用位级操作\n\n这些操作都作用于封装好的数据，即它们更新整个目的`XMM`寄存器，对两个源寄存器的所有位都实施指定的位级操作。从下面的例子中可以看出，运用这些操作通常可以简单方便地操作浮点数。\n\n| 单精度   | 双精度  | 效果                        | 描述     |\n| -------- | ------- | --------------------------- | -------- |\n| `vxorps` | `vorpd` | $D\\leftarrow S_2\\oplus S_1$ | 位级异或 |\n| `vandps` | `andpd` | $D\\leftarrow S_2\\\\&S_1$      | 位级与   |\n\n### 3.11.6浮点比较操作\n\n| 指令           | 基于  | 描述         |\n| -------------- | ----- | ------------ |\n| `ucomiss S, D` | $D-S$ | 比较单精度值 |\n| `ucomisd S, D` | $D-S$ | 比较双精度值 |\n\n这些指令比较操作数$S_1$和$S_2$，并设置条件码指示它们的相对值。\n\n浮点比较指令会设置三个条件码。\n\n| 顺序$S_2:S_1$ | CF   | ZF   | PF   |\n| ------------- | ---- | ---- | ---- |\n| 无序的        | 1    | 1    | 1    |\n| $S_2<S_1$     | 1    | 0    | 0    |\n| $S_2=S_1$     | 0    | 1    | 0    |\n| $S_2>S_1$     | 0    | 0    | 0    |\n\n当任一操作数为$\\text{NaN}$时，就会出现无序的情况。可以通过奇偶标志位发现这种情况。' 
                      },
                      { id: 'computer_basic-3', 
                        title: '5、优化程序性能', 
                        desc: '', 
                        content: '# 5.优化程序性能\n\n## 5.1优化编译器的能力和局限性\n\n大多数编译器向用户提供了一些对它们所使用的优化的**控制**。最简单的控制就是**指定优化级别**。\n\n**编译器必须使优化后的版本与优化前有相同的行为**。\n\n```c\nvoid test1(long *xp，long *yp) {\n    *xp += *yp;\n    *xp += *yp;\n}\n\nvoid test2(long *xp，long *yp) {\n    *xp += 2 * *yp;\n}\n```\n\n显然当`*xp`和`*yp`指向同一个地址的时候，两个代码的效果并不等同，因此`test2`不能作`test1`的优化版本。\n\n------\n\n```c\nx=114514, y=1919810;\n*q = x;\n*p = y;\nt = *q;\n```\n\n这里当`*p`和`*q`指向同一个地址与否也会影响`t`的取值，这会妨碍编译器优化。\n\n------\n\n```c\nlong cnt = 0;\nlong f() {\n    return cnt++;\n}\n\nlong f1() {\n    return f() + f() + f() + f();\n}\n\nlong f2() {\n    return 4 * f();\n}\n```\n\n函数修改全局程序状态，会导致`f1`和`f2`行为不同。\n\n大多数编译器不会试图判断一个函数是否没有副作用，如果没有，就可能被优化成像`f2`中的样子。相反，编译器会假设最糟的情况，并保持所有的函数调用不变。\n\n## 5.2表示程序性能\n\n每元素的周期数（Cycles Per Element，CPE）是一种表示程序性能并指导我们改进代码的方法。\n\n处理器活动的顺序是由时钟控制的，时钟提供了某个频率的规律信号，通常用**千兆赫兹（GHz）**，即**十亿周期每秒**来表示。\n\n**每个时钟周期的时间是时钟频率的倒数**。\n\n从程序员的角度来看，用时钟周期（一秒内执行了多少条指令）来表示度量标准要比用纳秒或皮秒来表示有帮助得多。\n\n------\n\n```c\nvoid psum1(float a[], float p[], long n) {\n    long i;\n    p[0] = a[0];\n    for(i = 1; i < n; i++) p[i] = p[i - 1] + a[i];\n}\n\nvoid psum2(float a[], float p[], long n) {\n    long i;\n    p[0] = a[0];\n    for(i = 1; i < n - 1; i += 2) {\n        float mid_val = p[i - 1] + a[i];\n        p[i] = mid_val;\n        p[i + 1] = mid_val + a[i + 1];\n    }\n    if(i < n) p[i] = p[i - 1] + a[i];\n}\n```\n\n`psum2`使用了**循环展开**。这两个函数的运行时间分别近似于$368+9.0n$和$368+6.0n$，其中$368$是循环以外过程。所以`psum1`的CPE为$9.0$，所以`psum2`的CPE为$6.0$。\n\n## 5.3程序示例\n\n~~这一部分用实验证明了优化选项可以近乎提高几个数量级的性能，接下来的测试中我们将用-O1和-O2级别的优化来生成和测量程序。~~\n\n## 5.4消除循环的低效率\n\n如果我们这么写：\n\n```c\nint getlen(int s[]) {\n    int len = 0;\n    while(s[len] != 0) len++;\n    return len;\n}\nfor(int i = 0; i < getlen(s); ++i) {\n    /*...*/\n}\n```\n\n这样子的写法由于不能确定`s[]`是否发生了更新，多次`getlen(s)`返回值可能不一样，每次循环都会执行一次。~~`strlen`也是~~\n\n## 5.5减少过程调用\n\n减少调用函数，虽然好像在数组求和的例子中这样性能反而下降，但我们还是相信这会带来性能提升。\n\n## 5.6消除不必要的内存引用\n\n```c\nvoid combine(/*...*/, int *dest) {\n    /*...*/\n    int tot = 1;\n    for(int i = 0; i < length; ++i) {\n        tot *= data[i];\n    }\n    *dest = tot;\n}\n```\n\n```c\nvoid combine(/*...*/, int *dest) {\n    /*...*/\n    *dest = 1;\n    for(int i = 0; i < length; ++i) {\n        *dest *= data[i];\n    }\n}\n```\n\n第一种写法相比第二种有显著的提升。\n\n请看原因：\n\n```bash\n.L25:\n	vmulsd (%rdx), %xmm0, %xmm0\n	addq   $8, %rdx\n	cmpq   %rax, %rdx\n	jne    .L25\n```\n\n```bash\n.L17:\n	vmovsd (%rbx), %xmm0\n	vmulsd (%rdx), %xmm0, %xmm0\n	vmovsd %xmm0, (%rbx)\n	addq   $8, %rdx\n	cmpq   %rax, %rdx\n	jne    .L17\n```\n\n第一种写法不需要从地址引用内存，快了许多。\n\n编译器不会优化这个过程，因为如果`*dest`指向的地址在我们累乘的数组内存内，显然也会导致函数效果不同。\n\n## 5.7理解现代处理器\n\n随着试图进一步提高性能，必须考虑利用**处理器微体系结构**的优化，也就是处理器用来执行指令的底层系统设计。\n\n要想充分提高性能，需要仔细分析程序，同时代码的生成也要针对目标处理器进行调整。\n\n------\n\n**指令级并行**：采用复杂而奇异的微处理器结构，其中，多条指令可以并行地执行，同时又呈现出一种简单的顺序执行指令的表象。\n\n**延迟界限**：当一系列操作必须按照严格顺序执行时，就会遇到**延迟界限**。当代码中的数据相关限制了处理器利用指令级并行的能力时，延迟界限能够限制程序性能。\n\n**吞吐量界限**：处理器功能单元的原始计算能力。这个界限是程序性能的终极限制。\n\n### 5.7.1整体操作\n\n下图是现代处理器的一个非常简化的示意图，这里假想的处理器设计是不太严格地基于Intel处理器的结构。\n\n这些处理器被称为是**超标量的 (superscalar)**，每个时钟周期可执行多个操作，且是**乱序的(out-of-order)**，意思就是指令的执行顺序不一定要与它们在机器级程序中的顺序一致。\n\n整体的设计分为两部分：\n\n**指令控制单元（Instruction Control Unit，ICU）**：负责从内存读出指令序列， 并根据这些指令序列生成一组针对程序数据的基本操作。\n\n**执行单元（Execution Unit，EU）**：执行ICU生成的操作。\n\n![image-20250430185916606](./pictures/image-20250430185916606.png)\n\n下面简单介绍处理器的各个部分：\n\n- **指令高速缓存（instruction cache）**：特殊的高速存储器，存储最近的指令，ICU就是从这里读取指令。\n\n  > 通常ICU会在当前正在执行的指令很早之前取指，以保证有足够的时间对指令译码，并把生成的操作发送给EU。不过一个问题是当程序遇到**分支（条件转移指令）** 时，程序可能会进入分支也可能跳过分支。\n  >\n  > 现代处理器采用一种称为**分支预测（branch prediction）** 的计数，处理器会猜测是否选择分支，同时预测分支的目标地址。\n  >\n  > 采用**投机执行（speculative execution）** 的计数，处理器会开始取出它预测的分支目标地址处取指令，并对指令译码，甚至在确定分支预测是否正确之前就开始执行这些操作。如果过后确定分支预测错误，会将状态重新设置到分支点的状态，并开始取出并执行另一个方向的指令。\n\n- **取指控制（fetch control）**：包括上述的分支预测。\n\n- **指令译码（instruction decode）**：接受实际的程序指令，并将它们转换成一组基本操作（有时称为微操作）。\n  \n  这样的操作完成一个简单的任务，如加减、内存读写。\n\n------\n\n在典型的x86实现中，一条只对寄存器的操作，如：\n\n```bash\naddq %rax, %rbx\n```\n会被转化为一个操作。而一条包含一个或多个内存引用的指令，如:\n\n```bash\naddq %rax, 8(%rdx)\n```\n\n会产生多个操作，把内存引用和算数运算分开。这条指令会被分为3个操作：从内存读，将读入的值加上`rax`中的值，对内存写。\n\n- **功能单元（functional units）**：EU中的用于执行不同的来自ICU操作的单元。\n- **数据高速缓存（data cache）**：高速存储器，存放最近访问的数据值。\n- **加载和存储单元（load&store）**：读写内存。均有一个加法器用于计算地址，通过数据高速缓存来访问内存。\n\n> 使用投机执行技术对操作求值，直到处理器能确定应该实际执行这些指令前，其最终结果不会存储在程序寄存器或内存中。分支操作被送到EU，用于确定分支是否预测正确。如果预测错误，EU会丢弃分支点之后计算的结果，并发送信号给**分支单元（branch）** 告诉预测是错误的，这样的预测错误会带来很大的性能开销。\n\n由于不同程序间所要求的操作变化很大，因此，算法运算单元被特意设计称能够执行不同的操作。\n\n举个例子，`Intel Core i7 Haswell`参考机有编号为0∼7的8个功能单元：\n\n- 0：整数运算、浮点乘、整数和浮点数除法、分支。\n- 1：整数运算、浮点加、整数乘、浮点乘。\n- 2：加载、地址计算。\n- 3：加载、地址计算。\n- 4：存储。\n- 5：整数运算。\n- 6：整数运算、分支。\n- 7：存储、地址计算。\n\n> [!CAUTION]\n>\n> 这一部分全都是原理级内容，暂时略了。\n\n## 5.8循环展开\n\n循环展开是一种程序变换，通过增加每次迭代计算的元素的数量，减少循环的迭代次数。\n\n循环展开能够从两个方面改进程序的性能：\n\n1. 它减少了不直接有助于程序结果的操作的数量，例如循环索引计算和条件分支。\n2. 它提供了一些方法，可以进一步变化代码，减少整个计算中关键路径上的操作数量。\n\n这个做法的原理：\n\n1. **减少循环控制开销**\n\n   每次循环迭代涉及条件检查、计数器更新等操作，展开后循环次数减少，降低了这些固定开销在总执行时间中的比例。\n\n2. **提高指令级并行性（ILP）**\n\n   展开后的循环体内包含更多独立指令，处理器可同时执行多个操作。现代CPU的乱序执行引擎能更好地填充流水线。\n\n3. **优化缓存利用率**\n\n   连续访问内存时，展开循环能更充分地利用缓存行。例如一次加载64字节缓存行后，处理其中的16个整型(4字节)元素，减少缓存未命中次数。\n\n## 5.9提高并行性\n\n### 5.9.1多个累积变量\n\n现代CPU（如Intel Skylake、AMD Zen）支持同时执行多个独立的运算指令。例如：\n\n- **4个独立的加法**可被分配到4个不同的ALU（算术逻辑单元）并发执行。\n\n另一方面：仅在最终合并时访问内存，中间结果保留在寄存器中。\n\n### 5.9.2重新结合变换 \n\n例如：\n\n```c\nresult = result * (a[i] * b[i]);\nresult = (result * a[i]) * b[i];\n```\n\n上述两种写法，第一种由于改变`result`的值的过程和循环的过程可以并行执行，会快一些。\n\n## 5.10优化合并代码的结果小结\n\n使用多项优化技术，我们获得的CPE已经接近于0.50和1.00的吞吐量界限，只受限于功能单元的容最。与原始代码相比提升了10~20倍，且使用普通的C代码和标准编译器就获得了所有这些改进。重写代码利用较新的SIMD指令得到了将近4倍或8倍的性能提升。比如单精度乘法，CPE从初值11.14降到了0.06，整体性能提升超过180倍。\n这个例子说明现代处理器具有相当的计算能力，但是我们可能需要按非常程式化的方式来编写程序以便将这些能力诱发出来。\n\n> [!CAUTION]\n>\n> 后面几章理论性极强，实用性不大，暂时略过。' 
                      },
                      { id: 'computer_basic-4', 
                        title: '7、链接', 
                        desc: '', 
                        content: '# 7.链接\n\n**链接（linking）** 是将各种代码和数据片段收集并组合成为一个单一文件的过程，这个文件可被加载（复制）到内存并执行。\n\n链接可以执行于：\n\n- **编译时（compile time）**：也就是在源代码被翻译成机器代码时。\n- **加载时（load time）**：也就是在程序被**加载器（loader）** 加载到内存并执行时\n- **运行时（run time）**：也就是由应用程序来执行。\n\n在早期的计算机系统中，链接是**手动执行**的。在现代系统中，链接是由叫做**链接器（linker）** 的程序自动执行的。\n\n~~学习本章节可以避免链接库失败带来的高血压~~，更好地利用共享库，避免危险的编程错误。\n\n**我们将在一个运行Linux的x86-64系统，使用标准的ELF-64目标文件格式的环境下研究**。\n\n## 7.1编译器驱动程序\n\n现在我们有程序`main.c`：\n\n```c\nint sum(int *a, int n);\nint array[2] = {1, 2};\nint main() {\n    int val = sum(array, 2);\n    return val;\n}\n```\n\n将`main.c`翻译成可执行目标文件`main.o`的过程：\n\n1. 驱动程序首先运行C预处理器(`cpp`)，它将`main.c`翻译成一个ASCII码的中间文件`main.i`：\n   `cpp [other arguments] main.c /tmp/main.i`\n2. 驱动程序运行C编译器(`ccl`)，它将`main.i`翻译成一个ASCII汇编语言文件`main.s`：\n   `ccl /tmp/main.i -Og [other arguments] -o /tmp/main.s`\n3. 驱动程序运行汇编器(`as`)，它将`main.s`翻译成一个可重定位目标文件（relocatable object file）`main. o`：\n   `as [other arguments] -o /tmp/main.o /tmp/main.s`\n\n假设我们还有程序`sum.c`：\n\n```c\nint sum(int *a, int n) {\n    int i, s = 0;\n    for(i = 0; i < n; i++) {\n        s += a[i];\n    }\n    return s;\n}\n```\n\n驱动程序经过相同的过程生成`sum.o`。\n\n我们链接的指令`gcc -Og -o prog main.c sum.c`，就要先生成`main.o`和`sum.o`文件。\n\n最后，它运行链接器程序`ld`，将`main.o`和`sum.o`以及一些必要的系统目标文件组合起来，创建一个**可执行目标文件（executable object file）** prog：\n\n`ld -o prog [system object files and args] /tmp/main.o /tmp/sum.o`\n\n`shell`调用操作系统中一个叫做**加载器（loader）** 的函数，它将可执行文件`prog`中的代码和数据复制到内存，然后将控制转移到这个程序的开头。\n\n## 7.2静态链接\n\n**静态链接器（static linker）**以一组**可重定位目标文件**（如`.o`，`.obj`文件）和命令行参数作为输入，生成一个完全链接的、可以加载和运行的**可执行目标文件**作为输出。\n\n在**可重定位目标文件**中包含各种不同的代码和数据节。每一节都是一个连续的字节序列，这个我们在7.4介绍。\n\n为了构造可执行文件，链接器必须完成两个主要任务：\n\n- **符号解析（symbol resolution）**：目标文件定义和引用符号，使每个符号引用正好和一个符号定义关联起来。\n- **重定位（relocation）**：编译器和汇编器生成从地址0开始的代码和数据节。链接器通过把每个符号定义与一个内存位置关联起来，从而重定位这些节，然后修改所有对这些符号的引用，使得它们指向这个内存位置。链接器使用汇编器产生的**重定位条目（relocation entry）** 的详细指令，不加甄别地执行这样的重定位。\n\n## 7.3目标文件\n\n目标文件包括：\n\n- **可重定位目标文件**：包含二进制代码和数据，其形式可以在编译时与其他可重定位目标文件合并起来，创建一个可执行目标文件。\n- **可执行目标文件**：包含二进制代码和数据，其形式可以被直接复制到内存并执行。\n- **共享目标文件**：一种特殊类型的可重定位目标文件，可以在加载或者运行时被动态地加载进内存并链接。\n\n编译器和汇编器生成**可重定位目标文件**（包括共享目标文件）。链接器生成**可执行目标文件**。\n\n从技术上来说， 一个**目标模块（object module）** 就是一个字节序列，而一个**目标文件（object file）** 就是一个以文件形式存放在磁盘中的目标模块。\n\n各个操作系统的目标文件格式都不相同。\n\n| 操作系统                   | 目标文件格式                                            |\n| -------------------------- | ------------------------------------------------------- |\n| Unix                       | `a.out`                                                 |\n| Windows                    | 可移植可执行（Portable Executable，PE）格式`a.exe`      |\n| MacOS-X                    | Mach-O格式                                              |\n| x86-64 Linux和现代Unix系统 | 可执行可链接格式（Executable and Linkable Format，ELF） |\n\n我们主要讨论ELF。\n\n## 7.4可重定位目标文件\n\n**ELF头（ELF header）** 以一个16字节的序列开始，这个序列描述了生成该文件的系统的字的大小和字节顺序。\n\nELF头剩下的部分包含帮助链接器语法分析和解释目标文件的信息。其中包括：\n\n- **ELF头的大小**。\n- **目标文件的类型（如可重定位、可执行或者共享的）**。\n- **机器类型（如x86-64）**。\n- **节头部表（section header table）的文件偏移**。\n- **节头部表中条目的大小和数量**。\n\n不同节的位置和大小是由节头部表描述的，其中目标文件中每个节都有一个固定大小的**条目(entry)**。\n\n|    ELF头    | 内容                                                         |\n| :---------: | ------------------------------------------------------------ |\n|   `.text`   | 已编译程序的机器代码。                                       |\n|  `.rodata`  | 只读数据，比如`printf`语句中的格式串和开关语句的跳转表。     |\n|   `.data`   | **已初始化的全局和静态C变量**。局部C变量在运行时被保存在栈中，既不出现在`.data`节中，也不出现在`.bss`节中。 |\n|   `.bss`    | **未初始化的全局和静态C变量，以及所有被初始化为0的全局或静态变量**。在目标文件中这个节不占据实际的空间，它仅仅是一个占位符。目标文件格式区分已初始化和未初始化变量是为了空间效率：在目标文件中，未初始化变量不需要占据任何实际的磁盘空间。运行时，在内存中分配这些变量，初始值为0。 |\n|  `.symtab`  | **一个符号表，它存放在程序中定义和引用的函数和全局变量的信息**。一些程序员错误地认为必须通过`-g`选项来编译一个程序，才能得到符号表信息。实际上，每个可重定位目标文件在`.symtab`中都有一张符号表（除非程序员特意用STRIP命令去掉它）。然而，和编译器中的符号表不同，`.symtab`符号表不包含局部变量的条目。 |\n| `.rel.text` | **一个**`.text`**节中位置的列表，当链接器把这个目标文件和其他文件组合时，需要修改这些位置**。一般而言，任何调用外部函数或者引用全局变量的指令都需要修改。另一方面，调用本地函数的指令则不需要修改。注意，可执行目标文件中并不需要重定位信息，因此通常省略，除非用户显式地指示链接器包含这些信息。 |\n| `.rel.data` | **被模块引用或定义的所有全局变量的重定位信息**。一般而言，任何已初始化的全局变量，如果它的初始值是一个全局变量地址或者外部定义函数的地址，都需要被修改。 |\n|  `.debug`   | **一个调试符号表，其条目是程序中定义的局部变量和类型定义，程序中定义和引用的全局变量，以及原始的C源文件**。只有以`-g`选项调用编译器驱动程序时，才会得到这张表。 |\n|   `.line`   | **原始C源程序中的行号和**`.text`**节中机器指令之间的映射**。只有以`-g`选项调用编译器驱动程序时，才会得到这张表。 |\n|  `.strtab`  | **一个字符串表，其内容包括**`.symtab`**和**`.debug`**节中的符号表，以及节头部中的节名字**。字符串表就是以`null`结尾的字符串的序列。 |\n|  节头部表   |                                                              |\n\n## 7.5符号和符号表\n\n每个可重定位目标模块$m$都有一个符号表，它包含$m$定义和引用的符号的信息。在链接器的上下文中，有三种不同的符号：\n\n| 符号类型                 | C语言对应关系                        | 作用域/可见性                         |\n| ------------------------ | ------------------------------------ | ------------------------------------- |\n| **全局符号（Global）**   | 非`static`的全局变量和函数           | 模块$m$定义，可被其他模块引用         |\n| **外部符号（External）** | 在其他模块定义的非`static`函数和变量 | 模块$m$引用，但在其他模块定义         |\n| **局部符号（Local）**    | 带有`static`属性的全局变量和函数     | 仅在模块$m$内可见，不能被其他模块引用 |\n\n> **注意：** 函数内的局部变量（栈管理）**不属于**链接器符号。但函数内的`static`变量会被分配在`.data`或`.bss`中，并生成唯一的符号名（如`x.1`，`x.2`）。\n\n**一个ELF符号表的条目**\n\n符号表存储在`.symtab`节中，每个条目的逻辑结构如下：\n\n```c\ntypedef struct {\n    int   name;      // 字符串表 strtab 中的偏移量，指向符号名称\n    char  type;      // 符号类型：数据 OBJECT 或函数 FUNC\n    char  binding;   // 绑定关系：LOCAL 或 GLOBAL\n    short section;   // 所在节的索引 Ndx\n    long  value;     // 偏移量（可重定位文件）或绝对地址（可执行文件）\n    long  size;      // 目标大小（字节为单位）\n} Elf64_Symbol;\n```\n\n**section**有时会是三个特殊的**伪节（pseudosection）**（只在可重定位目标文件中才有）之一，它们在节头部表中是没有条目的：\n\n- **ABS**：不该被重定位的符号。\n- **UNDEF**：未定义的符号，也就是在本目标模块中引用，但是却在其他地方定义的符号。\n- **COMMON**：还未被分配位置的未初始化的数据目标（链接器决定分配位置）。\n  - **value**字段给出对齐要求。\n  - **size**给出最小的大小。\n\n**COMMON** 和`.bss`的区别很细微。现代的GCC版本根据以下规则来将**可重定位目标文件（可执行目标文件中没有）**中的符号分配到**COMMON** 和.`bss`中：\n\n- **COMMON**：未初始化的全局变量。\n- `.bss`：未初始化的静态变量，以及初始化为0的全局或静态变量。\n\n我们可以用**GNU READELF**查看目标文件内容，例如：\n\n| Num  | Value            | Size | Type   | Bind   | Vis     | Ndx  | Name  |\n| ---- | ---------------- | ---- | ------ | ------ | ------- | ---- | ----- |\n| 8    | 0000000000000000 | 24   | FUNC   | GLOBAL | DEFAULT | 1    | main  |\n| 9    | 0000000000000000 | 8    | OBJECT | GLOBAL | DEFAULT | 3    | array |\n| 10   | 0000000000000000 | 0    | NOTYPE | GLOBAL | DEFAULT | UND  | sum   |\n\n其中`Ndx=1`表示`.text`节，而`Ndx=3`表示`.data`节。\n\n## 7.6符号解析\n\n**链接器**解析符号引用的方法是将每个引用与它输入的可重定位目标文件的符号表中的**一个确定的符号定义关联起来**。\n\n对那些和引用定义在相同模块中的局部符号的引用， 符号解析是非常简单明了的，例如：\n\n```c\n// file1.c\nstatic int localVar = 10;  // 静态局部变量\nstatic void localFunc() {  // 静态局部函数\n    localVar++;\n}\nint main() {\n    localFunc();\n    return 0;\n}\n```\n\n链接器在解析时，直接在`file1.o`中找到定义，无需与其他模块交互。\n\n编译器只允许每个模块中每个局部符号有一个定义。静态局部变量也会有本地链接器符号，编译器还要确保它们拥有唯一的名字。\n\n------\n\n对于全局符号的引用解析：**当编译器遇到一个不是在当前模块中定义的符号（变量或函数名）时，会假设该符号是在其他某个模块中定义的，生成一个链接器符号表条目，并把它交给链接器处理。如果链接器在它的任何输入模块中都找不到这个被引用符号的定义，就输出一条（通常很难阅读的）错误信息并终止**。\n\n我们来研究这个过程。\n\n### 7.6.1链接器如何解析多重定义的全局符号\n\n在编译时，编译器向汇编器输出每个全局符号，或者是**强（strong）**或者是**弱（weak）**，而汇编器把这个信息隐含地编码在可重定位目标文件的符号表里。**函数和已初始化的全局变量是强符号**，**未初始化的全局变量是弱符号**。\n\n处理多重定义的规则：\n\n1. **不允许有多个同名的强符号**。\n2. **如果有一个强符号和多个弱符号同名，那么选择强符号**。\n3. **如果有多个弱符号同名，那么从这些弱符号中任意选择一个**。\n\n**例1**：\n\n```c\n/* foo1.c */\nint main() {\n    return 0;\n}\n```\n\n```c\n/* bar1.c */\nint main() {\n    return 0;\n}\n```\n\n链接时会生成错误信息：\n\n```bash\nlinux> gcc foo1.c bar1.c\n/tmp/ccq2Uxnd.o: In function\'main\':\nbarl.c:(.text+OxO):multiple definition of \'main\'\n```\n\n表示强符号`main`被定义了多次，违背了规则1。\n\n**例2**：\n\n```c\n/* foo2.c */\n#include <stdio.h>\nvoid f(void);\nint x = 114514;\nint main() {\n    printf("%d\n", x);\n    f();\n    printf("%d", x);\n    return 0;\n}\n```\n\n```c\n/* bar2.c */\nint x;\nvoid f() {\n    x=1919810;\n}\n```\n\n链接时，`foo2.c`中`x`是强符号，`bar2.c`中x是弱符号。\n\n链接结果会是：\n\n```bash\nlinux> gcc -o foobar3 foo3.c bar3.c\nlinux> ./foobar3\n114514\n1919810\n```\n\n**例3**：\n\n```c\n/* foo4.c */\n#include <stdio.h>\nvoid f(void);\nint x;\nint main() {\n    x = 114514;\n    f();\n    printf("%d", x);\n    return 0;\n}\n```\n\n```c\n/* bar4.c*/\nint x;\nvoid f() {\n    x = 1919810;\n}\n```\n\n链接时，两个都是弱符号，取其一。\n\n**例4**：\n\n```c\n/* foo5.c */\n#include <stdio.h>\nvoid f(void);\nint x = 114514;\nint y = 1919810\nint main() {\n    f();\n    printf("%d %d", x, y);\n    return 0;\n}\n```\n\n```c\n/* bar5.c */\ndouble x;\nvoid f() {\n    x=-0.0;\n}\n```\n\n这个例子很有意思。\n\n在一台x86-64 / Linux机器上，`double`类型是8个字节，而`int`类型是4个字节。在我们的系统中，`x`的地址是`0x601020`，`y`的地址是`0x601024`。因此，`bar5.c`的第6行中的赋值`x= -0.0`将用负零的双精度浮点表示覆盖内存中`x`和`y`的位置。\n\n```bash\nlinux> gcc -Wall -Og -o foobar5 foo5.c bar5.c\n/usr/bin/ld: Warning: alignment 4 of symbol \'x\' in /tmp/cclUFK5g.o\nis smaller than 8 in /tmp/ccbTLcb9.o\nlinux> ./foobar5\n0x0 0x80000000\n```\n\n------\n\n由上面的分析可以知道：\n\n当编译器在翻译某个模块时，遇到一个**弱全局符号**，它并不知道其他模块是否也定义了，如果是，它无法预测链接器该使用多重定义中的哪一个。所以编译器将其分配成COMMON，把决定权留给链接器。\n\n另一方面，如果初始化为0，那么它是一个**强符号**，所以编译器可以很自信地将它分配成`.bss` 。类似地，静态符号的构造就必须是唯一的，所以编译器可以自信地把它们分配成`.data`或`.bss`。\n\n### 7.6.2与静态库链接\n\n实际上，所有的编译系统都提供一种机制，将所有相关的目标模块打包成为一个单独的文件，称为**静态库（static library）**，它可以用做链接器的输入。\n\n当链接器构造一个输出的可执行文件时，它只复制静态库里被应用程序引用的目标模块。\n\n------\n\n在此之前，`Pascal`（~~一个你都没听过的语言~~）等语言用的是提供一小部分标准函数，由编译器辨认你的调用，直接生成相应代码。\n\n此外，我们可以将所有的标准C函数都放在一个单独的可重定位目标模块。应用程序员可以把这个模块链接到他们的可执行文件中。\n\n```bash\nlinux > gcc main.c /usr/lib/libc.o\n```\n\n但是修改将会是极大的困难，而且很占磁盘，链接也很耗时。\n\n```bash\nlinux > gcc main.c /usr/lib/libm.a /usr/lib/libc.a\n```\n\n------\n\n静态库概念被提出来，以解决这些不同方法的缺点。\n\n相关的函数可以被编译为**独立的目标模块**，然后封装成一个单独的**静态库文件**。然后，应用程序可以通过在命令行上指定单独的文件名字来使用这些在库中定义的函数。\n\n比如，使用C标准库和数学库中函数的程序可以用形式如下的命令行来编译和链接：\n\n```bash\nlinux > gcc main.c /usr/lib/libm.a /usr/lib/libc.a\n```\n\n- 链接器将只复制被程序引用的目标模块，减少了可执行文件在磁盘和内存中的大小。\n- 应用程序员只需要包含较少的库文件的名字。\n\n------\n\n在Linux系统中，静态库以一种称为**存档（archive）** 的特殊文件格式存放在磁盘中。\n\n存档文件是一组连接起来的可重定位目标文件的集合，有一个头部用来描述每个成员目标文件的大小和位置。存档文件名由后缀`.a`标识。\n\n以下面两个向量例程说明：\n\n```c\n/* accvec.c */\nint addcnt = 0;\nvoid addvec(int *x, int *y, int *z, int n) {\n    int i;\n    addcnt++;\n    for(i = 0; i < n; ++i) {\n        z[i] = x[i] + y[i];\n    }\n}\n```\n\n```c\n/* multvec.c */\nint multcnt = 0;\nvoid multvec(int *x, int *y, int *z, int n) {\n    int i;\n    multcnt++;\n    for(i = 0; i < n; ++i) {\n        z[i] = x[i] * y[i];\n    }\n}\n```\n\n使用**AR工具**创建这些函数的一个静态库。\n\n```bash\nlinux> gcc -c addvec.c multvec.c\nlinux> ar rcs libvector.a addvec.o multvec.o\n```\n\n我们使用静态链接库：\n\n```c\n#include <stdio.h>\nint x[2] = {1, 2};\nint y[2] = {3, 4};\nint z[2];\nint main() {\n    addvec(x, y, z, 2);\n    printf("%d %d", z[0], z[1]);\n    return 0;\n}\n```\n\n```bash\nlinux> gcc -c main.c\nlinux> gcc -static -o prog main.o ./libvector.a\n# 或\nlinux> gcc -static -o prog main.o -L. -lvector\n```\n\n- `-static`参数告诉编译器驱动程序，链接器应该构建一个完全链接的可执行目标文件，它可以加载到内存并运行，在加载时无须更进一步的链接。\n- `-lvector`参数是`libvector.a`的缩写，`-L`参数告诉链接器在当前目录下查找`libvector.a`。\n\n当链接器运行时，它判定`main.o`引用了`addvec.o`定义的`addvec`符号，所以复制`addvec.o`到可执行文件。\n\n因为程序不引用任何由`multvec.o`定义的符号，所以链接器就不会复制这个模块到可执行文件。\n\n链接器还会复制许多C运行时系统中的其他模块。\n\n在此还复制了`libc.a`中的`printf.o`模块。\n\n### 7.6.3链接器如何使用静态库来解析引用\n\n在符号解析阶段，链接器从左到右按照它们在编译器驱动程序命令行上出现的顺序来扫描**可重定位目标文件（.o文件）**和**存档文件（.a文件）**。（驱动程序自动将命令行中所有的`.c`文件翻译为`.o`文件。）\n\n在这次扫描中，链接器维护一个**可重定位目标文件的集合**$E$（这个集合中的文件会被合并起来形成可执行文件），一个**未解析的符号**（即引用了但是尚未定义的符号）集合$U$，以及一个**在前面输入文件中已定义的符号集合**$D$ 。初始时，$E$、$U$和$D$均为空。\n\n- 对于输入文件$f$​，如果是一个**目标文件**：链接器把$f$添加到$E$，修改$U$和$D$来反映$f$中的符号定义和引用，并继续下一个输入文件。\n- 对于输入文件$f$​，如果是一个**存档文件**：链接器尝试匹配$U$中未解析的符号和由存档文件成员定义的符号。如果某个存档文件成员$m$定义了一个符号来解析$U$中的一个引用，那么就将$m$加到$E$中，并且链接器修改$U$和$D$来反映$m$中的符号定义和引用。对存档文件中所有的成员目标文件都依次进行这个过程，直到$U$和$D$都不再发生变化。此时，**任何不包含在$E$中的成员目标文件都简单地被丢弃，而链接器将继续处理下一个输入文件**。\n- 如果当链接器完成对命令行上输入文件的扫描后，$U$是非空的，那么链接器就会输出一个错误并终止。否则，它会合并和重定位$E$中的目标文件，构建输出的可执行文件。\n\n因此输入顺序很重要，例如：\n\n```bash\nlinux> gcc -static ./libvector.a main.c\n/tmp/cc9XH6Rp.o: In function \'main\':\n/tmp/cc9XH6Rp.o(.text+0x18): undefined reference to \'addvec\'\n```\n\n在处理`libvector.a`时，$U$是空的，所以没有`libvector.a`中的成员目标文件会添加到$E$中。因此，对`addvec`的引用是绝不会被解析的，所以链接器会产生一条错误信息并终止。\n\n------\n\n关于库的一般准则是**将它们放在命令行的结尾**。如果各个库的成员是相互独立的（也就是说没有成员引用另一个成员定义的符号），那么这些库就可以以任何顺序放置在命令行的结尾处。另一方面，如果库不是相互独立的，那么必须对它们**排序**，使得对于每个被存档文件的成员外部引用的符号$s$在命令行中至少有一个$s$的定义是在对$s$的引用之后的。（类似于搭积木）\n\n如果需要满足依赖需求，可以在命令行上重复库。\n\n另一种方法是，我们可以将`libx.a`和`liby.a`**合并成一个单独的存档文件**。\n\n## 7.7重定位\n\n一旦链接器完成了符号解析这一步，就把代码中的每个**符号引用**和正好一个**符号定义**（即它的一个输入目标模块中的一个符号表条目）关联起来。\n\n此时，链接器就知道它的输入目标模块中的代码节和数据节的确切大小。现在就可以开始**重定位**步骤了，在这个步骤中，将合并输入模块，并为每个符号分配运行时地址。\n\n1. **重定位节和符号定义**：在这一步中，链接器将**所有相同类型的节**合并为**同一类型的新的聚合节**。例如，来自所有输入模块的`.data`节被全部合并成一个节，这个节成为输出的可执行目标文件的`.data`节。然后，链接器将**运行时内存地址**赋给**新的聚合节**，赋给**输入模块定义的每个节**，以及赋给**输入模块定义的每个符号**。当这一步完成时，程序中的每条指令和全局变量都有唯一的运行时内存地址了。\n\n   | 符号         | 原始 | 分配后地址 |\n   | ------------ | ---- | ---------- |\n   | `main`       | 未知 | 0x400560   |\n   | `global_vat` | 未知 | 0x601040   |\n\n2. **重定位节中的符号引用**。在这一步中，链接器修改**代码节和数据节中对每个符号的引用**，使得它们指向正确的运行时地址。要执行这一步，链接器依赖于可重定位目标模块中称为**重定位条目（relocation entry）** 的数据结构，我们接下来将会描述这种数据结构。\n\n   把`.text`和`.data`里所有“用到符号”的地方（比如函数调用、变量访问）进行替换。\n\n   替换用的数据就来自`.rel.text`、`.rel.data`这样的重定位表。\n\n   比如：\n\n   原来代码中有个调用`call printf`，位置在`.text`的某个偏移处。\n\n   链接器查到`printf`的实际地址是`0x7ffff7e4b170`。\n\n   链接器就把`call ??`的问号，补上为相对地址偏移\n\n### 7.7.1重定位条目\n\n当汇编器生成一个**目标模块**时，它并不知道数据和代码最终将放在内存中的什么位置。它也不知道这个模块引用的任何外部定义的函数或者全局变量的位置。所以，无论何时汇编器遇到对最终位置未知的目标引用，它就会生成一个**重定位条目**，告诉链接器在将目标文件合并成可执行文件时如何修改这个引用。\n\n代码的重定位条目放在`.rel.text`中。\n\n已初始化数据的重定位条目放在`.rel.data`中。\n\n下面是一个ELF重定位条目格式示意图：\n\n```c\ntypedef struct {\n    long offset;    // 需要被修改的引用在节（Section）内的偏移位置\n    long type:32,   // 重定位类型（如何修改？）\n         symbol:32; // 符号在符号表中的索引（修改为哪个符号？）\n    long addend;    // 加数：辅助调整地址的常数\n} Elf64_Rela;\n```\n\n------\n\nELF定义了32种不同的重定位类型，我们只介绍两种：\n\n| 类型          | 说明                                              | 计算逻辑（简述）                  |\n| ------------- | ------------------------------------------------- | --------------------------------- |\n| R_X86_64_PC32 | **32位PC相对寻址**：常用于`call`或`jmp`指令。     | 目标地址=下一条指令地址+编码的值  |\n| R_X86_64_32   | **32位绝对寻址**：CPU直接把指令里的32位值当地址。 | 目标地址=编码的值（直接填入地址） |\n\n------\n\n这两种重定位类型支持**x86-64小型代码模型（small code model）**。\n\n该模型假设可执行目标文件中的代码和数据的总体大小小于2GB，因此在运行时可以用32位PC相对地址来访问。\n\nGCC默认使用**小型代码模型**。\n\n大于2GB的程序可以用`-mcmodel=medium`（中型代码模型）和`-mcmodel=large`（大型代码模型）标志来编译。\n\n### 7.7.2重定位符号引用\n\n用下面的伪代码解释：\n\n```c\nforeach section s {\n    foreach relocation entry r {\n        refptr = s + r.offset; // 计算的是需要被重定位的4字节引用的数组s中的地址\n\n        if (r.type == R_X86_64_PC32) {\n            refaddr = ADDR(s) + r.offset;\n            *refptr = (unsigned) (ADDR(r.symbol) + r.addend - refaddr);\n        }\n        if (r.type == R_X86_64_32) {\n            *refptr = (unsigned) (ADDR(r.symbol) + r.addend);\n        }\n    }\n}\n```\n\n例如：\n\n```bash\n0000000000000000 <main>:\n   0: 48 83 ec 08                sub   $0x8,%rsp\n   4: be 02 00 00 00             mov   $0x2,%esi\n   9: bf 00 00 00 00             mov   $0x0,%edi      # edi = $array\n                      a: R_X86_64_32 array\n   e: e8 00 00 00 00             callq 13 <main+Ox13> # sum()\n                      f: R_X86_64_PC32 sum-0x4\n  13: 48 83 c4 08                add   $0x8,%rsp\n  17: c3                         retq\n```\n\nmain函数引用了两个全局符号：`array`和`sum`。为每个引用，汇编器产生一个**重定位条目**，显示在引用的后面一行上。这些重定位条目告诉链接器对sum的引用要使用**32位PC相对地址**进行重定位，而对array的引用要使用**32位绝对地址**进行重定位。\n\n1. **重定位PC相对引用**\n\n   相应的重定位条目`r`：\n\n   ```bash\n   r.offset = 0xf\n   r.symbol = sum\n   r.type   = R_X86_64_PC32\n   r.addend = -4\n   ```\n\n   假设链接器已经确定：\n\n   ```bash\n   ADDR(s) = ADDR(.text) = 0x4004d0\n   ADDR(r.symbol) = ADDR(sum) = 0x4004e8\n   ```\n\n   首先计算出引用的运行时地址：\n\n   ```bash\n   refaddr = ADDR(s) + r.offset\n           = 0x4004d0 + 0xf\n           = 0x4004df\n   ```\n\n   然后，更新该引用，使得它在运行时指向sum程序：\n\n   ```bash\n   *refptr = (unsigned) (ADDR(r.symbol) + r.addend - refaddr)\n           = (unsigned) (0x4004e8)      + (-4)     - 0x4004df)\n           = (unsigned) (0x5)\n   ```\n\n   在得到的可执行目标文件中，`call`指令有如下的重定位的形式：\n\n   ```bash\n   4004de:  e8 05 00 00 00         callq  4004e8 <sum>\n   ```\n\n   在运行时，`call`指令将存放在地址`0x4004de`处。当CPU执行`call`指令时，PC的值为`0x4004e3`（`call`指令是5字节），即紧随在call指令之后的指令的地址。为了执行这条指令，CPU 执行以下的步骤：\n\n   1) 将PC压入栈中。\n   2) `PC=PC+0x5=0x4004e3+0x5=0x4004e8`\n\n   因此，要执行的下一条指令就是`sum`例程的第一条指令。\n\n2. **重定位绝对引用**\n\n   相应的重定位条目`r`：\n\n   ```bash\n   r.offset = 0xa\n   r.symbol = array\n   r.type   = R_X86_64_32\n   r.addend = 0\n   ```\n\n   假设链接器已经确定：\n\n   ```bash\n   ADDR(r.symbol) = ADDR(array) = 0x601018\n   ```\n\n   修改引用：\n\n   ```bash\n   *refptr = (unsigned) (ADDR(r.symbol) + r.addend)\n           = (unsigned) (0x601018)      + 0)\n           = (unsigned) (0x601018)\n   ```\n\n   在得到的可执行目标文件中，`call`指令有如下的重定位的形式：\n\n   ```bash\n   4004d9:  bf 18 10 60 00         mov    $0x601018,%edi\n   ```\n\n得到最终可执行目标文件中已重定位的`.text`节和`.data`节后。在加载的时候，加载器会把这些节中的字节直接复制到内存，不再进行任何修改地执行这些指令。\n\n## 7.8可执行目标文件\n\n类似地，我们给出一个ELF可执行目标文件的各类信息。\n\n|                      ELF头                       |\n| :----------------------------------------------: |\n| **段头部表**（将连续的文件节映射到运行时内存段） |\n|                     `.init`                      |\n|                     `.text`                      |\n|                    `.rodata`                     |\n|                     `.data`                      |\n|                      `.bss`                      |\n|                    `.symtab`                     |\n|                     `.debug`                     |\n|                     `.line`                      |\n|                    `.strtab`                     |\n|         **节头部表**（描述目标文件的节）         |\n\n-  从**ELF头**到`.rodata`是只读内存段（代码段）。\n- 从`.data`到`.bss`是读/写内存段（数据段）。\n- 从`.symtab`到节头部表是不加载到内存的符号表和调试信息。\n\n与可重定位目标文件不同的是：\n\n1. **ELF头**包括程序的**入口点（entry point）**，也就是当程序运行时要执行的第一条指令的地址。\n2. `.text`、`.rodata`和`.data`节已经被重定位到它们最终的运行时内存地址。\n3. `.init`节定义了一个小函数，叫做`_init`，程序的初始化代码会调用它。\n4. 可执行文件是完全链接的（已被重定位），不再需要`rel`节。\n\n**ELF可执行文件**被设计得很容易加载到内存，可执行文件的连续的**片（chunk）** 被映射到连续的内存段。\n\n> 你可以用`objdump -d `指令观察程序头部表来观察这个效果。\n\n**程序头部表**：\n\n```c\ntypedef struct {\n    uint32_t type;    // 当前段的类型（如 LOAD, DYNAMIC）\n    uint32_t flags;   // 运行时权限（R=读, W=写, X=执行）\n    uint64_t offset;  // 段在文件中的起始偏移量\n    uint64_t vaddr;   // 该段在虚拟内存中的起始地址\n    uint64_t paddr;   // 物理地址（通常在现代 OS 中忽略）\n    uint64_t filesz;  // 该段在目标文件中的大小\n    uint64_t memsz;   // 该段在虚拟内存中的总大小（可能比 filesz 大）\n    uint64_t align;   // 对齐要求（通常是 2^12 = 4KB 页面大小）\n} Elf64_Phdr;\n```\n\n并非所有文件内容都会进内存。最重要的是以下两类：\n\n- **PHDR**：程序头部表自身。\n- **INTERP**：指定程序解释器的路径（如动态链接器 `ld-linux.so`）。\n- **LOAD**：**最关键的类型**。描述了会被映射到内存中的代码和数据。通常有两个LOAD段：\n  1. **只读段**：包含`.init`，`.text`，`.rodata`。权限通常为`R E`。\n  2. **读写段**：包含`.data`，`.bss`。权限通常为`R W`。\n\n> `.bss`在磁盘上不占空间（`filesz`不计入），但在内存中需要分配并清零（`memsz`会计入）。因此，读写段的`memsz`往往大于`filesz`。\n\n```\nLOAD off    Ox0000000000000000 vaddr Ox0000000000400000 paddr Ox0000000000400000 align 2**21\n     filesz Ox000000000000069c memsz Ox000000000000069c flags r-x\n```\n\n上面是一个代码段的示例。\n\n对于任何段s，链接器必须选择一个起始地址$\\text{vaddr}$，使得$\\text{vaddr mod align} = \\text{off mod align}$\n\n这个对齐要求是一种优化，使得当程序执行时，目标文件中的段能够很有效率地传送到内存中。\n\n## 7.9加载可执行目标文件\n\n使用`linux> ./prog`运行可执行目标文件`prog`。\n\n`shell`会通过调用某个驻留在存储器中称为**加载器（loader）** 的操作系统代码来运行它。\n\n加载器将可执行目标文件中的代码和数据从磁盘复制到内存中，然后通过跳转到程序的第一条指令或入口点来运行该程序。\n\n这个将程序复制到内存并运行的过程叫做加载。\n\n当加载器运行时，它创建类似于下图所示的**内存映像**。在**程序头部表**的引导下，加载器将可执行文件的**片（chunk）** 复制到代码段和数据段。\n\n接下来，加载器跳转到程序的入口点， 也就是`_start`函数的地址。这个函数是在系统目标文件`ctrl.o`中定义的，对所有的C程序都是一样的。\n\n`_start`函数调用系统启动函数`__libc_start_main`，该函数定义在`libc.so`中。它初始化执行环境，调用用户层的`main`函数，处理`main`函数的返回值，并且在需要的时候把控制返回给内核。\n\n![image-20250426105703485](./pictures/image-20250426105703485.png)\n\n## 7.10动态链接共享库\n\n**共享库（shared library）**是一个目标模块，在运行或加载时，可以加载到任意的内存地址，并和一个在内存中的程序链接起来。这个过程称为**动态链接（dynamic linking）**，是由一个叫做**动态链接器（dynamic linker）**的程序来执行的。共享库也称为**共享目标（shared object）**，在Linux系统中通常用**.so**后缀来表示。微软的操作系统大量地使用了共享库，它们称为**DLL（动态链接库）** 。\n\n- 共享库其实是所有引用该库的可执行目标文件共享这个`.so`文件中的代码和数据。\n\n操作示例：\n\n```bash\nlinux> gcc -shared -fpic -o libvector.so addvec.c multvec.c\n```\n\n> 注：`-fpic`选项指示编译器生成与位置无关的代码，`-shared`选项指示链接器创建一个共享的目标文件。\n>\n\n```bash\nlinux> gcc -o prog21 main2.c ./libvector.so\n```\n\n这样就创建了一个可执行目标文件`prog21`，而此文件的形式使得它在运行时可以和`libvector.so`链接。\n\n同时链接器复制了一些重定位和符号表信息，它们使得运行时可以解析对`libvector.so`中代码和数据的引用：\n\n- `prog21`包含一个`.interp`节，这一节包含动态链接器的路径名。\n- 加载器加载和运行**动态链接器**（其实它本身就是个共享目标）。\n- 动态链接器执行下面的任务：\n  - 重定位`libc.so`的文本和数据到某个内存段。\n  - 重定位`libvector.so`的文本和数据到另一个内存段。\n  - 重定位`prog21`中所有对由`libc.so`和`libvector.so`定义的符号的引用。\n\n最后，共享库的位置（地址等）就固定了。\n\n## 7.11从应用程序中加载和链接共享库\n\n应用程序还可能在它运行时要求动态链接器加载和链接某个共享库，而无需在编译时将那些库链接到应用中，例如：\n\n- **分发软件**：微软Windows应用的开发者常常利用共享库来分发软件更新。他们生成一个共享库的新版本，然后用户可以下载，并用它替代当前的版本。下一次他们运行应用程序时，应用将自动链接和加载新的共享库。\n\n- **构建高性能Web服务器**：许多Web 服务器生成动态内容，比如个性化的Web页面、账户余额和广告标语。\n\n  - 早期的Web服务器通过使用`fork`和`execve`创建一个子进程，并在该子进程的上下文中运行CGI程序来生成动态内容。\n\n  - 现代高性能的Web服务器可以使用基于动态链接的更有效和完善的方法来生成动态内容。\n\n    其思路是**将每个生成动态内容的函数打包在共享库**中。当一个来自Web浏览器的请求到达时，服务器**动态地加载和链接适当的函数，然后直接调用它**，而不是使用`fork`和`execve`在子进程的上下文中运行函数。函数会一直**缓存在服务器的地址空间**中，所以只要一个简单的函数调用的开销就可以处理随后的请求了。这对一个繁忙的网站来说是有很大影响的。更进一步地说，在运行时无需停止服务器，就可以更新已存在的函数，以及添加新的函数。\n\n------\n\nLinux让我们可以用一个简单的接口，允许应用程序在运行时加载和链接共享库。\n\n```c\n#include <dlfcn.h>\nvoid *dlopen(const char *filename, int flag);\n```\n\n用已用带**RTLD_GLOBAL**选项打开了的库解析`filename`中的外部符号。\n\n如果当前可执行文件是带`-rdynamic`选项编译的，那么对符号解析而言，它的全局符号也是可用的。\n\n| flag参数    | 效果                                                         |\n| ----------- | ------------------------------------------------------------ |\n| RTLD_GLOBAL | 通过`dlopen()`加载的动态库（`.so`）中的符号会被加入全局符号表，**后续加载的库或程序自身可以直接引用这些符号**。 |\n| RTLD_LOCAL  | 动态库的符号仅对当前加载的库可见。                           |\n| RTLD_NOW    | 在调用`dlopen()`时立即解析动态库的所有符号引用。**优点**：立即发现符号缺失或版本冲突（启动时失败，而非运行时崩溃）。**缺点**：增加启动时间（尤其是大型库）。 |\n| RTLD_LAZY   | 延迟解析符号，仅在首次调用函数或访问变量时解析。**优点**：减少启动开销（按需解析符号）。**缺点**：首次调用可能因符号问题崩溃（运行时风险）。 |\n\n后两个参数可以与前两个参数取或。\n\n------\n\n```c\n#include <dlfcn.h>\nvoid *dlsym(void *handle, char *symbol);\n```\n\n`dlsym`函数的输入是一个指向前面巳经打开了的共享库的句柄和一个`symbol`名字，如果该符号存在，就返回符号的地址，否则返回`NULL`。\n\n------\n\n```c\n#include <dlfcn.h>\nint dlclose (void *handle);\n```\n\n如果没有其他共享库还在使用这个共享库， `dlclose`函数就卸载该共享库。\n\n------\n\n```c\n#include <dlfcn.h>\nconst char *dlerror(void);\n```\n\n`dlerror`函数返回一个字符串，它描述的是调用`dlopen`、`dlsym`或者`dlclose`函数时发生的最近的错误，如果没有错误发生，就返回`NULL`。\n\n------\n\n例如我们以下面的方式调用GCC：\n\n```bash\nlinux> gcc -rdynamic -o prog2r dll.c -ldl\n```\n\n这里`-ldl`是链接动态库`libdl.so`，提供动态加载功能（如`dlopen`、`dlsym`）。\n\n## 7.12位置无关代码\n\n**位置无关代码（PIC）** 是一种编译后的机器代码，其执行不依赖于固定的内存地址。\n\n多个进程可能同时使用同一个动态库（如 `libc.so`），但它们的地址空间不同。PIC允许动态库被加载到不同进程的任意位置，无需为每个进程单独重定位代码。\n\n------\n\n1. **PIC数据引用**\n\n   事实：**无论我们在内存中的何处加载一个目标模块（包括共享目标模块），数据段与代码段的距离总是保持不变**。\n\n   编译器在数据段开始的地方创建了一个表，叫做**全局偏移量表（Global Offset Table，GOT）**。在GOT中，每个被这个目标模块引用的**全局数据目标（过程或全局变量）**都有一个8字节条目。编译器还为GOT中每个条目生成一个重定位记录。在加载时，动态链接器会重定位GOT中的每个条目，使得它包含目标的正确的绝对地址。每个引用全局目标的目标模块都有自己的GOT。\n\n   例如：\n\n   ```bash\n   addvec: # 下面 GOT[3] 和 addl 指令之间固定距离是 0x2008b9，编译时已经确定\n     mov 0x2008b9(%rip), %rax # rax = *GOT[3] = &addcnt\n     addl $0x1,(%rax)         # addcnt++\n   ```\n\n   其中GOT表中`GOT[3]=&addcnt`。\n\n2. **PIC函数调用**\n\n   **延迟绑定（lazy binding）**：\n\n   只在第一次调用某函数的时候解析函数地址，这个过程涉及两个表：\n\n   - **过程链接表（PLT）**：\n\n     每个条目是16字节代码。\n\n     `PLT[0]`跳转到动态链接器。\n\n     `PLT[1]`调用系统启动函数。\n\n     之后的条目调用用户代码调用的函数。\n\n   - **全局偏移量表（GOT）**：\n     \n     和PLT联用时，`GOT[0]`和`GOT[1]`包含动态链接器在解析函数地址时会使用的信息。\n     \n     `GOT[2]`是动态链接器在`ld-linux.so`模块中的入口点。\n     \n     其余每个条目对应于一个被调用的函数。\n     \n     每个GOT条目初始时都对应PLT条目的第二条指令。\n     \n     以下是一个明确的过程，延迟调用`addvec()`：\n     \n     ```bash\n     GOT表:\n     GOT[0]: addr of .dynamic\n     GOT[1]: addr of reloc entries\n     GOT[2]: addr of dynamic linker\n     GOT[3]: 0x4005b6 # sys startup\n     GOT[4]: 0x4005c6 # addvec()\n     GOT[5]: 0x4005d6 # printf()\n     ```\n     \n     ```bash\n     PLT表:\n     # PLT[0]: call dynamic linker\n     4005a0: pushq *GOT[1]\n     4005a6: jmpq *GOT[2]\n     ...\n     # PLT[2]: call addvec()\n     4005c0: jmpq *GOT[4]\n     4005c6: pushq $0x1\n     4005cb: jmpq 4005a0\n     ```\n\n     - 不直接调用`addvec`而是进入`PLT[2]`。\n     - 通过`GOT[4]`间接跳转，把控制传送回`PLT[2]`中的下一条指令。\n     - 把`addvec`的ID(`0x1`)压入栈中，`PLT[2]`跳转回`PLT[0]`。\n     - `PLT[0]`通过`GOT[1]`间接地把动态链接器的一个参数压入栈中，然后通过`GOT[2]`间接跳转进动态链接器中。动态链接器使用两个栈条目来确定`addvec`的运行时位置，用这个地址重写`GOT[4]`，再把控制传递给`addvec` 。\n     \n     日后调用`addvec`，传递到`PLT[2]`，直接通过`GOT[4]`的间接跳转转移到`addvec`。\n\n## 7.13库打桩机制\n\n**库打桩机制**它允许你截获对共享库函数的调用，取而代之执行自己的代码。使用打桩机制，你可以追踪对某个特殊库函数的调用次数，验证和追踪它的输入和输出值，或者甚至把它替换成一个完全不同的实现。\n\n### 7.13.1编译时打桩\n\n通过预处理器宏或条件编译：\n\n```c\nint foo(int x) {return x * 2;}\n#define foo(x) (x*3) // 编译时替换所有 foo 调用\n```\n\n```c\n#ifdef STUB_MODE\n  int foo(int x) {return 0;}\n#else\n  int foo(int x) {return x * 2;}\n#endif\n```\n\n### 7.13.2链接时打桩\n\n```bash\n# 将原函数 foo 替换为 __wrap_foo，原函数重命名为 __real_foo\ngcc -Wl,--wrap=foo main.c -o program\n```\n\n```c\n// 桩函数定义\nint __wrap_foo(int x) {return x + 1;}\n// 可调用原函数(可选)\nint __real_foo(int x);\n```\n\n### 7.13.3运行时打桩\n\n在程序运行时，通过**动态链接拦截**或**函数指针替换**，覆盖目标函数。\n\n```c\n# 1.编写桩动态库\n// stublib.c\n#define _GNU_SOURCE\n#include <dlfcn.h>\nint foo(int x) {\n    typedef int (*RealFoo)(int);\n    RealFoo real_foo = dlsym(RTLD_NEXT, "foo"); // 获取原函数\n    return real_foo(x) + 100; // 修改行为\n}\n```\n\n```bash\n# 2. 编译为动态库\ngcc -shared -fpic -o stublib.so stublib.c -ldl\n```\n\n```bash\n# 3. 运行程序时加载桩库\nlinux> LD_PRELOAD=./stublib.so ./program\n#动态链接器(LD-LINUX.SO)会先搜索 LO_PRELOAD 库，然后才搜索任何其他的库\n```\n\n## 7.14处理目标文件的工具\n\n- `AR`：创建静态库，插入、删除、列出和提取成员。\n- `STRINGS`：列出一个目标文件中所有可打印的字符串。\n- `STRIP`：从目标文件中删除符号表信息。\n- `NM`：列出一个目标文件的符号表中定义的符号。\n- `SIZE`：列出目标文件中节的名字和大小。\n- `READELF`：显示一个目标文件的完整结构，包括ELF头中编码的所有信息。包含SIZE和NM的功能。\n- `OBJDUMP`：所有二进制工具之母。能够显示一个目标文件中所有的信息。它最大的作用是反汇编`.text`节中的二进制指令。\n\n`Linux`系统为操作共享库还提供了`LDD`程序：\n\n- `LDD`：列出一个可执行文件在运行时所需要的共享库。' 
                      },
                      { id: 'computer_basic-5', 
                        title: '8、异常控制流', 
                        desc: '', 
                        content: '# 8.异常控制流\n\n现代系统通过使控制流发生**突变**来对**系统状态的变化**做出反应 。一般而言 ，我们把这些**突变**称为**异常控制流（Exceptional Control Flow，ECF）**。\n\n异常控制流发生在计算机系统的各个层次。比如，在硬件层，硬件检测到的事件会触发控制突然转移到异常处理程序。\n\n在操作系统层，内核通过上下文切换将控制从一个用户进程转移到另一个用户进程。\n\n在应用层，一个进程可以发送信号到另一个进程，而接收者会将控制突然转移到它的一个信号处理程序。\n\n一个程序可以通过回避通常的栈规则，执行到其他函数中任意位置的本地跳转来对错误做出反应。\n\n## 8.1 异常\n\n> [!NOTE]\n>\n> **异常（exception）** 就是控制流中的突变，用来响应处理器状态中的某些变化，一部分由硬件实现，一部分由操作系统实现。\n>\n> 状态变化称为**事件（event）**。事件可能和当前指令的执行直接相关（虚拟内存缺页、算术溢出）。事件也可能和当前指令的执行没有关系（一个系统定时器产生信号）。\n\n在任何情况下，当处理器检测到有事件发生时，它就会通过一张**异常表（exception table）**的跳转表，进行一个间接过程调用（异常），到一个专门设计用来处理这类事件的**操作系统子程序（异常处理程序（exception handler））**。\n\n当异常处理程序完成处理后，根据引起异常的事件的类型，会发生以下情况中的一种：\n\n1. 处理程序将控制返回给当前指令$I_{curr}$，即当事件发生时正在执行的指令。\n2. 处理程序将控制返回给$I_{next}$，如果没有发生异常将会执行的下一条指令。\n3. 处理程序终止被中断的程序。\n\n### 8.1.1 异常处理\n\n系统中可能的每种类型的异常都分配了一个唯一的非负整数的**异常号（exception number）**，其中一些是**处理器设计者**分配的（被零除、缺页、内存访问违例、断点以及算术运算溢出），一些是**操作系统内核设计者**分配的（系统调用和来自外部设备的信号）。\n\n系统启动时，操作系统分配和初始化一张**异常表**，使得表目$k$包含异常$k$的处理程序的地址。当**运行时**检测到一个事件并确定异常号$k$，会通过异常表间接过程调用**异常处理程序**。\n\n> 异常表的起始地址放在一个叫做**异常表基址寄存器**的特殊CPU寄存器。\n\n| 异常和过程调用的区别 | 异常                                                         | 过程调用           |\n| -------------------- | ------------------------------------------------------------ | ------------------ |\n| 返回地址             | 当前指令或下一条指令                                         | 返回地址被压入栈中 |\n| 记录状态             | 将一些额外的处理器状态压到栈里                               | [none]             |\n| 控制转移             | 如果控制从用户程序转移到内核，所有项目都被压到内核栈中，而不是用户栈 | 压到用户栈         |\n| 访问权限             | **内核模式**（对所有的系统资源都有完全的访问权限）           | [none]             |\n\n### 8.1.2 异常的类别\n\n| 类别 | 原因                     | 异步/同步 | 返回行为             |\n| ---- | ------------------------ | --------- | -------------------- |\n| 中断 | 来自I/O设备的信号 | 异步      | 总是返回到下一条指令 |\n| 陷阱 | 有意的异常               | 同步      | 总是返回到下一条指令 |\n| 故障 | 潜在可恢复的错误         | 同步      | 可能返回到当前指令   |\n| 终止 | 不可恢复的错误           | 同步      | 不会返回             |\n\n\n> [!NOTE]\n>\n> **异步**：无法预知何时触发，例如用户突然按下键盘。\n>\n> **同步**：程序刻意触发，例如调用`printf`时会陷入内核。\n\n- **中断：由外部硬件设备（如键盘、磁盘、定时器）主动触发**，通知CPU处理异步事件。\n  \n- **陷阱：陷阱是有意的异常，是执行一条指令的结果**。陷阱最重要的用途是在用户程序和内核之间提供一个像过程一样的接口，叫做**系统调用**：\n  \n  当向内核请求服务，比如：\n\n  - **读个文件（read）**。\n  - **创建一个新的进程（fork）** 。\n  - **加载一个新的程序（execve）**。\n  - **终止当前进程（exit）**。\n\n  为了允许对这些内核服务的受控的访问，处理器提供了`syscall`指令，用户程序想要请求服务`n`时，执行`syscall n`。\n\n- **故障**：\n  \n  当故障发生时，处理器将控制转移给**故障处理程序**，如果处理程序能够修正这个错误情况，它就将控制返回到引起故障的指令，从而重新执行它。\n\n  否则，处理程序返回到内核中的`abort`例程，`abort`例程终止引起故障的应用程序。\n  \n- **终止**：\n  \n  终止是不可恢复的致命错误造成的结果，通常是一些硬件错误。终止处理程序从不将控制返回给应用程序，而可能会终止这个应用程序。\n\n### 8.1.3Linux/x86-64 系统中的异常\n\n> 这里介绍部分异常作为示例。\n\n| 异常号 | 描述                               | 异常类别   | 处理                                                         |\n| ------ | ---------------------------------- | ---------- | ------------------------------------------------------------ |\n| 0      | 除法错误                           | 故障       | 终止程序                                                     |\n| 13     | 一般保护故障（Segmentation fault） | 故障       | [none]                                                       |\n| 14     | 缺页                               | 故障       | 处理程序将适当的磁盘上虚拟内存的一个页面映射到物理内存的一个页面，然后重新执行这条产生故障的指令 |\n| 18     | 机器检查                           | 终止       | 机器检查处理程序从不返回控制给应用程序。                     |\n| 32~255 | 操作系统定义的异常                 | 中断或陷阱 | [none]                                                       |\n\nC 程序用 `syscall` 函数可以直接调用任何系统调用。然而，实际中几乎没必要这么做。对于大多数系统调用，标准库提供了一组方便的包装函数。这些包装函数将参数打包到一起，以适当的系统调用指令陷入内核，然后将系统调用的返回状态传递回调用程序。\n\n| 编号 | 名字    | 描述               | 编号 | 名字     | 描述                 |\n| ---- | ------- | ------------------ | ---- | -------- | -------------------- |\n| 0    | `read`  | 读文件             | 33   | `pause`  | 挂起进程直到信号到达 |\n| 1    | `write` | 写文件             | 37   | `alarm`  | 调度告警信号的传送   |\n| 2    | `open`  | 打开文件           | 39   | `getpid` | 获得进程ID           |\n| 3    | `close` | 关闭文件           | 57   | `fork`   | 创建进程             |\n| 4    | `stat`  | 获得文件信息       | 59   | `execve` | 执行一个程序         |\n| 9    | `mmap`  | 将内存页映射到文件 | 60   | `_exit`  | 终止进程             |\n| 12   | `brk`   | 重置堆顶           | 61   | `wait4`  | 等待一个进程终止     |\n| 32   | `dup2`  | 复制文件描述符     | 62   | `kill`   | 发送信号到一个进程   |\n\n## 8.2 进程\n\n异常是允许操作系统内核提供**进程（process）** 概念的基本构造块，进程是计算机科学中最深刻、最成功的概念之一。\n\n**进程的经典定义就是一个执行中程序的实例**。系统中的每个程序都运行在某个进程的**上下文（context）** 中。\n\n上下文是由程序正确运行所需的状态组成的。这个状态包括：\n\n- 存放在内存中的程序的代码和数据。\n- 它的栈。\n- 通用目的寄存器的内容。\n- 程序计数器。\n- 环境变量。\n- 打开文件描述符的集合。\n\n每次用户通过向shell输入一个可执行目标文件的名字，运行程序时，shell就会创建一个新的进程，然后在这个新进程的上下文中运行这个可执行目标文件。\n\n应用程序也能够创建新进程，并且在这个新进程的上下文中运行它们自己的代码或其他应用程序。\n\n进程提供给应用程序的关键抽象：\n\n- 一个独立的逻辑控制流，它提供一个假象，好像我们的程序独占地使用处理器。\n- 一个私有的地址空间，它提供一个假象，好像我们的程序独占地使用内存系统。\n\n### 8.2.1 逻辑控制流\n\n**逻辑控制流**：里面的**程序计数器（PC）** 的值唯一地对应于包含在程序的可执行目标文件中的指令，或是包含在运行时动态链接到程序的共享对象中的指令。\n\n**事实上**：进程是轮流使用处理器的。每个进程执行它的流的一部分，然后被**抢占（preempted）（暂时挂起）**，然后轮到其他进程。\n\n![image-20250508085948263](./pictures/image-20250508085948263.png)\n\n### 8.2.2 并发流\n\n一个**逻辑流**的执行在时间上与另一个流重叠，称为**并发流（concurrent flow）**，这两个流被称为并发地运行。\n\n多个流并发地执行的一般现象被称为**并发（concurrency）**。一个进程和其他进程轮流运行的概念称为**多任务（multitasking）**。一个进程执行它的控制流的一部分的每一时间段叫做**时间片（time slice）**。因此，多任务也叫做**时间分片（time slicing）**。\n\n> 如果流$X$在$Y$开始之后和$Y$结束之前开始，则称流$X$和$Y$互相并发。\n\n如果两个流并发地运行在不同的处理器核或者计算机上，那么我们称它们为**并行流（parallel flow）**，它们并行地**运行（running in parallel）**，且**并行地执行（parallel execution）**。\n\n### 8.2.3 私有地址空间\n\n在一台$n$位地址的机器上，地址空间是$2^n$个可能地址的集合，进程为每个程序提供它自己的私有地址空间。\n\n一般来说：**和这个空间中某个地址相关联的那个内存字节是不能被其他进程读或者写的**。\n\n一般地址空间都有相同的通用结构，~~经典老图~~。\n\n![image-20250508182149415](./pictures/image-20250508182149415.png)\n\n### 8.2.4 用户模式和内核模式\n\n为了**保护操作系统内核**，处理器必须提供一种机制，限制一个应用可以执行的指令以及它可以访问的地址空间范围。\n\n**模式位（mode bit）**：\n\n> 模式位是处理器状态寄存器（如x86的EFLAGS、ARM的CPSR）中的一个或多个二进制位，用于指示CPU当前所处的执行模式。\n\n- 当设置了**模式位**时，进程就运行在**内核模式**中（有时叫做超级用户模式）。一个运行在内核模式的进程可以执行指令集中的任何指令，并且可以访问系统中的任何内存位置。\n\n- 没有设置模式位时，进程就运行在**用户模式**中。用户模式中的进程不允许执行**特权指令（privileged instruction）**，比如停止处理器、改变模式位，或者发起一个I/O操作。也不允许用户模式中的进程直接引用地址空间中内核区内的代码和数据。任何这样的尝试都会导致致命的保护故障。\n  \n    反之，用户程序必须通过**系统凋用接口**间接地访问内核代码和数据。\n\n进程从**用户模式变为内核模式**的唯一方法是通过诸如**中断、故障或者陷入系统调用**这样的异常。\n\n当异常发生时，控制传递到异常处理程序，处理器将模式从用户模式变为内核模式。处理程序运行在内核模式中，当它返回到应用程序代码时，处理器就把模式从内核摸式改回到用户模式。\n\n**/proc 文件系统**：/proc文件系统将许多内核数据结构的内容输出为一个用户程序可以读的文本文件的层次结构，它不占用实际磁盘空间，而是由内核动态生成的，提供了一种访问内核数据和系统信息的接口。\n\n```bash\n/proc/cpuinfo      # CPU信息\n/proc/meminfo      # 内存使用情况\n/proc/version      # 内核版本\n/proc/uptime       # 系统运行时间\n/proc/loadavg      # 系统负载平均值\n/proc/interrupts   # 中断信息\n/proc/modules      # 已加载内核模块\n/proc/filesystems  # 支持的文件系统\n```\n\n每个运行进程都有一个以其PID命名的目录。\n\n```bash\n/proc/1234/        # PID为1234的进程信息\n    ├── cmdline    # 启动命令\n    ├── cwd        # 当前工作目录(符号链接)\n    ├── exe        # 执行文件路径(符号链接)\n    ├── fd/        # 打开的文件描述符\n    ├── status     # 进程状态信息\n    ├── statm      # 内存使用统计\n    └── ...\n\n```\n\n### 8.2.5 上下文切换\n\n操作系统内核使用一种称为**上下文切换（context switch）** 的较高层形式的异常控制流来实现多任务。\n\n**上下文**：\n\n> 上下文就是内核重新启动一个被抢占的进程所需的状态，它由一些对象的值组成：\n>\n> - 目的寄存器。\n> - 浮点寄存器。\n> - 程序计数器。\n> - 用户栈。\n> - 状态寄存器。\n> - 内核栈。\n> - 各种内核数据结构。\n>     - 描述地址空间的页表。\n>     - 包含有关当前进程信息的进程表。\n>     - 包含进程已打开文件的信息的文件表。\n\n**调度**：\n\n> 在进程执行的某些时刻，内核可以决定抢占当前进程，并重新开始一个先前被抢占了的进程。这是由由内核中称为**调度器（scheduler）** 的代码处理的。\n>\n> 在内核调度了一个新的进程运行后，它就抢占当前进程，并使用一种称为**上下文切换**的机制来将控制转移到新的进程。\n>\n> 1. 保存当前进程的上下文。\n> 2. 恢复某个先前被抢占的进程被保存的上下文。\n> 3. 将控制传递给这个新恢复的进程。\n\n如果系统调用因为等待某个事件发生而阻塞，那么内核可以让当前进程休眠，切换到另一个进程，以此来**优化进程调用**。\n\n**中断也可能引发上下文切换**。比如，所有的系统都有某种产生周期性定时器中断的机制，通常为每1毫秒或每10毫秒。\n\n每次发生定时器中断时，内核就能判定当前进程已经运行了足够长的时间，并切换到一个新的进程。\n\n## 8.3 系统调用错误处理\n\n当Unix系统级函数遇到错误时，它们通常会返回-1，并设置全局整数变量errno来表示什么出错了。\n\n例如：\n\n```c\nif((pid = fork()) < 0) {\n    fprintf(stderr, "fork error: %s\\n", strerror(errno));\n    exit(0);\n}\n```\n\n当然我们可以把这个错误函数封装成**错误报告函数**，以保持代码示例简洁。\n\n## 8.4 进程控制\n\n### 8.4.1 获取进程 ID\n\n`getpid`函数返回调用进程的PID。\n`getppid`函数返回它的父进程的PID（创建调用进程的进程）。\n\n```c\n#include <sys/types.h>\n#include <unistd.h>\n\npid_t getpid(void)\npid_t getppid(void)\n```\n\n> 在Linux上`pid_t`被定义为`int`。\n\n### 8.4.2创建和终止进程\n\n从程序员的角度，我们可以认为进程总是处于下面三种状态之一：\n\n- **运行**：进程要么在CPU上执行，要么在等待被执行且最终会被内核调度。\n- **停止**：进程的执行**被挂起（suspended）**，且不会被调度。当收到`SIGSTOP`、`SIGTSTP`、`SIGTTIN`或者`SIGTTOU`信号时，进程就停止，并且保待停止直到它收到一个`SIGCONT`信号，在这个时刻，进程再次开始运行。\n- **终止**：进程永远地停止了。进程会因为三种原因终止：\n    -  收到一个信号，该信号的默认行为是终止进程。\n    - 从主程序返回。\n    - 调用`exit`函数。\n\n```c\n#include <stdlib.h>\nvoid exit(int status);\n```\n\n`exit`函数以`status`退出状态来终止进程（另一种设置退出状态的方法是从主程序中返回一个整数值）。\n\n```c\n#include <sys/types.h>\n#include <unistd.h>\n\npid_t fork(void);\n```\n\n父进程通过调用`fork`函数创建一个新的运行的子进程。\n\n> [!NOTE]\n>\n> 子进程得到与父进程用户级虚拟地址空间相同的（但是独立的）一份副本，包括代码和数据段、堆、共享库以及用户栈。子进程还获得与父进程任何打开文件描述符相同的副本。\n>\n> 这就意味着当父进程调用fork时，子进程可以读写父进程中打开的任何文件。父进程和新创建的子进程之间最大的区别在于它们有不同的PID。\n\n```c\nint main() {\n    pid_t pid;\n    int x = 1;\n    pid = Fork();\n    if(pid == 0) { /* Child */\n        printf("child: x = %d\\n", ++x);\n        exit(0);\n    }\n    /* Parent */\n    printf("parent: x = %d\\n", --x);\n    exit(0);\n}\n```\n\n```bash\nlinux> ./fork\nparent: x = 0\nchild: x = 2\n```\n\n这个简单的例子有一些微妙的方面：\n\n- **调用一次，返回两次**：`fork`函数被父进程调用一次，但是却返回两次，一次是返回到父进程，一次是返回到新创建的子进程。\n\n- **并发执行**：父进程和子进程是并发运行的独立进程。内核能够以任意方式交替执行它们的逻辑控制流中的指令。在我们的系统上运行这个程序时，父进程先完成它的`printf`语句，然后是子进程。然而，在另一个系统上可能正好相反。\n\n- **相同但是独立的地址空间**：父进程和子进程有相同的用户栈、相同的本地变量值、相同的堆、相同的全局变量值，以及相同的代码。\n    \n    然而，因为父进程和子进程是独立的进程，它们都有自己的私有地址空间。父进程和子进程做的任何改变不会反映在另一个进程的内存中。\n    \n- **共享文件**：子进程继承了父进程所有的打开文件。当父进程调用`fork`时，`stdout`文件是打开的，并指向屏幕。子进程继承了这个文件，因此它的输出也是指向屏幕的。\n\n### 8.4.3回收子进程\n\n当一个进程由于某种原因终止时，被保持在一种已终止的状态中，直到被它的父进程**回收（reaped）** 。当父进程回收己终止的子进程时，内核将子进程的退出状态传递给父进程，然后抛弃己终止的进程，从此时开始，该进程就不存在了。\n\n一个终止了但还未被回收的进程称为**僵死进程（zombie）**。\n\n> `init`进程的PID为1，是在系统启动时由内核创建的，它不会终止，是所有进程的祖先。\n\n如果父进程没有回收它的僵死子进程就终止了，那么内核会安排`init`进程去回收它们。\n\n一个进程可以通过调用`waitpid`函数来等待它的子进程终止或者停止。\n\n```c\n#include <sys/types.h>\n#include <sys/wait.h>\n\npid_t waitpid(pid_t pid, int *statusp, int options);\n```\n\n当`options=0`时，`waitpid`挂起调用进程的执行，直到它的**等待集合（wait set）** 中的一个子进程终止，返回已终止子进程的PID。\n\n1. **判定等待集合的成员**：\n\n    如果`pid>0`，那么等待集合就是一个单独的子进程，进程ID等于`pid`。\n\n    如果`pid=-1`，那么等待集合就是由父进程所有的子进程组成的。\n\n2. **修改默认行为**：\n\n    将`options`设置为以下常量来修改默认行为：\n\n    `WNOHANG`：如果等待集合中的任何子进程都还没有终止，那么就立即返回0。默认的行为是挂起调用进程，直到有子进程终止。在等待子进程终止的同时，如果还想做些有用的工作，这个选项会有用。\n\n    `WUNTRACED`：挂起调用进程的执行，直到等待集合中的一个进程变成已终止或者被停止。返回的`PID`为导致返回的已终止或被停止子进程的`PID`。默认的行为是只返回己终止的子进程。当你想要检查己终止和被停止的子进程时，这个选项会有用。\n\n    `WCONTINUED`：挂起调用进程的执行，直到等待集合中一个正在运行的进程终止或等待集合中一个被停止的进程收到`SIGCONT`信号重新开始执行。\n\n3. **检查已回收子进程的退出状态**：\n\n    如果`statusp`参数是非空的，那么`waitpid`就会在`status`中放上关于导致返回的子进程的状态信息，`status`是`statusp`指向的值。`wait.h`头文件定义了解释`status`参数的几个宏：\n\n    - **WIFEXITED(status)**：如果子进程通过调用`exit`或者一个**返回(return)** 正常终止，就返回真。\n    - **WEXITSTATUS(status)**：返回一个正常终止的子进程的退出状态。只有在**WIFEXITED()** 返回为真时，才会定义这个状态。\n    - **WIFSIGNALED(status)**：如果子进程是因为一个未被捕获的信号终止的，那么就返回真。\n    - **WTERMSIG(status)**：返回导致子进程终止的信号的编号。只有在**WIFSIGNALED()** 返回为真时，才定义这个状态。\n    - **WIFSTOPPED(status)**：如果引起返回的子进程当前是停止的，那么就返回真。\n    - **WSTOPSIG(status)**：返回引起子进程停止的信号的编号。只有在**WIFSTOPPED()** 返回为真时，才定义这个状态。\n    - **WIFCONTINUED(status)**：如果子进程收到**SIGCONT**信号重新启动，则返回真。\n\n4. **错误条件**：\n\n    如果调用进程没有子进程，那么`waitpid`返回`-1`，并且设置`errno`为`ECHILD`。如果`waitpid`函数被一个信号中断，那么它返回`-1`，并设置`errno`为`EINTR`。\n\n5. **wait函数**：\n\n    `wait`函数是`waitpid`函数的简单版本：\n\n    ```c\n    #include <sys/types.h>\n    #include <sys/wait.h>\n    \n    pid_t wait(int *statusp);\n    // wait(&status) 等价于 waitpid(-1, &status, 0);\n    ```\n\n6. **使用waitpid的示例**：\n\n    以下展示了一个程序，它使用`waitpid`，不按照特定的顺序等待它的所有N个子进程终止。\n\n    ```c\n    #include <sys/types.h>\n    #include <sys/wait.h>\n    #include <unistd.h>\n    #include <stdlib.h>\n    #include <stdio.h>\n    #include <errno.h>\n    #define N 2\n    void unix_error(char *msg) {\n        fprintf(stderr, "%s: %s\\n", msg, strerror(errno));\n        exit(0); \n    }\n    pid_t Fork(void) {\n        pid_t pid;\n        if ((pid = fork()) < 0) unix_error("Fork error");\n        return pid;\n    }\n    int main() {\n        int status, i;\n        pid_t pid;\n        /* Parent creates N children */\n        for (i = 0; i < N; i++)\n            if ((pid = Fork()) == 0) /* Child */\n                exit(100 + i);\n        /* Parent reaps N children in no particular order */\n        while ((pid = waitpid(-1, &status, 0)) > 0) {\n            if (WIFEXITED(status)) printf("child %d terminated normally with exit status=%d\\n", pid, WEXITSTATUS(status));\n            else printf("child %d terminated abnormally\\n", pid);\n        }\n        /* The only normal termination is if there are no more children */\n        if (errno ! = ECHILD) unix_error("waitpid error");\n        exit(0);\n    }\n    ```\n\n    它可能输出：\n\n    ```bash\n    linux> ．/waitpid1\n    child 22966 terminated normally with exit status=100\n    child 22967 terminated normally with exit status=101\n    ```\n\n    或：\n\n    ```bash\n    linux> ．/waitpid1\n    child 22966 terminated normally with exit status=101\n    child 22967 terminated normally with exit status=100\n    ```\n\n    只需稍作改动即可让它不具有不确定性：\n\n    ```c\n    #include <sys/types.h>\n    #include <sys/wait.h>\n    #include <unistd.h>\n    #include <stdlib.h>\n    #include <stdio.h>\n    #include <errno.h>\n    #define N 2\n    void unix_error(char *msg) {\n        fprintf(stderr, "%s: %s\\n", msg, strerror(errno));\n        exit(0); \n    }\n    pid_t Fork(void) {\n        pid_t pid;\n        if ((pid = fork()) < 0) unix_error("Fork error");\n        return pid;\n    }\n    int main() {\n        int status, i;\n        pid_t pid[N], retpid;\n        /* Parent creates N children */\n        for (i = 0; i < N; i++)\n            if ((pid[i] = Fork()) == 0) /* Child */\n                exit(100 + i);\n        /* Parent reaps N children in no particular order */\n        i = 0;\n        while ((retpid = waitpid(pid[i++], &status, 0)) > 0) {\n            if (WIFEXITED(status)) printf("child %d terminated normally with exit status=%d\\n", retpid, WEXITSTATUS(status));\n            else printf("child %d terminated abnormally\\n", retpid);\n        }\n        /* The only normal termination is if there are no more children */\n        if (errno ! = ECHILD) unix_error("waitpid error");\n        exit(0);\n    }\n    ```\n\n\n### 8.4.4让进程休眠\n\n`sleep`函数将一个进程挂起一段指定的时间。\n\n如果请求的时间量已经到了，`sleep`返回`0`，否则返回还剩下的要休眠的秒数。后一种情况是可能的，如果因为`sleep`函数被一个信号中断而过早地返回。\n\n```c\n#include <unistd.h>\nunsigned int sleep(unsigned int secs);\n```\n\n`pause`函数让调用函数休眠，直到该进程收到一个信号。\n\n```c\n#include <unistd.h>\nint pause(void);\n```\n\n### 8.4.5加载并运行程序\n\n`execve`函数在当前进程的上下文中加载并运行一个新程序。\n\n**该函数调用一次从不返回**。\n\n```c\n#include <unistd.h>\nint execve(const char *filename, const char *argv[], const char *envp[]);\n```\n\n那么`argv[]`和`envp[]`是什么呢？\n\n![image-20250509231550396](./pictures/image-20250509231550396.png)\n\n`execve`加载`filename`后，调用**启动代码**，然后设置**栈**，将控制传递给新程序的主函数。\n\n```c\nint main(int argc, char*argv[], char *envp[]);\n```\n\n![image-20250509232158656](./pictures/image-20250509232158656.png)\n\n1. **argc**：给出`argv[]`数组中非空指针的数量。\n2. **argv**：指向`argv[]`数组中的第一个条目。\n3. **envp**：指向`envp[]`数组中的第一个条目。\n\nLinux提供了几个函数来操作环境数组：\n\n```c\n#include <stdlib.h>\nchar *getenv(const char *name);\n```\n\n将返回一个环境数组中指向`value`的指针或`NULL`。\n\n```c\n#include <stdlib.h>\nint setenv(const char *name, const char *newvalue, int overwrite);\n\nvoid unsetenv(const char *name);\n```\n\n前者在`overwrite`非零时，会用`newvalue`代替`oldvalue`。如果`name`不存在，那么把`name=newvalue`添加到数组中。\n\n后者回删除形如`name=oldvalue`的字符串。\n\n### 8.4.6利用fork和execve运行程序\n\n> [!IMPORTANT]\n>\n> 下面展示一个简单`shell`的`main`例程：`shell`打印一个命令行提示符，等待用户在`stdin`上输入命令行，然后对这个命令行求值。\n\n```c\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <unistd.h>\n#include <sys/types.h>\n#include <sys/wait.h>\n#include <errno.h>\n#define MAXARGS 128\n/* Function prototypes */\nchar *Fgets(char *ptr, int n, FILE *stream) {\n    char *rptr;\n    if (((rptr = fgets(ptr, n, stream)) == NULL) && ferror(stream))\n        app_error("Fgets error");\n    return rptr;\n}\nvoid eval(char *cmdline);\nint parseline(char *buf, char **argv);\nint builtin_command(char **argv);\nint main() {\n    char cmdline[MAXLINE]; /* Command line */\n    while (1) {\n        /* Read */\n        printf("> ");\n        Fgets(cmdline, MAXLINE, stdin);\n        if (feof (stdin)) exit(0);\n        /* Evaluate */\n        eval (cmdline);\n    }\n}\n```\n\n> [!IMPORTANT]\n>\n> 下面展示了对命令行求值的代码。\n\n```c\n/* eval - Evaluate a command line */\nvoid eval (char * cmdline) {\n    char *argv[MAXARGS]; /* Argument list execve() */\n    char buf[MAXLINE];   /* Holds modified command line */\n    int bg;              /* Should the job run in bg or fg? */\n    pid_t pid;           /* Process id */\n    strcpy(buf, cmdline);\n    bg = parseline(buf, argv);\n    /* Parses the space-delimited command line arguments and constructs the argv vector that will eventually be passed to execve */\n    /* bg will be 1 if the last parameter is \'&\' or bg will be 0 */\n    if (argv[0] == NULL) return; /* Ignore empty lines */\n    if (!builtin_command(argv)) { /* It is a built-in command or not. */\n        if ((pid = Fork()) == 0) { /* Child runs user job */\n            if (execve(argv[0], argv, environ) < 0) {\n                printf("%s: Command not found.\\n", argv[0]);\n                exit(0);\n            }\n        }\n        /* Parent waits for foreground job to terminate */\n        if (!bg) {\n            int status;\n            if (waitpid(pid, &status, 0) < 0) unix_error("waitfg: waitpid error");\n        }\n        else printf("%d %s", pid, cmdline);\n    }\n    return;\n}\n\n/* If first arg is a builtin command, run it and return true */\nint builtin_command(char **argv) { /* Actual builtin_command includes numerous other commands */\n    if (!strcmp(argv[0], "quit")) exit(0); /* quit command */\n    if (!strcmp(argv[0], "&")) return 1;   /* Ignore singleton & */\n    return 0;                              /* Not a builtin command */\n}\n```\n\n```c\n/* parseline - Parse the command line and build the argv array */\nint parseline(char *buf, char **argv) {\n    char *delim;        /* Points to first space delimiter */\n    int argc;           /* Number of args */\n    int bg;             /* Background job? */\n    buf[strlen(buf) - 1] = \' \'; /* Replace trailing \'\\n\' with space */\n    while (*buf && (*buf == \' \')) buf++; /* Ignore leading spaces */\n    /* Build the argv list */\n    argc = 0;\n    while ((delim = strchr(buf, \' \'))) {\n        argv[argc++] = buf;\n        *delim = \'\0\';\n        buf = delim + 1;\n        while (*buf && (*buf == \' \')) buf++; /* Ignore spaces */\n    }\n    argv[argc] = NULL;\n    if (argc == 0) return 1; /* Ignore blank line */\n    /* Should the job run in the background? */\n    if ((bg = (*argv[argc-1] == \'&\')) != 0) argv[--argc] = NULL;\n    return bg;\n}\n```\n\n注意这个shell并不回收后台子进程，我们将在下一节讨论这个问题。\n\n## 8.5信号\n\n> 在本节中，我们将研究一种更高层的软件形式的异常，称为**Linux信号**，它允许进程和内核中断其他进程。\n>\n> 一个信号就是一条小消息，它通知进程系统中发生了一个某种类型的事件。\n>\n> 每种信号类型都对应于某种系统事件。低层的硬件异常是由内核异常处理程序处理的，正常情况下，对用户进程而言是不可见的。信号提供了一种机制，通知用户进程发生了这些异常。\n>\n> 比如，如果当进程在前台运行时，你键入Ctrl+C，那么内核就会发送一个`SIGINT`信号（号码2）给这个前台进程组中的每个进程。\n\n| 序号 | 名称      | 默认行为              | 相应事件                       |\n| ---- | --------- | --------------------- | ------------------------------ |\n| 1    | SIGHUP    | 终止                  | 终端线挂断                     |\n| 2    | SIGINT    | 终止                  | 来自键盘的中断                 |\n| 3    | SIGQUIT   | 终止                  | 来自键盘的退出                 |\n| 4    | SIGILL    | 终止                  | 非法指令                       |\n| 5    | SIGTRAP   | 终止并转储内存        | 跟踪陷阱                       |\n| 6    | SIGABRT   | 终止并转储内存        | 来自abort函数的终止信号        |\n| 7    | SIGBUS    | 终止                  | 总线错误                       |\n| 8    | SIGFPE    | 终止并转储内存        | 浮点异常                       |\n| 9    | SIGKILL   | 终止                  | 杀死程序                       |\n| 10   | SIGUSR1   | 终止                  | 用户定义的信号1                |\n| 11   | SIGSEGV   | 终止并转储内存        | 无效的内存引用(段故障)         |\n| 12   | SIGUSR2   | 终止                  | 用户定义的信号2                |\n| 13   | SIGPIPE   | 终止                  | 向一个没有读用户的管道做写操作 |\n| 14   | SIGALRM   | 终止                  | 来自alarm函数的定时器信号      |\n| 15   | SIGTERM   | 终止                  | 软件终止信号                   |\n| 16   | SIGSTKFLT | 终止                  | 协处理器上的栈故障             |\n| 17   | SIGCHLD   | 忽略                  | 一个子进程停止或者终止         |\n| 18   | SIGCONT   | 忽略                  | 继续进程如果该进程停止         |\n| 19   | SIGSTOP   | 停止直到下一个SIGCONT | 不是来自终端的停止信号         |\n| 20   | SIGTSTP   | 停止直到下一个SIGCONT | 来自终端的停止信号             |\n| 21   | SIGTTIN   | 停止直到下一个SIGCONT | 后台进程从终端读               |\n| 22   | SIGTTOU   | 停止直到下一个SIGCONT | 后台进程向终端写               |\n| 23   | SIGURG    | 忽略                  | 套接字上的紧急情况             |\n| 24   | SIGXCPU   | 终止                  | CPU时间限制超出                |\n| 25   | SIGXFSZ   | 终止                  | 文件大小限制超出               |\n| 26   | SIGVTALRM | 终止                  | 虚拟定时器期满                 |\n| 27   | SIGPROF   | 终止                  | 剖析定时器期满                 |\n| 28   | SIGWINCH  | 忽略                  | 窗口大小变化                   |\n| 29   | SIGIO     | 终止                  | 在某个描述符上可执行I/O操作    |\n| 30   | SIGPWR    | 终止                  | 电源故障                       |\n\n> **转储内存**：把代码和数据内存段的映像写到磁盘上。\n\n### 8.5.1信号术语\n\n**传送一个信号到目的进程**：\n\n- **发送信号**：\n\n  - 内核检测到一个系统事件，比如除零错误或者子进程终止。\n  - 一个进程调用`kill`函数时。\n\n  内核会通过更新目的进程上下文中的某个状态，发送一个信号给目的进程。\n\n- **接收信号**：\n  当目的进程被内核~~强迫以某种方式~~对信号的发送做出反应时，它**接收信号**。进程可以\n\n  - **忽略这个信号**。\n  - **终止**。\n  - 通过执行一个称为**信号处理程序（signal handler）** 的用户层函数捕获这个信号。\n\n**待处理信号**：一个发出而没有被接收的信号。\n\n> 在任何时刻，一种类型至多只会有一个待处理信号。\n>\n> 当一个信号被进程阻塞时，它仍可以被发送，但是产生的待处理信号不会被接收，直到进程取消对这种信号的阻塞。\n\n**一个待处理信号最多只能被接收一次**。\n\n内核为每个进程在`pending`位向量中维护着待处理信号的集合，而在`blocked`位向量中维护着被阻塞的信号集合。\n\n只要发送了一个类型为`K`的信号，内核就会设置`pending`中的第`K`位，而只要接收了一个类型为`K`的信号，内核就会清除`pending`中的第`K`位。\n\n### 8.5.2发送信号\n\n**进程组**：\n\n每个进程都只属于一个进程组，进程组是由一个正整数进程组ID来标识的。\n\n```c\n#include <unistd.h>\npid_t getpgrp(void); \n```\n\n`getpgrp`返回当前进程的进程组ID。\n\n```c\n#include <unistd.h>\nint setpgid(pid_t pid, pid_t pgid);\n```\n\n`segpgid`将进程`pid`的进程组改为`pgid`。\n\n> `pid`为0时表示当前进程，`pgid`为0时就用`pid`指定的进程的`PID`作为进程组ID。\n\n**用/bin/kill程序发送信号**：\n\n`/bin/kill`程序可以向另外的进程发送任意的信号。\n\n```bash\nlinux> /bin/kill -9 -15213\n```\n\n是发送一个`SIGKILL`信号给进程组15213中的每个进程。\n\n> 为负的PID会导致信号被发送到进程组PID中的每个进程。\n>\n> 在此我们使用完整路径`/bin/kill`，因为有些Unix shell有自己内置的`kill`命令。\n\n**从键盘发送信号**：\n\n> **作业（job）**：表示为对一条命令行求值而创建的进程。\n>\n> 任何时刻，至多只有一个前台作业和0个或多个后台作业。\n\n```bash\nlinux> ls | sort\n```\n\n会创建一个由两个进程组成的前台作业。这两个进程是通过Unix管道连接起来的：**一个进程运行ls程序，另一个运行sort程序**。\n\nshell为每个作业创建一个独立的进程组。进程组ID通常取自作业中父进程中的一个。\n\n![image-20250511160814308](./pictures/image-20250511160814308.png)\n\n- 输入`Ctrl+C`会导致内核发送一个`SIGINT`信号到前台进程组中的每个进程。默认情况下，结果是**终止**前台作业。\n- 输入`Ctrl + Z`会发送一个SIGTSTP信号到前台进程组中的每个进程。默认情况下，结果是**停止（挂起）** 前台作业。\n\n**用kill函数发送信号**：\n\n进程通过调用`kill`函数发送信号给其他进程（包括它们自己）：\n\n```c\n#include <sys/types.h>\n#include <signal.h>\nint kill(pid_t pid, int sig);\n```\n\n> 如果`pid`大于零，那么`kill`函数发送信号号码`sig`给进程`pid`。\n>\n> 如果`pid`等于零，那么`kill`发送信号`sig`给调用进程所在进程组中的每个进程，包括调用进程自己。\n>\n> 如果`pid`小于零，`kill`发送信号`sig`给进程组`|pid|`中的每个进程。\n\n```c\n#include <sys/types.h>\n#include <sys/wait.h>\n#include <signal.h>\n#include <unistd.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <errno.h>\nvoid unix_error(char *msg) {\n    fprintf(stderr, "%s: %s\\n", msg, strerror(errno));\n    exit(0); \n}\nvoid Pause() {\n    (void)pause();\n    return;\n}\nvoid Kill(pid_t pid, int signum) {\n    int rc;\n    if ((rc = kill(pid, signum)) < 0) unix_error("Kill error");\n}\npid_t Fork(void) {\n    pid_t pid;\n    if ((pid = fork()) < 0) unix_error("Fork error");\n    return pid;\n}\nint main() {\n    pid_t pid;\n    /* Child sleeps until SIGKILL signal received, then dies */\n    if ((pid = Fork()) == 0) {\n        Pause(); /* Wait for a signal to arrive */\n        printf("control should never reach here!\\n");\n        exit(0);\n    }\n    /* Parent sends a SIGKILL signal to a child */\n    Kill (pid, SIGKILL);\n    exit(0);\n}\n```\n\n**用alram函数发送信号**：\n\n进程可以通过调用`alarm`函数向它自己发送`SIGALRM`信号。\n\n```c\n#include <unistd.h>\nunsigned int alarm(unsigned int secs);\n```\n\n> `alarm`函数安排内核在`secs`秒后发送一个`SIGALRM`信号给调用进程。\n>\n> 如果secs是零，那么不会调度安排新的**闹钟（alarm）**。在任何情况下，对`alarm`的调用都将取消任何待处理的**闹钟（pending）** ，并且返回其在被发送前还剩下的秒数，如果没有任何待处理的闹钟，就返回零。\n\n### 8.5.3接收信号\n\n当内核把进程`p`从内核模式切换到用户模式时（例如，从系统调用返回或是完成了一次上下文切换），它会检查进程`p`的**未被阻塞的待处理信号的集合（pending&~blocked）**。\n\n如果这个集合为空，那么内核将控制传递到**p的逻辑控制流中的下一条指令**（$I_{next}$）。\n\n如果集合非空，那么内核选择集合中的某个信号`k`（通常是最小的`k`），强制`p`接收信号`k`。收到这个信号会触发进程采取某种行为。一旦进程完成了这个行为，那么控制就传递回**p的逻辑控制流中的下一条指令**（$I_{next}$）。\n\n每个信号类型都有一个预定义的默认行为，是下面中的一种：\n\n- 进程终止。\n- 进程终止并转储内存。\n- 进程停止（挂起）直到被`SIGCONT`信号重启。\n- 进程忽略该信号。\n\n> 进程可以通过使用`signal`函数修改和信号相关联的默认行为，除了`SIGSTOP`和`SIGKILL`。\n\n```c\n#include <signal.h>\ntypedef void (*sighandler_t)(int);\n\nsighandler_t signal(int signum, sighandler_t handler);\n```\n\n- 如果`handler`是`SIG_IGN`，那么忽略类型为`signum`的信号。\n\n- 如果`handler`是`SIG_DFL`，那么类型为`signum`的信号行为恢复为默认行为。\n\n- 否则，`handler`就是用户定义的函数的地址，这个函数被称为**信号处理程序**，只要进程接收到一个类型为`signum`的信号，就会调用这个程序。\n  \n  通过把处理程序的地址传递到`signal`函数从而改变默认行为，这叫做**设置信号处理程序（installing the handler）**。\n  \n  **调用信号处理程序被称为捕获信号。执行信号处理程序被称为处理信号。**\n\n下面展示了一个程序，它捕获`SIGINT`信号（由键盘`Ctrl + C`发送），修改为输出错误信息然后退出。\n\n```c\n#include <sys/types.h>\n#include <sys/wait.h>\n#include <signal.h>\n#include <unistd.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <errno.h>\nvoid sigint_handler(int sig) { /* SIGINT handler */\n    printf("Caught SIGINT!\\n");\n    exit(0);\n}\nvoid unix_error(char *msg) {\n    fprintf(stderr, "%s: %s\\n", msg, strerror(errno));\n    exit(0); \n}\nint main() {\n    /* Install the SIGINT handler */\n    if (signal(SIGINT, sigint_handler) == SIG_ERR) unix_error("signal error");\n    pause(); /* Wait for the receipt of a signal */\n    return 0;\n}\n```\n\n### 8.5.4阻塞和解除阻塞信号\n\n**隐式阻塞机制**：内核默认阻塞任何当前处理程序正在处理信号类型的待处理的信号。\n\n**显式阻塞机制**：应用程序可以使用`sigprocmask`函数和它的辅助函数，明确地阻塞和解除阻塞选定的信号。\n\n```c\n#include <signal.h>\nint sigprocmask(int how, const sigset_t *set, sigset_t *oldset);\nint sigemptyset(sigset_t *set); // 初始化set为空集合。\nint sigfillset(sigset_t *set); // 把每个信号都添加到set中。\nint sigaddset(sigset_t *set, int signum); // 把signum添加到set中。\nint sigdelset(sigset_t *set, int signum); // 从set中删除signum。\n// 返回：如果成功则为0，若出错则为-1\nint sigismember(const sigset_t *set, int signum);\n// 返回：若signum是set的成员则为1，如果不是则为0，若出错则为-1\n```\n\n其中：\n\n```c\nint sigprocmask(int how, const sigset_t *set, sigset_t *oldset);\n```\n\n- `how`：用于指定信号修改的方式，可能选择有三种\n  - `SIG_BLOCK`：把`set`中的信号添加到`blocked`中（`blocked=blockedIset`）。\n  - `SIG_UNBLOCK`：从`blocked`中删除`set`中的信号（`blocked=blocked&~set`）。\n  - `SIG_SETMASK`：`block=set`。\n- 如果`oldset`非空，那么`blocked`位向量之前的值保存在`oldset`中。\n\n下面一个例子演示如何**临时阻塞接收SIGINT信号**：\n\n```c\nsigset_t mask, prev_mask;\n\nSigemptyset(&mask);\nSigaddset(&mask, SIGINT);\n\n/* Block SIGINT and save previous blocked set */\nSigprocmask(SIG_BLOCK, &mask, &prev_mask);\n/* Code region that will not be interrupted by SIGINT */\n/* Restore previous blocked set, unblocking SIGINT */\nSigprocmask(SIG_SETMASK, &prev_mask, NULL);\n```\n\n### 8.5.5编写信号处理程序\n\n- **安全的信号处理**：\n  这里引入一些原则，为您安全处理信号提供参考：\n\n  - **处理程序要尽可能简单**。\n\n  - **在处理程序中只调用异步信号安全的函数**。\n    \n    因为这些函数是**可重入的**（例如只访问局部变量），或者它不能被信号处理程序中断。\n\n    > `printf`、`sprintf`、`malloc`和`exit`不在其中。\n\n    ![image-20250512191003117](./pictures/image-20250512191003117.png)\n\n  - **保存和恢复errno**：\n    \n    在进入处理程序时把errno保存在一个局部变量中，在**处理程序返回**前恢复它。\n    \n  - **阻塞所有的信号，保护对共享全局数据结构的访问**：\n    \n    保证主程序在访问数据结构的时候，处理程序不会中断指令序列。\n    \n  - **用volatile声明全局变量。考虑一个处理程序和一个main函数，它们共享一个全局变量g**：\n\n    `volatile`限定符强迫编译器每次在代码中引用`g`时，都要从内存中读取`g`的值。否则如果编译器进行了优化，`main`函数可能**不会察觉到全局变量的变化**。\n  \n  - **用sig_atomic _t声明标志**：\n\n    ```c\n    volatile sig_atomic_t flag;\n    ```\n  \n    这样的数据类型对其读写会是原子的（不可中断的），所以可以直接读写，但要求是单个指令的读写，而`flag++`这种不是。\n  \n- **正确的信号处理**：\n  \n  `pending`位向量中每种类型的信号只对应有一位。~~也就是信号不会排队~~。\n  ~~书本例子太长了，反正建议我们**每接收一个信号就完成尽可能多的事**~~。\n  \n- **可移植的信号处理**：\n  \n  基于以下问题：\n  \n  - **signal函数的语义在各个系统上各有不同**\n  - **系统调用可以被中断**\n  \n  `Posix`标准定义了`sigaction`函数，它允许用户在设置信号处理时，明确指定他们想要的信号处理语义。\n  \n  ```c\n  #include <signal.h>\n  \n  int sigaction(int signum, struct sigaction *act, struct sigaction *oldact);\n  /*\n  参数1: 要捕获的信号\n  参数2: 接收到信号之后对信号进行处理的结构体\n  参数3: 接收到信号之后，保存原来对此信号处理的各种方式与信号。\n  成功时: 返回0\n  出错时: 返回-1，并将 errno 设置为指示错误\n  */\n  ```\n  \n  其中：\n  \n  ```c\n  struct sigaction {\n      void (*sa_handler)(int); // 信号处理函数，也可以设置为 SIG_IGN(向内核表示忽略此信号)或是 SIG_DFL(表示接到此信号后的动作是系统默认动作)\n      void (*sa_sigaction)(int, siginfo_t *, void *); // 当 sa_flags 成员是 SA_SIGINFO 标志时，就调用此函数，可以来获取该信号的很多详细信息，具体不介绍\n      sigset_t sa_mask; // 用来设置在处理该信号时暂时将 sa_mask 指定的信号集搁置\n      int sa_flags; // 用来设置信号处理的其他相关操作，具体不介绍\n      void (*sa_restorer)(void); // (废弃)\n  }\n  ```\n  \n  我们可以封装如下：\n  \n  ```c\n  handler_t  *Signal(int signum, handler_t *handler) {\n      struct sigaction action, old_action;\n      action.sa_handler = handler;  \n      sigemptyset(&action.sa_mask); /* block sigs of type being handled */\n      action.sa_flags = SA_RESTART; /* restart syscalls if possible */\n      if (sigaction(signum, &action, &old_action) < 0)\n          unix_error("Signal error");\n      return (old_action.sa_handler);\n  }\n  ```\n\n### 8.5.6同步流以避免讨厌的并发错误\n\n**竞争**：由父进程和子进程交错运行带来的错误。\n\n例如：\n\n```c\nvoid handler(int sig) {\n    int olderrno = errno;\n    sigset_t mask_all, prev_all;\n    pid_t pid;\n    Sigfillset(&mask_all);\n    while ((pid = waitpid(-1, NULL, 0)) > 0) { /* Reap a zombie child */\n        Sigprocmask(SIG_BLOCK, &mask_all, &prev_all);\n        deletejob(pid); /* Delete the child from the job list */\n        Sigprocmask(SIG_SETMASK, &prev_all, NULL);\n    }\n    if (errno != ECHILD) Sio_error("waitpid error");\n    errno = olderrno;\n}\nint main(int argc, char **argv) {\n    int pid;\n    sigset_t mask_all, prev_all;\n    Sigfillset(&mask_all);\n    Signal(SIGCHLD, handler);\n    initjobs(); /* Initialize the job list */\n    while (1) {\n        if ((pid = Fork()) == 0) { /* Child process */\n            Execve("/bin/date", argv, NULL);\n        }\n        Sigprocmask(SIG_BLOCK, &mask_all, &prev_all); /* Parent process */\n        addjob(pid); /* Add the child to the job list */\n        Sigprocmask(SIG_SETMASK, &prev_all, NULL);\n    }\n    exit(0);\n}\n```\n\n> 如果子进程在父进程能够开始运行前就结束了，那么`addjob`和`deletejob`会以错误的方式被调用。\n\n我们可以把`while(1)`循环中更改为如下，以避免这个烦人的错误。\n\n```c\nSigemptyset(&mask_one);\nSigaddset(&mask_one, SIGCHLD);\n/* ... */\nwhile (1) {\n    Sigprocmask(SIG_BLOCK, &mask_one, &prev_one); /* Block SIGCHLD */\n    if ((pid = Fork()) == 0) { /* Child process */\n        Sigprocmask(SIG_SETMASK, &prev_one, NULL); /* Unblock SIGCHLD */\n        Execve("/bin/date", argv, NULL);\n    }\n    Sigprocmask(SIG_BLOCK, &mask_all, NULL); /* Parent process */\n    addjob(pid); /* Add the child to the job list */\n    Sigprocmask(SIG_SETMASK, &prev_all, NULL);\n}\n```\n\n### 8.5.7显式地等待信号\n\n例如：\n\n```c\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/types.h>\n#include <sys/wait.h>\n#include <signal.h>\n#include <errno.h>\nvolatile sig_atomic_t pid;\nhandler_t *Signal(int signum, handler_t *handler) {\n    struct sigaction action, old_action;\n    action.sa_handler = handler;  \n    sigemptyset(&action.sa_mask); /* Block other signals during signal processing */\n    action.sa_flags = SA_RESTART; /* Automatic restart of system calls interrupted by signals */\n    if (sigaction(signum, &action, &old_action) < 0)\n        unix_error("Signal error");\n    return (old_action.sa_handler);\n}\nvoid Sigemptyset(sigset_t *set) {\n    if (sigemptyset(set) < 0) unix_error("Sigemptyset error");\n}\nvoid Sigaddset(sigset_t *set, int signum) {\n    if (sigaddset(set, signum) < 0) unix_error("Sigaddset error");\n}\nvoid Sigprocmask(int how, const sigset_t *set, sigset_t *oldset) {\n    /* \'how\' can be `SIG_BLOCK` (add masking), `SIG_UNBLOCK` (disable masking), or `SIG_SETMASK` (replace masking). */\n    if (sigprocmask(how, set, oldset) < 0) unix_error("Sigprocmask error");\n}\nvoid sigchld_handler(int s) {\n    int olderrno = errno;\n    pid = waitpid(-1, NULL, 0);\n    errno = olderrno;\n}\nvoid sigint_handler(int s) {}\nint main(int argc, char **argv) {\n    sigset_t mask, prev;\n    Signal(SIGCHLD, sigchld_handler);\n    Signal(SIGINT, sigint_handler);\n    Sigemptyset(&mask);\n    Sigaddset(&mask, SIGCHLD);\n    while (1) {\n        Sigprocmask(SIG_BLOCK, &mask, &prev); /* Block SIGCHLD */\n        if (Fork() == 0) exit(0); /* Child */\n        /* Parent */\n        pid = 0;\n        Sigprocmask(SIG_SETMASK, &prev, NULL); /* Unblock SIGCHLD */\n        /* Wait for SIGCHLD to be received (wasteful) */\n        while (!pid);\n        /* Do some work after receiving SIGCHLD */\n        printf(".");\n    }\n    exit(0);\n}\n```\n\n显然循环`while(!pid)`在浪费处理器资源，我们可以想到把它改成：\n\n```c\nwhile(!pid) pause(); /* Race! */\n```\n\n但是在进入该循环之前，如果收到`SIGCHLD`信号，那么`pause()`会永远睡眠。\n\n所以我们可以改成：\n\n```c\nwhile(!pid) sleep(1); /* Too slow! */\n```\n\n但是太慢。\n\n------\n\n最好的方法是使用`sigsuspend`。\n\n```c\n#include <signal.h>\nint sigsuspend(const sigset_t *mask);\n```\n\n`sigsuspend`函数暂时用`mask`替换当前的阻塞集合，然后挂起该进程，直到收到一个信号。\n\n其行为要么是运行一个处理程序，要么是终止该进程。\n\n如果它的行为是终止，那么该进程不从`sigsuspend`返回就直接终止。\n\n如果它的行为是运行一个处理程序，那么`sigsuspend`从处理程序返回，恢复调用`sigsuspend`时原有的阻塞集合。\n\n```c\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/types.h>\n#include <sys/wait.h>\n#include <signal.h>\n#include <errno.h>\nvolatile sig_atomic_t pid;\nhandler_t *Signal(int signum, handler_t *handler) {\n    struct sigaction action, old_action;\n    action.sa_handler = handler;  \n    sigemptyset(&action.sa_mask); /* Block other signals during signal processing */\n    action.sa_flags = SA_RESTART; /* Automatic restart of system calls interrupted by signals */\n    if (sigaction(signum, &action, &old_action) < 0)\n        unix_error("Signal error");\n    return (old_action.sa_handler);\n}\nvoid Sigemptyset(sigset_t *set) {\n    if (sigemptyset(set) < 0) unix_error("Sigemptyset error");\n}\nvoid Sigaddset(sigset_t *set, int signum) {\n    if (sigaddset(set, signum) < 0) unix_error("Sigaddset error");\n}\nvoid Sigprocmask(int how, const sigset_t *set, sigset_t *oldset) {\n    /* \'how\' can be `SIG_BLOCK` (add masking), `SIG_UNBLOCK` (disable masking), or `SIG_SETMASK` (replace masking). */\n    if (sigprocmask(how, set, oldset) < 0) unix_error("Sigprocmask error");\n}\nvoid sigchld_handler(int s) {\n    int olderrno = errno;\n    pid = waitpid(-1, NULL, 0);\n    errno = olderrno;\n}\nvoid sigint_handler(int s) {}\nint main(int argc, char **argv) {\n    sigset_t mask, prev;\n    Signal(SIGCHLD, sigchld_handler);\n    Signal(SIGINT, sigint_handler);\n    Sigemptyset(&mask);\n    Sigaddset(&mask, SIGCHLD);\n    while (1) {\n        sigprocmask(SIG_BLOCK, &mask, &prev); /* Block SIGCHLD */\n        if (Fork() == 0) exit(0); /* Child */\n        /* Wait for SIGCHLD to be received */\n        pid = 0;\n        while (!pid) sigsuspend(&prev);\n        /* Optionally unblock SIGCHLD */\n        sigprocmask(SIG_SETMASK, &prev, NULL);\n        /* Do some work after receiving SIGCHLD */\n        printf(".");\n    }\n    exit(0);\n}\n```\n\n## 8.6非本地跳转\n\n> **非本地跳转**是通过`setjmp`和`longjmp`实现的将控制直接从一个函数转移到另一个当前正在执行的函数。\n\n```c\n#include <setjmp.h>\n\nint setjmp(jmp_buf env);\nint sigsetjmp(sigjmp_buf env,int savesigs);\n```\n\n`setjmp`函数在`env`缓冲区中保存当前调用环境，以供后面的`longjmp`使用，并返回0。调用环境包括程序计数器、栈指针和通用目的寄存器\n\n```c\n#include <setjmp.h>\n\nvoid longjmp(jmp_buf env, int retval);\nvoid siglongjmp(sigjmp_buf env, int retval);\n```\n\n`longjmp`函数从`env`缓冲区中恢复调用环境，然后触发一个从最近一次初始化`env`的`setjmp`调用的返回。然后`setjmp`返回，并带有非零的返回值`retval`。\n\n> `sigsetjmp`和`siglongjmp`函数是`setjmp`和`longjmp`的可以被信号处理程序使用的版本。\n\n------\n\n非本地跳转的一个重要应用就是**允许从一个深层嵌套的函数调用中立即返回**，通常是由检测到某个错误情况引起的。\n\n如果在一个**深层嵌套的函数调用中发现了一个错误情况**，我们可以使用非本地跳转**直接返回到一个普通的本地化的错误处理程序**，而不是费力地解开调用栈。\n\n------\n\n`longjmp`类似于`goto`，可能会导致分配的某些数据结构最终没有被释放。\n\n## 8.7操作进程的工具\n\nLinux系统提供了大量的监控和操作进程的有用工具：\n\n`STRACE`：**打印一个正在运行的程序和它的子进程调用的每个系统调用的轨迹**。\n\n`PS`：**列出当前系统中的进程（包括僵死进程）**。\n\n`TOP`：**打印出关于当前进程资源使用的信息**。\n\n`PMAP`：**显示进程的内存映射**。\n\n`/proc`：**一个虚拟文件系统，以ASCII文本格式输出大量内核数据结构的内容，用户程序可以读取这些内容**。比如，输入`"cat/proc/loadavg"`，可以看到你的Linux系统上当前的平均负载。' 
                      },
                      { id: 'computer_basic-6', 
                        title: '10、系统级IO', 
                        desc: '', 
                        content: '# 10.系统级I/O\n\n## 10.1Unix I/O\n\n一个Linux文件就是一个$m$字节的序列：\n$$\nB_0,B_1,\\dots,B_k,\\dots,B_{m-1}\n$$\n**所有的I/O设备（例如网络、磁盘和终端）都被模型化为文件，而所有的输入和输出都被当作对相应文件的读和写来执行。**\n\n这种将设备优雅地映射为文件的方式，允许Linux内核引出一个简单、低级的应用接口，称为**Unix I/O**，这使得所有的输入和输出都能以一种统一且一致的方式来执行：\n\n- **打开文件**：应用程序请求内核打开**相应文件**，内核返回一个小的非负整数，叫做**描述符**，它在后续对此文件的所有操作中标识这个文件。\n  \n  内核**记录有关这个打开文件的所有信息**。\n  \n  应用程序只需**记住这个描述符**。\n  \n- `Linux shell`创建的进程开始时有三个打开的文件：标准输入（描述符为0`STDIN_FILENO`）、标准输出（描述符为1`STDOUT_FILENO`）和标准错误（描述符为2`STDERR_FILENO`）。\n\n- **改变当前的文件位置**：对于每个打开的文件，内核保持着一个文件位置$k$，初始为0。这个文件位置是从文件开头起始的字节偏移量。应用程序能够通过执行`seek`操作，显式地设置文件的当前位置为$k$。\n\n- **读写文件**：一个读操作就是从文件复制$n>0$个字节到内存，从当前文件位置$k$开始，然后将$k$增加到$k+n$ 。\n  \n  给定一个大小为$m$字节的文件，当$k\\ge m$ 时执行读操作会触发一个称为`end-of-file(EOF)`的条件，应用程序能检测到这个条件。尽管在文件结尾处并没有明确的EOF符号。\n  \n  类似地，写操作就是从内存复制$n>0$个字节到一个文件，从当前文件位置$k$开始，然后更新$k$。\n  \n- **关闭文件**：当应用完成了对文件的访问之后，它就通知内核关闭这个文件：**内核释放文件打开时创建的数据结构，并将这个描述符恢复到可用的描述符池中**。无论一个进程因为何种原因终止时，内核都会关闭所有打开的文件并释放它们的内存资源。\n\n## 10.2文件\n\n- **普通文件(regular file)**：包含**文本文件**和**二进制文件**。应用程序要区分它们，内核则不需要。\n- **目录(directory)**：包含一组**链接（link）** 的文件，每个链接都将一个文件名（filename）映射到一个文件。$.$是到该目录自身的链接，$..$是到父目录的链接。\n- **套接字(socket)**：是用来与另一个进程进行跨网络通信的文件。\n\n> 其他还有**命名通道（named pipe）**、**符号链接（symbolic link）**，以及**字符**和**块设备（character and block device）**，不在讨论范畴。\n\n## 10.3打开和关闭文件\n\n进程是通过调用`open`函数来打开一个已存在的文件或者创建一个新文件的：\n\n```c\n#include <sys/types.h> \n#include <sys/stat.h> \n#include <fcntl.h> \nint open(char *filename, int flags, mode_t mode);\n// 成功返回新文件描述符，出错为 -1\n```\n\n`open`函数将`filename`转换为一个文件描述符，并且返回描述符数字。返回的描述符总是在进程中当前没有打开的最小描述符。\n\n`flags`参数指明了进程打算如何访问这个文件：\n\n- `O_RDONLY`：只读。\n- `O_WRONLY`：只写。\n- `O_RDWR`：可读可写。\n- `O_CREAT`：如果文件不存在，就创建它的一个截断的（truncated）（空）文件。\n- `O_TRUNC`：如果文件已经存在，就截断它。\n- `O_APPEND`：在每次写操作前，设置文件位置到文件的结尾处。\n\n`mode`参数指定了新文件的访问权限位。\n\n| 掩码      | 描述                               |\n| --------- | ---------------------------------- |\n| `S_IRUSR` | 使用者（拥有者）能够读这个文件     |\n| `S_IWUSR` | 使用者（拥有者）能够写这个文件     |\n| `S_IXUSR` | 使用者（拥有者）能够执行这个文件   |\n| `S_IRGRP` | 拥有者所在组的成员能够读这个文件   |\n| `S_IWGRP` | 拥有者所在组的成员能够写这个文件   |\n| `S_IXGRP` | 拥有者所在组的成员能够执行这个文件 |\n| `S_IROTH` | 其他人（任何人）能够读这个文件     |\n| `S_IWOTH` | 其他人（任何人）能够写这个文件     |\n| `S_IXOTH` | 其他人（任何人）能够执行这个文件   |\n\n作为上下文的一部分，每个进程都有一个`umas`，`mode`是通过调用`umask`函数来设置的。\n\n例如：\n\n```c\n#define DEF_MODE S_IRUSR|S_IWUSR|S_IRGRP|S_IWGRP|S_IROTH|S_IWOTH \n#define DEF_UMASK S_IWGRP|S_IWOTH \numask(DEF_UMASK); // mode = mode&~umask\nfd = Open("foo.txt", O_CREATIO_TRUNCIO_WRONLY, DEF_MODE); // 权限设置为mode &~ umask\n```\n\n实现文件的拥有者有读写权限，而所有其他的用户都有读权限。\n\n------\n\n最后，进程通过涸用`close`函数关闭一个打开的文件。\n\n```c\n#include <unistd.h>\nint close(int fd);\n```\n\n## 10.4读和写文件\n\n应用程序是通过分别调用`read`和`write`函数来执行输入和输出的。\n\n```c\n#include <unistd.h>\nssize_t read(int fd, void *buf, size_t n);\nssize_t write(int fd, const void *buf, size_t n);\n// 若成功则为读或写的字节数，若出错则为 -1\n```\n\n`read`函数从描述符为`fd`的当前文件位置复制最多`n`个字节到内存位置`buf`。返回0表示`EOF`。否则，返回值表示的是实际传送的字节数量。\n\n`write`函数从内存位置`buf`复制至多`n`个字节到描述符`fd`的当前文件位置。\n\n------\n\n通过调用`lseek`函数，应用程序能够显示地修改当前文件的位置。\n\n------\n\n在某些情况下，`read`和`write`传送的字节比应用程序要求的要少。这些**不足值（short count）** 不表示有错误。出现这样情况的原因有：\n\n- **读时遇到**`EOF`。\n- **从终端读文本行**：如果打开文件是与终端相关联的（如键盘和显示器），那么每个`read`函数将一次传送一个文本行，返回的不足值等于文本行的大小。\n- 读和写**网络套接字（socket）**：对Linux**管道（pipe）** 调用`read`和`write`时，也有可能出现不足值。\n\n实际上，除了`EOF`，**当你在读写磁盘文件时，将不会遇到不足值**。 然而，如果你想创建健壮的诸如Web服务器这样的网络应用，就必须通过反复调用`read`和`write`处理不足值，直到所有需要的字节都传送完毕。\n\n## 10.5用RIO包健壮地读写\n\n### 10.5.1RIO的无缓冲的输入输出函数\n\n> 这些函数直接在内存和文件之间传送数据，没有应用级缓冲。它们对将二进制数据读写到网络和从网络读写二进制数据尤其有用。\n\n通过调用`rio_readn`和`rio_writen`函数，应用程序可以在内存和文件之间直接传送数据。\n\n```c\n#include "csapp.h" \nssize_t rio_readn(int fd, void *usrbuf, size_t n);\nssize_t rio_writen(int fd, void *usrbuf, size_t n);\n// 若成功则为传送的宇节数，若 EOF 则为 0 (只对 rio_readn 而言)，若出错则为 -1\n```\n\n这两个函数实现**描述符fd的当前文件位置**和**内存位置usrbuf**的字节传递。\n\n> 注意，如果`rio_readn`和`rio_writen`函数被一个从应用信号处理程序的返回中断，那么每个函数都会手动地重启`read`或`write`。\n\n### 10.5.2RIO的带缓冲的输入函数\n\n> 这些函数允许你高效地从文件中读取文本行和二进制数据，这些文件的内容缓存在应用级缓冲区内，~~类似于为printf这样的标准I/O函数提供的缓冲区~~。带缓冲的RIO输入函数是线程安全的，即它在同一个描述符上可以被交错地调用。\n\n**包装函数（rio_readlineb）**，它从一个内部**读缓冲区**复制一个文本行，当缓冲区变空时，会自动地调用`read`重新填满缓冲区。\n\n对于既包含文本行也包含二进制数据的文件，我们也提供了一个`rio_readn`带缓冲区的版本，叫做`rio_readnb`，它从和`rio_readlineb`一样的读缓冲区中传送原始字节。\n\n```c\n#include "csapp.h" \n#define RIO_BUFSIZE 4096\ntypedef struct{\n    int rio_fd; // 与缓冲区绑定的文件描述符的编号\n    int rio_cnt; // 缓冲区中还未读取的字节数\n    char *rio_bufptr; // 当前下一个未读取字符的地址\n    char rio_buf[RIO_BUFSIZE];\n}rio_t;\nvoid rio_readinitb(rio_t *rp, int fd);\n// 无返回值,可以将文件描述符与rio数据结构绑定起来\nssize_t rio_readlineb(rio_t *rp, void *usrbuf, size_t maxlen);\nssize_t rio_readnb(rio_t *rp, void *usrbuf, size_t n);\n// 若成功则为读的宇节数,若EOF则为0,若出错则为—1\n```\n\n> 对这些带缓冲的函数的调用不应和无缓冲的`rio_readn`函数交叉使用。\n\n------\n\nRIO读程序的核心是`rio_read`函数。`rio_read`函数是**`read`函数的带缓冲的版本** 。当调用`rio_read`要求读`n`个字节时，读缓冲区内有`rp->rio_cnt`个未读字节。**如果缓冲区为空**，那么会通过调用`read`再填满它。这个`read`调用会收到一个不足值，因为**读缓冲区填充了一部分**。**一旦缓冲区非空**，`rio_read`就从读缓冲区复制`n`和`rp->rio_cnt`中较小值个字节到用户缓冲区，并返回复制的字节数。\n\n欣赏一下：\n\n```c\nstatic ssize_t rio_read(rio_t *rp, char *usrbuf, size_t n) { \n    int cnt; \n    while (rp->rio_cnt <= 0) { /* Refill if buf is empty */\n        rp->rio_cnt = read(rp->rio_fd, rp->rio_buf, sizeof(rp->rio_buf));\n        if (rp->rio_cnt < 0) {\n            if (errno != EINTR) /* Interrupted by sig handler return */\n                return -1; \n        }\n        else if (rp->rio_cnt == 0) /* EOF */\n            return 0;\n        else\n            rp->rio_bufptr = rp->rio_buf; /* Reset buffer ptr */\n    }\n    /* Copy min(n, rp->rio_cnt) bytes from internal buf to user buf */\n    cnt = n;\n    if (rp->rio_cnt < n) cnt = rp->rio_cnt;\n    memcpy(usrbuf, rp->rio_bufptr, cnt);\n    rp->rio_bufptr += cnt;\n    rp->rio_cnt -= cnt;\n    return cnt;\n}\n```\n\n## 10.6读取文件元数据\n\n应用程序能够通过调用`stat`和`fstat`函数，检索到关于文件的信息（文件的**元数据（metadata）**）。\n\n```c\n#include <unistd.h>\n#include <sys/stat.h>\nint stat(const char *filename, struct stat *buf); // 接收文件名\nint fstat(int fd, struct stat *buf); // 接收文件描述符\n// 成功返回 0，出错为 -1\n```\n\n其中`stat`数据结构的定义：\n\n```c\n/* Metadata returned by the stat and fstat functions */\nstruct stat { \n    dev_t st_dev; /* Device */\n    ino_t st_ino; /* inode */\n    mode_t st_mode; /* Protection and file type */\n    /*\n    相关宏谓词:\n    S_ISREG(m) Is simple file.\n    S_ISDIR(m) Is dir file.\n    S_ISSOCK(m) Is web socket.\n    */\n    nlink_t st_nlink; /* Number of hard links*/\n    uid_t st_uid; /* User ID of owner */\n    gid_t st_gid; /* Group ID of owner*/\n    dev_t st_rdev; /* Device type (if inode device)*/\n    off_t st_size; /* Total size, in bytes */\n    unsigned long st_blksize; /* Block size for filesystem I/O */\n    unsigned long st_blocks; /* Number of blocks allocated */\n    time_t st_atime; /* Time of last access */\n    time_t st_mtime; /* Time of last modification */\n    time_t st_ctime; /* Time of last change */\n}; \n```\n\n## 10.7读取目录内容\n\n函数`opendir`以路径名为参数，返回指向**目录流（directory stream）** 的指针。 \n\n应用程序可以用`readdir`系列函数来读取目录的内容。\n\n```c\n#include <sys/types.h> \n#fnclude <dirent.h> \nDIR *opendir(const char *name);\n// 成功则返回处理的指针，否则 NULL\nstruct dirent *readdir(DIR *dirp);\n// 成功，则返回指向下一个目录项的指针；若没有更多的目录项或出错，则为 NULL，并设置 errno\nstruct __dirstream {\n    void *__fd;\n    char *__data;\n    int __entry_data;\n    char *__ptr;\n    int __entry_ptr;\n    size_t __allocation;\n    size_t __size;\n    __libc_lock_define (, __lock)\n};\ntypedef struct __dirstream DIR;\nstruct dirent {\n    ino_t d_ino; /* inode number */\n    char d_name[256]; /* Filename */\n}\n```\n\n------\n\n函数`closedir`关闭流并释放其所有的资源。\n\n```c\n#include <dirent.h> \nint closedir(DIR *dirp); \n// 成功返回 0，错误返回 -1\n```\n\n## 10.8共享文件\n\n内核用三个相关的数据结构来表示打开的文件：\n\n- **描述符表（descriptor table）**：每个进程都有它独立的描述符表，它的表项是由进程打开的文件描述符来索引的。 每个打开的描述符表项指向文件表中的一个表项。\n  \n  **人话：每一项指向文件表中的某个文件。**\n  \n- **文件表（file table）**：打开文件的集合是由一张文件表来表示的，所有的进程共享这张表。\n  \n  表项组成包括：\n  \n  - **当前的文件位置**。\n  - **引用计数（reference count），即当前指向该表项的描述符表项数**。\n  - **一个指向**`v-node`**表中对应表项的指针**：关闭一个描述符会减少相应的文件表表项中的引用计数。 内核不会删除这个文件表表项，直到它的引用计数为零。\n  \n- **v-node 表（v-node table）**：同文件表一样，所有的进程共享这张`v-node`表。每个表项包含`stat`结构中的大多数信息，包括`st_mode`和`st_size`成员。\n\n![image-20250517181914154](./pictures/image-20250517181914154.png)\n\n下面的图解释了父子进程是如何共享文件的。\n\n![image-20250517182631961](./pictures/image-20250517182631961.png)\n\n## 10.9I/O重定向\n\n```bash\nlinux> ls > foo.txt\n```\n\n实现了将标准输出重定向到磁盘文件`foo.txt`。\n\n------\n\n`dup2`函数复制描述符表表项`oldfd`到描述符表表项`newfd`，覆盖描述符表表项`new fd`以前的内容。如果`newfd`已经打开了，`dup2`会在复制`oldfd`之前关闭`newfd`。\n\n```c\n#include <unistd.h>\nint dup2(int oldfd, int newfd);\n// 若成功则返回非负的描述符，若出错则为 -1\n```\n\n例如在图`10-12`基础上调用`dup2(4,1)`，就会得到。\n\n![image-20250517183134714](./pictures/image-20250517183134714.png)\n\n## 10.10标准I/O\n\n~~高程A里的东西~~。' 
                      }
                  ]
                },
                { id: 'computer_organization_and_architecture', title: '计算机组成与体系结构A', icon: 'fas fa-question', desc: '<p>请输入文本。</p>',
                  chapters: [
                      { id: 'computer_organization_and_architecture-1', 
                        title: '1、计算机抽象及相关技术', 
                        desc: '', 
                        content: '# 1.计算机抽象及相关技术 \n\n## 1.2计算机体系结构中的8个伟大思想\n\n### 1.2.1摩尔定律\n\n**单芯片上所集成的晶体管资源每18-24个月翻一番**。\n\n> 计算机架构师必须预测其设计完成时的工艺水平而不是设计开始时的工艺水平。\n\n### 1.2.2抽象\n\n**隐藏低层细节以提供给高层一个更简单的模型**以提高硬件和软件生产率。\n\n### 1.2.3加速经常性事件\n\n加速经常性事件远比优化罕见情形能够更好地优化性能。\n\n### 1.2.4通过并行提高性能\n\n### 1.2.5通过流水线提高性能\n\n### 1.2.6通过预测提高性能\n\n### 1.2.7存储层次\n\n在存储层次中，速度最快、容量最小并且每位价格最昂贵的存储器处于顶层，而速度最慢容量最大旦每位价格最便宜的存储器处于底层。\n\n### 1.2.8通过冗余提高可靠性\n\n冗余组件在系统发生故障时替代失效组件并帮助检测故障。\n\n## 1.3程序表象之下\n\n**系统软件**：操作系统和编译器。\n\n**高级程序语言**$\\stackrel{编译器}\\rightarrow$**汇编语言**$\\stackrel{汇编器}\\rightarrow$**机器语言**。\n\n## 1.4箱盖后的硬件\n\n> 组成计算机的五个经典部件是**输入、输出、存储器、数据通路（在计算机中也称运算器）和控制器**，其中后两个部件通常合称为处理器。\n\n### 1.4.1显示器\n\n计算机硬件采用**光栅刷新缓冲区（又称为帧缓冲区）** 来保存位图以支持图像。要显示的图像保存在帧缓冲区中，每个像素的二进制值以刷新频率读出到显示设备。\n\n### 1.4.2触摸屏\n\n### 1.4.3打开机箱\n\n- **集成电路**（**芯片**）：一种集成了几十个至上亿个晶体管的设备。\n- **中央处理单元**（**CPU**)：包括**数据通路**和**控制器**。\n- **数据通路**：负责完成算术运算。\n- **控制器**：负责指导数据通路、存储器和I/O设备按照程序的指令正确执行。\n- **内存**：程序运行时的存储空间，同时还存储程序运行时所需的数据。\n- **DRAM**：动态随机访问存储器。\n- **SRAM**：静态随机访问存储器。\n- **高速缓存**：一种小而快的存储器，作为大而慢的存储器的缓冲。\n- **计算机指令系统体系结构**：低层次软件和硬件之间的抽象接口，包含了需要编写正确运行的机器语言程序所需要的全部信息，包括指令、寄存器、存储器访问和I/O等。\n- **应用二进制接口**：用户部分的指令加上应用程序员调用的操作系统接口，定义了二进制层次可移植的计算机的标准。\n\n### 1.4.4数据安全\n\n- **易失性存储**（主存）：类似**DRAM**，仅在加电时保存数据。\n- **非易失性存储**（辅存）：掉电时仍可保持数据的存储器。\n- **闪存**（flash memory）：个人移动设备中替代了**磁盘**。非易失性，比**DRAM**慢，更便宜，每位价格高于磁盘，在体积、电容、可靠性和能耗方面都更优。多次写入后可能老化或损坏。\n\n### 1.4.5与其他计算机通信\n\n**以太网**：最为普遍的网络类型，它连接计算机形成了**局域网**，局域网通过交换机进行连接，形成**广域网**。\n\n## 1.5处理器和存储制造技术\n\n| 年份 | 采用技术         | 相对性价比   |\n| ---- | ---------------- | ------------ |\n| 1951 | 真空管           | 1            |\n| 1965 | 晶体管           | 35           |\n| 1975 | 集成电路         | 900          |\n| 1995 | 超大规模集成电路 | 2400000      |\n| 2013 | 甚大规模集成电路 | 250000000000 |\n\n**晶体管**：一种受电流控制的开关。\n\n**集成电路**：由成千上万个晶体管组成的芯片。\n\n## 1.6性能\n\n### 1.6.1性能的定义\n\n**响应时间（执行时间）**：从开始一个任务到该任务完成的时间。\n\n**吞吐率（带宽）**：在给定时间内完成的任务数。\n\n对于某个计算机$X$：\n\n$$性能_X=\\frac{1}{执行时间_X}$$\n\n### 1.6.2性能的度量\n\n**挂钟时间（响应时间、运行时间）**：完成某项任务所需的总时间。\n\n**CPU执行时间（CPU时间）**：执行某一任务在CPU上所花费的时间。\n\n**用户CPU时间**：程序本身所花费的CPU时间。\n\n**系统CPU时间**：为执行程序而花费在操作系统上的时间。\n\n$$CPU执行时间=用户CPU时间+系统CPU时间。$$\n\n我们将使用**系统性能**表示空载系统的响应时间，**CPU性能**表示用户CPU时间。\n\n**时钟周期数**：离散时间间隔。\n\n**时钟周期**：一段时间。\n\n**时钟频率**：时钟周期的倒数。\n\n### 1.6.3CPU性能及其度量因素。\n\n$$程序的CPU执行时间=程序的CPU时钟周期数\\times 时钟周期长度$$\n$$程序的CPU执行时间=\\frac{程序的CPU时钟周期数}{时钟频率}$$\n\n### 1.6.4指令性能\n\n**指令平均时钟周期数（CPI）**：执行每条指令所需的时钟周期平均数。它与计算机各种设计细节密切相关，对于不同应用程序、指令系统是不同的。\n\n**每秒百万条指令数（MIPS）**：$$MIPS=\\frac{指令数}{执行时间\\times 10^6}$$\n\n$$CPU时钟周期数=程序的指令数\\times 指令平均时钟周期数$$\n### 1.6.5经典的CPU性能公式\n\n**指令数**：程序执行所需要的指令总数。\n\n**指令分布**：在程序中对指令的动态使用频度的评价指标。\n\n$$CPU时间=指令数\\times CPI\\times时钟周期长度$$\n$$CPU时间=\\frac{指令数\\times CPI}{时钟频率}$$\n$$CPI=\\frac{CPU时钟周期数}{指令数}$$\n## 1.7甄误\n\n**在改进计算机的某个方面时期望总性能的提高与改进大小成正比**。\n\n基于**Amdahl定律**：\n\n$$\n改进后的执行时间=\\frac{受改进影响的执行时间}{改进量}+不受影响的执行时间\n$$\n\n------\n\n**低利用率的计算机具有更低功耗**。\n\n由于服务器的工作负载时变化的，所以低利用率情况下的功率很重要。\n\n------\n\n**面向性能的设计和面向能效的设计具有不相关的目标**。\n\n------\n\n**用性能公式的一个子集去度量性能**。' 
                      },
                      { id: 'computer_organization_and_architecture-2', 
                        title: '2、指令：计算机的语言', 
                        desc: '', 
                        content: '# 2.指令:计算机的语言\n\n我们介绍$\\mathbf{RISC-V}$。\n\n## 2.1引言\n\n**存储程序概念**：指令与多种类型的数据不加区别地存储在存储器中并因此易于更改，因此产生了存储程序计算机。\n\n**RISC-V操作数**\n\n| 名字         | 示例                                                  | 注解                                                         |\n| ------------ | ----------------------------------------------------- | ------------------------------------------------------------ |\n| $32$个寄存器 | $x_0\\sim x_{31}$                                      | 快速定位数据。在RISC-V中，只对在寄存器中的数据执行算术运算   |\n| 存储器       | $\\mathrm{Memory[0],...,Memory[18446744073709551608]}$ | 只能被数据传输指令访问。RISC-V使用字节寻址，因此顺序双字访问相差8。存储器保存数据结构、数组和换出的寄存器的内容 |\n\n**RISC-V汇编语言**\n\n| 类别           | 指令                   | 示例                | 含义                      | 注解                                                     |\n| -------------- | ---------------------- | ------------------- | ------------------------- | -------------------------------------------------------- |\n| **算术运算**   | 加                     | `add x5, x6, x7`    | `x5=x6+x7`                | 三寄存器操作数：加                                       |\n|                | 减                     | `sub x5, x6, x7`    | `x5=x6-x7`                | 三寄存器操作数：减                                       |\n|                | 立即数加               | `addi x5, x6, 20`   | `x5=x6+20`                | 用于加常数                                               |\n| **数据传输**   | 取双字                 | `ld x5, 40(x6)`     | `x5=Memory[x6+40]`        | 从存储器取双字到寄存器                                   |\n|                | 存双字                 | `sd x5, 40(x6)`     | `Memory[x6+40]=x5`        | 从寄存器存双字到存储器                                   |\n|                | 取字                   | `lw x5, 40(x6)`     | `x5=Memory[x6+40]`        | 从存储器取字到寄存器                                     |\n|                | 取字(无符号)           | `lwu x5, 40(x6)`    | `x5=Memory[x6+40]`        | 从存储器取无符号字到寄存器                               |\n|                | 存字                   | `sw x5, 40(x6)`     | `Memory[x6+40]=x5`        | 从寄存器存字到存储器                                     |\n|                | 取半字                 | `lh x5, 40(x6)`     | `x5=Memory[x6+40]`        | 从存储器取半字到寄存器                                   |\n|                | 取半字(无符号)         | `lhu x5, 40(x6)`    | `x5=Memory[x6+40]`        | 从存储器取无符号半字到寄存器                             |\n|                | 存半字                 | `sh x5, 40(x6)`     | `Memory[x6+40]=x5`        | 从寄存器存半字到存储器                                   |\n|                | 取字节                 | `lb x5, 40(x6)`     | `x5=Memory[x6+40]`        | 从存储器取字节到寄存器                                   |\n|                | 取字节(无符号)         | `lbu x5, 40(x6)`    | `Memory[x6+40]=x5`        | 从寄存器存字节到存储器                                   |\n|                | 存字节                 | `sb x5, 40(x6)`     | `Memory[x6+40]=x5`        | 从寄存器存字节到存储器                                   |\n|                | 取保留字               | `lr.d x5, (x6)`     | `x5=Memory[x6]`           | 取；原子交换的前半部分                                   |\n|                | 存条件字               | `sc.d x7, x5, (x6)` | `Memory[x6]=x5;x7=0/1`    | 存；原子交换的后半部分                                   |\n|                | 取立即数高位           | `lui x5, 0x12345`   | `x5=0x12345000`           | 取左移12位后的20位立即数                                 |\n| **逻辑运算**   | 与                     | `and x5, x6, x7`    | `x5=x6&x7`                | 三寄存器操作数：按位与                                   |\n|                | 或                     | `or x5, x6, x8`     | `x5=x6|x8`                | 三寄存器操作数：按位或                                   |\n|                | 异或                   | `xor x5, x6, x9`    | `x5=x6^x9`                | 三寄存器操作数：按位异或                                 |\n|                | 与立即数               | `andi x5, x6, 20`   | `x5=x6&20`                | 寄存器与常数按位与                                       |\n|                | 或立即数               | `ori x5, x6, 20`    | `x5=x6|20`                | 寄存器与常数按位或                                       |\n|                | 异或立即数             | `xori x5, x6, 20`   | `x5=x6^20`                | 寄存器与常数按位异或                                     |\n| **移位操作**   | 逻辑左移               | `sll x5, x6, x7`    | `x5=x6<<x7`               | 按寄存器给定位数左移                                     |\n|                | 逻辑右移               | `srl x5, x6, x7`    | `x5=x6>>>x7`              | 按寄存器给定位数右移                                     |\n|                | 算术右移               | `sra x5, x6, x7`    | `x5=x6>>x7`               | 按寄存器给定位数算术右移                                 |\n|                | 逻辑左移立即数         | `slli x5, x6, 3`    | `x5=x6<<3`                | 根据立即数给定位数左移                                   |\n|                | 逻辑右移立即数         | `srli x5, x6, 3`    | `x5=x6>>>3`               | 根据立即数给定位数右移                                   |\n|                | 算术右移立即数         | `srai x5, x6, 3`    | `x5=x6>>3`                | 根据立即数给定位数算术右移                               |\n| **条件分支**   | 相等即跳转             | `beq x5, x6, 100`   | `if(x5==x6) go to PC+100` | 若寄存器数值相等则跳转到PC相对地址                       |\n|                | 不等即跳转             | `bne x5, x6, 100`   | `if(x5!=x6) go to PC+100` | 若寄存器数值不等则跳转到PC相对地址                       |\n|                | 小于即跳转             | `blt x5, x6, 100`   | `if(x5<x6) go to PC+100`  | 若寄存器数值比较结果小于则跳转到PC相对地址               |\n|                | 大于等于即跳转         | `bge x5, x6, 100`   | `if(x5>=x6) go to PC+100` | 若寄存器数值比较结果大于或等于则跳转到PC相对地址         |\n|                | 小于即跳转(无符号)     | `bltu x5, x6, 100`  | `if(x5<x6) go to PC+100`  | 若寄存器数值比较结果小于则跳转到PC相对地址(无符号)       |\n|                | 大于等于即跳转(无符号) | `bgeu x5, x6, 100`  | `if(x5>=x6) go to PC+100` | 若寄存器数值比较结果大于或等于则跳转到PC相对地址(无符号) |\n| **无条件跳转** | 跳转-链接              | `jal x1, 100`       | `x1=PC+4; go to PC+100`   | 用于PC相关的过程调用                                     |\n|                | 跳转-链接(寄存器地址)  | `jalr x1, 100(x5)`  | `x1=PC+4; go to x5+100`   | 用于过程返回；非直接调用                                 |\n\n## 2.2计算机硬件的操作\n\n**设计原则1：简单源于规整**：操作数不可变。\n\n## 2.3计算机硬件的操作数\n\n**字**：访问基本单位，32位一组。\n\n**双字**：访问基本单位，64位一组，对应RISC-V中寄存器大小。\n\n**设计原则2：更少则更快**：数量过多的寄存器可能会增加时钟周期，因为电信号传输的距离越远，所花费的时间就越长。\n\n### 2.3.1存储器操作数\n\n算术运算操作只作用于寄存器，而**数据传输指令**用于内存和寄存器之间传输数据。\n\n**基址寄存器**：存放基址的寄存器。\n\n**结构内存分配**：编译器会将数组和结构体这样的数据结构分配到内存中的相应位置，将正确的起始地址放入数据传输指令中。\n\n> RISC-V是小端寻址。\n\n**对齐限制**：数据在内存中要与自然边界对齐的要求，字和双字的起始地址必须分别是4和8的倍数。但是在**RISC-V**没有对齐限制。\n\n**寄存器换出**：编译器会尽量把最常用的变量存放在寄存器中，剩下的存放在内存中。\n\n### 2.3.2常数或立即数操作数\n\n**x0寄存器硬连线到常数0**。\n\n> 尽管RISC-V寄存器为64位宽，但作者仍构思了ISA的多种变体：RV32变体就是32位宽，成本较低。\n\n## 2.4有符号数与无符号数\n\n**原码**：最高位为符号位的数据表示方法，例如$10000010$表示$-2$。\n\n**补码**：一种美妙的有符号数表示方法，使得有符号数的计算可以直接进行。对于补码表示的负数$z$，其值为$z$各位取反再加$1$的相反数，例如$11111100$表示$-4$。\n\n**符号扩展**：用符号位填充扩展的位。\n\n## 2.5计算机中的指令表示\n\n**指令格式**：一条汇编指令通常会被$Assembler$转化为机器指令，这个指令可以被CPU直接读取。在RISC-V中，机器指令都是32位长。\n\n**机器语言**：为了区分汇编语言，我们将指令的数字表示为**机器语言**，这样的指令序列叫作**机器码**。\n\n下面我们具体地介绍**RISC-V字段**：\n\n**R型**：\n\n| funct7 | rs2  | rs1  | funct3 | rd   | opcode |\n| ------ | ---- | ---- | ------ | ---- | ------ |\n| 7位    | 5位  | 5位  | 3位    | 5位  | 7位    |\n\n- **funct7**：一个另外的操作码字段。\n- **rs2**：第二个源操作数寄存器。\n- **rs1**：第一个源操作数寄存器。\n- **funct3**：一个另外的操作码字段。\n- **rd**：目的操作数寄存器，用来存放操作结果。\n- **opcode（操作码）**：指令的基本操作，这个缩写是它的惯用名称。\n\n**I型**：\n\n| immediate | rs1  | funct3 | rd   | opcode |\n| --------- | ---- | ------ | ---- | ------ |\n| 12位      | 5位  | 3位    | 5位  | 7位    |\n\n- **immediate**：补码值。\n\n**S型**：\n\n| immediate[11:5] | rs2  | rs1  | funct3 | immediate[4:0] | opcode |\n| --------------- | ---- | ---- | ------ | -------------- | ------ |\n| 7位             | 5位  | 5位  | 3位    | 5位            | 7位    |\n\n- 把**immediate**拆成了两部分，使得**rs**字段在相同的位置，降低硬件的复杂性。\n\n**设计原则3：优秀的设计需要适当的折中**：设计人员保持所有的指令长度相同，对于不同的指令使用不同的指令格式。\n\n## 2.6逻辑操作\n\n**移位指令使用I型格式**。因为不适用于对64位寄存器移动大于63位，所以**shamt**只有低6位被使用，高6位被用作额外的操作码字段。\n\n| fcunt7 | shamt | rs1  | funct3 | rd   | opcode |\n| ------ | ----- | ---- | ------ | ---- | ------ |\n| 7位    | 5位   | 5位  | 3位    | 5位  | 7位    |\n\n> 按位取反是只有一个操作数的指令，为了保持三操作数的格式，决定用异或$-1$来实现按位取反。\n\n## 2.7用于决策的指令\n\n**条件分支指令**：一条指令，先检测一个值，然后根据检测结果允许后续控制流转移到程序中的一个新地址。`beq`代表**相等则分支**，`bne`代表**不等则分支**。这样带有判断和分支的指令通常称作**条件分支**指令。\n\n> 编译器经常产生分支和标签，它们不出现在编程语言中。\n\n### 2.7.1循环\n\n**基本块**：一个没有分支的指令序列（除了可能在结尾处），同时没有分支目标或分支标签（除了可能在起始处）。编译的基础工作之一就是将程序划分为基本块。\n\n> ARM指令系统通常保留额外的位来记录指令执行期间发生的情况，这些额外的位称为**条件代码**或**标志位**。就像我们学习过的X86一样。\n\n### 2.7.2边界检查的简便方法\n\n我们要求下标是$0$到$n$之间的整数。显然可以通过无符号比较的方法完成这个边界检查。\n\n### 2.7.3case/switch语句\n\n**分支地址表（分支表）**：一种包含了不同指令序列地址的表，相当于一个双字数组，包含与代码中标签对应的地址。\n\nRISC-V中跳转-链接指令（`jalr`）可以对寄存器中指定的地址执行无条件跳转。\n\n## 2.8计算机硬件对过程的支持\n\n**过程**：一个根据给定参数执行特定任务的已存储的子程序，相当于函数。\n\n**跳转-链接指令**：跳转到某个地址的同时将下一条指令的地址保存在寄存器。（RISC-V中通常是`x1`中的指令）。\n\n在执行过程时，通常有以下步骤：\n\n1. 将参数放在过程可以访问到的位置。\n2. 将控制转交给过程。\n3. 获取过程所需的存储资源。\n4. 执行所需的任务。\n5. 将结果值放在调用程序可以访问到的位置。\n6. 将控制返回到初始点，因为过程可以从程序中的多个点调用。\n\nRISC-V为过程调用分配寄存器有如下约定：\n\n- `x10`~ `x17`：八个参数寄存器，用于传递参数或返回值。\n- `x1`：一个返回地址寄存器，用于返回到起始点。\n\n**跳转-链接指令（`jal`）**：跳转并将返回地址写入`x1`。\n\n**程序计数器（PC）**：用来保存当前执行指令的地址。\n\n### 2.8.1使用更多的寄存器\n\n**栈**：被用于寄存器换出。\n\n**栈指针**：`x2`，也叫做`sp`。\n\n通常是向低地址**压栈**，向高地址**弹栈**。\n\n于是又引出更多寄存器的规定：\n\n- `x5`~ `x7`和`x28`~ `x31`：临时寄存器，在过程调用中不被被调用者保存。\n- `x8`~ `x9`和`x18`~ `x27`：保存寄存器，在过程调用中必须被保存。（一旦使用，由被调用者保存并恢复）。\n\n### 2.8.2嵌套过程\n\n**函数调用**：\n\n1. 调用者将所有调用后还需要的参数寄存器（`x10`~ `x17`）或临时寄存器（`x5`~ `x7`和`x28`~ `x31`）压栈。\n2. 被调用者将返回地址寄存器`x1`和被调用者使用的保存寄存器（`x8`~ `x9`和`x18`~ `x27`）压栈。\n3. 调整栈指针`sp`以计算压栈寄存器的数量。返回时，从存储器中恢复寄存器并重新调整栈指针。\n\n| 保存                               | 不保存                            |\n| ---------------------------------- | --------------------------------- |\n| 保存寄存器：`x8`~ `x9`，`x18`~ `x27` | 临时寄存器:`x5`~ `x7`，`x28`~ `x31` |\n| 栈指针寄存器：`x2(sp)`             | 参数/结果寄存器：`x10`~ `x17`      |\n| 帧指针：`x8(fp)`                   |                                   |\n| 返回地址：`x1(ra)`                 |                                   |\n| 栈指针以上的栈                     | 栈指针以下的栈                    |\n\n### 2.8.3在栈中为新数据分配空间\n\n**过程帧（活动记录）**：栈中包含过程保存的寄存器和局部变量的段。\n\n**帧指针**：指向给定过程的局部变量和保存的寄存器地址的值。\n\n**过程调用之中**：帧指针（`fp`或`x8`）指向帧的第一个双字，通常是**保存的参数寄存器**，栈指针（`sp`）指向栈顶，调整栈以容纳所有**保存的寄存器**和**常驻存储器的局部变量**。\n\n如果在过程中栈内没有局部变量，编译器将不设置和不恢复帧指针以节省时间。\n\n当使用帧指针时，在调用中使用`sp`的地址进行初始化，且可以使用`fp`恢复`sp`。\n\n### 2.8.4在堆中为新数据分配空间\n\n**代码段**：UNIX目标文件的段，包含源文件中例程的机器语言代码。\n\n**静态数据段**：用于存放常量和其他静态变量的段。\n\n**堆**：存放数组和链表这类的数据结构的段。\n\n堆和栈在动态数据段相向而长。\n\n以下是寄存器约定，这个约定是**加速经常性事件**的另一个例子：\n\n| 名称        | 寄存器号 | 用途                   | 调用时是否保存 |\n| ----------- | -------- | ---------------------- | -------------- |\n| `x0`        | 0        | 常数0                  | 不适用         |\n| `x1(ra)`    | 1        | 返回赋值（链接寄存器） | 是             |\n| `x2(sp)`    | 2        | 栈指针                 | 是             |\n| `x3(gp)`    | 3        | 全局指针               | 是             |\n| `x4(tp)`    | 4        | 线程指针               | 是             |\n| `x5`~ `x7`   | 5~7      | 临时                   | 否             |\n| `x8`~ `x9`   | 8~9      | 保存                   | 是             |\n| `x10`~ `x17` | 10~17    | 参数/结果              | 否             |\n| `x18`~ `x27` | 18~27    | 保存                   | 是             |\n| `x28`~ `x31` | 28~31    | 临时                   | 否             |\n\n## 2.9人机交互\n\n**加载无符号字节(lbu)** 指令从内存加载一个字节，将其放在寄存器的最右边8位。\n\n**存储字节(sb)** 指令从寄存器的最右边8位取一个字节，并将其写入内存。\n\n**加载无符号半字(lhu)** 指令从内存中读取一个半字，将它放在寄存器的最右边16位，用零填充最左边的48位。\n\n**存储半字(sh)** 指令从寄存器的最右边16位取半字并将其写入内存。\n\n## 2.10对大立即数的RISC-V编址和寻址\n\n### 2.10.1大立即数\n\n**取立即数高位(lui)** 指令用于将20位常数加载到寄存器的第31位到第12位。将第31位的值复制填充到最左边32位，最右边的12位用0填充。\n\n> **lui**使用新的指令格式-U型。\n\n| immediate | rd   | opcode |\n| --------- | ---- | ------ |\n| 20位      | 5位  | 7位    |\n\n\n\n### 2.10.2分支中的寻址\n\n**SB型**：这种格式可以表示从-4096到4094的偶数分支地址。\n\n> 地址必须是偶数地址，这是因为RISC-V的地址是两字节对齐的（就像结构体中`short`类型对齐地址一样）。\n\n| imm[12] | imm[10:5] | rs2  | rs1  | funct3 | imm[4:1] | imm[11] | opcode |\n| ------- | --------- | ---- | ---- | ------ | -------- | ------- | ------ |\n| 1位     | 6位       | 5位  | 5位  | 3位    | 4位      | 1位     | 7位    |\n\n**UJ型**：只有**无条件跳转-链接(jal)** 指令使用这种格式，同样只能跳转到偶数分支地址。\n\n| imm[20] | imm[10:1] | imm[11] | imm[19:12] | rd   | opcode |\n| ------- | --------- | ------- | ---------- | ---- | ------ |\n| 1位     | 10位      | 1位     | 8位        | 5位  | 7位    |\n\n**UJ型**寻址最多可以寻址到$2^{20}$，这是远远不够的。为此我们引入**PC相对寻址**。\n\n**PC相对寻址**：一种寻址方式，它的地址是**PC**和指令中的常量之和。\n\nRISC-V允许使用**双指令序列**来非常长距离地跳转到任何32位地址：\n\n`lui`将地址的第12位至第31位写入临时寄存器，`jalr`将地址的低12位加到临时寄存器并跳转到目标位置。\n\n### 2.10.3RISC-V寻址模式总结\n\n1. **立即数寻址**：\n\n   **I型指令**\n\n   操作数是指令本身的常量。\n\n2. **寄存器寻址**：\n\n   **R型指令**\n\n   操作数在寄存器中。\n\n3. **基址寻址**：\n\n   **I型指令**\n\n   操作数于内存中，其地址是寄存器和指令中的常量之和。\n\n4. **PC相对寻址**\n\n   **S型指令**\n\n   分支地址是PC和指令中常量之和。\n\n### 2.10.4机器语言译码\n\n以下是指令格式。\n\n| 类型 | 字段            |                |              |              |               |        | 备注            |\n| ---- | --------------- | -------------- | ------------ | ------------ | ------------- | ------ | --------------- |\n|      | 7位             | 5位            | 5位          | 3位          | 5位           | 7位    |                 |\n| R型  | funct7          | rs2            | rs1          | funct3       | rd            | opcode | 算术指令格式    |\n| I型  | immediate[11:5] | immediate[4:0] | rs1          | funct3       | rd            | opcode | 加载&立即数算术 |\n| S型  | immed[11:5]     | rs2            | rs1          | funct3       | immed[4:0]    | opcode | 存储            |\n| SB型 | immed[12,10:5]  | rs2            | rs1          | funct3       | immed[4:1,11] | opcode | 条件分支格式    |\n| UJ型 | immed[20,10:5]  | immed[4:1,11]  | immed[19:15] | immed[14:12] | rd            | opcode | 无条件跳转      |\n| U型  | immed[19:13]    | immed[12:8]    | immed[7:3]   | immed[2:0]   | rd            | opcode | 大立即数格式    |\n\n以下是汇编语言与机器语言的对译。\n\n| 类型 | 指令 | opcode  | funct3 | funct7  |\n| ---- | ---- | ------- | ------ | ------- |\n| R型  | add  | 0110011 | 000    | 0000000 |\n|      | sub  | 0110011 | 000    | 0100000 |\n|      | sll  | 0110011 | 001    | 0000000 |\n|      | xor  | 0110011 | 100    | 0000000 |\n|      | srl  | 0110011 | 101    | 0000000 |\n|      | sra  | 0110011 | 101    | 0100000 |\n|      | or   | 0110011 | 110    | 0000000 |\n|      | and  | 0110011 | 111    | 0000000 |\n|      | lr.d | 0110011 | 011    | 0001000 |\n|      | sc.d | 0110011 | 011    | 0001100 |\n| I型  | lb   | 0000011 | 000    | n.a.    |\n|      | lh   | 0000011 | 001    | n.a.    |\n|      | lw   | 0000011 | 010    | n.a.    |\n|      | ld   | 0000011 | 011    | n.a.    |\n|      | lbu  | 0000011 | 100    | n.a.    |\n|      | lhu  | 0000011 | 101    | n.a.    |\n|      | lwu  | 0000011 | 110    | n.a.    |\n|      | addi | 0010011 | 000    | n.a.    |\n|      | slli | 0010011 | 001    | 0000000 |\n|      | xori | 0010011 | 100    | n.a.    |\n|      | srli | 0010011 | 101    | 0000000 |\n|      | srai | 0010011 | 101    | 0100000 |\n|      | ori  | 0010011 | 110    | n.a.    |\n|      | andi | 0010011 | 111    | n.a.    |\n|      | jalr | 1100111 | 000    | n.a.    |\n| S型  | sb   | 0100011 | 000    | n.a.    |\n|      | sh   | 0100011 | 001    | n.a.    |\n|      | sw   | 0100011 | 010    | n.a.    |\n|      | sd   | 0100011 | 011    | n.a.    |\n| SB型 | beq  | 1100011 | 000    | n.a.    |\n|      | bne  | 1100011 | 001    | n.a.    |\n|      | blt  | 1100011 | 100    | n.a.    |\n|      | bge  | 1100011 | 101    | n.a.    |\n|      | bltu | 1100011 | 110    | n.a.    |\n|      | bgeu | 1100011 | 111    | n.a.    |\n| U型  | lui  | 0110111 | n.a.   | n.a.    |\n| UJ型 | jal  | 1101111 | n.a.   | n.a.    |\n\n## 2.11指令与并行性：同步\n\n**数据竞争**：如果来自两个不同的线程的访存请求访问同一个位置，至少有一个是写，且连续出现，那么这两次存储访问形成了数据竞争。\n\n**硬件原语**：指的是由硬件直接支持的一类**最小且不可分割的操作**，它们可以在多处理器或多线程环境下保证执行过程不会被打断。\n\n**LR/SC**：RISC-V使用**保留加载双字（lr.d）**的特殊加载指令和**条件存储双字（sc.d）**的特殊存储指令。如果**lr**指令指定的内存位置的内容在**sc**指令执行到同一地址之前发生了变化，则**sc**指令失败且不会将值写入内存。\n\n**sc指令**：将（可能是不同的）寄存器的值存储在内存中，如果成功则将另一个寄存器的值更改为0，如果失败则更改为非零值。\n\n因此，**sc.d**指定了三个寄存器：第一个用于指示原子操作失败或成功，第二个用于保存地址，第三个用于如果成功则将值存储在内存中。\n\n看下面这个示例：\n\n```\nagain: lr.w x10,(x20)\n       sc.w x11,x23,(x20)\n       bne  x11,x0,again\n		addi x23,x10,0\n```\n\n执行`lr.w`的时候硬件会对该地址注册一个保留标记，`x10`读取地址内容。\n\n执行`sc.w`的时候会检测是否有保留标记，如果有则赋`x11`为0，并把`x23`存入地址，否则赋为1，取消赋值操作。\n\n若`x11`为1，说明`(x20)`地址的内容被更改，可能与`x10`当初读到的不一样，确保`x10`足够新，重新读一遍。\n\n直到`x11`为0，后续`addi`指令完成交换。\n\n且看加锁的示例：\n\n```\naddi x7,x0,1\nloop: lr.w x8,(x10)\n      bne  x8,x0,loop\n      sc.w x9,x7,(x10)\n      bne  x9,x0,loop\n```\n\n锁通常是一个内存变量，若为1，说明锁正在被占用，这里`x10`指向这个内存空间。\n\n执行`lr.w`的时候程序试图获得锁，若`x8`为1，说明锁正在被占用，重新申请锁。\n\n执行`sc.w`的时候程序申请锁成功，得尽快把锁赋为1，若这个步骤成功了（也就是申请锁到`sc.w`之间没有别的进程申请锁），则进程才算真的获得了锁，否则进程要回去重新申请锁。\n\n## 2.12翻译并启动程序\n\n### 2.12.1编译器（Compiler）\n\n编译器将C程序转换为机器能理解的符号形式**汇编语言程序**。\n\n当今的优化编译器生成的汇编语言程序很优越，有时候甚至优于人工优化。\n\n### 2.12.2汇编器（Assembler）\n\n**伪指令**：汇编指令的一种常见变体，可以把它看作汇编语言指令。在RISC-V中是汇编器提供的真指令的简化写法。\n\n例如伪指令`li x1, imm`，不同的`imm`可能会采取不同的真指令写法。\n\n**符号表**：用于匹配标签名和指令所在内存的地址的表。\n\n汇编器会跟踪分支中使用的标签和符号表中的数据传输指令。\n\n**UNIX系统的目标文件通常包含**：\n\n- **目标文件头**，描述了目标文件的其他部分的大小和位置。\n- **代码段**，包含机器语言代码。\n- **静态数据段**，包含在程序生命周期内分配的数据（UNIX允许程序使用静态数据，它在整个程序中都存在；也允许使用动态数据，它可以根据程序的需要增长或缩小。）\n- **重定位信息**，标记了在程序加载到内存时依赖于绝对地址的指令和数据。\n- **符号表**，包含剩余的未定义的标签，例如外部引用。\n- **调试信息**，包含有关如何编译目标模块的简明描述，以便调试器可以将机器指令与源文件相关联并使数据结构可读。\n\n### 2.12.3链接器（Linker）\n\n**链接器**：也叫链接编辑器，是一个系统程序，它将独立汇编的机器语言程序组合起来，并解析所有未定义的标签，最终生成可执行文件。\n\n链接器的工作有三个步骤：\n\n1. 将代码和数据模块按符号特征放入内存。在放入内存之后必须重定位所有模块的绝对引用。\n2. 决定数据和指令标签的地址。\n3. 修正内部和外部引用。\n\n链接器生成可在计算机上运行的**可执行文件**，它不包含任何未解析的引用。\n\n### 2.12.4加载器（Loader）\n\n1. 读取可执行文件首部以确定正文段和数据段的大小。\n2. 为正文和数据创建足够大的地址空间。\n3. 将可执行文件中的指令和数据复制到内存中。\n4. 将主程序的参数（如果有）复制到栈顶，\n5. 初始化处理器寄存器并将栈指针指向第一个空闲位置。\n6. 跳转到启动例程，将参数复制到参数寄存器中并调用程序的主例程。当主例程返回时，启动例程通过exit系统调用终止程序。\n\n**加载器**：将目标程序放在主存中以准备执行的系统程序。\n\n### 2.12.5动态链接库\n\n**动态链接库**：在执行期间链接到程序的库例程。\n\n1. 第一次调用库例程时，程序调用虚入口并执行**间接跳转**。\n2. 这个跳转指向一段代码，它将一个数字放入寄存器来识别所需的库例程。\n3. 跳转到**动态链接器/加载器**，**动态链接器/加载器**找到所需的例程，重新映射它，并更改间接跳转位置中的地址以指向该例程。\n4. 跳转到该例程。此后调用该库例程都会直接跳转到该例程。\n\n### 2.12.6启动Java程序\n\n**Java字节码**：为解释Java程序而设计的指令系统中的指令。\n\nJava代码首先被编译成**Java字节码指令系统**，没有进行任何优化。\n\n**解释器（Interpreter）**：一个模拟指令系统体系结构的程序。逐行读取源代码，解析并立即执行，而无需事先将代码转换为机器码。\n\n**即时编译器（JIT）**：该类编译器在运行时将已解释过的代码段翻译为宿主机上的机器语言。\n\n> Java的转换层次结构：Java程序首先被编译成Java字节码的二进制版本，所有地址都由编译器定义。Java程序现在可以在解释器上运行，称为Java虚拟机（JVM）。程序运行时，JVM链接到Java库中所需的方法。为了获得更高的性能，JVM可以调用JIT，该编译器有选择地将方法编译为运行它的机器的本地机器语言。编译过的部分将在下次运行程序时保存，以便每次运行时速度更快。\n\n## 2.13以C排序程序为例的汇总整理\n\n把C翻译为汇编语言时，遵循：\n\n1. 为变量分配寄存器。\n2. 为过程体生成汇编代码。\n3. 保存过程调用间的寄存器。\n\n### 2.13.1swap过程\n\n```c\nvoid swap(int v[], size_t k) {\n    int temp;\n    temp = v[k];\n    v[k] = v[k + 1];\n    v[k + 1] = temp;\n}\n```\n\n`x5`作为临时寄存器，`x10`和`x11`作为参数寄存器。\n\n```bash\nswap:\n  slli    x6, x11, 2   // reg x6 = k * 4\n  add     x6, x10, x6  // reg x6 = v + k * 4\n  lw      x5, 0(x6)    // reg x5 (temp) = v[k]\n  lw      x7, 4(x6)    // reg x7 = v[k + 1]\n  sw      x7, 0(x6)    // v[k] = reg x7\n  sw      x5, 4(x6)    // v[k + 1] = reg x5 (temp)\n  jalr    x0, 0(x1)    // return to calling routine\n```\n\n### 2.13.2sort过程\n\n这里不予展示`sort`过程。\n\n以下是编译器优化对`sort`（冒泡排序）各项性能的影响。（具体参数省略，排序个数为`n=100000`）\n\n| gcc优化 | 相对性能 | 时钟周期（百万） | 指令数（百万） | CPI  |\n| ------- | -------- | ---------------- | -------------- | ---- |\n| 无优化  | 1.00     | 158615           | 114938         | 1.38 |\n| O1      | 2.37     | 66990            | 37470          | 1.79 |\n| O2      | 2.38     | 66521            | 39993          | 1.66 |\n| O3      | 2.41     | 65747            | 44993          | 1.46 |\n\n同一段代码在JAVA上的表现和快速排序的表现。\n\n| 语言 | 执行模式   | 优化选项 | 冒泡排序相对性能 | 快速排序相对性能 | 快速排序与冒泡排序加速比 |\n| ---- | ---------- | -------- | ---------------- | ---------------- | ------------------------ |\n| C    | 编译器     | 无优化   | 1.00             | 1.00             | 2468                     |\n|      | 编译器     | O1       | 2.37             | 1.50             | 1562                     |\n|      | 编译器     | O2       | 2.38             | 1.50             | 1555                     |\n|      | 编译器     | O3       | 2.41             | 1.91             | 1955                     |\n| Java | 解释器     | ---      | 0.12             | 0.05             | 1050                     |\n|      | 即时编译器 | ---      | 2.13             | 0.29             | 388                      |\n\n## 2.14数组与指针\n\n在一个形如实现`v.assign(n, 0)`的程序中，比较数组和指针的区别。\n\n在不加入优化的时候，后者相比于前者有**移位替代乘法**和**消除循环内的数组地址计算**的编译优化。\n\n## 2.16MIPS和ARM指令集\n\n| 特征         | RISC-V                               | MIPS                             | ARM                                               |\n| ------------ | ------------------------------------ | -------------------------------- | ------------------------------------------------- |\n| **性质**     | **开源免费**ISA                      | **商业授权**ISA                  | **商业授权**ISA                                   |\n| **设计哲学** | 模块化、可扩展、简洁                 | 经典 RISC、流水线优化            | 高能效比、广泛应用、生态成熟                      |\n| **指令集**   | 模块化（核心+标准/自定义扩展）       | 相对固定，但有不同版本           | 演进式，有不同版本（ARMv7, ARMv8/AArch64, ARMv9） |\n| **生态系统** | **快速发展中**，潜力巨大             | 相对萎缩                         | 极其庞大成熟                                      |\n| **主要优势** | 灵活性、低成本、定制化、无专利壁垒   | 历史悠久，特定领域性能不错       | **市场领导者**，能效比高，生态最完善              |\n| **主要应用** | 嵌入式、IoT、AI、HPC、通用计算       | 过去是路由器、消费电子；现在较少 | 移动设备、嵌入式、服务器、汽车                    |\n| **商业模式** | 使用免费，可自己设计核心或使用第三方 | 购买授权                         | 购买架构/核心 IP 授权                             |\n\n## 2.17RISC-V指令系统的剩余部分\n\n| 名称    | 格式 | 描述                                                         |\n| ------- | ---- | ------------------------------------------------------------ |\n| `auipc` | U    | 立即数高20位与PC相加；将结果写到寄存器                       |\n| `slt`   | R    | 比较寄存器，如果小于就设置，将布尔结果写到寄存器             |\n| `sltu`  | R    | 比较寄存器，如果小于就设置（无符号），将布尔结果写到寄存器   |\n| `slti`  | I    | 比较寄存器，如果小于就设置（立即数）；将布尔结果写到寄存器   |\n| `sltiu` | I    | 比较寄存器，如果小于就设置（无符号立即数）；将布尔结果写到寄存器 |\n\n下面列出了五个标准扩展：\n\n| 助记符 | 描述          | 指令数 |\n| ------ | ------------- | ------ |\n| **I**  | 基本体系结构  | 51     |\n| **M**  | 整数乘法/除法 | 13     |\n| **A**  | 原子操作      | 22     |\n| **F**  | 单精度浮点    | 30     |\n| **D**  | 双精度浮点    | 32     |\n| **C**  | 压缩指令      | 36     |\n\n我们会在第三章讲述**M,F,D**三种扩展。\n\n**A**扩展包括`lr.d`，`sc.d`以及它们的32位版本`lr.w`，`sc.w`。剩余18条指令是常见同步模式的优化。\n\n**C**扩展会缩短指令位数以对于部分操作提高性能。\n\n## 2.22谬误与陷阱\n\n**谬误：更强大的指令意味着更高的性能**\n\n**谬误：用汇编语言编程以获得最高性能**\n\n**谬误：商用计算机二进制兼容的重要性意味着成功的指令系统无需改变**\n\n**陷阱：忘记在字节寻址的机器中，连续的字地址相差不为1**\n\n**陷阱：在变量的定义过程外，使用一个指针指向该变量**' 
                      },
                      { id: 'computer_organization_and_architecture-3', 
                        title: '3、计算机的算术运算', 
                        desc: '', 
                        content: '# 3.计算机的算术运算 \n\n## 3.1引言\n\n本章涉及**表示小数和其它实数**，**表示特大数**，**硬件真正实现乘除法**。\n\n## 3.2加法和减法\n\n加法就是传统的逐位相加进位。\n\n减法：取反再加法操作。\n\n**溢出**：\n\n- 有符号数：当两个操作数：同号且和与原操作数异号$\\Rightarrow$溢出\n- 无符号数：\n  - 加法：总和小于加数中的任何一个$\\Rightarrow$溢出\n  - 减法：差大于被减数$\\Rightarrow$溢出\n\n> **饱和**：当计算溢出时，自动设置为极大值或极小值。这可能会出现在多媒体设备。\n\n> **加法速度**：加法的速度取决于向高位进位的计算速度。这里介绍**超前进位加法器**：\n>\n> - **进位产生**：$G_i=A_i\\land B_i$ (当$A_i$和$B_i$都是$1$时，本位产生进位)\n>\n> - **进位传递**：$P_i=A_i⊕B_i$ (当$A_i$和$B_i$相异时，本位将前一级的进位传递过来)\n>\n> 利用这两个信号，任何一位的进位输入$C_{i+1}$ 都可以用逻辑表达式表示，而无需等待前一级的进位计算结果。例如：\n>\n> $C_1=G_0+P_0⋅C_0$\n>\n> $C_2=G_1+P_1⋅C_1=G_1+P_1⋅(G_0+P_0⋅C_0)$\n\n## 3.3乘法\n\n### 3.3.1串行版的乘法算法及其硬件实现\n\n![image-20250925100703653](./pictures/image-20250925100703653.png)\n\n![image-20250925100914102](./pictures/image-20250925100914102.png)\n\n![image-20250925101411096](./pictures/image-20250925101411096.png)\n\n### 3.3.2带符号乘法\n\n独立处理符号位即可。\n\n事实上，**直接**使用补码形式的数，再迭代执行移位和加法，**每次右移时进行符号扩展（对于负数进行算术右移）**。\n\n### 3.3.3快速乘法\n\n可以为每个乘数位提供一个32位加法器：一个输入是被乘数和一个乘数位相与的结果，另一个输入是上一个加法器的输出。\n\n- 用64个32位加法器形成一个高64位的加法器栈。\n\n- 第二种是\n\n  ![image-20250925105036839](./pictures/image-20250925105036839.png)\n\n由于使用**进位保留加法器**，乘法速度比5次加法还快。\n\n> 进位保留加法器：\n>\n> `input(A, B, C)`\n>\n> `output(sum, carry)`\n>\n> 公式上：$A+B+C=\\text{sum}+\\text{carry<<1}$\n>\n> 分开计算`sum`和`carry`，从而各位都能并行计算。\n\n### 3.3.4RISC-V中的乘法\n\nRISC-V中有四条乘法指令：\n\n- `mul`：乘。\n- `mulh`：乘法取高位。\n- `mulhu`：无符号乘法取高位。\n- `mulhsu`：有符号同无符号乘法取高位。\n\n## 3.4除法\n\n### 3.4.1除法算法及其硬件实现\n\n![image-20250925110559938](./pictures/image-20250925110559938.png)\n\n![image-20250925110642133](./pictures/image-20250925110642133.png)\n\n![image-20250925112533800](./pictures/image-20250925112533800.png)\n\n### 3.4.2有符号除法\n\n单独处理符号位。\n\n### 3.4.3快速除法\n\n**SRT除法**：根据被除数和余数的高位来查找表，以预测每步的多个商的位数。\n\n### 3.4.4RISC-V中的除法\n\nRISC-V中有四条除法指令：\n\n- `div`：除。\n- `divu`：无符号除。\n- `rem`：余数。\n- `remu`：无符号余数。\n\n### 3.4.5总结\n\n下表相比上一章表格基础上给出了**RISC-V**体系结构的优化处理。\n\n| 类别           | 指令                     | 示例                | 含义                      | 注解                                                     |\n| -------------- | ------------------------ | ------------------- | ------------------------- | -------------------------------------------------------- |\n| **算术运算**   | 加                       | `add x5, x6, x7`    | `x5=x6+x7`                | 三寄存器操作数：加                                       |\n|                | 减                       | `sub x5, x6, x7`    | `x5=x6-x7`                | 三寄存器操作数：减                                       |\n|                | 立即数加                 | `addi x5, x6, 20`   | `x5=x6+20`                | 用于加常数                                               |\n|                | 小于置位                 | `slt x5, x6, x7`    | `x5=1 if x6<x7, else 0`   | 两个寄存器比较                                           |\n|                | 小于置位（无符号数）     | `sltu x5, x6, x7`   | `x5=1 if x6<x7, else 0`   | 两个寄存器比较                                           |\n|                | 小于置位（立即数）       | `slti x5, x6, 20`   | `x5=1 if x6<20, else 0`   | 与立即数比较                                             |\n|                | 小于置位（无符号立即数） | `sltiu x5, x6, 20`  | `x5=1 if x6<20, else 0`   | 与立即数比较                                             |\n|                | 乘                       | `mul x5, x6, x7`    | `x5=x6*x7`                | 64位乘积的低32位                                         |\n|                | 高位乘                   | `mulh x5, x6, x7`   | `x5=(x6*x7)>>32`          | 64位有符号乘积的高32位                                   |\n|                | 高位乘（无符号数）       | `mulhu x5, x6, x7`  | `x5=(x6*x7)>>32`          | 64位无符号乘积的高32位                                   |\n|                | 高位乘（有-无符号数）    | `mulhsu x5, x6, x7` | `x5=(x6*x7)>>32`          | 64位有-无符号乘积的高32位                                |\n|                | 除                       | `div x5, x6, x7`    | `x5=x6/x7`                | 除有符号32位数字                                         |\n|                | 无符号除                 | `divu x5, x6, x7`   | `x5=x6/x7`                | 除无符号32位数字                                         |\n|                | 取余                     | `rem x5, x6, x7`    | `x5=x6%x7`                | 对有符号32位除法取余                                     |\n|                | 无符号取余               | `remu x5, x6, x7`   | `x5=x6%x7`                | 对无符号32位除法取余                                     |\n| **数据传输**   | 取双字                   | `ld x5, 40(x6)`     | `x5=Memory[x6+40]`        | 从存储器取双字到寄存器                                   |\n|                | 存双字                   | `sd x5, 40(x6)`     | `Memory[x6+40]=x5`        | 从寄存器存双字到存储器                                   |\n|                | 取字                     | `lw x5, 40(x6)`     | `x5=Memory[x6+40]`        | 从存储器取字到寄存器                                     |\n|                | 取字(无符号)             | `lwu x5, 40(x6)`    | `x5=Memory[x6+40]`        | 从存储器取无符号字到寄存器                               |\n|                | 存字                     | `sw x5, 40(x6)`     | `Memory[x6+40]=x5`        | 从寄存器存字到存储器                                     |\n|                | 取半字                   | `lh x5, 40(x6)`     | `x5=Memory[x6+40]`        | 从存储器取半字到寄存器                                   |\n|                | 取半字(无符号)           | `lhu x5, 40(x6)`    | `x5=Memory[x6+40]`        | 从存储器取无符号半字到寄存器                             |\n|                | 存半字                   | `sh x5, 40(x6)`     | `Memory[x6+40]=x5`        | 从寄存器存半字到存储器                                   |\n|                | 取字节                   | `lb x5, 40(x6)`     | `x5=Memory[x6+40]`        | 从存储器取字节到寄存器                                   |\n|                | 取字节(无符号)           | `lbu x5, 40(x6)`    | `Memory[x6+40]=x5`        | 从寄存器存字节到存储器                                   |\n|                | 存字节                   | `sb x5, 40(x6)`     | `Memory[x6+40]=x5`        | 从寄存器存字节到存储器                                   |\n|                | 取保留字                 | `lr.d x5, (x6)`     | `x5=Memory[x6]`           | 取；原子交换的前半部分                                   |\n|                | 存条件字                 | `sc.d x7, x5, (x6)` | `Memory[x6]=x5;x7=0/1`    | 存；原子交换的后半部分                                   |\n|                | 取立即数高位             | `lui x5, 0x12345`   | `x5=0x12345000`           | 取左移12位后的20位立即数                                 |\n|                | 加立即数高位到`PC`       | `auipc x5, 0x12345` | `x5=PC+0x12345000`        | 用作程序计数器相对寻址                                   |\n| **逻辑运算**   | 与                       | `and x5, x6, x7`    | `x5=x6&x7`                | 三寄存器操作数：按位与                                   |\n|                | 或                       | `or x5, x6, x8`     | `x5=x6|x8`                | 三寄存器操作数：按位或                                   |\n|                | 异或                     | `xor x5, x6, x9`    | `x5=x6^x9`                | 三寄存器操作数：按位异或                                 |\n|                | 与立即数                 | `andi x5, x6, 20`   | `x5=x6&20`                | 寄存器与常数按位与                                       |\n|                | 或立即数                 | `ori x5, x6, 20`    | `x5=x6|20`                | 寄存器与常数按位或                                       |\n|                | 异或立即数               | `xori x5, x6, 20`   | `x5=x6^20`                | 寄存器与常数按位异或                                     |\n| **移位操作**   | 逻辑左移                 | `sll x5, x6, x7`    | `x5=x6<<x7`               | 按寄存器给定位数左移                                     |\n|                | 逻辑右移                 | `srl x5, x6, x7`    | `x5=x6>>x7`               | 按寄存器给定位数右移                                     |\n|                | 算术右移                 | `sra x5, x6, x7`    | `x5=x6>>x7`               | 按寄存器给定位数算术右移                                 |\n|                | 逻辑左移立即数           | `slli x5, x6, 3`    | `x5=x6<<3`                | 根据立即数给定位数左移                                   |\n|                | 逻辑右移立即数           | `srli x5, x6, 3`    | `x5=x6>>3`                | 根据立即数给定位数右移                                   |\n|                | 算术右移立即数           | `srai x5, x6, 3`    | `x5=x6>>3`                | 根据立即数给定位数算术右移                               |\n| **条件分支**   | 相等即跳转               | `beq x5, x6, 100`   | `if(x5==x6) go to PC+100` | 若寄存器数值相等则跳转到PC相对地址                       |\n|                | 不等即跳转               | `bne x5, x6, 100`   | `if(x5!=x6) go to PC+100` | 若寄存器数值不等则跳转到PC相对地址                       |\n|                | 小于即跳转               | `blt x5, x6, 100`   | `if(x5<x6) go to PC+100`  | 若寄存器数值比较结果小于则跳转到PC相对地址               |\n|                | 大于等于即跳转           | `bge x5, x6, 100`   | `if(x5>=x6) go to PC+100` | 若寄存器数值比较结果大于或等于则跳转到PC相对地址         |\n|                | 小于即跳转(无符号)       | `bltu x5, x6, 100`  | `if(x5<x6) go to PC+100`  | 若寄存器数值比较结果小于则跳转到PC相对地址(无符号)       |\n|                | 大于等于即跳转(无符号)   | `bgeu x5, x6, 100`  | `if(x5>=x6) go to PC+100` | 若寄存器数值比较结果大于或等于则跳转到PC相对地址(无符号) |\n| **无条件跳转** | 跳转-链接                | `jal x1, 100`       | `x1=pc+4; go to PC+100`   | 用于PC相关的过程调用                                     |\n|                | 跳转-链接(寄存器地址)    | `jalr x1, 100(x5)`  | `x1=PC+4; go to x5+100`   | 用于过程返回；非直接调用                                 |\n\n> **RISC-V除法**中有两种异常要求软件进行判断：\n>\n> 1. 除法溢出。\n> 2. 除数为0。\n\n## 3.5浮点运算\n\n> **规格化**：没有前导0的浮点表示法。\n\n> **浮点**：二进制小数点不固定的数的计算机表示。\n\n支持浮点数的计算机运算称为**浮点**运算。\n\n### 3.5.1浮点表示\n\n> **尾数**：该值通常在0和1之间，放置在尾数字段中。\n\n> **指数**：在浮点运算的数值表示系统中，放置在指数字段中的值。\n\n于是乎我们有上学期就了解到的熟悉的单/双精度浮点表示。（来自IEEE754标准）\n\n> **上/下溢出**：正/负指数太大而无法用指数字段表示的情况。\n\n除了0以外，符号位为0的单精度的表示范围$2^{-149}\\sim(1-2^{-24})\\times 2^{128}$。\n\n除了0以外，符号位为0的双精度的表示范围$2^{-1074}\\sim(1-2^{-53})\\times2^{1024}$。\n\n### 3.5.2例外和中断\n\n> **例外**：也叫中断。打扰程序执行的意外事件；用于检测溢出。\n>\n> **中断**：来自处理器之外的例外。\n\n有些计算机会通过**例外**告知问题的出现。\n\n造成溢出的指令的地址会被保留在寄存器，然后计算机跳转到预定义的地址以调用相应的例外处理程序。中断的地址被保存下来，以便处理完后继续执行程序。\n\n**RISC-V**不会在溢出引发例外。软件可以通过**浮点控制**和**状态寄存器（fscr）** 来检测是否溢出。\n\n### 3.5.3IEEE754浮点数标准\n\n参见计算机系统基础。\n\n### 3.5.4浮点加法\n\n1. 将**较小数**的有效数位进行右移，直到它的指数与**较大数**的指数相等。\n2. 有效数位相加。\n3. 调整**指数**，把它变为规格化的形式。这一步需要检测上溢。\n4. **舍入**：如果这个结果不是规格化数，重新进行上一步。\n\n![image-20250928200613724](./pictures/image-20250928200613724.png)\n\n### 3.5.5浮点乘法\n\n1. 指数相加。这里要以移码表示指数，两个指数相加后减去一个偏移值。\n\n   > **移码**：对于$n$位字段，偏移量$offset=2^{n-1}$移码就是原来的数加上$offset$。\n\n2. 有效数位相乘。\n\n3. 调整**指数**，把它变为规格化的形式。这一步需要检测上溢和下溢。\n\n4. **舍入**。如果这个结果不是规格化数，重新进行上一步。\n\n5. 根据操作数的符号确定结果的符号。\n\n![image-20250930184251036](./pictures/image-20250930184251036.png)\n\n### 3.5.6RISC-V中的浮点指令\n\n> [!NOTE]\n>\n> 浮点数据传输指令的基址寄存器仍为整点寄存器。\n>\n> 浮点寄存器`f0`不像`x0`硬连接0。\n>\n> 载入指令使用`I`型指令，存储指令使用`S`型指令，算术指令使用`R`型指令。\n\n| 名称             | 示例                                        | 注解                                                         |\n| ---------------- | ------------------------------------------- | ------------------------------------------------------------ |\n| 32个浮点寄存器   | `f0`~ `f31`                                  | 一个`f`寄存器可以保存一个单精度浮点数或一个双精度浮点数      |\n| $2^{30}$个存储字 | `Memory[0], Memory[4],…,Memory[4294967292]` | 只能被数据传输指令访问。RISC-V使用字节地址，因此顺序字相差4。存储器保存数据结构、数组和换出的寄存器的内容 |\n\n\n\n| 类别         | 指令                 | 示例                | 含义                       | 注解                               |\n| ------------ | -------------------- | ------------------- | -------------------------- | ---------------------------------- |\n| **算术**     | 单精度浮点加法       | `fadd.s f0, f1, f2` | `f0=f1+f2`                 | （单精度）浮点数加法               |\n|              | 单精度浮点减法       | `fsub.s f0, f1, f2` | `f0=f1-f2`                 | （单精度）浮点数减法               |\n|              | 单精度浮点乘法       | `fmul.s f0, f1, f2` | `f0=f1*f2`                 | （单精度）浮点数乘法               |\n|              | 单精度浮点除法       | `fdiv.s f0, f1, f2` | `f0=f1/f2`                 | （单精度）浮点数除法               |\n|              | 单精度浮点平方根     | `fsqrt.s f0，f1`    | `f0=sqrt(f1)`              | （单精度）浮点数平方根             |\n|              | 双精度浮点加法       | `fadd.d f0, f1, f2` | `f0=f1+f2`                 | （双精度）浮点数加法               |\n|              | 双精度浮点减法       | `fsub.d f0, f1, f2` | `f0=f1-f2`                 | （双精度）浮点数减法               |\n|              | 双精度浮点乘法       | `fmul.d f0, f1, f2` | `f0=f1*f2`                 | （双精度）浮点数乘法               |\n|              | 双精度浮点除法       | `fdiv.d f0, f1, f2` | `f0=f1/f2`                 | （双精度）浮点数除法               |\n|              | 双精度浮点平方根     | `fsqrt.d f0, f1`    | `f0=sqrt(f1)`              | （双精度）浮点数平方根             |\n| **比较**     | 单精度浮点相等       | `feq.s x5, f0, f1`  | `x5=1 if f0 == f1, else 0` | （单精度）浮点数比较               |\n|              | 单精度浮点小于       | `fit.s x5, f0, f1`  | `x5=1 if f0 < f1, else 0`  | （单精度）浮点数比较               |\n|              | 单精度浮点小于或等于 | `fle.s x5, f0, f1`  | `x5=1 if f0 <= f1, else 0` | （单精度）浮点数比较               |\n|              | 双精度浮点相等       | `feq.d x5, f0, f1`  | `x5=1 if f0 == f1, else 0` | （双精度）浮点数比较               |\n|              | 双精度浮点小于       | `fit.d x5, f0, f1`  | `x5=1 if f0 < f1, else 0`  | （双精度）浮点数比较               |\n|              | 双精度浮点小于或等于 | `fle.d x5, f0, f1`  | `x5=1 if f0 <= f1, else 0` | （双精度）浮点数比较               |\n| **数据传输** | 浮点取字             | `flw f0, 4(x5)`     | `f0=Memory[x5+4]`          | 从内存中取单精度字到浮点寄存器     |\n|              | 浮点取双字           | `fld f0, 8(x5)`     | `f0=Memory[x5+8]`          | 从内存中取双精度字到浮点寄存器     |\n|              | 浮点存字             | `fsw f0, 4(x5)`     | `Memory[x5+4]=f0`          | 将浮点寄存器中的单精度字存储到内存 |\n|              | 浮点存双字           | `fsd f0, 8(x5)`     | `Memory[x5+8]=f0`          | 将浮点寄存器中的双精度字存储到内存 |\n\n### 3.5.7精确算术\n\n显然双精度浮点数能精确表示的最多只有$2^{53}$个数，我们不可能精确地表示每个实数。IEEE754在中间计算时，总是在右边保留两个额外的位，分别是**保护位**和**舍入位**。\n\n> **保护位**：在浮点运算的中间计算中，保留在右侧的两个额外位的第一位，用于提高舍入精度。\n\n> **舍入位**：使中间结果符合浮点格式的方法，目标通常是找到符合格式的最接近的数。它也是在浮点运算的中间运算中保留在右侧的两个额外位的第二位，可以提高舍入精度。\n\n以浮点加法为例：**保护位**和**舍入位**会在有效位数右移的时候充当占位，减少可能被丢掉的位。\n\n> **最后位置单位**：用于表示在实际数和可表示数之间的有效位数中最低有效位上的误差位数。\n\n浮点的精度通常以有效数位中最低有效位的错误位数来衡量，这种衡量方式称为**最后位置单位的数目**，即**ulp**。\n\n在没有**上溢**、**下溢**或**无效操作**引发例外的情况下，IEEE754标准保证计算机使用的数的误差在半个**ulp**以内。\n\n---\n\n乘法可能需要两个额外位。因为二进制积可能有一个前导0，因此，规格化时必须将积左移一位。这就将保护位转换为积的最低有效位，留下舍入位来帮助进行精确舍入。\n\n### 3.5.8总结\n\n**无序比较**：设计`NaN`的比较。\n\nRISC-V不提供无序比较的指令，但经过设计的有序比较序列具有相同的效果。\n\n具体为：**比较的其中一个数涉及**$\\text{NaN}$**，会将标记寄存器设为0**。\n\n## 3.6并行性与计算机算术：子字并行\n\n**子字并行**：通过在128位加法器内划分进位链，处理器可以同时对16个8位操作数、8个16位操作数、4个32位操作数、2个64位操作数的短向量进行并行操作。\n\n## 3.7x86中的SIMD扩展和高级向量扩展\n\nx86的原始**MMX（MultiMedia eXtension，多媒体扩展）** 包含操作整数短向量的指令。\n\n而后，**SSE（StreamingSIMDExtension，流式SIMD扩展）** 提供了操作单精度浮点数短向量的指令。\n\n2011年，Intel使用**高级向量扩展（Advanced Vector Extensions，AVX）**将寄存器的位宽再次翻倍，现称为**YMM**。\n\n2015年，英特尔将寄存器扩展至512位，现在称为**ZIMM**，在某些微处理器中使用了**AVX512**。英特尔已官布计划在x86架构的最新版本中将AVX寄存器扩展到1024位。\n\n## 3.9谬误与陷阱\n\n**谬误：正如左移指令可以代替一个乘以2的幂的整数，右移等同于除以一个2的幂的整数**\n\n**陷阱：浮点加法不满足结合律**\n\n**谬误：适用于整型数据类型的并行执行策略也适用于浮点数据类型**\n\n**谬误：只有理论数学家关心浮点精度**' 
                      },
                      { id: 'computer_organization_and_architecture-4', 
                        title: '4、处理器', 
                        desc: '', 
                        content: '# 4.处理器\n\n## 4.1引言\n\n### 4.1.1一种基本的RISC-V实现\n\n我们将实现RISC-V的一个核心子集：\n\n- 存储器访问指令**load word（lw）**和**store word（sw）**。\n- 算术逻辑指令**add**，**sub**，**and**，**or**。\n- 条件分支指令**branch if equal（beq）**。\n\n### 4.1.2实现概述\n\n实现每条指令的前两条步骤是相同的：\n\n1. **PC**发送到指令所在的存储单元，并从中取出指令。\n2. 根据指令的某些字段选择要读取的一个或两个寄存器。对于**lw**指令，只需要读取个寄存器，但大多数其他指令需要读取两个寄存器。\n\n所有类型的指令在读取寄存器后都使用**算术逻辑单元（ALU）**。\n\n- 存储器访问指令用**ALU**进行地址计算。\n- 算术逻辑指令用**ALU**来执行运算。\n- 条件分支指令用**ALU**进行比较。\n\n但是经过ALU后：\n\n- 存储器访问指令需要访问存储器以读取数据或存储数据。\n- 算术逻辑指令或载入指令需要将来自ALU或存储器的数据写回寄存器。\n- 条件分支指令需要根据比较结果更改下一条指令的地址；否则，下一条指令的地址会通过PC加4来获得。\n\n![image-20251009111156158](./pictures/image-20251009111156158.png)\n\n**忽略的内容**\n\n- 上面的图对于多个数据流的输入缺少了**多选器**。\n- 一些功能单元的控制依赖于当前执行的指令类型。但是**ALU**不是，它需要新增的控制线确定做哪种运算。\n\n![image-20251014183901352](./pictures/image-20251014183901352.png)\n\n上面的图已经实现了**控制器**，**存储器**，**运算器**。\n\n## 4.2逻辑设计的一般方法\n\nRISC-V实现中的数据通路包含两种逻辑单元：**处理数据值的单元**和**存储状态的单元**。\n\n- 处理数据值的单元是**组合逻辑**。组合逻辑单元没有内部存储功能，对于相同的输入有相同的输出。\n- 其他单元则是**包含状态**的，有内部存储，就是**状态单元**。一个状态单元至少有两个输人和一个输出。\n  - 输入：**要写入状态单元的数据值**和**决定何时写入数据值的时钟信号**。\n  - 输出：提供了在前一个时钟周期写入单元的数据值。\n\n包含状态的逻辑部件也被称为**时序的**，因为其输出取决于输入和内部状态。\n\n---\n\n**时钟同步方法**\n\n> **时钟同步方法**：用来确定数据相对于时钟何时稳定和有效的方法。\n>\n> **边沿触发的时钟**：所有状态的改变发生于时钟边沿的机制。\n>\n> **控制信号**：用来决定多选器选择或指示功能单元操作的信号；它与数据信号相对应，数据信号包含功能单元所操作的信息。\n\n**时钟同步方法（clocking methodology）** 规定了信号可以读出和写入的时间。\n\n为简单起见，假定我们采用**边沿触发的时钟（edge-triggeredclocking）**，即存储在时序逻辑单元中的所有值仅在时钟边沿更新，这是从低电平快速跳变到高电平（反之亦然）的过程。\n\n所有组合逻辑单元都必须从状态单元集合接收输入，并将输出写入状态单元集合。其输入是之前某时钟周期写入的值，输出的值可以在后续时钟周期使用。\n\n如果状态单元在每个有效时钟边沿都进行写入则可忽略**写控制信号（controlsignal）**。反之则反之。\n\n![image-20251014185656557](./pictures/image-20251014185656557.png)\n\n---\n\n> **有效**：信号为逻辑高或真。\n>\n> **无效**：信号为逻辑低或假。\n\n在32位RISC-V指令系统体系结构，几乎所有的状态单元和逻辑单元的输入和输出都是32位，因为处理器处理的大部分数据的宽度是32位。\n\n## 4.3建立数据通路\n\n> **数据通路单元**：一个用来操作或保存处理器中数据的单元。在RISC-V实现中，数据通路单元包括指令存储器、数据存储器、寄存器堆、ALU和加法器。\n> **程序计数器**：包含当前程序正在执行的指令地址的寄存器。\n\n![image-20251014190525685](./pictures/image-20251014190525685.png)\n\n- `a)`为**存储单元**，用于存储程序的指令，并根据给定地址提供指令。\n- `b)`为**程序计数器（PC）**，它用于保存当前指令的地址。\n- `c)`为一个加法器来增加PC的值以获得下一条指令的地址。这个加法器是一个组合逻辑电路，可由ALU实现，只需将其中的控制信号设为总是进行加法运算即可。\n\n执行一条指令：从存储器中取出指令。增加程序计数器的值，使其指向下一条指令，即向后移动4个字节。\n\n![image-20251014190852221](./pictures/image-20251014190852221.png)\n\n处理器的32个通用寄存器位于被称为**寄存器堆**的结构中。\n\n> **寄存器堆**：包含一系列寄存器的状态单元，可通过所提供的寄存器号进行读写。\n\n---\n\n以R型指令（涉及逻辑和运算的指令）为例。\n\nR型指令有三个寄存器操作数，每条指令需要从寄存器堆中读出两个数据字，再写入一个数据字。\n\n- **读一个数据字**：一个指定要读寄存器号的输入，一个从寄存器堆读出的输出。\n- **写一个数据字**：一个输入指定要写的寄存器号；另一个输入提供要写入寄存器的数据。\n\n寄存器堆根据输入的寄存器号输出相应寄存器的内容。\n\n写操作由写控制信号控制，在写操作发生的时钟边沿，写控制信号必须是有效的。\n\n![image-20251014192518538](./pictures/image-20251014192518538.png)\n\n输入的寄存器号为5位宽，（因为有32个寄存器），数据输入总线和两个数据输出总线也均为32位宽。\n\n略带提一下**ALU**：它读取两个32位输入并产生一个32位输出，还有一个1位输出指示其结果是否为0。\n\n---\n\n再考虑存取指令：\n\n这类指令通过将基址寄存器`x2`与指令中包含的12位有符号偏移量相加，得到存储器地址。也会用到寄存器`x1`读出或写入数据。\n\n所以上述**寄存器堆**和**ALU**都会被用到。\n\n此外，还需要将指令中的12位偏移量**符号扩展（sign-extend）**为32位有符号数，以及一个执行读写操作的**数据存储单元**。数据存储单元在存储指令时被写入，所以它有读写控制信号、地址输入和写入存储器的数据输入。\n\n> **符号扩展**：为增加数据的长度，将原数据的最高位复制到新数据多出来的高位。\n\n![image-20251014193444026](./pictures/image-20251014193444026.png)\n\n---\n\n`beq`指令有三个操作数，其中两个寄存器用于比较是否相等，另一个是12位偏移量，用于计算相对于分支指令所在地址的**分支目标地址**。它的指令格式是`beq x1, x2, offset`。\n\n为实现beq指令，需将PC值与符号扩展后的指令偏移量相加以得到分支目标地址。\n\n> **分支目标地址**：分支指令中指定的地址，如果分支发生，该地址成为新的程序计数器的值。在RISC-V体系结构中，分支目标地址为该指令的偏移量字段与分支指令所在地址的和。\n\n> **分支发生**：一种分支指令，其分支条件满足，程序计数器变为分支目标地址，所有无条件分支指令都是发生的分支。\n\n> **分支未发生**：一种分支指令，其分支条件不成立，程序计数器变为分支指令的下一条指令的地址。\n\n分支指令的数据通路需要执行两个操作：**计算分支目标地址**和**检测分支条件**。\n\n![image-20251014194040547](./pictures/image-20251014194040547.png)\n\n---\n\n**建立一个简单的数据通路**\n\n这个**最简单**的数据通路在每个时钟周期执行一条指令。\n\n这意味着每条指令在执行过程中的任何数据通路单元都只能使用一次，如果需要多次使用某数据通路单元，则要将其复制多份。\n\n因此，需要一个**指令存储器**和**一个与之分开的数据存储器**。尽管还有一些功能单元需要多份，但很多功能单元可以在不同的指令流动中被共享。\n\n为在两个不同类指令之间共享数据通路单元，需要允许一个单元有多个输入，我们用多路选择器和控制信号在多个输入中进行选择。\n\n**我们为建立只有一个寄存器堆和一个ALU的数据通路，需支持ALU的第二个输入和要存入寄存器堆的数据都有两个不同的来源**。因此，在ALU的输入端和寄存器堆的数据输入端分别添加一个多路选择器。\n\n![image-20251014195306395](./pictures/image-20251014195306395.png)\n\n现在，把**取指令数据通路**、**R型指令和存储类指令数据通路**、**分支指令数据通路**合并，得到RISC-V指令系统核心集的一个简单数据通路。\n\n![image-20251014195855863](./pictures/image-20251014195855863.png)\n\n## 4.4一个简单的实现方案\n\n### 4.4.1ALU控制\n\n**RISC-V ALU**定义了四根输入控制线的以下四种组合：\n\n| ALU控制线 | 功能     |\n| --------- | -------- |\n| `0000`    | AND      |\n| `0001`    | OR       |\n| `0010`    | add      |\n| `0110`    | subtract |\n\n根据不同指令类型，**ALU**执行以上四种功能中一种：\n\n- `load`和`store`：ALU做加法计算存储器地址。\n- R型指令，根据`funct7`和`funct3`字段执行这四种中的一种。\n- 条件分支指令，ALU将两个操作数做减法并检测结果是否为0。\n\n4位ALU的输入控制信号可由一个小型控制单元产生，其输入是指令的`funct7`和`funct3`和`ALUOp`字段。\n\n| 指令操作码 | ALUOp | 操作            | funct7字段 | funct3字段 | ALU期望行为 | ALU控制输入 |\n| ---------- | ----- | --------------- | ---------- | ---------- | ----------- | ----------- |\n| `lw`       | `00`  | load word       | `xxxxxxx`  | `xxx`      | add         | 0010        |\n| `sw`       | `00`  | store word      | `xxxxxxx`  | `xxx`      | add         | 0010        |\n| `beq`      | `01`  | branch if equal | `xxxxxxx`  | `xxx`      | subtract    | 0110        |\n| R-type     | `10`  | add             | `0000000`  | `000`      | add         | 0010        |\n| R-type     | `10`  | sub             | `0100000`  | `000`      | subtract    | 0110        |\n| R-type     | `10`  | and             | `0000000`  | `111`      | AND         | 0000        |\n| R-type     | `10`  | or              | `0000000`  | `110`      | OR          | 0001        |\n\n**多级控制**：上面通过**ALUOp**用作**ALU**的输入控制信号，再生成实际信号来控制**ALU**。这样可以减小控制单元的规模。\n\n---\n\n现在我们要一张**真值表**设计一个小逻辑单元：识别可能的取值并生成恰当的ALU控制信号。\n\n| ALUOp  |        | funct7字段 |       |       |       |       |       |       | funct3字段 |       |       | 操作 |\n| ------ | ------ | ---------- | ----- | ----- | ----- | ----- | ----- | ----- | ---------- | ----- | ----- | ---- |\n| ALUOp1 | ALUOp0 | I[31]      | I[30] | I[29] | I[28] | I[27] | I[26] | I[25] | I[14]      | I[13] | I[12] |      |\n| 0      | 0      | x          | x     | x     | x     | x     | x     | x     | x          | x     | x     | 0010 |\n| x      | 1      | x          | x     | x     | x     | x     | x     | x     | x          | x     | x     | 0110 |\n| 1      | x      | 0          | 0     | 0     | 0     | 0     | 0     | 0     | 0          | 0     | 0     | 0010 |\n| 1      | x      | 0          | 1     | 0     | 0     | 0     | 0     | 0     | 0          | 0     | 0     | 0110 |\n| 1      | x      | 0          | 0     | 0     | 0     | 0     | 0     | 0     | 1          | 1     | 1     | 0000 |\n| 1      | x      | 0          | 0     | 0     | 0     | 0     | 0     | 0     | 1          | 1     | 0     | 0001 |\n\n### 4.4.2设计主控制单元\n\nRISC-V通过复杂指令格式简化了硬件：\n\n- S型指令将立即数拆开为两部分，使得目的寄存器始终在指令的第11至7位。\n- SB与S、UJ与U这两组指令具有相同字段，但是立即数位置相反。奇怪的设计降低了立即数生成器中多路复用器的端口数量。\n  ![image-20251016102532654](./pictures/image-20251016102532654.png)\n\n下面给出了增加**ALU控制模块**、**状态单元的写信号**、**数据存储器的读信号**和**多路选择器的控制信号**的数据通路图。\n\n![image-20251016102902651](./pictures/image-20251016102902651.png)\n\n我们先来看看ALUOp以外的六个控制信号如何工作。\n\n| 信号名     | 无效时的效果（置0）                                          | 有效时的效果（置1）                                          |\n| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| `RegWrite` | 无                                                           | 被写的寄存器号来自Write register信号的输入，数据来自Write data信号的输入 |\n| `ALUSrc`   | 第二个ALU操作数来自第二个寄存器堆的输出（即 Read data 2 信号的输出） | 第二个ALU操作数是指令的低12位符号扩展                        |\n| `PCSrc`    | PC值被adder的输出所替换，即PC+4得值                          | PC值被adder的输出所替换，即分支目标                          |\n| `MemRead`  | 无                                                           | 读地址由Address信号的输入指定，输出到Read data信号的输出中   |\n| `MemWrite` | 无                                                           | 写地址由Address信号的输入指定，写入内容是Write data信号的输入中的值 |\n| `MemtoReg` | 寄存器写数据得输入值来自ALU                                  | 寄存器写数据的输入值来自数据存储器                           |\n\n下面给出带有控制单元的简单数据通路：\n\n![image-20251016104502612](./pictures/image-20251016104502612.png)\n\n接着我们需要定义每个操作码的取值下（即指令类型）每个控制信号的取值。\n\n| Instr                   | ALUSrc | MemtoReg | RegWrite | MemRead | MemWrite | Branch | ALUOp |\n| ----------------------- | ------ | -------- | -------- | ------- | -------- | ------ | ----- |\n| `R-type`<br />`0110011` | `0`    | `0`      | `1`      | `0`     | `0`      | `0`    | `10`  |\n| `lw`<br />`0000011`     | `1`    | `1`      | `1`      | `1`     | `0`      | `0`    | `00`  |\n| `sw`<br />`0100011`     | `1`    | `x`      | `0`      | `0`     | `1`      | `0`    | `00`  |\n| `beq`<br />`1100011`    | `0`    | `x`      | `0`      | `0`     | `0`      | `1`    | `01`  |\n\n> `x`表示无关。\n\n### 4.4.3数据通路操作\n\n下面介绍三类指令在执行中按信息的流动顺序得到的步骤：\n\n**R-type**\n\n1. 取出指令，PC自增。\n2. 从寄存器堆读出两个寄存器`x2`和`x3`，同时主控制单元在此步骤计算控制信号。\n3. 根据部分操作码确定ALU的功能，对从寄存器堆读出的数据进行操作。\n4. 将ALU的结果写入寄存器堆中的目标寄存器（`x1`）。\n\n---\n\n**load**\n\n1. 从指令存储器中取出指令，PC自增。\n2. 从寄存器堆读出寄存器（`x2`）的值。\n3. ALU将从寄存器堆中读出的值和符号扩展后的指令中的12位（偏移量）相加。\n4. 将ALU的结果用作数据存储器的地址。\n5. 将从存储器读出的数据写入寄存器堆（`x1`）。\n\n---\n\n**beq**\n\n1. 从指令存储器中取出指令，PC自增。\n2. 从寄存器堆中读出两个寄存器`x1`和`x2`。\n3. ALU将从寄存器堆读出的两数相减。PC与左移一位、符号扩展的指令中的12位（偏移）相加，结果是分支目标地址。\n4. ALU的零输出决定将哪个加法器的结果写入PC。\n\n### 4.4.4控制的约束\n\n教材对数据通路的设计在此停步。\n\n如要继续，我们还需要实现更多的指令，可能需要更多的控制信号与多路选择器。\n\n| Instr                   | ALUSrc | MemtoReg | RegWrite | MemRead | MemWrite | Branch | ALUOp | RegDst | Jump |\n| ----------------------- | ------ | -------- | -------- | ------- | -------- | ------ | ----- | ------ | ---- |\n| `R-type`<br />`0110011` | `0`    | `0`      | `1`      | `0`     | `0`      | `0`    | `10`  | `0`    | `0`  |\n| `lw`<br />`0000011`     | `1`    | `1`      | `1`      | `1`     | `0`      | `0`    | `00`  | `0`    | `0`  |\n| `sw`<br />`0100011`     | `1`    | `x`      | `0`      | `0`     | `1`      | `0`    | `00`  | `x`    | `0`  |\n| `beq`<br />`1100011`    | `0`    | `x`      | `0`      | `0`     | `0`      | `1`    | `01`  | `x`    | `0`  |\n| `jal`<br />`1101111`    | `x`    | `x`      | `1`      | `0`     | `0`      | `x`    | `xx`  | `1`    | `1`  |\n| `jalr`<br />`1100111`   | `1`    | `x`      | `1`      | `0`     | `0`      | `0`    | `00`  | `1`    | `j`  |\n\n> 多出来的控制信号参照：\n>\n> 想象多出一条Jump控制信号与Branch和Zero信号的**与门**输出添加一个**或门**，取代原来的与门输出信号。\n>\n> 想象多出一条RegDst控制信号影响一个输入为右上和右下两个多路选择器的输出的多路选择器，其输出影响Write Data。\n\n### 4.4.5为什么现在不使用单周期实现\n\n**效率太低**：单周期设计中时钟周期对于每条指令必须等长。处理器的最长路径决定了时钟周期。（通常是`load`）\n\n## 4.5多周期实现\n\n**多周期**：一条指令的执行被分成多个时钟周期完成，每个周期只完成指令执行的一个阶段（或部分阶段）。\n\n其实现：\n\n- 允许每个指令多次使用同一个功能单元（不同周期），减少所需的硬件数量。\n- 允许指令采用不同数量的时钟周期。\n\n## 4.6流水线概述\n\n**流水线**是一种能使多条指令重叠执行的实现技术。\n\nRISC-V指令执行通常包含五个步骤：\n\n1. 从存储器中取出指令。\n2. 读寄存器并译码指令。\n3. 执行操作或计算地址。\n4. 访问数据存储器中的操作数（如有必要）。\n5. 将结果写入寄存器（如有必要）。\n\n给出一个情境，在此我们假设主要功能单元的操作时间为：\n\n| 指令类型 | 取指令 | 读寄存器 | ALU操作 | 数据存取 | 写寄存器 | 总时间 |\n| -------- | ------ | -------- | ------- | -------- | -------- | ------ |\n| lw       | 200ps  | 100ps    | 200ps   | 200ps    | 100ps    | 800ps  |\n| sw       | 200ps  | 100ps    | 200ps   | 200ps    |          | 700ps  |\n| R-type   | 200ps  | 100ps    | 200ps   |          | 100ps    | 600ps  |\n| beq      | 200ps  | 100ps    | 200ps   |          |          | 500ps  |\n\n单周期设计必须满足最慢的指令的时间作为时间间隔。\n\n流水线设计必须满足最慢的单元操作时间作为单元操作时间间隔。\n如果流水线各阶段操作平衡，那么流水线处理器上的指令执行时间理想化为：\n$$\nT_{流水线}=\\frac{T_{非流水线}}{流水线级数}\n$$\n**在理想和大量指令条件下，流水线带来加速比约等于流水线级数**。\n\n流水线技术通过**提高指令吞吐率**来提高性能，而**不是减少单个指令的执行时间**。\n\n### 4.6.1面向流水线的指令系统设计\n\nRISC-V在流水线指令系统设计的优势：\n\n1. 所有RISC-V指令长度相同。\n2. RISC-V指令格式少，源寄存器和目标寄存器字段的位置相同。\n3. 存储器操作数只出现在load和store中。\n\n### 4.6.2流水线冒险\n\n流水线中有一种情况，在下一个时钟周期中下一条指令无法执行。这种情况叫做**冒险**。\n\n> **结构冒险**\n>\n> 因缺乏硬件支持而导致指令不能在预定的时钟周期内执行的情况。\n\n多条指令在同一时钟周期使用同一个硬件资源时：\n\n```bash\nlw x1, 0(x2)\nsw x3, 4(x2)\n```\n\n> **数据冒险**\n>\n> 因无法提供指令执行所需数据而导致指令不能在预期的时钟周期内执行。\n\n数据冒险源于一条指令依赖于前面一条尚在流水线中的指令：\n\n```bash\nadd x19, x0, x1\nsub x2, x19, x3\n```\n\n这会导致`sub`所在指令流水线不得不在**ID**阶段等待，这将浪费三个时钟周期。\n\n或许可以通过编译器消除这些冒险，但是面对大量的此类情况效果甚微。\n\n一种基本的解决方案是通过**向内部资源添加额外的硬件以尽快找到缺少的运算项的方法**。\n\n> **前递或旁路**：提前从内部缓冲中取到数据，而不是等到数据到达程序员可见的寄存器或存储器。\n\n如果对于下面这种情况：\n\n```bash\nlw x3, 0(x1)\nadd x4, x3, x2\n```\n\n> **载入 - 使用型数据冒险**：指当载入指令要取的数据还没取回时，其他指令就需要该数据的情况。\n\n这将浪费四个时钟周期。\n\n第二种方案是**气泡**。\n\n> **流水线停顿**：为了解决冒险而实施的一种阻塞。\n\n也就是对第二个指令适当停顿。这个过程直到第二条指令被取出并译码后才知道是否需要停顿。\n\n第三种方案是**代码重新排序**，比如下面这个例子。\n\n```bash\nlw  x1, 0(x31)\nlw  x2, 8(x31)\nadd x3, x1, x2\nsw  x3, 24(x31)\nlw  x4, 16(x31)\nadd x5, x1, x4\nsw  x5, 32(x31)\n```\n\n简单重排后得到的指令序列将比原始版本快两个时钟周期。\n\n```bash\nlw  x1, 0(x31)\nlw  x2, 8(x31)\nlw  x4, 16(x31)\nadd x3, x1, x2\nsw  x3, 24(x31)\nadd x5, x1, x4\nsw  x5, 32(x31)\n```\n\n> **控制冒险**\n>\n> 也叫**分支冒险**。由于取到的指令并不是所需要的，或者指令地址的流向不是流水线所预期的，导致正确的指令无法在正确的时钟周期内执行。\n\n在条件分支指令中，取出分支指令后，紧接着在下一个时钟周期就会取下一条指令。流水线不能确定下一条指令是哪一条。具体地说：\n\n```bash\nbeq x1, x2, L1\nadd x3, x4, x5\n...\nL1:\nand x9, x10, x11\n```\n\n`beq`只在**EX**才能比较`x1`和`x2`，如果`x1`=`x2`，那么第二条指令的**IF**理应在`beq`的**EX**阶段结束才进行（或者以一种方式abort掉）。\n\n第一种方案是停顿，显而易见，代价不小。\n\n第二种方案是**预测**，一旦发生预测错误，就回滚。\n\n- 一种简单的方法是总是预测（不）发生跳转，若最终判断要跳转，就清空错误的指令。\n\n- > **分支预测**\n  > 预测分支的结果并沿预测方向执行，而不是等分支结果确定后才开始执行。 \n\n  预测一些条件分支指令发生跳转，而另一些不发生跳转。\n  简单来说，是根据每个条件分支是否发生分支的历史记录，根据最近的过去行为来预测未来。\n\n  具体的细节在以后阐述。动态分支预测器的正确率超过$90\%$。\n\n第三种方案是**延迟决定**。\n\n延迟转移顺序执行延迟槽中指令，并在该指令后再执行分支。\n\n> 编译器通常的填充策略：\n>\n> 1. 把**有用的计算指令**提前到延迟槽（避免浪费）。\n> 2. 如果没有合适的指令，就放一条**空操作**（`nop`）。\n\n这种做法在现代超标量或乱序 CPU 中几乎废弃。\n\n---\n\n较长的流水线会恶化预测的性能，并增加预测错误的代价。\n\n### 4.6.3总结\n\n流水线技术是一种在顺序指令流中开发指令间**并行性**的技术。与多处理器编程相比其优点在于它对程序员是不可见的。\n\n> 除存储系统以外，流水线的有效操作是决定处理器CPI及其性能的最重要因素。\n\n> 结构冒险通常出现在浮点单元周围，而浮点单元可能不是完全流水线化的。\n>\n> 控制冒险通常出现在定点程序中，因为其中条件分支指令出现的频率更高，也更难预测。\n>\n> 数据冒险在定点和浮点程序中都可能成为性能瓶颈：\n>\n> - 浮点程序中的数据冒险通常更容易处理，因为其中条件分支指令的频率更低并且存储访问更规则，这使编译器能够调度指令以避免冒险。\n> - 定点程序的存储器访问更不规则且包含大量指针，实现这样的优化更困难。\n\n## 4.7流水线数据通路和控制\n\n数据通路被划分成五个部分：\n\n1. **IF**：取指令。\n2. **ID**：指令译码和读寄存器堆。\n3. **EX**：执行或计算地址。\n4. **MEM**：存储器访问。\n5. **WB**：写回。\n\n![image-20251030101202903](./pictures/image-20251030101202903.png)\n\n如果执行\n\n```bash\nlw x1, 100(x4)\nlw x2, 200(x4)\nlw x3, 400(x4)\n```\n\n看起来三条指令需要三条数据通路。\n\n通过**引入寄存器保存数据**，部分数据通路可以在指令执行的过程中被共享。\n\n例如：指令寄存器只在指令的**IF**阶段使用，为了后四个阶段还能保留指令，可以把从指令寄存器中读取的数据保存在寄存器中。\n\n![image-20251030103226907](./pictures/image-20251030103226907.png)\n\n> **IF/ID**寄存器的位宽必须为96位，包括存储器中提取出的32位指令以及自增的64位PC地址。目前，其它三个流水线寄存器位宽分别为256位、193位和128位。\n\n**PC**也可被看作一个流水线寄存器，它给**IF**阶段提供数据。\n不同的是，在发生**例外（异常）** 时，**PC**的内容必须被保存。\n\n---\n\n下面给出很多图显示了`lw`在通过流水线的五个阶段。其中左半阴影表示被**写入**，右半阴影表示被**读取**。\n\n![image-20251030105157630](./pictures/image-20251030105157630.png)\n\n1. **取指**：**PC**指令进入**IF/ID**，**PC**自增4。\n\n![image-20251030105222726](./pictures/image-20251030105222726.png)\n\n2. **指令译码和读寄存器堆**：**Imm**和寄存器编号和**PC**地址都被放入**ID/EX**。\n\n![image-20251030105434760](./pictures/image-20251030105434760.png)\n\n3. **执行或计算地址**：读取一个寄存器的值和**Imm**，加和存入**EX/MEM**。\n\n![image-20251030105457715](./pictures/image-20251030105457715.png)\n\n4. **存储器访问**：读取存入**MEM/WB**。\n\n![image-20251030105518631](./pictures/image-20251030105518631.png)\n\n5. **写回**：写回。\n\n> 你可能好奇**rd**（目标寄存器）如何确定，会不会要在写回阶段再读**IF/ID**呢（显然不会，因为此时**IF/ID**可能都不存当前指令了。事实上**rd**被解析到**IF/ID**，随着流水线寄存器行走）。\n>\n> ~~我醉了，教材后面才指出这个问题并给了一个修正版。~~\n>\n> ![image-20251030112629111](./pictures/image-20251030112629111.png)\n\n存储指令留作读者思考。\n\n**每一个逻辑部件只能在单个流水线阶段中被使用，否则发生结构冒险**。\n\n### 4.7.1流水线的图形化表示\n\n**多时钟周期流水线图**，考虑：\n\n```bash\nlw  x10, 40(x1)\nsub x11, x2, x3\nadd x12, x3, x4\nlw  x13, 48(x1)\nadd x14, x5, x6\n```\n\n同样地，左半阴影表示被**写入**，右半阴影表示被**读取**。\n\n![image-20260104131258012](./pictures/image-20260104131258012.png)\n\n**单时钟周期流水线图**显示了在一个单时钟周期内整个数据通路的状态：\n\n![image-20251104225819556](./pictures/image-20251104225819556.png)\n\n### 4.7.2流水线控制\n\n我们要将控制添加到流水线数据通路中。\n\n第一步是在现有的数据通路上标记控制线。\n\n![image-20251104230200355](./pictures/image-20251104230200355.png)\n\n与单周期实现的情况一样，假定**PC**在每个时钟周期被写入，因此**PC**没有单独的写入信号，流水线寄存器也是如此，因为它们也在每个时钟周期内被写入。\n\n因为每条控制线都只与一个流水线阶段中的功能部件相关，所以可以把控制线划分为五组。\n\n1. **取指**：该指令存储器和写**PC**的控制信号总是有效的，因此这个阶段没有什么需要特别控制的内容。\n2. **指令译码和读寄存器堆**：在**RISC-V**指令格式中两个源寄存器总是位于相同的位置，因此在这个阶段也没有什么需要特别控制的内容。\n3. **执行或计算地址**：设置**ALUOp**和**ALUSrc**。\n4. **存储器访问**：设置**Branch**、**MemRead**和**MemWrite**。\n5. **写回**：设置**MemtoReg**和**RegWrite**。\n\n![image-20251104231752972](./pictures/image-20251104231752972.png)\n\n![image-20251104231820186](./pictures/image-20251104231820186.png)\n\n## 4.8数据冒险：前递与停顿\n\n看一个存在更多相关的指令序列：\n\n```bash\nsub  x2, x1, x3\nand  x12, x2, x5\nor   x13, x6, x2\nadd  x14, x2, x2\nsw   x15, 100(x2)\n```\n\n后四个指令都依赖于第一条指令的修改。\n\n![image-20251106095136842](./pictures/image-20251106095136842.png)\n\n`sw`指令不会发生数据冒险。我们研究一下`add`指令：\n\n这一个潜在的冒险可以通过寄存器堆的硬件设计来解决：**假定写操作发生在一个时钟周期的前半部分，读操作发生在后半部分**。\n\n`and`和`or`指令会发生数据冒险：但我们发现，如果可以把`sub`指令**EX**阶段结果前递给等待该数据的单元，就不需要停顿地执行这段指令。\n\n书上采取一种诡异的文法检测冒险：\n\n- 定义**ID/EX.RegisterRs1**表示一个寄存器的编号，它的值在**ID/EX**中。可以得到两对冒险的条件：\n  - **EX/MEM.RegisterRd=ID/EX.RegisterRs1**\n  - **EX/MEM.RegisterRd=ID/EX.RegisterRs2**\n  - **MEM/WB.RegisterRd=ID/EX.RegisterRs1**\n  - **MEM/WB.RegisterRd=ID/EX.RegisterRs2**\n\n`and`指令的数据冒险可以由第一个条件表示，`or`指令的数据冒险可以由第四个条件表示。\n\n额外修正：\n\n- 如果指令不会写回寄存器，那就不需要前递，这可以通过检查**RegWrite**判断。\n- 考虑`x0`这个特殊的寄存器，我们还要要求**EX/MEM.RegisterRd≠0**，**MEM/WB.RegisterRd≠0**。\n\n---\n\n![image-20251106101200750](./pictures/image-20251106101200750.png)\n\n通过在**ALU**输入上添加多选器再辅以适当的控制，就可以在存在数据冒险的情况下全速运行流水线。\n\n![image-20251106101624752](./pictures/image-20251106101624752.png)\n\n![image-20251106101640860](./pictures/image-20251106101640860.png)\n\n你可以发现，现在需要让**ID/EX**留出存储**Rs1**和**Rs2**的存储空间。\n\n~~试着自己补充前递信号？~~\n\n只要满足某个冒险条件，我们就会修改**Forward**信号，实现前递。\n\n![image-20251106103002353](./pictures/image-20251106103002353.png)\n\n---\n\n当一条指令在加载指令写入一个寄存器之后读这个寄存器，前递不能解决此处的冒险。此时必须阻塞以消除这种指令组合带来的冒险。\n\n![image-20251106103419262](./pictures/image-20251106103419262.png)\n\n如果**EX**阶段的加载指令的目标寄存器与**ID**阶段的指令中的某一个源寄存器相匹配，那么后者就会停顿一个时钟周期，具体是：\n\n- 如果处于**ID**阶段的指令被停顿了，那么在**IF**阶段中的指令也要被停顿，否则已经取到的指令就会丢失。这可以通过禁止**PC**和**IF/ID**的改变。\n- **EX**阶段开始的流水线后半部分必须执行**空指令（通过设置控制这些阶段的信号为0）**。\n\n![image-20251106105727232](./pictures/image-20251106105727232.png)\n\n为此，我们需要一个**冒险检测单元**。\n\n![image-20251106105750806](./pictures/image-20251106105750806.png)\n\n## 4.9控制冒险\n\n![image-20251106110111386](./pictures/image-20251106110111386.png)\n\n因为是否跳转在**DM**才决定，所以如果不加干预，后3个指令会偷偷执行。\n\n### 4.9.1假设分支不发生\n\n一种提升分支阻塞效率的方法是**预测**条件分支不发生并持续执行顺序指令流，一旦条件分支发生，已经被读取和译码的指令就将被**丢弃**。\n\n### 4.9.2缩短分支延迟\n\n书上给了令人**绝望**的一页字，大致说的是：\n\n一种提升条件分支性能的方式是**减少发生分支时所需的代价**：如果将流水线中的条件分支指令提早移动执行，就可以刷新更少的指令，这需要两个操作提早发生：\n\n- 计算分支目标地址：把**EX**阶段得到的分支地址移动到**ID**阶段。\n- 分支决定：\n  - 在**ID**阶段将指令译码，决定是否要将指令旁路至检测单元，并且完成测试以防要发生分支，如果是，就把**PC**设置为分支目标地址。麻烦的是，这需要添加新的前递逻辑，于是有了**冲突检测单元**。\n  - 在**ID**阶段分支比较所需的值可能还会发生改变，因此会发生数据冒险。例如：\n    - 如果一条**ALU**指令在分支指令之前且产生条件分支检测所需的操作数，那么对分支指令停顿是必要的。\n    - 如果加载指令在分支指令之后，并且分支指令依赖加载指令的结果，那么对加载指令停顿是必要的。\n\n```bash\n36 sub  x10, x4, x8\n40 beq  x1,  x3, 16\n44 and  x12, x2, x5\n48 or   x13, x2, x6\n52 add  x14, x4, x2\n56 sub  x15, x6, x7\n...\n72 lw   x4, 50(x7)\n```\n\n![image-20251106144519015](./pictures/image-20251106144519015.png)\n\n上面是第三、四个时钟周期的单周期流水线图。\n\n注意：图中添加了**IF.Flush**控制线，它用来清除**IF/ID** 。\n\n### 4.9.3动态分支预测\n\n> **动态分支预测**：在程序运行时使用运行信息进行分支预测。\n\n这里采用一种策略：检查指令中的地址，查看上一次该指令执行时条件分支是否发生的跳转，如果发生了，则从上一次执行的地址中取出指令。\n\n> **分支预测缓存**：也称分支历史表，一块按照分支指令的低位地址定位的小容量存储器，包含一个或多个比特以表明一个分支最近是否发生了跳转。\n\n分支预测缓存是一块按照分支指令的地位地址定位的小容量存储器，包含一个比特，表明一个分支最近是否发生了跳转。\n\n我们会依赖存储器提供的假设跳转，如果这个假设是错误的，那就把它取反。\n\n> [!NOTE]\n>\n> 现在考虑一个循环分支，它在一行代码中发生了$9$次跳转，之后产生$1$次未跳转。假定这个分支的预测位在预测缓存中，则这条分支指令的预测正确率为$80\%$（首次和最后一次）。\n\n这个例子中：\n\n- 如果连续发生跳转的次数更多，那么预测正确率必然会更高，然而如果**跳转未跳转交替发生**，或者更复杂的情况，正确率并不会很高。\n- 理想状态下，对于规律性很强的分支来说：分支预测的准确率应该与分支发生的频率相匹配。通常我们采用更多的预测位机制。\n- 在$2$位预测机制中，只有在发生两次错误时预测结果才会被改变。如图：![image-20251111182450256](./pictures/image-20251111182450256.png)\n\n> **分支目标缓存**：一个缓存分支目标**PC**值或目标指令的结构。通常被组织为一个带有标记的缓存，相比简单的预测缓存需要更多的硬件消耗。\n\n分支预测缓存可以被实现为一个小而专用的、可以被**IF**阶段的指令地址所访问的缓存。\n\n如果指令被预测为跳转，一旦新的**PC**已知就开始从目标地址取指，这个操作可以被前移至**ID**阶段。\n\n> **相关预测器**：一种组合了特殊分支指令的局部行为和最近执行的一些分支指令的全局行为信息的分支预测器。\n\n研究表明，对于相同的预测位，同时使用局部分支和最近执行分支的全局行为的信息能获得更好的预测准确率。\n\n> **锦标赛分支预测器**：一个对于每个分支具有多种预测的分支预测器，其具有一种选择机制，该机制选择对于给定分支选择哪个预测器作为预测结果。\n\n选择基于局部信息和基于全局分支行为中更准确的那个。\n\n### 4.9.4流水线总结\n\n![image-20251111183407164](./pictures/image-20251111183407164.png)\n\n## 4.10例外\n\n> **例外**：也称异常，与中断并指那些打断程序正常执行的意外事件，比如未定义指令。\n\n> **中断**：来自于处理器外部的例外，一些体系结构也会使用中断表示所有的例外。\n\n这个概念有些模糊，我们做一下修正：\n\n> [!NOTE]\n>\n> **异常（例外）(Exception)**：指代意外的控制流变化。\n>\n> **中断（Interrupt）**：指代由处理器外部事件引发的控制流变化。\n\n| 事件类型                 | 例外来源 | RISC-V中的表示 |\n| ------------------------ | -------- | -------------- |\n| 系统重启                 | 外部     | 异常           |\n| I/O设备请求              | 外部     | 中断           |\n| 用户程序进行操作系统调用 | 内部     | 异常           |\n| 未定义指令               | 内部     | 异常           |\n| 硬件故障                 | 皆可     | Both           |\n\n### 4.10.1RISC-V体系结构中如何处理异常\n\n> **SEPC**：64位寄存器，用来保存引起例外的指令的地址。\n>\n> **SCAUSE**：用来记录例外原因的寄存器。**RISC-V**中该寄存器为$64$位，大多数位未被使用。（未定义指令为$2$，硬件故障为$12$）。\n\n发生异常时，控制权将转交给操作系统，由操作系统根据异常原因做出操作。\n\n获得异常原因的方法：\n\n- 通过**SCAUSE**获得异常原因，这是**RISC-V**使用的方法。\n\n- **向量式中断**：\n\n  设置一个**基址寄存器**，保存了向量式中断内存区域的起始地址。\n\n  | 异常类型   | 偏移       |\n  | ---------- | ---------- |\n  | 未定义指令 | 0001000000 |\n  | 硬件故障   | 0110000000 |\n\n  具体来说，用基址寄存器的起始地址加上偏移（SCAUSE决定），来到对应异常处理的区域（$32$字节或$8$条指令大小的区域），供操作系统记录异常原因并进行简单处理。\n\n\n### 4.10.2流水线实现中的异常\n\n流水线把异常处理看成另一种控制冒险，具体来说：\n\n- 为**PC**多选器新增一个输入，在**RISC-V**中这个输入是`0000 0000 1C09 0000`作为异常入口地址。\n- 发生异常时，清楚当前指令的执行（具体来说：$flush$掉异常发生阶段之前的流水线寄存器，异常发生阶段之后的指令正常执行），在**SEPC**保存当前执行的指令地址（而不是下一个指令地址），**PC**跳转到异常入口地址。\n\n![image-20251111220139467](./pictures/image-20251111220139467.png)\n\n一个周期可能发生多个异常，**RISC-V**的方案是按照**固定的硬件优先级规则**处理异常。通常**异常**比**中断**优先级高，**SCAUSE**当然记录最高优先级的异常信息。\n\n另外，部分异常的处理机制相同，比如**I/O设备请求**和**硬件故障**，它们的处理机制可以复用。\n\n## 4.11指令间的并行性\n\n之前我们接触了流水线实现的**指令级并行（ILP）**，还有一种提高指令级并行度的方法是**多发射**。\n\n> **多发射**：一个时钟周期内可以发射多条指令的策略。\n\n显然这个技术实现稍显复杂，还需要考虑哪些指令可以同时执行（这部分指令会打包并放入**发射槽**），可能更多的冒险。\n\n> **静态多发射**：多发射的一种实现方法：由编译器判断哪些指令发射。\n\n> **动态多发射**：多发射的一种实现方法：由硬件完成发射相关判断。\n\n### 4.11.2静态多发射\n\n> **发射指令包**：同一周期发射的指令组合。可能是由编译器静态打包，也可能是由处理器在动态执行过程中进行调度。\n\n> **超长指令字**：一种类型的指令系统体系结构，支持在单条指令中使用不同的编码位来定义多个可同时被发射的独立操作。\n\n静态多发射处理器会将**发射指令包**看成一条预先定义好、需要进行多种操作的指令。\n\n一些处理器为简化指令的译码和发射，对可同时发射的指令组合做出了限制，双发射**RISC-V**处理器为例：\n\n- 指令成对。\n- 指令地址需要64位边界对齐。\n- **ALU**指令和分支指令放在前面。\n- 当怎样都有一条指令需要单独发射，给它组合**nop**指令。\n\n对于冒险：\n\n- 编译器解决**所有**的冒险，完成代码调度和**nop**插入。\n- 硬件检测两个指令包之间数据冒险，产生流水线停顿。编译器只负责单个指令包中的类型相关。\n\n假设采取第二种处理冒险的方法：\n\n首先要添加：\n\n- 寄存器堆的读写口（同一个时钟周期内，**ALU**指令需要读取两个源寄存器，**store**指令可能需要读两个以上的源寄存器；**ALU**和**load**指令也都需要更新一个目标寄存器）以避免**结构冒险**。\n\n另外，**load**指令有一个周期的**使用延迟**，如果后续指令使用**load**的结果，必须停顿一周期。在双发射下，这将停顿后续两条指令的执行。\n\n另另外，双发射下，同时发射**ALU**和**l/s**指令，如果它们本身就有数据冒险，那么有一个会被替换为**nop**，这将导致**ALU**也具有**使用延迟**。\n\n![image-20251112114720769](./pictures/image-20251112114720769.png)\n\n> **循环展开**：一种针对数组访问循环体的提高程序性能的技术。它将循环体展开多遍，对不同循环内的指令进行统一调度。\n\n> **反相关**：也叫名字相关，由于名字复用被迫导致的顺序排列。\n\n> **寄存器重命名**：编译器或硬件对寄存器进行重命名，消除指令序列中的反相关。\n\n我们看一个例子就能清晰地明白程序是如何通过**循环展开**结合**寄存器重命名**完成优美的优化。\n\n```bash\nLoop: lw   x31, 0(x20)\n      add  x31, x31, x21\n      sw   x31, 0(x20)\n      addi x20, x20, -4\n      blt  x22, x20, Loop\n```\n\n上述代码实现功能如下：\n\n```c++\nfor(int i = 0; i < n; ++i) {\n    a[i] += constant;\n}\n```\n\n双发射流水线进行调度后：\n\n|       | ALU或branch指令      | 数据传输指令     | 时钟周期 |\n| ----- | -------------------- | ---------------- | -------- |\n| Loop: | `nop`                | `lw x31, 0(x20)` | 1        |\n|       | `addi x20, x20, -4`  | `nop`            | 2        |\n|       | `add x31, x31, x21`  | `nop`            | 3        |\n|       | `blt x22, x20, Loop` | `sw x31, 4(x20)` | 4        |\n\n循环展开（4重）后：\n\n|       | ALU或branch指令      | 数据传输指令      | 时钟周期 |\n| ----- | -------------------- | ----------------- | -------- |\n| Loop: | `addi x20, x20, -16` | `lw x28 0(x20)`   | 1        |\n|       | `nop`                | `lw x29, 12(x20)` | 2        |\n|       | `add x28, x28, x21`  | `lw x30, 8(x20)`  | 3        |\n|       | `add x29, x29, x21`  | `lw x31, 4(x20)`  | 4        |\n|       | `add x30, x30, x21`  | `sw x28, 16(x20)` | 5        |\n|       | `add x30, x30, x21`  | `sw x29, 12(x20)` | 6        |\n|       | `nop`                | `sw x30, 8(x20)`  | 7        |\n|       | `blt x22, x20, Loop` | `sw x31, 4(x20)`  | 8        |\n\n这使得流水线性能提高了$1$倍以上。\n\n### 4.11.3动态多发射\n\n有些困难，略。\n\n## 4.15谬误与陷阱\n\n**谬误：流水线是简单的**。\n\n**谬误：对于流水线等结构设计，可以与工艺无关**。\n\n**陷阱：缺乏对指令系统设计的考虑反过来会影响流水线的实现**。' 
                      },
                      { id: 'computer_organization_and_architecture-5', 
                        title: '5、层次化存储', 
                        desc: '', 
                        content: '# 5.层次化存储\n\n## 5.1引言\n\n> **局部性原理**：访问某个数据项，则它或相邻的数据很容易再被访问。\n\n基于此构建计算机的存储系统，也叫**存储层次结构**：\n\n- 存储速度越快，价格越昂贵，但容量越小。\n- 速度越快的存储越靠近处理器（比如寄存器）；越慢的存储成本越低，离处理器越远。\n\n| 速度 | 处理器   | 尺寸 | 价格 | 当前技术 |\n| ---- | -------- | ---- | ---- | -------- |\n| 最快 | 小存储器 | 最小 | 最高 | SRAM     |\n|      | 中存储器 |      |      | DRAM     |\n| 最慢 | 大存储器 | 最大 | 最低 | 磁盘     |\n\n下面介绍很多基础概念：\n\n**块或行**：在相邻两层之间进行信息交换的最小单元。\n\n**命中（hit）**：处理器所需的数据在本层的存储中找到。\n\n**失效（miss）**：没能在本层存储中找到所需数据。\n\n**命中率（hit rate）**：在访问某个存储层次时命中的次树占总访问次数的比例。\n\n**失效率（miss rate）**：在访问某个存储层次时失效的次树占总访问次数的比例。\n\n**命中时间（hit time）**：访问某个存储层次所需的时间，包括判断命中或失效的时间。\n\n**失效损失（miss penalty）**：将数据块从下层存储复制至某层所需的时间，包括数据块的访问时间、传输时间、写入目标层的时间和将数据块返回给请求者的时间。\n\n## 5.2存储技术\n\n| 存储技术 | 典型访问时间（ns）    | 单位成本（美元/GB） |\n| -------- | --------------------- | ------------------- |\n| SRAM     | $0.5\\sim2.5$          | $500\\sim1000$       |\n| DRAM     | $50\\sim70$            | $3\\sim6$            |\n| 闪存     | $5000\\sim50000$       | $0.06\\sim0.12$      |\n| 磁盘     | $5000000\\sim20000000$ | $0.01\\sim0.02$      |\n\n### 5.2.1SRAM存储技术\n\n**SRAM**存储是一种存储阵列结构的简单集成电路，通常有一个读写端口。每比特**SRAM**采用$6$或$8$个晶体管实现，断电时信息丢失，待机模式下只需要最小的功率保持电荷。\n\n### 5.2.2DRAM存储技术\n\n**DRAM**存储使用单个晶体管存储每个比特，因此不能长久保持数据（电容漏电），必须进行周期性地刷新。相比**SRAM**密度更高，价格更低廉。断电时信息丢失。\n\n**DRAM**中的电荷可以保持几微秒，使用两级译码电路，同一行上的数据共享一条字线，使得我们可以使用一个读周期紧跟一个写周期的方式一次性完成整行刷新。\n\n![image-20251229221838257](./pictures/image-20251229221838257.png)\n\n> **DRAM**被分成若干个**bank**，它们可以**并发**读写，轮转访问，这叫**交叉地址访问（address interleaving）**。每个**bank**都有自己的**行缓冲寄存器（Row Buffer)**。\n>\n> **row**存储一整行上的数据，当激活一个**row**时，对应行的数据会被搬进**Row Buffer**，这个过程非常耗时且耗电。\n>\n> **column**是数据的“字”，用于决定第几个比特被送到芯片引脚上，切换列地址的速度是非常快的；或者给定一个起始列地址，发送地址后面指定个数据的速度也是非常快的。后者取决于芯片位宽。\n\n**SDRAM**：同步**DRAM**，是**DRAM**添加了时钟，用于配合上面提到的**起始列地址**发送数据。其中**DDR SDRAM**可以同时在时钟上升/下降沿进行数据传输。\n\n### 5.2.3闪存\n\n**闪存**是一种**电可擦除的可编程只读存储器**。\n\n因为缓存写操作会产生磨损，所以包含一个控制器，用于将多次写的块映射到较少写的块，使得操作尽可能分散。这叫**耗损均衡（wear leveling）**。\n\n### 5.2.4磁盘\n\n磁盘包括一堆盘片，每一面都被磁性记忆材料覆盖。一个称为**读写头**的小型电磁线圈在盘面上方读写信息。\n\n每个磁盘表面被分为若干个同心圆称为**磁道**。\n\n每条磁道分为上千个**扇区**，包括**扇区号，间隙，信息，间隙，下一扇区号**。\n\n每个盘面配有**磁头**，可以读写每个盘面的每一条磁道。\n\n**柱面**表示所有盘面上半径相同的磁道。\n\n**寻道**是把磁头定位在正确的磁道上方的过程，其时间是**寻道时间**。\n\n**旋转延时**是磁盘上所需扇区旋转到读写磁头下的时间，通常假设为旋转半周的时间。\n\n磁盘控制器也会内置一个缓存，用来保存刚刚读取过的扇区的数据。\n\n## 5.3cache基础\n\n### 5.3.1cache访问\n\n对于总共1024个cache行的直接映射，每个cache行数据块大小为4B，考虑32位字节地址可以被分隔为如下三段：\n\n| Tag     | Index  | Byte offset |\n| ------- | ------ | ----------- |\n| [31:12] | [11:2] | [1:0]       |\n\n一个cache行包括\n\n| Valid | Dirty | Tag     | Data   |\n| ----- | ----- | ------- | ------ |\n| [53]  | [52]  | [51:32] | [31:0] |\n\n> [!caution]\n>\n> 注意区分**字地址**和**字节地址**，大部分情况下1字等于4字节等于32位。\n>\n> 显然Tag的长度是由cache行个数和字地址长度决定的。\n\n参考书本上例题：\n\n> [!note]\n>\n> 假设64位的存储地址，对于直接映射cache，如果数据大小为16KiB，每个数据块为4字大小。该cache容量多大？\n>\n> **解答**：16KiB=2^14B=2^12字，每个数据块是4字=128位，所以cache行的个数是2^12/4=2^10个（$数据大小=Data位数（数据块大小）\\times cache个数$），对于64位地址，可以认为是这样分段的：\n>\n> | Tag     | Index  | Block offset | Byte offset |\n> | ------- | ------ | ------------ | ----------- |\n> | [63:14] | [13:4] | [3:2]        | [1:0]       |\n>\n> 从而cache行为：\n>\n> | Valid | Dirty | Tag       | Data    |\n> | ----- | ----- | --------- | ------- |\n> | 179   | 178   | [177:128] | [127:0] |\n>\n> 该cache容量为180*1024/8=23040B=22.5KiB。\n\n---\n\n下面给出块大小（指cache行个数）与失效率的关系：\n\n![image-20251230005744176](./pictures/image-20251230005744176.png)\n\n不难推敲：\n\n- 块大小比较小的时候，考虑块大小为4，每个cache行存储256位数据：\n\n  ```c++\n  int a[114514] = {0};\n  for(int i = 0; i < 8; ++i) {\n      for(int j = 0; j < 5; ++j) {\n          ++a[j * 8 + i];\n      }\n  }\n  ```\n\n  后果是全miss了。\n\n- 块大小比较大的时候，会发生太多初始访问，它们一定是miss的。\n\n### 5.3.2处理cache失效\n\n**I-cache**失效：暂停处理器。一种方案是只暂停取指，流水线剩余的指令会被执行完；另一种方案是全线暂停，流水线寄存器锁存自己的信息。保留导致cache miss的指令，缓存写入后重新读取该条指令。\n\n不难想到第二种方案发生cache miss时，如果一个跳转指令发生，PC发生了改变，使得cache miss不应发生，相关逻辑会比较复杂。\n\n**D-cache**失效：简单地暂停处理器，直到内存返回数据。由于访问内存是五级流水线的第四阶段，通常前面阶段的指令会被暂停，流水线寄存器锁存自己的信息。\n\n### 5.3.3处理写操作\n\n**写穿透**或**写直达**：如果cache被更改，立即将数据写回主存保持内容一致。\n\n显然这种方案很蠢，只是修改cache内容就要付出接近cache miss的代价。\n\n**写缓冲**：开辟一个缓冲区保存等待写回主存的数据，当缓冲区满了，停顿流水线，将缓冲区数据写回主存，直到产生空位。\n\n显然如果写操作产生速度快于主存处理速度（在频繁递归调用中很容易发生这种事），那么缓冲区几乎一直是满的，导致几乎和写穿透一样低的效率。\n\n**写返回**：这就是脏位（Dirty）存在的意义。当缓存数据被改写，就赋脏位为1，当缓存行被覆盖，若脏位为1，才执行写回主存操作。\n\n写回主存的过程很慢，可以在cache与CPU之间设置**Store Buffer**：\n\n- CPU只要把数据和目标地址丢进Store Buffer，就认为写操作完成，这样cache写回主存时依然可以执行指令。\n- Store Buffer在Cache空闲时，就自动把数据搬进去。\n- 如果Store Buffer发现接连好几个写操作都是往同一个Cache行写的，它在Store Buffer里把它们合好，一次性塞给Cache。\n\n引入新结构总是意味着新麻烦，比如下一指令读取的数据在Store Buffer里怎么办？Store Buffer对多核是共享的吗？如果不是，当前核访问的数据在另一核的Store Buffer里怎么办？\n\n这里我们不去深究，旨在培养系统级思考的能力。\n\n**写分配**：如果cache miss，CPU直接将数据写入到内存中。\n\n**写不分配**：如果cache miss，CPU将数据写入cache和内存中。\n\n### 5.3.4cache实例：Intrinsity FastMATH 处理器\n\n![image-20251230131012138](./pictures/image-20251230131012138.png)\n\n## 5.4cache的性能评估和改进\n\n我们直接从例题着手：\n\n> [!note]\n>\n> 假设I-cache的失效率为2%，D-cache的失效率为4%。处理器的CPI为2，没有任何的访存停顿；对于所有的失效，失效代价都为100个时钟周期。如果配置了一个从不失效的完美cache，那么处理器的性能会提高多少？假设`load`和`store`指令占36%。\n>\n> **解答**：假设$I$条指令，从不失效的cache的时钟周期是$2\\times I=2I$。\n>\n> `load`和`store`指令带来的访存失效周期数为$I\\times 36\%\\times4\%\\times100=1.44I$。\n>\n> I-cache带来的访存失效周期数为$I\\times2\%\\times 100=2I$。\n>\n> 提高为$\\frac{(2+2+1.44)I}{2I}=2.72$。\n\n由于总有些人追求命中率而忘了命中时间也在相应增加（比如全相联确实有极高的命中率，但是存储的表项多了后，遍历cache的时间成本也很大），所以我们定义**AMAT（平均存储访问时间）** 作为评判指标。\n$$\nAMAT=命中时间+失效率\\times失效代价\n$$\n\n### 5.4.1使用更为灵活的替换策略降低cache失效率\n\n回顾**直接映射**：不同index的数据存放在不同组里，相同index的数据如果tag不同就会发生替换。\n\n**全相联**：没有index的概念。读写数据时，如果当前某个cache行的tag对的上，那么命中。否则若存在未被使用的cache行，就开辟为当前数据的cache行。否则踢出某个cache行的数据,再作为当前数据的cache行。\n\n**n路组相连**：每个cache行复制n份，即：\n\n| index | valid/dirty/tag/data | valid/dirty/tag/data | ...  | valid/dirty/tag/data |\n| ----- | -------------------- | -------------------- | ---- | -------------------- |\n\n不同index的数据存放在不同组里，相同index的数据在组里执行类似全相联的策略。\n\n### 5.4.2在cache中查找数据块\n\n感觉你已经很懂了嘛，我们来做题：\n\n> [!note]\n>\n> 32位字地址，考虑4路组相联cache，数据块为4字大小，若有$n=2^k(k\\ge1)$个cache组，状态位仅考虑有效位和脏位。\n>\n> （1）cache容量是多少？\n>\n> **解答**：最清晰的做法还是给地址和cache组分段：\n>\n> | Tag      | Index   | Block offset | Byte offset |\n> | -------- | ------- | ------------ | ----------- |\n> | [31:k+4] | [k+3:4] | [3:2]        | [1:0]       |\n>\n> | Valid/Dirty/Tag/Data | Valid/Dirty/Tag/Data | Valid/Dirty/Tag/Data | Valid/Dirty/Tag/Data |\n> | -------------------- | -------------------- | -------------------- | -------------------- |\n> | [631-4k:474-3k]      | [473-3k:316-2k]      | [315-2k:158-k]       | [157-k:0]            |\n>\n> cache容量是$\\frac{((632-4k)\\times2^k)}{8}$B。\n\n### 5.4.3选择替换的数据块\n\n最常用的策略是**最近最少使用（Least Recently Used，LRU）**。\n\n对于直接映射，由于LRU策略是针对单个cache组的，所以没有体现。\n\n对于全相联或多路组相联：\n\n- 若有2个cache行，当第1个cache行被访问时，用一个寄存器记录。当当前组要踢出cache行时，踢出未被记录的cache行。\n\n- 若有$n(n>=3)$个cache行，事情就略显复杂，不难想到一个精确的LRU需要维护一个势为$n!$的双射，例如当$n=4$：\n\n  ```\n  0123 -> 1230  0 -> 9\n  0132 -> 1320  1 -> 11\n  0213 -> 2130  2 -> 15\n  0231 -> 2310  3 -> 17\n  0312 -> 3120  4 -> 21\n  0321 -> 3210  5 -> 23\n  \n  1023 -> 0231  6 -> 3\n  1032 -> 0321  7 -> 5\n  1203 -> 2031  8 -> 13\n  1230 -> 2301  9 -> 16\n  1302 -> 3021  10-> 19\n  1320 -> 3201  11-> 22\n  \n  2013 -> 0132  12-> 1\n  2031 -> 0312  13-> 4\n  2103 -> 1032  14-> 7\n  2130 -> 1302  15-> 10\n  2301 -> 3012  16-> 18\n  2310 -> 3102  17-> 20\n  \n  3012 -> 0123  18-> 0\n  3021 -> 0213  19-> 2\n  3102 -> 1023  20-> 6\n  3120 -> 1203  21-> 8\n  3201 -> 2013  22-> 12\n  3210 -> 2103  23-> 14\n  ```\n\n  当$n$很大，精确LRU很不现实。对于$n=4$有一种粗略LRU的实现：\n\n  为每个组额外分配3个Bit，组成一棵二叉树：\n\n  - Bit 0：指向左半边（Way 0，1）还是右半边（Way 2，3）。\n  - Bit 1：如果选了左半边，指向Way 0还是Way 1。\n  - Bit 2：如果选了右半边，指向Way 2还是Way 3。\n\n  如果访问Way 2，那么修改Bit 0指向左半边，Bit 2指向Way 3。\n\n还有一种策略是**随机踢出**，虽然很莫名其妙，但是效率惊人的高。\n\n### 5.4.4使用多级cache减少失效代价\n\n通常高级cache比低级cache容量大得多，相连度也会更高，访问高级cache比访问主存的代价多得多。\n\n> [!note]\n>\n> 假设所有的存储访问在一级cache命中，则基准处理器的CPI为1，时钟频率为4GHz。假设主存访问时间为100ns，包括所有失效处理过程。一级cache中每条指令的平均失效率为2%。现增加二级cache，访问时间为5ns，容量足够大，失效率为0.5%。则处理器增速多少？\n>\n> **解答**：1时钟周期为$\\frac{1}{4\\times10^9}s=0.25ns$，所以主存访问时间为400时钟周期，二级cache访问时间为20时钟周期。设指令条数$I$。\n>\n> 未增加二级cache的时钟周期数为$I+2\%I\\times 400=9I$。\n>\n> 增加二级cache的时钟周期数为$I+2\%I\\times20+0.5\%I\\times400=1+0.4+2=3.4I$。\n\n> [!caution]\n>\n> 你可能会疑惑题目中失效率为0.5%是不是有歧义？我也觉得，但是如果这里的0.5%表示L2 cache的局部失效率，那么L2cache的表现比L1cache好得多！这通常不合常理。那么你可以算出L2cache的局部失效率吗？不难得到应该是25%。\n\n![image-20251230195330134](./pictures/image-20251230195330134.png)\n\n### 5.4.5通过分块进行软件优化\n\n> [!note]\n>\n> ```c++\n> #define N 256\n> double M[N][N];\n>    for(int i = 0; i < N; ++i) {\n>        for(int j = 0; j < N; ++j) {\n>         ans[j][i] = M[i][j];\n>     }\n> }\n> ```\n>\n> 两个矩阵都以行优先方式存储。处理器带有一个16KiB全相联、LRU策略的D-cache，cache line大小为64字节，采取写分配策略。\n>\n> (1)若要保证**最大程度地利用**cache，输入矩阵和输出矩阵的起始地址应该按多少字节对齐。\n>\n> **解答**：$16KiB=2^{14}B$，所以有$2^8$个cache line，每个cache line可以存储$8$个double元素。矩阵应该按$64$字节对齐。（如果不记得为什么，回去看地址分段）。\n>\n> (2)设块大小为$B\\times B$，如果要采用分块执行的策略，使程序cache性能最好的$B$的值可以是？理想最小缺失率是？\n>\n> **解答**：我们希望`ans[j][i]`和`M[i][j]`的命中率尽可能高。如果令$B=8$，对于第一个块，会把`M[0][0:7]`放在0号cache行，`ans[0][0:7]`放在1号cache行，...，`ans[7][0:7]`放在8号cache行，接着`ans`的写入将不会miss，`M`的读出都将会是1次miss和7次hit,然后下一组`M`可以复用原先的cache行。你可能已经明白了：对于每个块，都将用掉$9$个cache行，且每个cache行都被利用殆尽，并保持着最小$12.5\%$的缺失率。因为我们有256个cache行，所以B取不大于248的8的倍数都会是最好效率。\n>\n> ~~批注，后来证明这个答案是错误的。模拟的结果应该是**B取不大于224的8的倍数**。~~\n\n## 5.5可靠的存储器层次\n\n### 5.5.1失效的定义\n\n**平均无故障时间（MTTF）** 是可靠性的度量方法，代表设备平均多少年才会失效一次。\n\n**年度失效率（AFR）** 指给定MTTF一年内预期的器件失效百分比。\n$$\nAFR=\\frac{365\\times24h}{MTTF}\n$$\n**平均修复时间（MTTR）** 代表设备修复好的平均时间。\n\n**平均失效间隔时间（MTBF）**=MTTF+MTTR。\n$$\n可用性=\\frac{MTTF}{MTTF+MTTR}\n$$\n\n### 5.5.2纠正1位错、检测2位错的汉明编码\n\n> [!note]\n>\n> 假设一个8位数据10011010，写出对应的汉明纠错码，再将其第10位取反，体会纠错过程。\n>\n> **解答**：\n>\n> | 1     | 2     | 3    | 4     | 5    | 6    | 7    | 8     | 9    | 10   | 11   | 12   |\n> | ----- | ----- | ---- | ----- | ---- | ---- | ---- | ----- | ---- | ---- | ---- | ---- |\n> | **0** | **1** | 1    | **1** | 0    | 0    | 1    | **0** | 1    | 0    | 1    | 0    |\n>\n> 第1位是编号二进制第1位为1的的数的异或值。\n>\n> 以此类推。\n>\n> 取反第10位：011100101110。\n>\n> 按得到汉明码的方法验证汉明码，发现第2、8位出错推得第2+8=10位出错。\n\n上述方法能做到1位检错，下面是符合标题的进阶方法：\n\n> [!note]\n>\n> 假设一个4位数据1101，在上述方法的基础上，末尾增加1位偶校验位p。\n>\n> | 1     | 2     | 3    | 4     | 5    | 6    | 7    | 8     |\n> | ----- | ----- | ---- | ----- | ---- | ---- | ---- | ----- |\n> | **1** | **0** | 1    | **0** | 1    | 0    | 1    | **0** |\n>\n> 像上一种方法一样计算奇偶校验位$H$。\n>\n> $p$是当前所有位的异或和。\n>\n> 以下是可能出现的4种情况:\n>\n> 1. $H＝0\\land p=0$，表示没有错。\n> 2. $H\\ne 0\\land p=1$，表示发生了1位可纠正错误。\n> 3. $H=0\\land p=1$，表示仅$p$出错\n> 4. $H≠0\\land p=0$，表示发生了2位错。\n\n有兴趣可以了解里德所罗门码，这个加密被用在了二维码中。\n\n## 5.6虚拟机\n\n略。\n\n## 5.7虚拟存储\n\n虚拟存储实现了将程序地址空间转换为物理地址，加强了各个程序地址空间之间的保护。\n\n同时虚拟存储免去了程序员划分物理内存的麻烦，这个工作由虚拟内存自动管理。\n\n**页（Page）**：虚拟存储块。\n\n**缺页失效（Page Miss）**：虚拟存储失效。\n\n**虚拟地址（Virtual Address）**：映射到物理地址或磁盘地址。\n\n> 可以把物理存储视作全相联策略缓存。\n\n![image-20251231005426017](./pictures/image-20251231005426017.png)\n\n> [!note]\n>\n> 假设虚拟内存使用48位虚拟地址（通常是字节地址），页大小4KiB，物理内存1GiB。为地址分段：\n>\n> **解答**：$4KiB=2^{12}B$，意味着页偏移是12位，剩余36位都是虚拟页号。\n>\n> | Virtual page number | Page offset |\n> | ------------------- | ----------- |\n> | [47:12]             | [11:0]      |\n>\n> $1GiB=2^{30}B$，意味着物理地址有30位，物理页数为$2^{18}$个。\n>\n> | Physical page number | Page offset |\n> | -------------------- | ----------- |\n> | [29:12]              | [11:0]      |\n>\n\n虚拟存储系统通常有几个关键决策：\n\n- 页应足够大以分摊长访问时间，通常在4KiB和64KiB之间。\n- 主要使用全相联存储页。\n- 缺页失效由软件处理。\n- 写穿透不合适，因为写入时间过长，一般使用写回策略。\n\n### 5.7.1页的存放和查找\n\n虚拟映射会借助**页表（Page Table）** 通过操作系统的调配，使每个程序有若干连续的虚拟地址空间。\n\n页表存在**主存**中，每个程序都有自己的页表。\n\n硬件包含一个指向页表首地址的寄存器，称为**页表寄存器**。\n\n假定页表存在一个固定的连续区域中。\n\n在上面的例子中，虚拟页数为$2^{36}$个，页表的项数就是$2^{36}$个。\n\n每一个页表项会包含（一种可能）：\n\n| Valid | Read/Write | User/Supervisor | Dirty | Physical page number |\n| ----- | ---------- | --------------- | ----- | -------------------- |\n| 21    | 20         | 19              | 18    | [17:0]               |\n\n这样的一个页表大小为$2.75\\times2^{36}B$。\n\n页表的索引即虚拟页号。\n\n虚拟地址高位似乎没有被怎么使用，我们会在多级页表讨论这个问题。\n\n### 5.7.2缺页失效\n\n发生缺页失效，操作系统会获得控制，将在存储结构下一级找到该页，并确定页放在主存哪个位置。\n\n![image-20251231134857031](./pictures/image-20251231134857031.png)\n\n### 5.7.3支持大虚拟地址空间的虚拟存储\n\n5.7.1中计算的页表大小有些恐怖了，目前有5种技术从2个角度解决问题。\n\n- **角度1**：减少页表本身的大小。\n- **角度2**：减少存放页表花的空间大小。\n\n1. 限制给定进程的页表大小，只有虚拟地址大于某个界限寄存器的值时，才扩展页表。\n2. 考虑堆栈的地址方向不同，分成两个页表并采取第一种技术。\n3. **反向（倒置）页表**：原先虚拟地址到页表项的映射是VPN=页表项序号，现在整一个哈希函数$f:VPN\\to页表项序号$，确保页表项序号从0递增，这样页表项序号不会超过物理页号最大值，从而降低页表大小。\n4. 页表再分页，即局部页表的页表。\n5. 多级页表。通过下面一题体会这个思路。\n\n> [!note]\n>\n> 给出虚拟内存系统的参数：\n>\n> | 虚拟地址位数 | 物理DRAM | 页大小 | PTE大小（字节） |\n> | ------------ | -------- | ------ | --------------- |\n> | 43           | 16GiB    | 4KiB   | 4               |\n>\n> （1）对于单级页表，需要多少PTE？存储页表需要多少物理内存？\n>\n> **解答**：页大小$4KiB=2^{12}B$，所以VPN位数为31位。需要$2^{31}$个PTE，需要$2^{33}B$存储页表。\n>\n> （2）使用多级页表可以只考虑需要被调用的物理页而减少页表的创建。如果限制每级页表大小为4KiB，则需要多少级页表？\n>\n> **解答**：巧妙的是页表大小也是4KiB，这意味着每个页表恰能被当作一个页处理，所以指向页表的PTE大小还可以维持4B不变。\n>\n> 页表大小$2^{12}B$，有$2^{10}$个页表项，可以支持10位地址的索引。\n>\n> VPN位数是31位，所以需要4级页表。\n>\n> （3）如果限制每级页表大小为8KiB？\n>\n> **解答**：每个页表要两个页存储，所以页表的PTE要翻倍（假设保护位数远小于数据位数）。页表大小$2^{13}B$，有$2^{10}$个页表项。悲催的是，即使页表大小增大，还是需要4级页表。\n>\n> （4）倒置页表存储页表需要多少PTE？\n>\n> 倒置页表简单粗暴，存储物理页号个数个PTE就行了。物理$DRAM=16GiB=2^{34}B$，页大小$4KiB=2^{12}B$，共$2^{22}$个物理页。\n\n### 5.7.4关于写\n\n写回策略，与cache类似，不过多介绍。\n\n### 5.7.5加快地址转换：TLB\n\n还记得**Store Buffer**吗？TLB和它思想类似，但不完全一样。\n\nTLB对于进程是唯一的，切换进程会清空TLB。\n\n![image-20251231141348445](./pictures/image-20251231141348445.png)\n\n在前面的例子中，TLB表项应该是：\n\n| (保护位) | Tag     | Physical page number |\n| -------- | ------- | -------------------- |\n| ...      | [53:18] | [17:0]               |\n\n这里Tag即虚拟页号。\n\nTLB失效时，CPU会杀到页表里找相应的物理页号，如果找到就把它插入TLB中，并用LRU策略踢出其它表项。如果没有找到，就换操作系统处理缺页异常。\n\n通常比较小的TLB使用全相联，比较大的TLB使用随机替换。\n\n### 5.7.6Intrinsity FastMATH TLB\n\n![image-20251231143038077](./pictures/image-20251231143038077.png)\n\n![image-20251231143152246](./pictures/image-20251231143152246.png)\n\n### 5.7.7集成虚拟存储、TLB和cache\n\n> [!note]\n>\n> 考虑TLB、页表、cache的组合能否发生。\n>\n> **解答**：\n>\n> | TLB  | 页表 | cache | 情况                                                         |\n> | ---- | ---- | ----- | ------------------------------------------------------------ |\n> | hit  | hit  | miss  | 可能，TLB命中意味着页表一定有记录，因为页表不会踢表项        |\n> | miss | hit  | hit   | 可能                                                         |\n> | miss | hit  | miss  | 可能                                                         |\n> | miss | miss | miss  | 可能，冷启动                                                 |\n> | hit  | miss | miss  | 不可能，TLB命中意味着页表一定有记录                          |\n> | hit  | miss | hit   | 不可能，同上                                                 |\n> | miss | miss | hit   | 不可能，因为页表不会踢表项，如果页表都没有，说明数据没被读取过，更不会在cache命中 |\n\n### 5.7.8虚拟存储中的保护\n\n联想保护位，思考页访问权限等问题。\n\n略。\n\n### 5.7.9处理TLB失效和缺页失效\n\nTLB失效或缺页失效发生时，用SEPC保存导致失效的指令的PC，阻止一系列读写指令进行。\n\n操作系统接管，以类似处理cache失效的状态机模式的方法写回被替换的页，搬运需要的页...\n\n## 5.8存储层次结构的一般框架\n\n| 特征             | L1 cache典型值 | L2 cache典型值 | 页典型值           | TLB典型值 |\n| ---------------- | -------------- | -------------- | ------------------ | --------- |\n| 块总大小（个数） | 250~2000       | 2500~25000     | 16000~250000       | 40~1024   |\n| 总容量（KiB）    | 16~64          | 125~2000       | 1000000~1000000000 | 0.25~16   |\n| 块的字节数       | 16~64          | 64~128         | 4000~64000         | 4~32      |\n| 失效代价的周期数 | 10~25          | 100~1000       | 10000000~100000000 | 10~1000   |\n| 失效率           | 2%~5%          | 5%~20%         | 0.00001%~0.0001%   | 0.01%~2%  |\n\n### 5.8.1问题一：块放在何处\n\n| 机制     | 组数               | 每组中块数  |\n| -------- | ------------------ | ----------- |\n| 直接映射 | cache中块数        | 1           |\n| 组相联   | cache中块数/相联度 | 相联度      |\n| 全相联   | 1                  | cache中块数 |\n\n![image-20251231151640830](./pictures/image-20251231151640830.png)\n\n### 5.8.2问题二：如何找到块\n\n| 机制     | 定位方法             | 需要比较的次数 |\n| -------- | -------------------- | -------------- |\n| 直接映射 | 索引                 | 1              |\n| 组相联   | 索引组，查找组中元素 | 相联度         |\n| 全相联   | 查找所有表项         | cache容量      |\n\n### 5.8.3问题三：当cache发生失效时替换哪一块\n\n通常LRU和随即替换都很优秀。\n\n### 5.8.4问题四：写操作如何处理\n\n**写穿透**和**写返回**。\n\n### 5.8.53C：一种理解存储层次结构的直观模型\n\n所有失效被分为：\n\n- **强制失效**：冷启动失效。\n- **容量失效**：无能的存储结构不能容纳太多的存储项。\n- **冲突失效**：同一组的竞争导致的**碰撞失效**。\n\n## 5.16谬误与陷阱\n\n**陷阱：在写程序或编译器生成代码时忽略存储系统的行为。**\n\n从分块运算不难体会到。\n\n**陷阱：在模拟cache的时候，忘记说明字节编址或者cache块大小。**\n\n虚拟地址反而总是字节地址。\n\n**陷阱：对于共享cache，组相联度少于核的数量或者共享该cache的线程数(详见第6章)。**\n\n**陷阱：用平均访存时间来评估乱序处理器的存储器层次结构。**\n\n处理器可能在cache失效时继续执行指令。\n\n**陷阱：通过在未分段地址空间的顶部增加段来扩展地址空间。**\n\n**谬误：实际的磁盘故障率和规格书中声明的一致。**\n\n实际的通常更高。\n\n**谬误：操作系统是调度磁盘访问的最好地方。**\n\n**陷阱：在不为虚拟化设计的指令系统体系结构上实现虚拟机监视器。**\n\n**陷阱：硬件攻击可能危及系统安全。**' 
                      },
                      { id: 'computer_organization_and_architecture-6', 
                        title: '6、并行处理器：从客户端到云', 
                        desc: '', 
                        content: '# 6.并行处理器：从客户端到云\n\n## 6.1引言\n\n对多个相互独立的任务，高性能意味着更高的吞吐量，称之为**任务级并行**或**进程级并行**。\n\n**并行处理程序**指代同时运行在多个处理器上的单个程序。\n\n**集群**是通过局域网连接的一组计算机，等同于单个大型多处理器。\n\n**多核微处理器**：比如你的可以调配多个核的处理器。\n\n**共享内存处理器**：具有单个物理地址空间的并行处理器。\n\n| 硬件/软件 | 顺序                     | 并发                            |\n| --------- | ------------------------ | ------------------------------- |\n| **串行**  | Intel Pentium 4 + MATLAB | Intel Pentium 4 + Windows Vista |\n| **并行**  | Intel Core i7 + MATLAB   | Intel Core i7 + Windows Vista   |\n\n软件顺序/并发和硬件串行/并行不冲突。\n\n## 6.2创建并行处理程序的难点\n\n1. 通常很难编写能在多处理器上才能更快完成任务的程序。\n\n2. Amdahl定律：\n   $$\n   改进后的执行时间=\\frac{受改进影响的执行时间}{改进量}+不受影响的执行时间\n   $$\n\n   > [!note]\n   >\n   > 假设希望在100个处理器上实现90倍的加速，那么原始计算中的多少可以顺序执行。\n   >\n   > **解答**：利用Amdahl定律（或其思想）：设有$I$的任务，顺序执行所有这些任务只会用到一个核。如果有$kI$的部分可以并行，它们可以用全部100个核执行，所以加速比为\n   > $$\n   > \\frac{I}{I-kI+\\frac{kI}{100}}=\\frac{1}{1-k+\\frac{k}{100}}=90\n   > $$\n   > 得$k\\approx 0.898$。\n   >\n   > 仅仅1%的顺序代码，就吃掉了接近10%的理论性能提升空间。\n\n**强比例缩放**：保持问题规模不变的同时所测量的加速比。\n\n**弱比例缩放**：问题规模与处理器的数量成比例增长时所测量的加速比。\n\n**均衡负载**：木桶效应说明让每个核处理的任务量相近的必要性，因此并行处理程序的构造困难。\n\n## 6.3SISD、MIMD、SIMD、SPMD和向量机\n\n|              | 单数据流              | 多数据流            |\n| ------------ | --------------------- | ------------------- |\n| **单指令流** | SISD: Intel Pentium 4 | SIMD: x86的SSE指令  |\n| **多指令流** | MISD: 无实例          | MIMD: Intel Core i7 |\n\n**单程序多数据流（Single Program Multiple Data，SPMD）**：编写能在多处理器上运行的程序。\n\n**SIMD**：优点是所有的并行执行单元都是同步的，都响应自同一PC发出的指令。减少指令带宽和空间。\n\n**数据级并行（data-level parallelism）**：程序中必须存在大量相同结构的数据确保在SIMD上并行运行。\n\n### 6.3.1x86中的SIMD：多媒体扩展\n\n流式SIMD扩展（SSE）和高级向量扩展（AVX）。\n\n### 6.3.2向量机\n\n下面是向量扩展的汇编指令示例：\n\n```c++\n#define N 1024\nint a[N], b[N];\nfor (int i = 0; i < N; ++i) {\n    a[i] += 4*b[i];\n}\n```\n\n```\n10470:	0d0077d7          	vsetvli	x15,x0,e32,m1,ta,ma\n10474:	00032737          	lui	x14,0x32\n10478:	5e0231d7          	vmv.v.i	v3,4\n1047c:	01870713          	addi	x14,x14,24 # 32018 <a>\n10480:	65c9              	c.lui	x11,0x12\n10482:	853a              	c.mv	x10,x14\n10484:	01858593          	addi	x11,x11,24 # 12018 <b>\n10488:	40000693          	addi	x13,x0,1024\n1048c:	0d06f7d7          	vsetvli	x15,x13,e32,m1,ta,ma\n10490:	02056107          	vle32.v	v2,(x10)\n10494:	0205e087          	vle32.v	v1,(x11)\n10498:	00279613          	slli	x12,x15,0x2\n1049c:	8e9d              	c.sub	x13,x15\n1049e:	9532              	c.add	x10,x12\n104a0:	95b2              	c.add	x11,x12\n104a2:	a621a0d7          	vmadd.vv	v1,v3,v2\n104a6:	020760a7          	vse32.v	v1,(x14)\n104aa:	9732              	c.add	x14,x12\n104ac:	f2e5              	c.bnez	x13,1048c <main+0x1c>\n```\n\n`vsetvli x15,x13,e32,m1,ta,ma`：\n\n- `x13`：要处理的总元素个数。\n\n  `x15`：硬件实际一次能读取元素个数（取决于硬件寄存器位数）。\n\n  `e32`：每个元素是32位（对应`int`）。\n\n  `m1`：倍率，表示用1个向量寄存器存数据。\n\n  `ta, ma`：尾部和掩码的处理策略（通常设为“无关”，以提高性能）\n\n`vmv.v.i v3,4`：\n\n- 给向量寄存器`v3`赋4。\n\n`vle32.v v1,(x12)`：\n\n- 从内存地址`x12`开始，一次性读取`x15`个32位数据，装进向量寄存器`v1`中。\n\n`vmadd.vv v1,v3,v2`：\n\n- 向量寄存器加法。\n\n`vse32.v v1,(x14)`：\n\n- 将处理好的`v1`寄存器里的那一排数据，原样写回到内存地址`x14` 处。\n\n在实际测试中，`N`达到8e6时，向量机才有明显更优的效率。\n\n### 6.3.3向量与标量\n\n- 单个向量指令指定了大量工作相当于执行了完整的循环。指令取指和译码带宽大大减少。\n- 通过使用向量指令，编译器或程序员确认了向量中的每个结果都是独立的，因此硬件无须再检查向量指令内的数据冒险。\n- 当程序中存在数据级并行时，相比使用MIMD多处理器，使用向量体系结构和编译器的组合更容易写出高效的应用程序。\n- 硬件只需要在两条向量指令之间检查向量操作数之间的数据冒险，而无须检查向量中的每个数据元。减少检查的次数。\n- 访问存储器的向量指令具有确定的访问模式。如果向量中的数据元位置都是连续的，则可以从一组存储器中交叉访问数据块，从而快速获取向量。因此，对整个向量而言，主存储器的延迟开销看上去只有一次，而不是对向量中的每个字都产生一次。\n- 因为整个循环被具有已知行为的向量指令所取代，所以通常由循环引发的控制冒险不再存在。\n- 与标量体系结构相比，节省的指令带宽和冒险检查以及对存储器带宽的有效利用，使得向量体系结构在功耗和能耗方面更具有优势。\n\n### 6.3.4向量与多媒体扩展\n\n**向量通道（vector lane）**：硬件设计者会定义一个**SLEN（条带宽度）**。例如，一个256位的向量单元可能被拆分为4个64位的通道。每个通道内部都有一套完整的运算单元。执行向量运算时，所有的通道会同时启动。Lane 0 处理第1个元素，Lane 1处理第2个元素……\n\n向量体系结构比x86体系结构的多媒体扩展更容易改进。\n\n## 6.4硬件多线程\n\n**硬件多线程（hardware multithreading）**：通过在一个线程停顿时切换到另一个线程来提高处理器利用率。\n\n**细粒度多线程（fine-grained multithreading）**：在每条指令执行后进行线程切换。\n\n**粗粒度多线程（coarse-grained multithreading）**：仅在高开销的停顿上切换线程。\n\n**同时多线程（Simultaneous Multithreading，SMT）**：多发射、动态调度流水线的处理器资源来挖掘线程级并行和指令级并行。\n\n![image-20260101010453025](./pictures/image-20260101010453025.png)\n\n## 6.5多核及其他共享内存多处理器\n\n**共享内存多处理器（SMP）**：所有处理器提供统一物理地址空间。\n\n![image-20260101011438588](./pictures/image-20260101011438588.png)\n\n**统一内存访问（UMA）**：所有的CPU核心通过一条共享的总线连接到同一个内存控制器上。访问延迟相同。\n\n**非统一内存访问（NUMA）**：物理内存被拆分成多个本地节点，每个CPU插槽或核心群簇拥有自己直连的内存。访问延迟不相同。\n\n**同步（synchronization）**：协调多进程行为，避免冲突等。\n\n**锁（lock）**：同一时刻只能有一个处理器获得锁并使用数据。\n\n下面是64个线程并行计算64000个数据求和的示例：\n\n```c++\n#include <iostream>\n#include <vector>\n#include <omp.h>\nint main() {\n    const int num_threads = 64;\n    const int data_per_thread = 1000;\n    const int total_data = num_threads * data_per_thread;\n    std::vector<int> data(total_data, 1);\n    long long total_sum = 0;\n    omp_set_num_threads(num_threads);\n    #pragma omp parallel for reduction(+:total_sum)\n    for (int i = 0; i < total_data; i++) {\n        total_sum += data[i];\n    }\n    std::cout << total_sum << std::endl;\n    return 0;\n}\n```\n\n注意`reduction(+:total_sum)`，它会让各个线程负责的子集求和并行执行。\n\n如果不用它：64个线程会同时尝试修改同一个`total_sum`变量。这会产生数据竞争，导致多个线程的写入相互覆盖。\n\n使用它后：编译器会为每个线程创建一个私有副本。最后一步汇总时，它通常会使用类似于“二叉树”的并行归约法，将64个局部结果两两相加。\n\n~~实际上在当前时代处理器的性能下，上面这点数据量根本看不出来并行的威力，以及所谓写入覆盖的事儿也因此基本不会发生~~\n\n---\n\n这里提供一个好玩的代码，用多线程结合原子指令：\n\n```c++\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n#define THREAD_COUNT 20\n#define ATTEMPT_COUNT 100000\nint shared_data = 0;\nlong total_failures = 0;\nint atomic_write_conditional(int *addr, int new_val) {\n    int failure = 1;\n    __asm__ volatile (\n        "lr.w   t0, (%1)       \\n" \n        "sc.w   %0, %2, (%1)   \\n" \n        : "=r" (failure)           \n        : "r" (addr), "r" (new_val)\n        : "t0", "memory"           \n    );\n    return failure; \n}\nvoid* worker(void* arg) {\n    int tid = *(int*)arg;\n    long local_fail = 0;\n    for (int i = 0; i < ATTEMPT_COUNT; i++) {\n        if (atomic_write_conditional(&shared_data, tid) != 0) {\n            local_fail++;\n        }\n    }\n    printf("线程 %d 结束，失败次数: %ld\\n", tid, local_fail);\n    __sync_fetch_and_add(&total_failures, local_fail);\n    return NULL;\n}\nint main() {\n    pthread_t threads[THREAD_COUNT];\n    int tids[THREAD_COUNT];\n    printf("开始测试高并发冲突...\\n");\n    for (int i = 0; i < THREAD_COUNT; i++) {\n        tids[i] = i + 1;\n        pthread_create(&threads[i], NULL, worker, &tids[i]);\n    }\n    for (int i = 0; i < THREAD_COUNT; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    printf("------------------------------\\n");\n    printf("测试完成！所有线程总失败次数: %ld\\n", total_failures);\n    printf("最终共享地址的值: %d\\n", shared_data);\n\n    return 0;\n}\n```\n\n## 6.6GPU简介\n\n**图形处理单元（Graphics Processing Unit）**：CPU补充的加速器，将所有资源用于图形。问题规模在几百MB到GB之间。存储器主存更小。\n\n### 6.6.1NVDIA GPU体系结构简介\n\nGPU是由多线程SIMD处理器组成的MIMD，有两级硬件调度器：\n\n1. **线程块调度器**：用于多线程SIMD处理器分配线程块。\n2. **SIMD线程调度器**：位于SIMD处理器内部，可在SIMD线程运行时进行调度。\n\n![image-20260101024551760](./pictures/image-20260101024551760.png)\n\n### 6.6.2NVIDIA GPU存储结构\n\n**局部存储器（local memory）**：每个多线程SIMD处理器本地的片上存储器。\n\n**GPU存储器（GPU memory）**：整个GPU和所有线程块共享的片外DRAM。\n\n![image-20260101030048886](./pictures/image-20260101030048886.png)\n\n### 6.6.3对GPU的展望\n\n| 特点                         | SIMD扩展的多核处理器 | GPU        |\n| ---------------------------- | -------------------- | ---------- |\n| SIMD处理器数量               | 8~32                 | 15~128     |\n| SIMD通道/处理器数量          | 2~4                  | 8~16       |\n| 支持SIMD线程的多线程硬件数量 | 2~4                  | 16~32      |\n| 最大cache容量                | 48MiB                | 6MiB       |\n| 存储器地址大小               | 64位                 | 64位       |\n| 主存容量                     | 64GiB~1024GiB        | 4GiB~16GiB |\n| 页级别的内存保护             | 是                   | 是         |\n| 动态页面调度                 | 是                   | 否         |\n| cache一致性                  | 是                   | 否         |' 
                      },
                      { id: 'computer_organization_and_architecture-7', 
                        title: '实验指导', 
                        desc: '', 
                        content: '# 前言\n\n这篇文档是针对专业必修课**计算机组成与设计**的课程设计实验项目的辅助学习文档，**不是**武汉大学课程组官方文档。\n\n文档编写由两位刚做完计组课设的同学完成。\n\n> ~~私人恩怨~~：\n>\n> 官方文档堪称是**认知负担的集大成者**。课设占15%的分数，但是其文档**逻辑支离破碎**，章节之间**缺乏连贯性**，宛如一盘散沙，迫使学生在迷雾中自行拼凑实验目标。排版审美堪称**灾难**，字号、行距、缩进全凭随心所欲，配图更是公然违背人体工学原理——图中嵌字不仅字号随机，更有甚者小如蚁足，令人阅读时不得不**贴屏识图**，堪称视觉上的酷刑。\n>\n> 最令人难以忍受的是，每次实验的原理与目的阐述极度含糊不清，往往用大量篇幅堆砌名词，却对核心任务避而不谈。最终导致一个仅需十几行代码即可实现的实验，学生却要耗费一个多小时去**考古**文档，试图**破译**其真实意图。这种本末倒置的文档设计，严重拖累了课程进度——原本10小时足以速通的实验内容，竟被拉长成数次实验课、累计近50小时的**持久消耗战**。这已不是在学习组成原理，而是在**修炼文档解读与意志力忍耐**的附加课程。\n\n一方面趁着笔者刚做完实验的终极任务**单周期**，对实验了解程度高。\n\n另一方面笔者实在难以回味**写代码十分钟，中译中两小时**的实验历程，决心整改文档，为后人栽树。\n\n文档仅针对课设实验提供帮助，让同学们学到基本的硬件知识的同时节省花费在实验上的时间。但不代表本人不赞同课程组，文档本身不代表任何个人立场，以下是免责声明。\n\n> [!warning]\n>\n> 首先，对于课程组提供的《计组课间实验CPU模块设计》，我们**充分理解并尊重**其在指导实验教学中的核心地位和编写初衷。文档是课程团队辛勤工作的成果，其内容覆盖了实验所需的全部知识点和步骤。\n>\n> 然而，在实际操作过程中，由于实验环境、个人理解差异以及文档在**排版细节和表达习惯**上可能存在的一些微小疏漏，导致部分同学在快速抓取核心信息时遇到了一定困难。\n>\n> 因此，我们选择自行整理并制作一份**侧重于流程优化和视觉辅助**的**伴随性**修正文档。此举绝非意在否定或替代课程组的原版指导书，而是希望作为一份**额外的、便于快速查阅的学习辅助资料**：\n>\n> 这份修正文档的出发点，完全是出于**服务同学、提高整体学习效率**的良好愿望，希望能以协作的方式，共同保障实验教学的顺利进行。\n\n祝各位度过一次愉快的实验之旅。\n\n# 正文\n\n## 旅程起点-`Vivado`安装\n\n由于这个软件占用内存过大，我们强烈建议您仔细阅读此文档前安装好`Vivado`。我们所有的**项目构建**、**综合**、**仿真**、**下板**都需要经过`Vivado`。\n\n> [点击这里，强烈建议选择2022.1版本，选择适合您操作系统的软件下载](https://china.xilinx.com/support/download/index.html/content/xilinx/zh/downloadNav/vivado-design-tools/archive.html)\n\n### 注册\n\n是的，在这里下载需要注册一个AMD帐号。什么？你说怎么注册帐号都要讲？是的，不得不提AMD的**绝密反用户型密码设置**：\n\n笔者尝试了如下密码：\n\n```\nLarryxxxxx_xxxxxx             未通过，疑似是因为包含Larry\nxxxxxxxxxx_114514             未通过，疑似是因为包含114514\nxxxxxxxxHuang_xxxxxx570       未通过，疑似是因为包含Huang\nxxxxxxxxx_2718                通过\n```\n\n鉴于同学们可能不会用到AMD帐号第二次，建议选择一个极复杂密码，省去**反复修改密码**的麻烦。\n\n### 下载\n\n直接打开您刚刚下载的文件，**务必**选择一个足够空间的下载目录。下载的过程可能长达数十小时。\n\n- 科学上网可能提高下载速度，但**务必**注意流量消耗。\n- 下载过程会发生异常中断下载过程，这是**正常**的，选择恢复下载即可。软件会借助缓存迅速恢复下载进度，不用担心。\n\n## 前置知识-`Verilog`语法\n\n茶歇之余，学习一下实验的**语言**。\n\n> 我们要使用的语言是`Verilog`语言，是一种硬件描述语言（Hardware Describe Language，HDL）。它与我们熟悉的编程语言有很大的不同，通常`C`，`C++`，`java`，`python`等高级程序语言的重要特点是顺序执行，而HDL不会。事实上，HDL做的事情更像是告诉机器**我需要一个什么样的逻辑电路**，**各个元器件之间的连线是怎么样的**。当然，`Verilog`语言支持使用`if...else`，`case`和`for`等语法来简化逻辑，可以说`Verilog`就像一个接口，帮助我们以**高级程序语言思维**构造电路，最终落到线路怎么连接，不是我们要考虑的。所以`Verilog`的一个很重要的特点就是：写上去的代码不分先后，都是同步执行的。\n\n> [!caution]\n>\n> 本标题中代码块里部分`[]`表示实现中可加可不加。\n\n### 整体框架\n\n如果你写过`java`，你会知道**文件名**必须与其中定义的**公共类的名称**完全相同。\n\n```java\n// Main.java\n\npublic class Main{\n    public static void main(String[] args){\n\n    }\n}\n```\n\n虽然`Verilog`中没有这样的限制，但我们在**实际的硬件设计**中，强烈建议让文件名与文件中定义的**顶层模块**或**主要模块**的名称相同。\n\n类似`java`的公共类，而`Verilog`的主要对象是`module`（也叫模块）。\n\n```verilog\n// main.v\nmodule main(\n\n);\n    \nendmodule\n```\n\n一个文件可以定义多个`module`。\n\n```verilog\n// main.v\nmodule main(\n\n);\n\nendmodule\n\nmodule show(\n\n);\n\nendmodule\n\n```\n\n每个模块都可能有**输入**或**输出**，每个模块都有其完成的功能块，如下所示：\n\n```verilog\nmodule mux(\n        input x,y,\n        input signal,\n        output mux_res\n);\n    assign mus_res = signal ? y : x;\nendmodule\n```\n\n接下来我们将自底向上介绍`Verilog`语法。\n\n### 基础语法\n\n#### 注释\n\n与`C++`完全一样的注释规则。\n\n```verilog\n// 一行注释\n/*\n很多注释\n*/\n///////////// 有格调的注释\n```\n\n#### 立即数\n\n##### sized\n\n```verilog\n[声明的位宽]\'[进制][数值]\n其中:\nb - 二进制\no - 八进制\nd - 十进制\nh - 十六进制\n```\n\n> [!note]\n>\n> 如果位宽大于表示的值，会将实际位宽**扩充**到指定位宽。\n>\n> 如果位宽小于表示的值，会将实际位宽**截断**到指定位宽。\n\n```verilog\n3\'b010;     // 表示十进制下的 2\n\n8\'h70;      // 表示十进制下的 112\n\n2\'b111;     // 发生截断，表示十进制下的 3\n```\n\n##### Unsized\n\n```verilog\n\'[进制][数值]\n或者\n一个十进制数\n```\n\n```verilog\n114514;     // 表示十进制下的 恶臭\n\'h1AD7;     // 表示十进制下的 6871\n```\n\n##### 负数\n\n直接加负号就可以了。\n\n> [!note]\n>\n> [数值]中可以加`_`分隔，比如：\n>\n> ```verilog\n> \'b0001_0010;\n> ```\n>\n> `_`会被忽略。\n\n#### 变量\n\n##### 变量名\n\n变量命名的规则与`C++`基本一致，在此基础上，变量可以包含`$`，但`$`不能作为首字符。\n\n```verilog\ninteger a$;\n```\n\n##### 值\n\n| 值   | 含义                                   |\n| ---- | -------------------------------------- |\n| `0`  | 逻辑`0`，或`false`                     |\n| `1`  | 逻辑`1`，或`true`                      |\n| `x`  | 未知逻辑值（`0`或`1`）（**不必理会**） |\n| `z`  | 高组态（**不必理会**）                 |\n\n##### 线（wire）\n\n`Verilog`中有很多种线，我们只需要掌握最基础的`wire`。\n\n```verilog\nwire [signed/unsigned] [msb:lsb] (name) [=initial_value];\n```\n\n`[signed/unsigned]`与`C++`中有/无符号数的定义基本相同，默认为`unsigned`。\n\n`[msb:lsb]`表示这是一个索引从`lsb`到`msb`的位宽为`msb+lsb+1`的线。\n\n可以把`wire`视为变量，但它本质只是一个传递媒介，**作为左值，它表示用线把值接出来**，**作为右值，它表示把线连接到左值**。\n\n##### 寄存器（reg）\n\n```verilog\nreg [signed/unsigned] [msb:lsb] (name) [=initial_value];\n```\n\n`reg`是一个活生生的变量，定义与`wire`几乎一样。\n\n##### 整数（integer）\n\n~~姑且这么翻译~~。\n\n```verilog\ninteger (name);\n```\n\n`integer`被视为`32`位`signed`的`reg`，但它本身不是`reg`，是一种用于辅助编程的抽象，不实际存在。\n\n##### 参数（parameter）\n\n```verilog\nparameter (name) (=initial_value);\n```\n\n注意这里赋值只能是立即数。\n\n`parameter`就像宏定义，会在编译的时候把所有`name`替换为`initial_value`。\n\n#### 向量\n\n前面提到了`[msb:lsb]`，这一标题就是解决这个定义的疑问。\n\n> [!note]\n>\n> 绝大部分情况下我们都令`lsb`为`0`，且`msb>=lsb`。\n\n当对`reg`和`wire`的定义都不指定位宽的时候，它们默认位宽为`1`，就像一个`bool`变量。\n\n否则，它就像一个占用比特为`msb+lsb+1`的布尔数组。\n\n这样的变量的存储永远是最低位为`lsb`，最高位为`msb`存储，例如：\n\n> [!important]\n>\n> ```\n> reg [7:0] ys = 8\'b0100_1101;\n> ```\n>\n> `ys`的第零位就是`1`，第一位就是`0`，以此类推。\n>\n> `ys`的值为十进制下的`77`。\n\n有下列两种方式截取部分位：\n\n> [!important]\n>\n> **直接截取**：\n>\n> ```verilog\n> reg [7:0] y;\n> addr [0] = 1;           // 赋值 y 的第零位为 1\n> addr [3 : 6] = 4\'b1010; // 赋值 y 的第三、四、五、六位分别为 0，1，0，1\n> ```\n>\n> **诡谲截取**：\n>\n> ```verilog\n> reg [7:0] y;\n> addr [3 +: 4] = 4\'b1010; // 赋值 y 的第三、四、五、六位分别为 0，1，0，1\n> ```\n\n#### 数组\n\n对于`reg`和`wire`也有数组。\n\n```verilog\nreg y [11:0];                 // 包含 12 个一位宽的 reg\nwire [0:7] s [3:0]            // 包含 4 个八位宽的 reg\nreg [7:0] yy [1:0][3:0];      // 包含 8 个八位宽的 reg\ny[0] = 1\'b1;\ns[2] = 8\'h1c;\nyy[1][2] = 8\'hdd;\n```\n\n> [!note]\n>\n> 如果数组深度（变量个数）较小，并且它被用于像CPU寄存器文件那样，通过地址输入进行选择性读写，它会被综合成一个包含`8`个触发器组的**寄存器堆（Register File）**，并配有地址解码器和多路选择器。\n>\n> 如果数组只是在组合逻辑中被索引以进行读取，例如：\n>\n> ```\n> assign output_val = y[addr];\n> ```\n>\n> 在这种情况下，`y`的每个元素被视为一个输入，整个结构会被综合成一个大型的**多路选择器**，`addr`作为选择线。\n\n### 模块化\n\n#### 模块（module）\n\n```verilog\nmodule (name) [(input, output)];\n        // Contents of the module\nendmodule\n```\n\n##### 端口（input, output）\n\n我们会用到的端口声明包括：\n\n```verilog\ninput  [wire]     [signed/unsigned] [msn:lsb] list_of_names;\noutput [wire/reg]     [signed/unsigned] [msn:lsb] list_of_names;\n```\n\n`[wire]`和`[wire/reg]`若不指定，就默认为`wire`。\n\n> [!note]\n>\n> 这种情况下，我们可以再次在网络或变量类型声明中声明该端口。\n>\n> ```verilog\n> module test (\n>         input [7:0] y,\n>         output [7:0] s\n> );\n>     reg [7:0] e; // 好的，它被改成 reg 了\n> endmodule\n> ```\n\n`[signed/unsigned]`若不指定，就默认为`signed`。\n\n`list_of_names`中可以声明多个变量，它们有相同的定义。\n\n##### 连接（connection）\n\n模块定义的端口就是为连接服务的。\n\n这里我们只介绍一种通用且美观的写法。\n\n```verilog\nmodule to_be_connected(\n    input  [7:0] y;\n    input  [3:0] s;\n    output [7:0] v;\n);\n    reg [31:0] cute;\n    assign v = y[3:0] & s;\nendmodule\n\nmodule connector;\n    reg [19:0] r;\n    to_be_connected any_name_u_like(\n        .y (r[6:0]),\n        .z (r[10:7]),\n        .v (r[17:11]),\n    ); // <- important!!!!\nendmodule\n```\n\n上述代码生成了一个子模块`any_name_u_like`。子模块一经生成，就像把子模块逻辑嵌入调用模块一样执行子模块的逻辑。\n\n> [!important]\n>\n> 你可能发现了上述`y`的输入位宽与传入位宽不匹配，遇到这种情况，`Verilog`会采取**扩充**或**截断**策略。\n>\n> ---\n>\n> 你可以在调用模块使用`any_name_u_like.cute`直接调用这个寄存器，这对`wire`也是合法的。\n\n#### 线赋值（assign）\n\n```verilog\nassign <wire_name> = <信号(reg, wire)和常数的表达式>\n```\n\n> [!important]\n>\n> - 如你所见，`assign`只能对`wire`使用。\n> - 这可以视为一种**强绑定**，意思是右侧表达式的值一旦有变化，左边会立即更新为右侧的值。\n> - 每个`wire`都只能被强绑定一次。\n\n#### 块（always）\n\n`always`语句是最强大也是最容易出错的方法。\n\n```verilog\nalways @ (event) [statement]\nalways @ (event) begin\n    [multiple statements]\nend\n```\n\n##### 事件（event）\n\n> 这里的`event`指的是**敏感列表事件**，注意与**仿真**里的`event`区别。\n\n一个`event`可以表示为\n\n```verilog\nsignal_name or posedge signal_name or negedge signal_name\n*\n```\n\n例如：\n\n```verilog\nalways @(posedge clk or negedge rstn) begin\nend\n\nalways @* begin\nend\n\nalways @ys begin\n    r = ys;\nend\n```\n\n| 类型                  | 效果                                                   |\n| --------------------- | ------------------------------------------------------ |\n| `signal_name`         | 当`signal_name`发生变化时，执行`always`块里的内容      |\n| `posedge signal_name` | 当`signal_name`从`0`→`1`时，执行`always`块里的内容     |\n| `negedge signal_name` | 当`signal_name`从`1`→`0`时，执行`always`块里的内容     |\n| `*`                   | 当`always`块中有输入信号变化时，执行`always`块里的内容 |\n\n##### 声明（statement）\n\n~~姑且用这个翻译~~。\n\n表示`always`块内的内容。\n\n通常来说，我们把上表中第`1`，`4`种类型叫做**组合逻辑**，第`2`，`3`种类型叫做**时序逻辑**。\n\n###### 组合逻辑\n\n对`reg`的赋值通常使用`=`，类似于对`wire`赋值的无需`assign`版本，可视为硬连接。\n\n###### 时序逻辑\n\n> [!warning]\n>\n> 由于渲染问题，所有的小于等于号都被渲染为`<=`，注意甄别。（如果没有这个问题，请忽略）\n\n对`reg`的赋值通常使用`<=`。\n\n表达式里信号的值是这个信号**上个时钟周期**的值。\n\n> [!important]\n>\n> ```verilog\n> // a = 114514;\n> always @(posedge clk) a <= 1919810;\n> always @(posedge clk) b <= a;\n> ```\n>\n> 在`clk`从`0`→`1`的瞬间，`a`的值变为`1919810`，`b`的值变为`114514`。\n\n###### 条件判断（if...else）\n\n除了大括号的区别以外，与`C++`的使用方法是一致的（包括逻辑表达式）。\n\n```verilog\nalways @(posedge clk) begin\n    if (y == 3\'b010) y <= s;\n    if (y == 3\'b011) begin\n        s <= y;\n    end\n    else begin\n        y <= 2 * s;\n    end    \nend\n```\n\n> [!important]\n>\n> 不妨想想**条件判断**在硬件层面会被映射为什么？\n>\n> 再去了解一下为什么不建议写这样的代码？\n>\n> ```verilog\n> always @* begin\n>  if (flag_i == 1\'b1) begin\n>      data_out = data_a;\n>  end\n>  // 没有否则支\n> end\n> ```\n\n###### 选择（case）\n\n通常遵循下面的结构：\n\n```verilog\nalways @* begin\n    case (y)\n        3\'b000: s = 0;\n        3\'b001: s = y;\n        3\'b010: begin\n            s = y + 1;\n        end\n        default: s = 114514;\nend\n```\n\n> [!important]\n>\n> `default`行不是必须的，但是强烈建议添加（为什么？）。\n>\n> 通常`case`比`if...else`在硬件实现上的速度更快，尽管`case`就像多个`if`的并列，但是它们生成的硬件是不同的。\n\n###### 循环（for）\n\n小心使用，但是功能强大。\n\n```verilog\ninteger i;\nreg [31:0] reg_[3:0];\nalways @* begin\n    for (i = 0; i < 4; i = i + 1) begin\n        reg_[i] = i;\n    end\nend\n```\n\n> [!important]\n>\n> - 循环变量通常为`integer`，当然也可以使用`reg`（存疑），但是会浪费一个寄存器的内存。\n> - `for()`中**初始值**，**循环边界**和**步长**都必须只包含常量，这是因为综合时的`for`会被处理为生成若干组仅有**循环变量不同**的语句。\n\n##### 运算符（operator）\n\n大部分运算符与`C++`含义相同，这里仅介绍不同的部分。\n\n###### 常规运算符\n\n| 运算符  | 效果         |\n| ------- | ------------ |\n| `a^~b`  | 按位同或     |\n| `a**b`  | `a`的`b`次幂 |\n| `a<<<b` | 算术左移     |\n| `a>>>b` | 算术右移     |\n\n> [!important]\n>\n> 这里提一个有意思的关于**截断**的知识。\n>\n> ```verilog\n> reg [15:0] a, b, ans, ans_;\n> always * begin\n>     a = 16\'hFFFF;\n>     b = 16\'h0001;\n>     ans = (a + b) >> 1;\n>     ans_ = (a + b + 0) >> 1;\n> end\n> ```\n>\n> `ans`和`ans_`的值依次是`0`和`16\'h8000`。\n>\n> 这是因为`0`把表达式的符号扩展为`32`位了。\n\n###### 级联（Concatenation）\n\n这个运算用于便利的生成特定长度的一个`2`进制串。\n\n```verilog\n{信号或常数, 信号或常数, … , 信号或常数}\n```\n\n同时，允许对某些信号重复常数次。\n\n```verilog\na=4\'b0010;\nb=8\'b11110110;\n{{3{a[1:0]}}， {2{1\'b0}}, {2{b[1].，b[3]}}}};\n// 会是 12\'b101010001010\n```\n\n###### 缩减运算符\n\n**这个运算符其实是简写**\n\n`b=&a`等价于各位与。\n\n```verilog\nreg b;\nreg [4:0] a;\nb=&a;\nb=((a[0]&a[1])&a[2])&[3];\n// 两个式子等价\n```\n\n总共有以下几种缩减运算符可以使用。\n\n| 运算符 | 功能 |\n| ------ | ---- |\n| `&`   | 与   |\n| `\\|`    | 或   |\n| `^`    | 异或 |\n| `~&` | 与非 |\n| `~\\|`  | 或非 |\n| `~^`  | 同或 |\n\n######  条件运算符\n\n与`C++`基本一样。\n\n```verilog\n<条件表达式>?<表达式1>:<表达式2>;\n```\n\n```verilog\nassign y = (s == 1)? a : b;\n```\n\n## 硬件介绍-芯片和板\n\n### 芯片\n\n`xc7a100tcsg324-1` 是Xilinx的**Artix-7**系列FPGA中的一个具体型号，广泛应用于各种高性能、高带宽和低功耗的应用中。\n\n芯片市场价在`150$~350$`浮动，**务必**妥善保管你的板子！\n\n> [!important]\n>\n> 你有一次更换板子的机会，当且仅当你的板子发生了损坏导致无法用于实验。\n>\n> ~~第二次弄坏怎么办，要赔吗？我不知道啊，最好别弄坏吧。~~\n\n以下介绍与实验内容基本无关，仅为保持知识的全面性作科普。\n\n#### 型号解析\n\n这个型号代码可以分解为几个部分，每个部分都有特定的含义：\n\n| **部分**   | **含义**      | **细节**                                                     |\n| ---------- | ------------- | ------------------------------------------------------------ |\n| **XC**     | 制造商代码    | Xilinx Corporation                                           |\n| **7**      | 架构系列      | **7 系列 FPGA**（包括 Artix-7, Kintex-7, Virtex-7）          |\n| **A**      | 家族/型号系列 | **Artix-7** 家族                                             |\n| **100T**   | 逻辑容量      | **100T** 代表拥有约 10 万个逻辑单元                          |\n| **CSG324** | 封装形式      | **CSG** 是 Ball Grid Array (BGA) 封装的一种类型，**324** 指芯片有 324 个引脚。 |\n| **-1**     | 速度等级      | **-1** 是最低的速度等级（通常是标准速度），功耗最低，性能相对保守。 |\n\nArtix-7 家族是 Xilinx 7 系列产品中定位于**低功耗、高逻辑密度和高带宽串行连接**的系列。它通常用于替代传统的 ASIC 或低端定制逻辑。\n\n**典型应用领域：**\n\n- 软件定义无线电。 \n- 医疗成像。\n- 工业控制。\n- 航空航天与国防。\n- 视频处理和嵌入式视觉。\n\n#### 性能参数\n\n| **资源名称**      | **数量**   | **说明**                                                     |\n| ----------------- | ---------- | ------------------------------------------------------------ |\n| **逻辑单元**      | 101440     | 衡量芯片规模的主要指标。                                     |\n| **查找表**        | 63400      | 可配置逻辑块中的主要资源，用于实现组合逻辑。                 |\n| **触发器**        | 126800     | 用于实现时序逻辑和寄存器。                                   |\n| **块RAM**         | 4860 Kbits | 总共约4.75Mbits的片上存储器，用于高速数据缓冲。              |\n| **DSP切片**       | 240        | 专用的数字信号处理单元，适用于乘法、累加、滤波等高性能计算。 |\n| **时钟管理**      | 6个        | 复杂的时钟生成和管理模块，用于频率合成、去抖动和相位调整。   |\n| **PCI Express块** | 1个        | 集成的 PCIe Gen2 接口（硬核），用于高速主机连接。            |\n\n### 板\n\nNexys A7是一款非常著名且流行的**FPGA 开发板**。\n\n它是由Digilent公司生产的一系列开发板，目的是为学生、教育者和工程师提供一个功能完善、易于上手且价格合理的平台，用于学习和开发基于Xilinx Artix-7 FPGA的项目。\n\n#### 组成介绍\n\n![wtf](./pictures/wtf.png)\n\n这里我们只介绍部分需要用到的组成部分。\n\n| 序号  | 名称                       | 功能                                                         |\n| ----- | -------------------------- | ------------------------------------------------------------ |\n| **①** | 接口                       | USB数据线的连接口                                            |\n| **②** | 开关                       | 当处于**ON**状态时，板子才能工作                             |\n| **③** | CPU RESET（复位按钮）      | 对应输入信号的`rstn`，按下后`rstn`从高电平（1）变为低电平（0），松开后恢复高电平 |\n| **④** | PROG（高级复位）           | 按下后，清除所有逻辑，因此需要重新加载比特流                 |\n| **⑤** | 滑动开关（Slide switches） | 对应输入信号的`sw_i`，从右往左依次是`sw_i[0]`，`sw_i[1]`，……，`sw_i[15]`。拨上代表对应输入信号为`1`，否则为`0` |\n| **⑥** | LED灯                      | 对应输出信号的`led_o`，从右往左依次是`led_o[0]`，`led_o[1]`，……，`led_o[15]`。亮灯代表对应输出信号为`1`，否则为`0` |\n| **⑦** | 数码管                     | 对应输出信号的`disp_seg_o`和`disp_an_o`，都是八位信号。前者控制亮灯数码管的哪些笔画被点亮；后者第`i`位为`0`，则从右往左数第`i+1`个数码管会亮灯 |\n\n> 对应输入、输出信号是人为规定的，具体来说有一个**限制文件**将硬件与信号对应。\n>\n> 你很容易发现数码管的信号功能**几乎不能同时**让不同的数码管显示不同的数字，具体该如何做呢？\n\n#### 使用说明\n\n盒子内配备了一条**USB数据线**，一端连接电脑，另一端连接开关，其中的一端还是适配古早年代手机的充电接口，所以**务必注意接入正反**。\n\n打开开关，若板子有亮灯，则说明板子基本正常。\n\n**导入位流**后，即可调试板子。\n\n## 软件使用-综合与下板\n\n### 开始页面\n\n和其他工程软件十分类似，开始页面最重要的功能只有两个--**打开文件**和**新建文件**。\n这里总结一下新建文件的步骤。\n\n> [!Warning]\n> 新建文件所选项与FPGA芯片有关，切勿盲目照抄。\n>\n> 请尽最大努力使用全英文路径，**这个软件没那么智能**。\n\n![picture_1](./pictures/picture_1.jpg)\n![picture_3](./pictures/picture_3.png)\n![picture_4](./pictures/picture_4.png)\n![picture_5](./pictures/picture_5.png)\n![picture_6.png](./pictures/picture_6.png)\n\n>[!important]\n>\n>此时先不添加**源文件（Sources）**。\n\n\n![picture_7](./pictures/picture_7.png)\n\n>[!important]\n>\n>此时先不添加**限制文件（Constraints）**。\n\n![picture_8](./pictures/picture_8.png)\n\n> [!important]\n>\n> 这里选择了我们使用的数码版对应的参数。\n\n>完成以上步骤即可创建一个新工程。\n\n---\n\n\n### 主要页面\n\n![picture_2.jpg](./pictures/picture_2.jpg)\n首先请看左侧的区域1，从上到下是基本的设计流程。\n\n>[!important]\n>\n>1. **Project Manager（项目管理）**：添加约束文件，编辑verilog代码\n>2. **IP integrator（IP整合）**：添加IP核文件（在实验中涉及较少）\n>3. **Simulation（仿真）**：在程序中模拟运行，可以查看模块内的数值，用于检查代码\n>4. **RTL analysis（检查）**：检查代码是否有错误，不用点击，会在下面的综合前自动运行\n>5. **synthesis（综合）**：将代码和约束文件等内容翻译为网表文件\n>6. **implementation（实现）**：决定网表中的每一个逻辑单元应该放置在FPGA芯片上的哪个具体位置\n>7. **program and debug**：生成位流文件以及把位流文件烧到板子上\n\n### 项目管理\n\n>[!note]\n>有些同学可能把项目运行到后面的一些阶段时想要返回修改代码，但是发现找不到了，这里补充一点，那个**PROJECT MANAGER**是可以点的。\n\n#### 添加文件\n\n添加用于写代码的`.v`文件：点击左侧的`add sources`->`add or create design sources`->`create File`->输入文件名->`Finish`->`OK`。\n\n>[!note]\n>\n>最后一步点击OK之后会弹出提醒，无需在意，模块的输入输出可以直接在文件中修改。\n\n>[!note]\n>在区域2中的`Design sources`文件夹中的就是代码文件，在`non-module files`中的是没有被使用到的模块（可能是语法明显错误的模块）。也可以在这里看到你所编写的各个模块之间的关系。\n\n添加约束文件`.xdc`:点击左侧的`add sources`→`add or create constraints`→`add files`→找到老师发的约束文件，通常是`icf.xdc`，点击`open`→`Finish`→`OK`。\n\n\n#### 写代码 \n\n畅所欲写。\n\n> [!note]\n>\n> 非常建议用其它`ide`编写代码，毕竟`Vivado`那个前端真的不敢恭维。推荐使用`vscode`并下载`verilog`相应扩展。~~有语法高亮会好写很多。~~\n\n#### 综合 实现 生成位流\n\n代码完成后，请按顺序点击左侧的`Run Synthesis`->`Run Implementation`->`Generate Bitstream`。\n\n>[!note]\n>在运行这几个步骤时需要较长的时间，请耐心等待，注意右上角的区域`3`，当其为加载的转圈状时，建议不要操作。\n\n#### 烧板子\n\n**请不要把你的板子放到火里去烧**，这里的烧指的是一种叫烧录的古老技术，这里只是沿用了名称。更合理的名字叫下载。\n\n点击左侧最下面的`Open Hardware Manager`→中间偏上非常显眼的荧光绿条带上的`Open Target`→选择`Auto connect`→连接成功后点击`Program Device`。\n\n等待片刻，你的板子上即可运行你的程序。\n\n#### 仿真\n\n理论上讲，仿真应该在综合之前，但是仿真文件并不好写。除非你的程序有重大问题而且无法定位，考虑使用仿真定位问题。\n\n>[!important]\n>\n>上面一句话是仅在本次实验中的建议。事实上当使用`Vivado`进行开发，比如参加比赛或专业级别的开发，仿真是必要的**减少烧位流浪费的时间**的方法。如果你有相关意向，~~立志成为Vivado大师~~，建议掌握仿真。\n\n## 旅程开始-各项实验介绍\n\n### 时钟分频-跑马灯\n\n#### 目标\n\n> 当`sw_i`输入为`16\'h000A`时，led灯从右往左依次点亮，具体来说：\n>\n> 使`led_o`从`16\'b0000_0000_0000_0001`->`16\'b0000_0000_0000_0010`->...->`16\'b1000_0000_0000_0000`->`16\'b0000_0000_0000_0001`->...\n>\n> 相邻变化的间隔约为1s。\n\n#### 做法\n\n作为第一讲，有一些不得不强调的知识：\n\n> [!important]\n>\n> 所有实验的主模块都应当有一个输入信号`clk`，这是板子内置的**时钟信号**，会在低电平和高电平之中规律跳变，即`0`->`1`->`0`->`1`->...，它变化一个周期的时间大约为100ns。\n>\n> 所有实验的主模块都应当有一个输入信号`rstn`，如上文所述，添加这个信号利于你重新调试板子。\n\n1. 判断`sw_i`输入为`4\'b1010`：\n\n   不难想到这就是一个条件判断的事，注意条件判断语句应当放在`always`块内。\n\n2. `led_o`的变化：\n\n   不难想到一种方法是通过**级联**，即`led_o <= {led_o[14:0], led_o[15]};`。\n\n   注意务必使用**时序逻辑**，否则因为语句两边都包含`led_o`，一旦`led_o`变化，这个语句就会执行，这会导致一些不可预知的错误。同时将`led_o`声明设为`reg`而不是`wire`。\n\n3. 时间间隔：\n\n   利用`clk`，一种方案是设计\n\n   ```verilog\n   reg [31:0] clk_cnt;\n   always@(posedge clk or negedge rstn) begin\n       if (!rstn) clk_cnt <= 32\'b0;\n       else clk_cnt <= clk_cnt + 1\'b1;\n   end\n   ```\n\n   每一个时钟周期都会让`clk_cnt`自增`1`，只要我们确定`clk_cnt[i]`变化所需要的时钟周期，就能大致确定时间间隔。\n\n   不难得出：相邻两次`clk_cnt[i]`从下降沿变化到上升沿所花的时间是`100ns * 2 ^ (i+1)`，所以你应该选择`i=26`。\n\n> [!important]\n>\n> 通过观察`clk_cnt[i]`是一种简便的写法，如果追求精确的`1s`，你应该换一种策略（比如让`clk_cnt`关于某数取模）。\n\n#### 参考代码\n\n```verilog\nmodule main(\n        input clk,\n        input rstn,\n        input [15:0] sw_i,\n        output reg [15:0] led_o\n    );\n    parameter div_num = 27;\n    reg[31:0] clk_cnt;\n    wire clk_1s;\n    always@(posedge clk or negedge rstn)\n    begin\n        if(!rstn)clk_cnt <= 32\'b0;\n        else clk_cnt <= clk_cnt + 1\'b1;\n    end\n    assign clk_1s = clk_cnt[div_num];\n    parameter led_val = 16\'h0001;\n    always@(posedge clk_1s or negedge rstn) begin\n        if (!rstn) led_o <= led_val;\n        else if (sw_i[0]) led_o <= {led_o[14:0], led_o[15]};\n        else led_o <= led_o;\n    end\nendmodule\n\n```\n\n### 八位数码管\n\n#### 目标\n\n> 构造一个模块，它能支持：\n>\n> 1. 当`sw_i[0]`为`0`时，八位数码管能显示你想要显示的内容（比如你的生日）。\n> 2. 当`sw_i[1]`为`1`时，实现**矩形变换**。\n> 3. 当`sw_i[15]`为`1`时，修改主模块的时序为慢时序（`i`修改为`27`）。\n\n#### 做法\n\n> [!important]\n>\n> 对于第一项任务：\n>\n> 很容易发现**同一时刻我们只能让部分位数码管都显示相同的数字**，这是一种出于节省资源的考虑：\n>\n> - 我们只需要总共`16`位输出信号就可以实现目标效果。\n> - 如果为每位数码管都配置`8`位，加上还需要`8`位确认哪些数码管要点亮，总计需要`72`位输出信号，微微浪费资源。\n>\n> 具体如何实现呢？\n>\n> 我们选择一个更快的时钟频率（更短的时钟周期），在这个更短的时钟周期**只显示一位数码管，其余位不显示**，从右到左依次显示每一位数码管。\n>\n> 试想如果我们选择的**更快的时钟频率**对应`i=14`，那么我们每`100ns * 2 ^ 15`时间会显示一位数码管，总共有八位数码管，那么`100ns * 2 ^ 18`时间会显示一轮数码管。原先**较慢的时钟频率**对应`i=26`，时钟周期是`100ns * 2 ^ 27`。所以每一个较长时钟周期会显示`512`轮数码管，依靠**视觉暂留**，看起来不同数码管显示了不同的内容。\n>\n> 对于第二项任务：\n>\n> 说实在的我也没搞懂在做什么，直接复制代码吧。\n>\n> 对于第三项任务：\n>\n> 很简单，检测`sw_i[15]`的值，对`clk_1s`做出相应修改即可。\n\n- 确定时钟分频：\n\n  子模块应该有**更快的时钟频率**。\n\n- 构造数码管亮灯逻辑：\n\n  注意这是**共阳极数码管**，这意味着当`disp_an_o[i]`为`0`，则从右往左数第`i+1`位数码管会亮灯。\n\n  当`disp_seg_o[i]`为`0`，则对应的段会亮灯，具体来说：\n\n  | `i`  | 段     |\n  | ---- | ------ |\n  | `0`  | 最上方 |\n  | `1`  | 右上方 |\n  | `2`  | 右下方 |\n  | `3`  | 最下方 |\n  | `4`  | 左下方 |\n  | `5`  | 左上方 |\n  | `6`  | 中间   |\n  | `7`  | 小数点 |\n\n- 构造子模块并在主模块调用。\n\n#### 参考代码\n\n```verilog\nmodule alg(\n        input clk,\n        input rstn,\n        input[63:0] i_data,\n        input disp_mode,\n        output reg[7:0] o_seg,\n        output reg[7:0] o_sel\n    );\n    parameter div_num = 14;\n    reg [31:0] cnt;\n    always @(posedge clk or negedge rstn) begin\n        if (!rstn) cnt <= 32\'b0;\n        else cnt <= cnt + 1;\n    end\n    wire clk_1s = cnt[div_num];\n    reg [2:0] seg_cnt; // 依次选择数码管\n    always @(posedge clk_1s or negedge rstn) begin\n        if (!rstn) begin\n            seg_cnt <= 3\'b0;\n            o_sel <= 8\'b1111_1111;\n        end\n        else begin\n            seg_cnt <= seg_cnt + 1;\n            o_sel <= ~(8\'b0000_0001 << seg_cnt);\n        end\n    end\n    wire [3:0] seg_data_r; // 任务一用到的输出\n    wire [7:0] seg_data_g; // 任务二用到的输出\n    assign seg_data_r = (i_data >> (seg_cnt * 4)) & 4\'hF;\n    assign seg_data_g = (i_data >> (seg_cnt * 8)) & 8\'hFF;\n    always @(posedge clk_1s or negedge rstn) begin\n        if (!rstn) o_seg <= 8\'b1111_1111;\n        else begin\n            if (disp_mode) o_seg <= seg_data_g;\n            else case(seg_data_r)\n                4\'h0: o_seg <= 8\'hC0;\n                4\'h1: o_seg <= 8\'hF9;\n                4\'h2: o_seg <= 8\'hA4;\n                4\'h3: o_seg <= 8\'hB0;\n                4\'h4: o_seg <= 8\'h99;\n                4\'h5: o_seg <= 8\'h92;\n                4\'h6: o_seg <= 8\'h82;\n                4\'h7: o_seg <= 8\'hF8;\n                4\'h8: o_seg <= 8\'h80;\n                4\'h9: o_seg <= 8\'h90;\n                4\'hA: o_seg <= 8\'h88;\n                4\'hB: o_seg <= 8\'h83;\n                4\'hC: o_seg <= 8\'hC6;\n                4\'hD: o_seg <= 8\'hA1;\n                4\'hE: o_seg <= 8\'h86;\n                4\'hF: o_seg <= 8\'h8E;\n                default: o_seg <= 8\'b1111_1111;\n            endcase\n        end\n    end\nendmodule\n```\n\n```verilog\nmodule main(\n        input clk,\n        input rstn,\n        input [15:0] sw_i,\n        output [7:0] disp_seg_o,\n        output [7:0] disp_an_o\n    );\n    reg [31:0] cnt;\n    always @(posedge clk or negedge rstn) begin\n        if (!rstn) cnt <= 32\'b0;\n        else cnt <= cnt + 1;\n    end\n    assign clk_1s = (sw_i[15]) ? cnt[27] : cnt[25];\n    reg [63:0] LED_DATA [18:0];\n    initial begin\n        LED_DATA[0]  = 64\'hC6F6F6F0C6F6F6F0;\n        LED_DATA[1]  = 64\'hF9F6F6CFF9F6F6CF;\n        LED_DATA[2]  = 64\'hFFC6F0FFFFC6F0FF;\n        LED_DATA[3]  = 64\'hFFC0FFFFFFC0FFFF;\n        LED_DATA[4]  = 64\'hFFA3FFFFFFA3FFFF;\n        LED_DATA[5]  = 64\'hFFFFA3FFFFFFA3FF;\n        LED_DATA[6]  = 64\'hFFFF9CFFFFFF9CFF;\n        LED_DATA[7]  = 64\'hFF9EBCFFFF9EBCFF;\n        LED_DATA[8]  = 64\'hFF9CFFFFFF9CFFFF;\n        LED_DATA[9]  = 64\'hFFC0FFFFFFC0FFFF;\n        LED_DATA[10] = 64\'hFFA3FFFFFFA3FFFF;\n        LED_DATA[11] = 64\'hFFA7B3FFFFA7B3FF;\n        LED_DATA[12] = 64\'hFFC6F0FFFFC6F0FF;\n        LED_DATA[13] = 64\'hF9F6F6CFF9F6F6CF;\n        LED_DATA[14] = 64\'h9EBEBEBC9EBEBEBC;\n        LED_DATA[15] = 64\'h2737373327373733;\n        LED_DATA[16] = 64\'h505454EC505454EC;\n        LED_DATA[17] = 64\'h744454F8744454F8;\n        LED_DATA[18] = 64\'h0062080060620800;\n    end\n    reg [5:0] led_data_addr;\n    reg [63:0] led_disp_data;\n    always @(posedge clk_1s or negedge rstn) begin\n        if (!rstn) begin\n            led_data_addr <= 6\'d0;\n            led_disp_data <= 64\'b1;\n        end else if (sw_i[0] == 1\'b1) begin\n            if (led_data_addr == 19) begin\n                led_data_addr <= 6\'d0;\n                led_disp_data <= LED_DATA[0];\n            end else begin\n                led_data_addr <= led_data_addr + 1\'b1;\n                led_disp_data <= LED_DATA[led_data_addr];\n            end\n        end else begin\n            led_data_addr <= led_data_addr;\n        end\n    end\n    reg [63:0] display_data;\n    always @(sw_i) begin\n        if (sw_i[0] == 1\'b0) begin\n            display_data <= 537265440; // 猜猜这是什么...\n        end\n        else begin\n            display_data <= led_disp_data;\n        end\n    end\n    alg u_alg (\n        .clk (clk),\n        .rstn (rstn),\n        .i_data (display_data),\n        .disp_mode(sw_i[0]),\n        .o_seg (disp_seg_o),\n        .o_sel (disp_an_o)\n    );\nendmodule\n```\n\n### ROM IP核\n\n#### 目标\n\n> 通过`IP Catalog`构建一个ROM IP核，调用这个模块以读取指定位置的指令，当`sw_i[14]`为`1`时依次将指令显示到数码管上。\n>\n\n#### 做法\n\n仅完成实验不需要掌握以下`important`块内容。\n\n> [!important]\n>\n> IP核是具有**特定功能、知识产权受保护的电路模块**，通常是已封装好的**黑/白盒**模块。\n>\n> IP核可以根据其提供的形式和抽象程度分为几大类：\n>\n> | **类型**           | **描述**                                                     | **交付形式**              | **举例**                                                     |\n> | ------------------ | ------------------------------------------------------------ | ------------------------- | ------------------------------------------------------------ |\n> | **软核 (Soft IP)** | 以**源代码（HDL，如 Verilog/VHDL）** 形式交付。用户可以查看、修改和综合到任何目标工艺上。 | Verilog/VHDL代码文件      | RISC-V软核CPU、简单的FIFO队列、自定义控制器。                |\n> | **固核 (Firm IP)** | 以**网表（Netlist）** 形式交付。代码已加密或模糊处理，用户不能修改，但可以重新布局布线。 | 门级网表                  | 复杂的加密算法模块、高性能DSP模块。                          |\n> | **硬核 (Hard IP)** | 以**物理布局（Layout）** 形式交付。与特定工艺和芯片位置绑定，性能最高，但无法移植或修改。 | 掩模文件，物理 GDSII 文件 | 板载PCIe控制器、DDR PHY、高速SerDes模块、CPU芯片中的ARM核心。 |\n\n我们要手动构建一个IP核：\n\n- 创建文件`rom_instructions.coe`，并在里面粘贴如下内容\n\n  ```\n  memory_initialization_radix=16;\n  memory_initialization_vector=000000b3,00108093,00000133,00210113,000001b3,00318193,001020a3,00202123,003021a3,00102203,00202283,00302303;\n  ```\n\n  第一行规定了后续数据是16进制，第二行是指令存储器内部的**初始数据**。\n\n- 在你的`vivado`项目中点击`IP Catalog`，在右侧框内选择`Distributed Memory Generator`，在弹出的窗口中修改`Depth`为`64`（决定存储器可以存储的地址单元数量），`Data Width`为`32`（决定每次读取的位宽），`Memory Type`为`ROM`（只读存储器）。\n\n- 切换至`RST & Initialization`，导入你的`coe`文件，并点击旁边按钮检测文件有效性。点击`OK`生成`IP`核。\n\n- 你可以在你的项目目录看到`dist_mem_gen_0`，它将作为一个你可以调用的模块名称，由于我们没有额外设定，这个**只读存储器**的IP核只有这样一种朴素的用法：\n\n  ```verilog\n  reg [5:0] rom_addr;\n  wire [31:0] instr;\n  dist_mem_gen_0 u_dist_mem_gen_0 (\n      .a(rom_addr), // input signal\n      .spo(instr)   // output signal\n  );\n  ```\n\n#### 参考代码\n\n```verilog\nmodule main(\n        input clk,\n        input rstn,\n        input [15:0] sw_i,\n        output [7:0] disp_seg_o,\n        output [7:0] disp_an_o\n    );\n    reg [31:0] cnt;\n    always @(posedge clk or negedge rstn) begin\n        if (!rstn) begin\n            cnt <= 32\'d0;\n        end else begin\n            cnt <= cnt + 1\'b1;\n        end\n    end\n    assign clk_1s = (sw_i[15]) ? cnt[27] : cnt[25];\n    reg [5:0] rom_addr;\n    always @(posedge clk_1s or negedge rstn) begin\n        if (!rstn) rom_addr <= 0;\n        else rom_addr <= rom_addr + 1;\n    end\n    wire [31:0] instr;\n    dist_mem_gen_0 u_dist_mem_gen_0 (\n        .a(rom_addr),\n        .spo(instr)\n    );\n    alg u_alg (\n        .clk (clk),\n        .rstn (rstn),\n        .i_data (instr),\n        .disp_mode (sw_i[0]),\n        .o_seg (disp_seg_o),\n        .o_sel (disp_an_o)\n    );\nendmodule\n\n```\n\n### RegisterFile\n\n#### 目标\n\n> 实现一个寄存器堆，要求有如下的端口和寄存器：\n>\n> ```verilog\n> module RF(\n>     input clk,\n>     input rst,  // ~rstn 不知道取非是何意味\n>     input RFWr, // 写入寄存器信号, 相当于 mem2reg，当前实验令其为 sw_i[3] & ~sw_i[1]\n>     input [15:0] sw_i, // 这根线接的意义不明\n>     input [4:0] A1, A2, A3, // 分别是读取的寄存器号 1, 读取的寄存器号 2, 待写入的寄存器号，这里为sw_i[11:8]\n>     input [31:0] WD, // 待写入的数据，这里为sw_i[7:4]\n>     output reg [31:0] RD1, RD2, // 读取的两个寄存器的值\n> );\n>     reg [31:0] rf[31:0];\n> endmodule\n> ```\n>\n> 在原有功能的基础上实现：\n>\n> - 复位（`rstn`为`0`）时：初始化`rf[i]`为`i`。\n> - 当`sw_i[13]`为`1`时：循环显示RF中的32个寄存器的内容，一轮循环结尾显示一次`FFFFFFFF`。\n> - 当`sw[1]`为`0`且`sw_i[3]`为`1`时，将`sw_i[11:8]`对应寄存器值修改为`sw_i[7:4]`。\n\n#### 做法\n\n这一关不涉及新知识，只要遵守代码规范，通过是很简单的，故不作讲述。\n\n> [!important]\n>\n> **组合逻辑写，时序逻辑读**。\n\n#### 参考代码\n\n```verilog\nmodule rf(\n        input clk,\n        input rst,\n        input RFWr,\n        input [15:0] sw_i,\n        input [4:0] A1, A2, A3,\n        input [31:0] WD,\n        output [31:0] RD1, RD2\n    );\n    reg [31:0] rf [31:0];\n    integer i;\n    always @(posedge clk) begin\n        if (rst) begin\n            for (i = 0; i < 32; i = i + 1) begin\n                rf[i] <= i;\n            end\n        end else if (!RFWr && A3 != 5\'b0) begin\n            rf[A3] <= WD;\n        end\n    end\n    assign RD1 = (A1 == 5\'b0) ? 32\'b0 : rf[A1];\n    assign RD2 = (A2 == 5\'b0) ? 32\'b0 : rf[A2];\nendmodule\n```\n\n主模块调用：\n\n```verilog\nreg [4:0] reg_addr;\nalways @(posedge clk_1s or negedge rstn) begin\n    if (!rstn)\n        reg_addr <= 0;\n    else\n        reg_addr <= reg_addr + 1;\nend\nwire [31:0] data_reg;\nwire [31:0] data_reg_;\nrf u_rf (\n    .clk (clk_1s),\n    .rst (!rstn),\n    .RFWr (sw_i[3] & ~sw_i[1]),\n    .sw_i (sw_i),\n    .A1 (reg_addr),\n    .A2 (reg_addr),\n    .A3 (sw_i[11:8]),\n    .WD (sw_i[7:4]),\n    .RD1 (data_reg),\n    .RD2 (data_reg_)\n);\n```\n\n> 此时笔者技艺不精，部分实现与目标有所区别~~但我懒得改了~~，上述代码仅供参考。\n\n### ALU\n\n#### 目标\n\n> 实现一个算术逻辑单元，要求有如下的端口和寄存器：\n>\n> ```verilog\n> module alu(\n>     input signed [31:0] A, B, // 输入值\n>     input [4:0] ALUOp, // 决定 ALU 运算符\n>     output signed [31:0] C, // 计算结果\n>     output reg [7:0] Zero // 计算结果是否为 0\n> );\n> ```\n>\n> 在原有功能的基础上实现：\n>\n> - 当`sw_i[12]`为`1`时：循环显示`A`，`B`，`C`，`Zero`，一轮循环结尾显示一次`FFFFFFFF`。\n> - 当`sw[1]`为`0`时，`sw_i[10:7]`对应寄存器值作为`A`，`sw_i[6:3]`对应寄存器值作为`B`，`sw_i[2]`为`0`时`C=A-B`，`sw_i[2]`为`1`时`C=A+B`。\n\n#### 做法\n\n这一关不涉及新知识，只要遵守代码规范，通过是很简单的，故不作讲述。\n\n#### 参考代码\n\n```verilog\nmodule alu(\n        input signed [31:0] A, B,\n        input [4:0] ALUOp,\n        output signed [31:0] C,\n        output reg [7:0] Zero\n    );\n    reg signed [31:0] res;\n    always @* begin\n        res = 32\'b0;\n        if (ALUOp == 2\'b00) begin\n            res = A - B;\n            Zero = 8\'b00000000;\n        end\n        else begin\n            res = A + B;\n            Zero = 8\'b00000000;\n        end\n    end\n    assign C = res;\nendmodule\n\n```\n\n### RF & ALU\n\n#### 目标\n\n> 主要内容是把前两次实验模块结合，同时修改部分端口调用。\n>\n> ~~我也不知道为什么要设置一次单独的实验讲如何把RF和ALU结合。~~笔者认为没有意义，此节可以略过。\n\n#### 做法\n\n这一关不涉及新知识，只要遵守代码规范，通过是很简单的，故不作讲述。\n\n#### 参考代码\n\n`没有参考代码`。\n\n### DM\n\n#### 目标\n\n> `DM`本质是数据存储器，在这一节实验中几乎与`RF`等同。此外，`DM`和`单周期`一并作为一次实验项目验收。经过考虑，决定跳过本节实验内容。\n\n#### 做法\n\n这一关不涉及新知识，只要遵守代码规范，通过是很简单的，故不作讲述。\n\n#### 参考代码\n\n`没有参考代码`。\n\n### 单周期\n\n#### 目标\n\n> 实现如图一个单周期**串行**数据通路，并让它执行`ROM IP`核中的指令，包括`add`，`addi`，`lw`，`sw`。\n>\n> ![image-20251130205732867](./pictures/image-20251130205732867.png)\n>\n> 为了方便验收，你可能需要自定义`sw_i`信号使得在某个时候数据通路可以停下来，我的做法是当`sw_i[1]`为`1`时，`PC`读取自己而不是`PC+4`，然后检查各个寄存器的值或内存地址的值。\n\n#### 做法\n\n~~简单的目标往往意味着挑战，别怕！~~\n\n观察这个极简数据通路，你的脑子里可能有一个雏形了，但还是容我简单介绍一下：\n\n- 你可能需要一个`PC`（程序计数器）表示待取指令地址。回想我们学习的`risc-v`指令系统，大部分指令都是`4`字节对齐的，所以`PC`应当是`4`的倍数。\n- `Instruction memory`：我们把指令存储器抽象为之前实现的`IP`核。`Read address`理应为`PC`，而`IP`核的输入`a`并不是`PC`，而应该是`PC>>2`。\n- `Registers`：你之前实现的`RF`已经比较完备了，所以这一块不需要很多改动，图中的控制信号`RegWrite`就是`RFWr`。\n- `ALU`：你之前实现的`ALU`由`sw_i[2]`决定运算。这里你需要用控制信号`ALU operation`决定运算，你可能需要查表。\n- `Data memory`：完全可以把`DM`当作`RF`，没有什么需要讲述的。\n- `Imm Gen`：立即数生成器，注意**负数补码末位补1**。\n- `Mux`：二路选择器，略。\n- `Control`：图中没有标明，建议单独设置一个控制单元输入指令的`opcode`，输出控制信号。\n\n> [!important]\n>\n> **时序逻辑写，组合逻辑读**。\n>\n> **调用模块信号位宽对齐**。\n>\n> **加油**！\n\n#### 参考代码\n\n由于笔者的疏忽，他没有留下针对此次实验的代码，取而代之的是一个支持大部分**R型**，**I型**，**U型**，**UJ型**，**S型**指令的单周期，仅供参考。\n\n*下图为大致示意图（不包括处理`jalr`，`jal`涉及的信号）*\n\n![image-20251016104502612](./pictures/image-20251016104502612.png)\n\n##### `main.v`\n\n```verilog\n`timescale 1ns / 1ps\n//////////////////////////////////////////////////////////////////////////////////\n// Company: WuhanUniversity\n// Engineer: Larry\n// \n// Create Date: 2025/11/21 21:22:27\n// Design Name: CPU\n// Module Name: main\n// Project Name: Digital-Design-Lab\n// Target Devices: Nexys A7\n// Tool Versions: vivado 2023.2\n// Description: A simple RISC-V CPU\n// \n// Dependencies: None\n// \n// Revision:\n// Revision 0.01 - File Created\n// Additional Comments: None\n// \n//////////////////////////////////////////////////////////////////////////////////\n\n\nmodule main(\n        input clk,\n        input rstn,\n        input [15:0] sw_i,\n        output [7:0] disp_seg_o,\n        output [7:0] disp_an_o\n    );\n    reg [31:0] cnt;\n    always @(posedge clk or negedge rstn) begin\n        if (!rstn) begin\n            cnt <= 32\'d0;\n        end else begin\n            cnt <= cnt + 1\'b1;\n        end\n    end\n//    wire clk_1s = sw_i[15] ? cnt[27] : cnt[25];\n    wire clk_1s = clk;\n    reg signed [31:0] PC;\n    wire [31:0] next_PC;\n    always @(posedge clk_1s or negedge rstn) begin\n        if (!rstn) begin\n            PC <= 32\'b0;\n        end \n        else if (sw_i[1]) begin \n            PC <= PC;\n        end \n        else begin\n            PC <= next_PC;\n        end\n    end\n    wire [31:0] instruction;\n    instructions u_instructions(\n        .PC(PC),\n        .instruction(instruction)\n    );\n/*    dist_mem_gen_0 u_dist_mem_gen_0 (\n        .a(PC >> 2),\n        .spo(instruction)\n    );*/\n    wire RegWrite, ALUsrc, MemWrite, MemtoReg, MemRead, Branch, JumpJal, JumpJalr, RegDest, ALUsrcLui, ALUsrcAuipc;\n    wire [1:0] ALUOp;\n    wire [2:0] DMType = instruction[14:12];\n    control u_control(\n        .opcode(instruction[6:0]),\n        .RegWrite(RegWrite),\n        .ALUsrc(ALUsrc),\n        .MemWrite(MemWrite),\n        .MemtoReg(MemtoReg),\n        .MemRead(MemRead),\n        .Branch(Branch),\n        .JumpJal(JumpJal),\n        .JumpJalr(JumpJalr),\n        .RegDest(RegDest),\n        .ALUsrcLui(ALUsrcLui),\n        .ALUsrcAuipc(ALUsrcAuipc),\n        .ALUOp(ALUOp)\n    );\n    wire [31:0] Read_data1, Read_data2;\n    rf u_rf(\n        .clk(clk_1s),\n        .rstn(rstn),\n        .RegWrite(RegWrite),\n        .Read_register1(instruction[19:15]),\n        .Read_register2(instruction[24:20]),\n        .Write_register(instruction[11:7]),\n        .Write_data(mux_res4),\n        .Read_data1(Read_data1),\n        .Read_data2(Read_data2) \n    );\n    wire signed [31:0] imm;\n    immgen u_immgen(\n        .instruction(instruction),\n        .imm(imm)\n    );\n    wire [3:0] ALUoperation;\n    ALUcontrol u_ALUcontrol(\n        .funct({instruction[31:25], instruction[14:12]}),\n        .ALUOp(ALUOp),\n        .ALUoperation(ALUoperation)\n    );\n    wire [31:0] mux_res1;\n    mux u_mux1(\n        .x(Read_data2),\n        .y(imm),\n        .signal(ALUsrc),\n        .z(mux_res1)\n    );\n    wire [31:0] mux_res6;\n    mux u_mux6(\n        .x(Read_data1),\n        .y(0),\n        .signal(ALUsrcLui),\n        .z(mux_res6)\n    );\n    wire [31:0] mux_res7;\n    mux u_mux7(\n        .x(mux_res6),\n        .y(PC),\n        .signal(ALUsrcAuipc),\n        .z(mux_res7)\n    );\n    wire [31:0] ALUresult;\n    wire Zero, Negative, Overflow, Carry;\n    alu u_alu(\n        .ALUoperation(ALUoperation),\n        .A(mux_res7),\n        .B(mux_res1),\n        .ALUresult(ALUresult),\n        .Zero(Zero),\n        .Negative(Negative),\n        .Overflow(Overflow),\n        .Carry(Carry)\n    );\n    wire jump_taken;\n    jump u_jump(\n        .Zero(Zero),\n        .Negative(Negative),\n        .Overflow(Overflow),\n        .Carry(Carry),\n        .funct3(instruction[14:12]),\n        .jump_taken(jump_taken)\n    );\n    wire [31:0] mux_res3;\n    mux u_mux3(\n        .x(PC + 4),\n        .y(imm + PC),\n        .signal((jump_taken & Branch) | JumpJal),\n        .z(mux_res3)\n    );\n    mux u_mux5(\n        .x(mux_res3),\n        .y(ALUresult),\n        .signal(JumpJalr),\n        .z(next_PC)\n    );\n    wire [31:0] Read_data;\n    dm u_dm(\n        .clk(clk_1s),\n        .rstn(rstn),\n        .MemWrite(MemWrite),\n        .MemRead(MemRead),\n        .DMType(DMType),\n        .Address(ALUresult),\n        .Write_data(Read_data2),\n        .Read_data(Read_data)\n    );\n    wire [31:0] mux_res2, mux_res4;\n    mux u_mux2(\n        .x(ALUresult),\n        .y(Read_data),\n        .signal(MemtoReg),\n        .z(mux_res2)\n    );\n    mux u_mux4(\n        .x(mux_res2),\n        .y(PC + 4),\n        .signal(RegDest),\n        .z(mux_res4)\n    );\n    /* 调试部分 */\n    // 寄存器\n    reg [4:0] reg_addr;\n    always @(posedge clk_1s or negedge rstn) begin\n        if (!rstn) reg_addr <= 5\'b0;\n        else reg_addr <= reg_addr + 1;\n    end\n    // ALU结果\n    reg [1:0] alu_addr;\n    reg [31:0] alu_res;\n    always @(posedge clk_1s or negedge rstn) begin\n        if (!rstn) alu_addr <= 2\'b0;\n        else begin\n            alu_addr <= alu_addr + 1;\n            case(alu_addr)\n                2\'b00: alu_res <= Read_data1;\n                2\'b01: alu_res <= mux_res1;\n                2\'b10: alu_res <= ALUresult;\n                2\'b11: alu_res <= Zero;\n            endcase\n        end\n    end\n    // 数据存储器\n    reg [5:0] dm_addr;\n    always @(posedge clk_1s or negedge rstn) begin\n        if (!rstn) dm_addr <= 6\'b0;\n        else dm_addr <= dm_addr + 1;\n    end\n    reg [31:0] display_data;\n    always @(posedge clk_1s or negedge rstn) begin\n        if (!rstn) begin\n            display_data <= 32\'b0;\n        end else begin\n            case(sw_i[14:10])\n                5\'b10000: display_data <= /*instruction*/PC;\n                5\'b01000: display_data <= {35\'b0, reg_addr, u_rf.Registers[reg_addr][23:0]};\n                5\'b00100: display_data <= {32\'b0, alu_res};\n                5\'b00010: display_data <= {34\'b0, dm_addr, 16\'b0, u_dm.data[dm_addr]};\n                default: display_data <= 32\'b0;\n            endcase\n        end\n    end\n    /*alg u_alg(\n        .clk(clk),\n        .rstn(rstn),\n        .i_data(display_data),\n        .disp_mode(sw_i[0]),\n        .o_seg(disp_seg_o),\n        .o_sel(disp_an_o)\n    );*/\nendmodule\n```\n\n##### `instructions.v`\n\n```verilog\n`timescale 1ns / 1ps\nmodule instructions(\n        input signed [31:0] PC,\n        output reg [31:0] instruction\n    );\n    always @* begin\n        case (PC)\n            32\'d0: instruction = 32\'h00500513;    // addi x10, x0, 5\n            32\'d4: instruction = 32\'h06400093;    // addi x1, x0, 100\n            32\'d8: instruction = 32\'h20000113;    // addi x2, x0, 512\n            32\'d12: instruction = 32\'h00100793;   // addi x15, x0, 1\n            32\'d16: instruction = 32\'h04a7f663;   // bgeu x15, x10, 76\n            32\'d20: instruction = 32\'hFF010113;   // addi x2, x2, -16\n            32\'d24: instruction = 32\'h00112623;   // sw x1, 12(x2)\n            32\'d28: instruction = 32\'h00812423;   // sw x8, 8(x2)\n            32\'d32: instruction = 32\'h00912223;   // sw x9, 4(x2)\n            32\'d36: instruction = 32\'h00050413;   // addi x8, x10, 0\n            32\'d40: instruction = 32\'hFFF50513;   // addi x10, x10, -1\n            32\'d44: instruction = 32\'h00000317;   // auipc x6, 0\n            32\'d48: instruction = 32\'hFE0300E7;   // jalr x1, x6, -32\n            32\'d52: instruction = 32\'h00050493;   // addi x9, x10, 0\n            32\'d56: instruction = 32\'hFFE40513;   // addi x10, x8, -2\n            32\'d60: instruction = 32\'h00000317;   // auipc x6, 0\n            32\'d64: instruction = 32\'hFD0300E7;   // jalr x1, x6, -48\n            32\'d68: instruction = 32\'h00A48533;   // add x10, x9, x10\n            32\'d72: instruction = 32\'h00C12083;   // lw x1, 12(x2)\n            32\'d76: instruction = 32\'h00812403;   // lw x8, 8(x2)\n            32\'d80: instruction = 32\'h00412483;   // lw x9, 4(x2)\n            32\'d84: instruction = 32\'h01010113;   // addi x2, x2, 16\n            32\'d88: instruction = 32\'h00008067;   // jalr x0, x1, 0\n            32\'d92: instruction = 32\'h00100513;   // addi x10, x0, 1\n            32\'d96: instruction = 32\'h00008067;   // jalr x0, x1, 0\n            default: instruction = 32\'h00000000;  // nop\n        endcase\n    end\nendmodule\n\n```\n\n##### `alg.v`\n\n```verilog\n`timescale 1ns / 1ps\nmodule alg(\n        input clk, rstn,\n        input[63:0] i_data,\n        input disp_mode,\n        output reg[7:0] o_seg,\n        output reg[7:0] o_sel\n    );\n    parameter div_num = 14;\n    reg [31:0] cnt;\n    always @(posedge clk or negedge rstn) begin\n        if (!rstn) cnt <= 32\'b0;\n        else cnt <= cnt + 1;\n    end\n    wire clk_1s = cnt[div_num];\n    reg [2:0] seg_cnt;\n    always @(posedge clk_1s or negedge rstn) begin\n        if (!rstn) seg_cnt <= 3\'b0;\n        else seg_cnt <= seg_cnt + 1;\n    end\n    wire [3:0] seg_data_r;\n    wire [7:0] seg_data_g;\n    assign seg_data_r = (i_data >> (seg_cnt * 4)) & 4\'hF;\n    assign seg_data_g = (i_data >> (seg_cnt * 8)) & 8\'hFF;\n    always @(seg_cnt or negedge rstn) begin\n        if (!rstn) o_sel <= 8\'b1111_1111;\n        else o_sel <= ~(8\'b0000_0001 << seg_cnt);\n    end\n    always @(seg_data_g or seg_data_r or disp_mode or negedge rstn) begin\n        if (!rstn) o_seg <= 8\'b1111_1111;\n        else begin\n            if (disp_mode) o_seg <= seg_data_g;\n            else begin\n                case(seg_data_r)\n                    4\'h0: o_seg <= 8\'hC0;\n                    4\'h1: o_seg <= 8\'hF9;\n                    4\'h2: o_seg <= 8\'hA4;\n                    4\'h3: o_seg <= 8\'hB0;\n                    4\'h4: o_seg <= 8\'h99;\n                    4\'h5: o_seg <= 8\'h92;\n                    4\'h6: o_seg <= 8\'h82;\n                    4\'h7: o_seg <= 8\'hF8;\n                    4\'h8: o_seg <= 8\'h80;\n                    4\'h9: o_seg <= 8\'h90;\n                    4\'hA: o_seg <= 8\'h88;\n                    4\'hB: o_seg <= 8\'h83;\n                    4\'hC: o_seg <= 8\'hC6;\n                    4\'hD: o_seg <= 8\'hA1;\n                    4\'hE: o_seg <= 8\'h86;\n                    4\'hF: o_seg <= 8\'h8E;\n                    default: o_seg <= 8\'b1111_1111;\n                endcase\n            end\n        end\n    end\nendmodule\n```\n\n##### `rf.v`\n\n```verilog\n`timescale 1ns / 1ps\nmodule rf(\n        input clk, rstn,\n        input RegWrite,\n        input [4:0] Read_register1, Read_register2, Write_register,\n        input [31:0] Write_data,\n        output [31:0] Read_data1, Read_data2 \n    );\n    reg [31:0] Registers[31:0];\n    integer i;\n    always @(posedge clk or negedge rstn) begin\n        if (!rstn) for (i = 0; i < 32; i = i + 1) Registers[i] <= 32\'b0;\n        else if (RegWrite && Write_register != 5\'b0) Registers[Write_register] <= Write_data;\n    end\n    assign Read_data1 = Registers[Read_register1];\n    assign Read_data2 = Registers[Read_register2];\nendmodule\n\n```\n\n##### `control.v`\n\n```verilog\n`timescale 1ns / 1ps\nmodule control(\n        input [6:0] opcode,\n        output reg RegWrite, ALUsrc, MemWrite, MemtoReg, MemRead, Branch, JumpJal, JumpJalr, RegDest, ALUsrcLui, ALUsrcAuipc,\n        output reg [1:0] ALUOp\n    );\n    always @* begin\n        case(opcode[6:0])\n            7\'b0000000: begin\n                RegWrite = 0;\n                ALUsrc = 0;\n                MemWrite = 0;\n                MemtoReg = 0;\n                MemRead = 0;\n                Branch = 0;\n                JumpJal = 0;\n                JumpJalr = 0;\n                RegDest = 0;\n                ALUsrcLui = 0;\n                ALUsrcAuipc = 0;\n                ALUOp = 2\'b00;\n            end\n            7\'b0110011: begin // R\n                RegWrite = 1;\n                ALUsrc = 0;\n                MemWrite = 0;\n                MemtoReg = 0;\n                MemRead = 0;\n                Branch = 0;\n                JumpJal = 0;\n                JumpJalr = 0;\n                RegDest = 0;\n                ALUsrcLui = 0;\n                ALUsrcAuipc = 0;\n                ALUOp = 2\'b10;\n            end\n            7\'b0000011: begin // I_1\n                RegWrite = 1;\n                ALUsrc = 1;\n                MemWrite = 0;\n                MemtoReg = 1;\n                MemRead = 1;\n                Branch = 0;\n                JumpJal = 0;\n                JumpJalr = 0;\n                RegDest = 0;\n                ALUsrcLui = 0;\n                ALUsrcAuipc = 0;\n                ALUOp = 2\'b00;\n            end\n            7\'b0010011: begin // I_2\n                RegWrite = 1;\n                ALUsrc = 1;\n                MemWrite = 0;\n                MemtoReg = 0;\n                MemRead = 0;\n                Branch = 0;\n                JumpJal = 0;\n                JumpJalr = 0;\n                RegDest = 0;\n                ALUsrcLui = 0;\n                ALUsrcAuipc = 0;\n                ALUOp = 2\'b11;\n            end\n            7\'b0100011: begin // S\n                RegWrite = 0;\n                ALUsrc = 1;\n                MemWrite = 1;\n                MemtoReg = 0;\n                MemRead = 0;\n                Branch = 0;\n                JumpJal = 0;\n                JumpJalr = 0;\n                RegDest = 0;\n                ALUsrcLui = 0;\n                ALUsrcAuipc = 0;\n                ALUOp = 2\'b00;\n            end\n            7\'b1100011: begin // B\n                RegWrite = 0;\n                ALUsrc = 0;\n                MemWrite = 0;\n                MemtoReg = 0;\n                MemRead = 0;\n                Branch = 1;\n                JumpJal = 0;\n                JumpJalr = 0;\n                RegDest = 0;\n                ALUsrcLui = 0;\n                ALUsrcAuipc = 0;\n                ALUOp = 2\'b01;\n            end\n            7\'b1100111: begin // jalr\n                RegWrite = 1;\n                ALUsrc = 1;\n                MemWrite = 0;\n                MemtoReg = 0;\n                MemRead = 0;\n                Branch = 0;\n                JumpJal = 0;\n                JumpJalr = 1;\n                RegDest = 1;\n                ALUsrcLui = 0;\n                ALUsrcAuipc = 0;\n                ALUOp = 2\'b00;\n            end\n            7\'b1101111: begin // jal\n                RegWrite = 1;\n                ALUsrc = 0;\n                MemWrite = 0;\n                MemtoReg = 0;\n                MemRead = 0;\n                Branch = 0;\n                JumpJal = 1;\n                JumpJalr = 0;\n                RegDest = 1;\n                ALUsrcLui = 0;\n                ALUsrcAuipc = 0;\n                ALUOp = 2\'b00;\n            end\n            7\'b0110111: begin // lui\n                RegWrite = 1;\n                ALUsrc = 1;\n                MemWrite = 0;\n                MemtoReg = 0;\n                MemRead = 0;\n                Branch = 0;\n                JumpJal = 0;\n                JumpJalr = 0;\n                RegDest = 0;\n                ALUsrcLui = 1;\n                ALUsrcAuipc = 0;\n                ALUOp = 2\'b00;\n            end\n            7\'b0010111: begin // auipc\n                RegWrite = 1;\n                ALUsrc = 1;\n                MemWrite = 0;\n                MemtoReg = 0;\n                MemRead = 0;\n                Branch = 0;\n                JumpJal = 0;\n                JumpJalr = 0;\n                RegDest = 0;\n                ALUsrcLui = 0;\n                ALUsrcAuipc = 1;\n                ALUOp = 2\'b00;\n            end\n        endcase\n    end\nendmodule\n```\n\n##### `immgen.v`\n\n```verilog\n`timescale 1ns / 1ps\nmodule immgen(\n        input [31:0] instruction,\n        output reg signed [31:0] imm\n    );\n    always @* begin\n        case(instruction[6:0])\n            7\'b0110011: begin // R\n                imm = 32\'b0;\n            end\n            7\'b0000011: begin // I_1\n                imm = (instruction[31] == 0) ? {20\'b0, instruction[31:20]} : {20\'hFFFFF, instruction[31:20]};\n            end\n            7\'b0010011: begin // I_2\n                if (instruction[14:12] == 3\'b001 || instruction[14:12] == 3\'b101) imm = {25\'b0, instruction[26:20]};\n                else imm = (instruction[31] == 0) ? {20\'b0, instruction[31:20]} : {20\'hFFFFF, instruction[31:20]};\n            end\n            7\'b1100111: begin // jalr\n                imm = (instruction[31] == 0) ? {20\'b0, instruction[31:20]} : {20\'hFFFFF, instruction[31:20]};\n            end\n            7\'b0100011: begin // S\n                imm = (instruction[31] == 0) ? {20\'b0, instruction[31:25], instruction[11:7]} : {20\'hFFFFF, instruction[31:25], instruction[11:7]};\n            end\n            7\'b1100011: begin // SB\n                imm = (instruction[31] == 0) ? {19\'b0, instruction[31], instruction[7], instruction[30:25], instruction[11:8], 1\'b0} : {19\'h7FFFF, instruction[31], instruction[7], instruction[30:25], instruction[11:8], 1\'b0};\n            end\n            7\'b1101111: begin // UJ\n                imm = (instruction[31] == 0) ? {11\'b0, instruction[31], instruction[19:12], instruction[20], instruction[30:21], 1\'b0} : {11\'h7FF, instruction[31], instruction[19:12], instruction[20], instruction[30:21], 1\'b0};\n            end\n            7\'b0110111: begin // lui\n                imm = {instruction[31:12], 12\'b0};\n            end\n            7\'b0010111: begin // auipc\n                imm = (instruction[31] == 0) ? {instruction[31:12], 12\'b0} : {instruction[31:12], 12\'hFFF};\n            end\n            default: begin\n                imm = 32\'b0;\n            end\n        endcase\n    end\nendmodule\n```\n\n##### `ALUcontrol.v`\n\n```verilog\n`timescale 1ns / 1ps\nmodule ALUcontrol(\n        input [9:0] funct,\n        input [1:0] ALUOp,\n        output reg [3:0] ALUoperation\n    );\n    always @* begin\n        case(ALUOp)\n            2\'b00: begin\n                ALUoperation = 4\'b0000;\n            end\n            2\'b01: begin\n                ALUoperation = 4\'b0001;\n            end\n            2\'b10: begin\n                case(funct)\n                    10\'b0000000_000: ALUoperation = 4\'b0000;\n                    10\'b0100000_000: ALUoperation = 4\'b0001;\n                    10\'b0000000_001: ALUoperation = 4\'b0101;\n                    10\'b0000000_100: ALUoperation = 4\'b0100;\n                    10\'b0000000_101: ALUoperation = 4\'b0110;\n                    10\'b0100000_101: ALUoperation = 4\'b0111;\n                    10\'b0000000_110: ALUoperation = 4\'b0011;\n                    10\'b0000000_111: ALUoperation = 4\'b0010;\n                    10\'b0000001_000: ALUoperation = 4\'b1000;\n                    10\'b0000001_001: ALUoperation = 4\'b1001;\n                    10\'b0000001_011: ALUoperation = 4\'b1010;\n                    10\'b0000001_010: ALUoperation = 4\'b1011;\n                    10\'b0000001_100: ALUoperation = 4\'b1100;\n                    10\'b0000001_101: ALUoperation = 4\'b1101;\n                    10\'b0000001_110: ALUoperation = 4\'b1110;\n                    10\'b0000001_111: ALUoperation = 4\'b1111;\n                    default: ALUoperation = 4\'b0000;\n                endcase\n            end\n            2\'b11: begin\n                case(funct[2:0])\n                    3\'b000: ALUoperation = 4\'b0000;\n                    3\'b001: ALUoperation = 4\'b0101;\n                    3\'b100: ALUoperation = 4\'b0100;\n                    3\'b101: begin\n                        if (funct[3] == 1\'b0) ALUoperation = 4\'b0110;\n                        else ALUoperation = 4\'b0111;\n                    end\n                    3\'b110: ALUoperation = 4\'b0011;\n                    3\'b111: ALUoperation = 4\'b0010;\n                    default: ALUoperation = 4\'b0000;\n                endcase\n            end\n            default: ALUoperation = 4\'b0000;\n        endcase\n    end\nendmodule\n```\n\n##### `alu.v`\n\n```verilog\n`timescale 1ns / 1ps\nmodule alu(\n        input [3:0] ALUoperation,\n        input signed [31:0] A, B,\n        output signed [31:0] ALUresult,\n        output Zero, Negative, Overflow, Carry\n    );\n    reg signed [31:0] res;\n    always @* begin\n        res = 32\'b0;\n        case(ALUoperation)\n            4\'b0000: res = A + B;\n            4\'b0001: res = A - B;\n            4\'b0010: res = A & B;\n            4\'b0011: res = A | B;\n            4\'b0100: res = A ^ B;\n            4\'b0101: res = A << B;\n            4\'b0110: res = A >> B;\n            4\'b0111: res = A >>> B;\n            4\'b1000: res = A * B;\n            4\'b1001: res = A * B; // 暂略\n            4\'b1010: res = A * B; // 暂略\n            4\'b1011: res = A * B; // 暂略\n            4\'b1100: res = A / B;\n            4\'b1101: res = A / B; // 暂略\n            4\'b1110: res = A % B;\n            4\'b1111: res = A % B; // 暂略\n            default: res = 0;\n        endcase\n    end\n    assign ALUresult = res;\n    assign Zero = (res == 32\'b0) ? 1\'b1 : 1\'b0;\n    assign Negative = res[31];\n    assign Overflow = ((ALUoperation == 4\'b0000) && (A[31] == B[31]) && (res[31] != A[31])) ? 1\'b1 :\n                      ((ALUoperation == 4\'b0001) && (A[31] != B[31]) && (res[31] != A[31])) ? 1\'b1 : 1\'b0;\n    assign Carry = ((ALUoperation == 4\'b0000) && (res < A)) ? 1\'b1 :\n                   ((ALUoperation == 4\'b0001) && {1\'b0, A} < {1\'b0, B}) ? 1\'b1 : 1\'b0;\nendmodule\n```\n\n##### `dm.v`\n\n```verilog\n`timescale 1ns / 1ps\nmodule dm(\n        input clk, rstn,\n        input MemWrite, MemRead,\n        input [2:0] DMType,\n        input [31:0] Address, Write_data,\n        output [31:0] Read_data\n    );\n    reg [7:0] data[63:0];\n    reg [31:0] R_d;\n    integer i;\n    always @(posedge clk or negedge rstn) begin\n        if (!rstn) for (i = 0; i < 512; i = i + 1) data[i] <= 8\'b0;\n        else begin\n            if (MemWrite) begin\n                case (DMType)\n                    3\'b000: begin\n                        data[Address] <= Write_data[7:0];\n                    end\n                    3\'b001: begin\n                        data[Address] <= Write_data[7:0];\n                        data[Address + 1] <= Write_data[15:8];\n                    end\n                    3\'b010: begin\n                        data[Address] <= Write_data[7:0];\n                        data[Address + 1] <= Write_data[15:8];\n                        data[Address + 2] <= Write_data[23:16];\n                        data[Address + 3] <= Write_data[31:24];\n                    end/*\n                    3\'b011: begin\n                        data[Address] <= Write_data[7:0];\n                        data[Address + 1] <= Write_data[15:8];\n                        data[Address + 2] <= Write_data[23:16];\n                        data[Address + 3] <= Write_data[31:24];\n                        data[Address + 4] <= Write_data[39:32];\n                        data[Address + 5] <= Write_data[47:40];\n                        data[Address + 6] <= Write_data[55:48];\n                        data[Address + 7] <= Write_data[63:56];\n                    end*/\n                endcase\n            end\n        end\n    end\n    always @* begin\n        if (MemRead) begin\n            case (DMType)\n                3\'b000: begin\n                    R_d[31:0] = {{24{data[Address + 3][7]}}, data[Address + 3]};\n                end\n                3\'b001: begin\n                    R_d[31:0] = {{16{data[Address + 1][7]}}, data[Address + 1], data[Address]};\n                end\n                3\'b010: begin\n                    R_d[31:0] = {data[Address + 3], data[Address + 2], data[Address + 1], data[Address]};\n                end/*\n                3\'b011: begin\n                    R_d[63:0] = {data[Address + 7], data[Address + 6], data[Address + 5], data[Address + 4], data[Address + 3], data[Address + 2], data[Address + 1], data[Address]};\n                end*/\n                3\'b100: begin\n                    R_d[31:0] = {24\'b0, data[Address]};\n                end\n                3\'b101: begin\n                    R_d[31:0] = {16\'b0, data[Address + 1], data[Address]};\n                end\n                3\'b110: begin\n                    R_d[31:0] = {data[Address + 3], data[Address + 2], data[Address + 1], data[Address]};\n                end\n            endcase\n        end\n    end\n    assign Read_data = R_d[31:0];\nendmodule\n```\n\n##### `jump.v`\n\n```verilog\n`timescale 1ns / 1ps\nmodule jump(\n        input Zero, Negative, Overflow, Carry,\n        input [2:0] funct3,\n        output reg jump_taken\n    );\n    always @* begin\n        case (funct3)\n            3\'b000: jump_taken = Zero;\n            3\'b001: jump_taken = ~Zero;\n            3\'b100: jump_taken = Negative ^ Overflow;\n            3\'b101: jump_taken = ~(Negative ^ Overflow);\n            3\'b110: jump_taken = Carry;\n            3\'b111: jump_taken = ~Carry;\n            default: jump_taken = 1\'b0;\n        endcase\n    end\nendmodule\n```\n\n##### `mux.v`\n\n```verilog\n`timescale 1ns / 1ps\nmodule mux(\n        input [31:0] x,\n        input [31:0] y,\n        input signal,\n        output [31:0] z\n    );\n    assign z = signal ? y : x;\nendmodule\n```' 
                      }
                  ]
                },
                { id: 'operating_system', title: '操作系统A', icon: 'fas fa-question', desc: '<p></p>',
                  chapters: [
                      { id: 'operating_system-1', 
                        title: '1、导论', 
                        desc: '', 
                        content: '# 1.导论\n\n> 阅读此章节，对操作系统形成一个初步印象。\n\n## 1.1操作系统的功能\n\n### 1.1.1用户视角\n\n操作系统设计的主要目的是用户**使用方便**，次要目的是**性能**，不在乎的是**资源利用（如何共享硬件和软件资源）**。\n\n对于**大型机或小型机相连的终端**或**工作站**，操作系统要兼顾使用方便性和资源利用率。\n\n### 1.1.2系统视角\n\n可将操作系统看作**资源分配器**，以及作为**控制程序**管理用户程序的执行尤其是I/O设备的运行和控制。\n\n### 1.1.3操作系统的定义\n\n一个比较公认的定义是：程序包含**内核**、**系统程序**和**应用程序**。\n\n- 操作系统是一直运行在计算机上的程序**内核（kernel）**。\n- 系统程序与系统运行有关但不是内核一部分。\n- 应用程序与系统运行无关。\n\n至于移动操作系统，通常除了内核还有**中间件（为应用程序开发人员提供其他功能的软件框架）**。\n\n## 1.2计算机系统的组成\n\n### 1.2.1计算机系统的运行\n\n![image-20260207170654319](./pictures/image-20260207170654319.png)\n\n- 计算机开始运行时，需要运行一个初始程序，其位于**ROM**或**EEPROM**部分，初始化系统的各个组件。\n\n  > [!note]\n  >\n  > 在Ubuntu虚拟机上：\n  >\n  > ```cmd\n  > > sudo dd if=/dev/sda of=mbr.bin bs=512 count=1\n  > > ndisasm -b 16 -o 7c00h mbr.bin > atest\n  > ```\n  >\n  > 启动时BIOS会读取硬盘的第一个扇区并加载到内存地址`0x7C00`。\n  >\n  > 这两段指令的含义是读取这个扇区的指令并反汇编。\n  >\n  > ```bash\n  > 00007C00  EB63              jmp short 0x7c65\n  > 00007C02  90                nop\n  > 00007C03  0000              add [bx+si],al\n  > 00007C05  0000              add [bx+si],al\n  > 00007C07  0000              add [bx+si],al\n  > 00007C09  0000              add [bx+si],al\n  > 00007C0B  0000              add [bx+si],al\n  > 00007C0D  0000              add [bx+si],al\n  > 00007C0F  0000              add [bx+si],al\n  > 00007C11  0000              add [bx+si],al\n  > 00007C13  0000              add [bx+si],al\n  > 00007C15  0000              add [bx+si],al\n  > 00007C17  0000              add [bx+si],al\n  > 00007C19  0000              add [bx+si],al\n  > 00007C1B  0000              add [bx+si],al\n  > 00007C1D  0000              add [bx+si],al\n  > 00007C1F  0000              add [bx+si],al\n  > 00007C21  0000              add [bx+si],al\n  > 00007C23  0000              add [bx+si],al\n  > 00007C25  0000              add [bx+si],al\n  > 00007C27  0000              add [bx+si],al\n  > 00007C29  0000              add [bx+si],al\n  > 00007C2B  0000              add [bx+si],al\n  > 00007C2D  0000              add [bx+si],al\n  > 00007C2F  0000              add [bx+si],al\n  > 00007C31  0000              add [bx+si],al\n  > 00007C33  0000              add [bx+si],al\n  > 00007C35  0000              add [bx+si],al\n  > 00007C37  0000              add [bx+si],al\n  > 00007C39  0000              add [bx+si],al\n  > 00007C3B  0000              add [bx+si],al\n  > 00007C3D  0000              add [bx+si],al\n  > 00007C3F  0000              add [bx+si],al\n  > 00007C41  0000              add [bx+si],al\n  > 00007C43  0000              add [bx+si],al\n  > 00007C45  0000              add [bx+si],al\n  > 00007C47  0000              add [bx+si],al\n  > 00007C49  0000              add [bx+si],al\n  > 00007C4B  0000              add [bx+si],al\n  > 00007C4D  0000              add [bx+si],al\n  > 00007C4F  0000              add [bx+si],al\n  > 00007C51  0000              add [bx+si],al\n  > 00007C53  0000              add [bx+si],al\n  > 00007C55  0000              add [bx+si],al\n  > 00007C57  0000              add [bx+si],al\n  > 00007C59  0000              add [bx+si],al\n  > 00007C5B  800008            add byte [bx+si],0x8\n  > 00007C5E  0000              add [bx+si],al\n  > 00007C60  0000              add [bx+si],al\n  > 00007C62  0000              add [bx+si],al\n  > 00007C64  FF                db 0xff\n  > 00007C65  FA                cli\n  > 00007C66  90                nop\n  > 00007C67  90                nop\n  > 00007C68  F6C280            test dl,0x80\n  > 00007C6B  7405              jz 0x7c72\n  > 00007C6D  F6C270            test dl,0x70\n  > 00007C70  7402              jz 0x7c74\n  > 00007C72  B280              mov dl,0x80\n  > 00007C74  EA797C0000        jmp 0x0:0x7c79\n  > 00007C79  31C0              xor ax,ax\n  > 00007C7B  8ED8              mov ds,ax\n  > 00007C7D  8ED0              mov ss,ax\n  > 00007C7F  BC0020            mov sp,0x2000\n  > 00007C82  FB                sti\n  > 00007C83  A0647C            mov al,[0x7c64]\n  > 00007C86  3CFF              cmp al,0xff\n  > 00007C88  7402              jz 0x7c8c\n  > 00007C8A  88C2              mov dl,al\n  > 00007C8C  52                push dx\n  > 00007C8D  BB1704            mov bx,0x417\n  > 00007C90  F60703            test byte [bx],0x3\n  > 00007C93  7406              jz 0x7c9b\n  > 00007C95  BE887D            mov si,0x7d88\n  > 00007C98  E81701            call 0x7db2\n  > 00007C9B  BE057C            mov si,0x7c05\n  > 00007C9E  B441              mov ah,0x41\n  > 00007CA0  BBAA55            mov bx,0x55aa\n  > 00007CA3  CD13              int 0x13\n  > 00007CA5  5A                pop dx\n  > 00007CA6  52                push dx\n  > 00007CA7  723D              jc 0x7ce6\n  > 00007CA9  81FB55AA          cmp bx,0xaa55\n  > 00007CAD  7537              jnz 0x7ce6\n  > 00007CAF  83E101            and cx,byte +0x1\n  > 00007CB2  7432              jz 0x7ce6\n  > 00007CB4  31C0              xor ax,ax\n  > 00007CB6  894404            mov [si+0x4],ax\n  > 00007CB9  40                inc ax\n  > 00007CBA  8844FF            mov [si-0x1],al\n  > 00007CBD  894402            mov [si+0x2],ax\n  > 00007CC0  C7041000          mov word [si],0x10\n  > 00007CC4  668B1E5C7C        mov ebx,[0x7c5c]\n  > 00007CC9  66895C08          mov [si+0x8],ebx\n  > 00007CCD  668B1E607C        mov ebx,[0x7c60]\n  > 00007CD2  66895C0C          mov [si+0xc],ebx\n  > 00007CD6  C744060070        mov word [si+0x6],0x7000\n  > 00007CDB  B442              mov ah,0x42\n  > 00007CDD  CD13              int 0x13\n  > 00007CDF  7205              jc 0x7ce6\n  > 00007CE1  BB0070            mov bx,0x7000\n  > 00007CE4  EB76              jmp short 0x7d5c\n  > 00007CE6  B408              mov ah,0x8\n  > 00007CE8  CD13              int 0x13\n  > 00007CEA  730D              jnc 0x7cf9\n  > 00007CEC  5A                pop dx\n  > 00007CED  84D2              test dl,dl\n  > 00007CEF  0F83D000          jnc near 0x7dc3\n  > 00007CF3  BE937D            mov si,0x7d93\n  > 00007CF6  E98200            jmp 0x7d7b\n  > 00007CF9  660FB6C6          movzx eax,dh\n  > 00007CFD  8864FF            mov [si-0x1],ah\n  > 00007D00  40                inc ax\n  > 00007D01  66894404          mov [si+0x4],eax\n  > 00007D05  0FB6D1            movzx dx,cl\n  > 00007D08  C1E202            shl dx,byte 0x2\n  > 00007D0B  88E8              mov al,ch\n  > 00007D0D  88F4              mov ah,dh\n  > 00007D0F  40                inc ax\n  > 00007D10  894408            mov [si+0x8],ax\n  > 00007D13  0FB6C2            movzx ax,dl\n  > 00007D16  C0E802            shr al,byte 0x2\n  > 00007D19  668904            mov [si],eax\n  > 00007D1C  66A1607C          mov eax,[0x7c60]\n  > 00007D20  6609C0            or eax,eax\n  > 00007D23  754E              jnz 0x7d73\n  > 00007D25  66A15C7C          mov eax,[0x7c5c]\n  > 00007D29  6631D2            xor edx,edx\n  > 00007D2C  66F734            div dword [si]\n  > 00007D2F  88D1              mov cl,dl\n  > 00007D31  31D2              xor dx,dx\n  > 00007D33  66F77404          div dword [si+0x4]\n  > 00007D37  3B4408            cmp ax,[si+0x8]\n  > 00007D3A  7D37              jnl 0x7d73\n  > 00007D3C  FEC1              inc cl\n  > 00007D3E  88C5              mov ch,al\n  > 00007D40  30C0              xor al,al\n  > 00007D42  C1E802            shr ax,byte 0x2\n  > 00007D45  08C1              or cl,al\n  > 00007D47  88D0              mov al,dl\n  > 00007D49  5A                pop dx\n  > 00007D4A  88C6              mov dh,al\n  > 00007D4C  BB0070            mov bx,0x7000\n  > 00007D4F  8EC3              mov es,bx\n  > 00007D51  31DB              xor bx,bx\n  > 00007D53  B80102            mov ax,0x201\n  > 00007D56  CD13              int 0x13\n  > 00007D58  721E              jc 0x7d78\n  > 00007D5A  8CC3              mov bx,es\n  > 00007D5C  60                pusha\n  > 00007D5D  1E                push ds\n  > 00007D5E  B90001            mov cx,0x100\n  > 00007D61  8EDB              mov ds,bx\n  > 00007D63  31F6              xor si,si\n  > 00007D65  BF0080            mov di,0x8000\n  > 00007D68  8EC6              mov es,si\n  > 00007D6A  FC                cld\n  > 00007D6B  F3A5              rep movsw\n  > 00007D6D  1F                pop ds\n  > 00007D6E  61                popa\n  > 00007D6F  FF265A7C          jmp [0x7c5a]\n  > 00007D73  BE8E7D            mov si,0x7d8e\n  > 00007D76  EB03              jmp short 0x7d7b\n  > 00007D78  BE9D7D            mov si,0x7d9d\n  > 00007D7B  E83400            call 0x7db2\n  > 00007D7E  BEA27D            mov si,0x7da2\n  > 00007D81  E82E00            call 0x7db2\n  > 00007D84  CD18              int 0x18\n  > 00007D86  EBFE              jmp short 0x7d86\n  > 00007D88  47                inc di\n  > 00007D89  52                push dx\n  > 00007D8A  55                push bp\n  > 00007D8B  42                inc dx\n  > 00007D8C  2000              and [bx+si],al\n  > 00007D8E  47                inc di\n  > 00007D8F  656F              gs outsw\n  > 00007D91  6D                insw\n  > 00007D92  004861            add [bx+si+0x61],cl\n  > 00007D95  7264              jc 0x7dfb\n  > 00007D97  204469            and [si+0x69],al\n  > 00007D9A  736B              jnc 0x7e07\n  > 00007D9C  005265            add [bp+si+0x65],dl\n  > 00007D9F  61                popa\n  > 00007DA0  640020            add [fs:bx+si],ah\n  > 00007DA3  45                inc bp\n  > 00007DA4  7272              jc 0x7e18\n  > 00007DA6  6F                outsw\n  > 00007DA7  720D              jc 0x7db6\n  > 00007DA9  0A00              or al,[bx+si]\n  > 00007DAB  BB0100            mov bx,0x1\n  > 00007DAE  B40E              mov ah,0xe\n  > 00007DB0  CD10              int 0x10\n  > 00007DB2  AC                lodsb\n  > 00007DB3  3C00              cmp al,0x0\n  > 00007DB5  75F4              jnz 0x7dab\n  > 00007DB7  C3                ret\n  > 00007DB8  0000              add [bx+si],al\n  > 00007DBA  0000              add [bx+si],al\n  > 00007DBC  0000              add [bx+si],al\n  > 00007DBE  0000              add [bx+si],al\n  > 00007DC0  0200              add al,[bx+si]\n  > 00007DC2  EE                out dx,al\n  > 00007DC3  FF                db 0xff\n  > 00007DC4  FF                db 0xff\n  > 00007DC5  FF01              inc word [bx+di]\n  > 00007DC7  0000              add [bx+si],al\n  > 00007DC9  00FF              add bh,bh\n  > 00007DCB  FF                db 0xff\n  > 00007DCC  FF0F              dec word [bx]\n  > 00007DCE  0000              add [bx+si],al\n  > 00007DD0  0000              add [bx+si],al\n  > 00007DD2  0000              add [bx+si],al\n  > 00007DD4  0000              add [bx+si],al\n  > 00007DD6  0000              add [bx+si],al\n  > 00007DD8  0000              add [bx+si],al\n  > 00007DDA  0000              add [bx+si],al\n  > 00007DDC  0000              add [bx+si],al\n  > 00007DDE  0000              add [bx+si],al\n  > 00007DE0  0000              add [bx+si],al\n  > 00007DE2  0000              add [bx+si],al\n  > 00007DE4  0000              add [bx+si],al\n  > 00007DE6  0000              add [bx+si],al\n  > 00007DE8  0000              add [bx+si],al\n  > 00007DEA  0000              add [bx+si],al\n  > 00007DEC  0000              add [bx+si],al\n  > 00007DEE  0000              add [bx+si],al\n  > 00007DF0  0000              add [bx+si],al\n  > 00007DF2  0000              add [bx+si],al\n  > 00007DF4  0000              add [bx+si],al\n  > 00007DF6  0000              add [bx+si],al\n  > 00007DF8  0000              add [bx+si],al\n  > 00007DFA  0000              add [bx+si],al\n  > 00007DFC  0000              add [bx+si],al\n  > 00007DFE  55                push bp\n  > 00007DFF  AA                stosb\n  > ```\n  >\n  > 里面有一些初始化的指令，比如`00007C7F  BC0020            mov sp,0x2000`初始化栈指针。\n  >\n  > 最后两条指令的`55AA`被叫做**魔数**，用于验证MBR的完整性。若损坏，磁盘无法被识别。\n  >\n  > 注意，由于反汇编的疏漏，部分地址字符应当对应字符串却被翻译为其它指令。\n  >\n  > 如果我们试图修改魔数，会导致启动出现故障，你可以这样做：\n  >\n  > ```cmd\n  > > sudo hexedit /dev/sda\n  > ```\n  >\n  > 修改魔数，`ctrl+x`保存。\n\n- 内核加到内存并执行时，它和系统程序（作为系统进程）为系统和用户提供服务。后续的操作通过事件发生完成。\n\n- 硬件可以随时通过**系统总线发送信号**到CPU触发中断。软件通过**系统调用**触发中断。组成原理的知识告诉我们中断可以采取**中断向量**的方式处理。\n\n### 1.2.2存储结构\n\n这一部分我们不作过多介绍。\n\n![image-20260207213208667](./pictures/image-20260207213208667.png)\n\n### 1.2.3I/O结构\n\n这一部分同样在组成原理有概述，我们会在后面详细介绍。\n\n![image-20260207213852035](./pictures/image-20260207213852035.png)\n\n## 1.3计算机系统的体系结构\n\n### 1.3.1单处理器系统\n\n一个主CPU，执行一个通用指令集，其它部件都有专用的处理器，比如：\n\n- I/O处理器\n- 显卡处理器\n\n- 终端/通信处理器\n\n专用处理器执行有限指令集，不执行用户进程。\n\n### 1.3.2多处理器系统\n\n这类系统有两个或多个紧密通信的CPU，它们共享计算机总线，有时还共享时钟、内存、外设等。\n\n这种系统能**增加吞吐量**、**布设规模经济**、**可靠性强**。\n\n关于可靠性，有一些机制对故障检测或者纠错：\n\n- **HP NonStop**：每对处理器同步执行相同的指令，如果结果不一样，就转到另一对CPU执行。\n\n最为常用的多处理器系统采用**对称多处理（SMP）**，也就是每个处理器对等地参加操作系统的任务。\n\n![image-20260207215122372](./pictures/image-20260207215122372.png)\n\n多处理使系统的内存访问模型从**均匀内存访问（UMA）**改成**非均匀内存访问（NUMA）**。\n\n### 1.3.3集群系统\n\n另一类型的多处理器系统，由多个独立系统组成。\n\n它可以是**对称**或**非对称**的，取决于主机之间的策略。\n\n因集群网络相连的计算机系统结构，可以提供**高性能计算**环境，称为**并行计算**。但这类技术通常需要专门编写程序，我们可以在分布式计算相关的课程学习到。\n\n## 1.4操作系统的结构\n\n**多道程序设计**的思想如下：\n\n所有作业保存在磁盘的**作业池**上。操作系统为部分作业分配内存，从内存中选择执行作业。当某个作业需要等待某个任务时，CPU会切换到另一个作业继续执行，CPU不会空闲。\n\n在此基础上延伸出了**分时系统**：\n\n任务执行要在**时间片**内，超过这个时间强制切换任务。因而切换频率很高，用户可以在程序运行时与其交互。\n\n用户通过输入设备发出指令，等待输出设备的即时结果，这个过程**响应时间**通常小于1秒。\n\n---\n\n以上结构贯穿始终，我们将会学习有关**作业调度**、**CPU调度**、**存储结构**、**文件系统**等知识去完善操作系统结构。\n\n## 1.5操作系统的执行\n\n### 1.5.1双重模式与多重模式的执行\n\n至少需要两种单独运行模式：**用户模式（user mode）**和**内核模式（kernel mode）**，它们通过一个模式位表示，比如众所周知64位机的高16位地址不被使用，其实这16位会被用来区分两种模式。\n\n![image-20260207224900308](./pictures/image-20260207224900308.png)\n\n操作系统在用户模式下执行用户程序，一旦有陷阱或中断，就会切换为内核模式，在将控制交给用户程序前，系统会切换到用户模式。\n\n硬件只在内核模式下执行**特权指令**，比如：\n\n- I/O操作。\n- 修改中断描述符表。\n- 停机指令`HLT`。\n- 修改寄存器`CR3`，这个寄存器控制着页表。\n- 修改定时器。\n\n### 1.5.2定时器\n\n**定时器（timer）** 可设置为在指定周期后中断计算机。\n\n**可变定时器（variable timer）** 一般通过一个固定速率的时钟和计数器来实现。\n\n定时器可以应对用户程序死循环的情况。\n\n## 1.6进程管理\n\n进程是执行程序的主动实体。\n\n单线程进程有一个**程序计数器（PC）**，每个进程执行最多一条指令，CPU根据PC顺序执行指令。\n\n## 1.7内存管理\n\n操作系统负责以下活动：\n\n- 记录内存的哪部分在被使用以及被谁使用。\n- 决定哪些进程或其部分会调入或调出内存。\n- 根据需要分配和释放内存空间。\n\n## 1.8存储管理\n\n### 1.8.1文件系统管理\n\n操作系统负责以下活动：\n\n- 创建和删除文件。\n- 创建和删除目录，以便组织文件。\n- 提供文件和目录的操作原语。\n- 映射文件到外存。\n- 备份文件到稳定存储介质。\n\n### 1.8.2大容量存储器管理\n\n操作系统负责有关活动：\n\n- 空闲空间管理。\n- 存储空间分配。\n- 硬盘调度。\n\n通常外存的读取会和次数有关，因此计算机运行的最终速度会受限于硬盘子系统的调度算法。\n\n### 1.8.3高速缓存\n\n我们了解过CPU的高速缓存机制，未来我们需要理解更多软件控制的各种高速缓存的置换算法。\n\n![image-20260207231154303](./pictures/image-20260207231154303.png)\n\n缓存通常还待面临多写冲突等问题。\n\n### 1.8.4I/O系统\n\n**I/O子系统**为操作系统隐藏了I/O设备的特性，包括：\n\n- 缓冲、高速缓存和假脱机的内存管理组件。\n- 设备驱动器的通用接口。\n- 特定硬件设备的驱动程序。\n\n只有设备驱动程序才能知道控制设备的特性。\n\n## 1.9保护与安全\n\n有关数据访问控制。\n\n## 1.10内核数据结构\n\n简单介绍会用到的数据结构。\n\n### 1.10.1列表、堆栈及队列\n\n### 1.10.2树\n\n### 1.10.3哈希函数与哈希表\n\n### 1.10.4位图\n\n位图是$n$个二进制位的串，用于表示$n$项的状态。\n\n> [!note]\n> Linux内核所用的数据结构有源码。头文件`<linux/list.h>`包括内核所用的链表数据结构的实现细节。Linux的队列称为kfifo，源代码的目录kernel的文件kfifo.c包含它的实现。Linux通过红黑树提供了平衡二分查找树的实现，头文件`<linux/rbtree.h>`包括它的细节。\n\n## 1.11计算环境\n\n### 1.11.1传统计算\n\n### 1.11.2移动计算\n\n### 1.11.3分布计算\n\n### 1.11.4客户机-服务器计算\n\n### 1.11.5对等计算\n\n### 1.11.6虚拟化\n\n### 1.11.7云计算\n\n### 1.11.8实时嵌入式系统' 
                      },
                      { id: 'operating_system-2', 
                        title: '2、操作系统结构', 
                        desc: '', 
                        content: '# 2.操作系统结构\n\n## 2.1操作系统的服务\n\n![image-20260211091727536](./pictures/image-20260211091727536.png)\n\n操作系统服务提供用户功能：\n\n- **用户界面（User Interface，UI）**：一种形式是**命令行界面（Command-Line Interface，CLI）**，另一种是**批处理界面（Batch Interface）**，还有**图形用户界面（Graphical User Interface，GUI）**。\n\n  > [!note]\n  >\n  > 我们对CLI和GUI都十分熟悉。\n  >\n  > 如果你尝试过超算、服务器部署任务，你会对BI很熟悉。以下是一个`sbatch`脚本示例：\n  >\n  > ```bash\n  > #!/bin/bash\n  > \n  > # --- SLURM 指令区 (以 #SBATCH 开头) ---\n  > \n  > #SBATCH --job-name=MBR_Analysis         # 任务名称\n  > #SBATCH --output=result_%j.log          # 标准输出文件 (%j 会替换为任务 ID)\n  > #SBATCH --error=error_%j.log            # 错误日志文件\n  > #SBATCH --partition=compute             # 提交到哪个分区（队列）\n  > #SBATCH --nodes=1                       # 请求 1 个节点\n  > #SBATCH --ntasks=1                      # 总共运行 1 个任务\n  > #SBATCH --cpus-per-task=4               # 每个任务分配 4 个 CPU 核心\n  > #SBATCH --mem=8G                        # 申请 8GB 内存\n  > #SBATCH --time=00:30:00                 # 最大运行时间 (时:分:秒)\n  > #SBATCH --mail-type=END,FAIL            # 任务结束或失败时发邮件通知\n  > #SBATCH --mail-user=yourname@example.com\n  > \n  > # --- 环境准备区 ---\n  > \n  > echo "任务开始时间: $(date)"\n  > echo "运行节点: $(hostname)"\n  > \n  > # 加载你需要的软件模块（集群常用）\n  > # module load python/3.8\n  > # module load gcc/9.3.0\n  > \n  > # --- 执行指令区 ---\n  > \n  > # 比如运行你的反汇编分析程序\n  > # python3 my_analysis.py --input ./mbr.bin\n  > \n  > echo "任务执行完毕！"\n  > ```\n\n- **程序执行**：系统应能加载程序到内存并运行、结束执行、包括正常或不正常（并给出错误）。\n\n- **I/O操作**：为了效率和保护，用户通常不应该直接控制I/O设备而是由操作系统提供手段。\n\n- **文件系统操作**：有关创建、删除、搜索文件、列出文件信息，权限管理。\n\n- **通信**：有关两个进程（可能在不同计算机之间）交换信息。这可以通过**共享内存（shared memory）**即多进程读写共享内存区域，也可以通过**消息交换（message passing）**即符合预先定义格式的信息分组通过操作系统在进程之间移动。当然还有**管道**、**信号**等方式。\n\n- **错误检测**：对于每类错误，操作系统可能停机、也可以终结出错进程或者将出错码返给进程以便进程检测或纠正。\n\n操作系统确保系统运行高效：\n\n- **资源分配**：多个用户多个作业都需要分配资源。前面我们提到还会给一些程序分配打印机、USB存储器等其他外设。\n\n- **记账**：记录用户使用资源的类型和数量。\n\n- **保护与安全**：信息安全。进程不能干预其它进程和操作系统。\n\n  > [!note]\n  >\n  > 我们当然知道linux下可以用`sudo`+密码提权。\n  >\n  > 如果执行\n  >\n  > ```cmd\n  > ls -l /usr/bin/sudo\n  > ```\n  >\n  > 可能输出\n  >\n  > ```\n  > -rwsr-xr-x 1 root root 277936  6月 25  2025 /usr/bin/sudo\n  > ```\n  >\n  > - **`-`**：代表这是一个普通文件（如果是`d`则是目录）\n  > - `r`：root用户可以读。\n  >\n  > - `w`：root用户可以写。\n  > - **`s`**：**SetUID**。它取代了原本的`x`。代表任何用户执行它，都会临时获得该文件所有者（root）的身份。\n  > - **`r-x`**：root组的用户可以读和执行。\n  > - **`r-x`**：普通用户只能读和执行。\n  > - **`1`**：硬链接数。\n  > - **`root root`**：第一个是**所有者**，第二个是**所属组**。\n  >\n  > 运行`sudo`时，内核读取`/etc/sudoers`，检查当前用户有没有被列入越权白名单。如果有，则要求输入当前用户的密码，`sudo`调用PAM去验证密码正确。\n  >\n  > 运行`sudo`后，该程序都会获得所有者（root）的身份，具体来说是执行`setuid(0)`，随后`sudo`会使用`execvp()`启动真正要运行的命令。\n  >\n  > 你可以输入`id`查看当前用户是否属于`sudo`或`admin`组。\n  >\n  > 你可以作死执行`sudo chmod 755 /usr/bin/sudo`，这样即使在`sudo`组内，也再也不能临时获得（root）身份了，恭喜你的操作系统成砖。\n\n## 2.2用户与操作系统的界面\n\n### 2.2.1命令解释程序\n\n解释程序称为shell。实现命令：\n\n- shell本身包含代码以执行这些命令。\n- 调用文件加载到内存并执行以完成命令。\n\n### 2.2.2图形用户界面\n\n就会很人性化。\n\n### 2.2.3界面的选择\n\nGUI到底只支持有限命令，新命令需要添加UI以支持。具体选择可以自己体悟。\n\n## 2.3系统调用\n\n**系统调用（system call）** 提供操作系统服务接口，通常以C、C++编写。\n\n我们在祭祖学过，中断、异常就是CPU发生变化（如RISC-V是某个寄存器被写入异常号）转而执行中断、异常处理的过程。系统调用就是使CPU发生变化的接口。\n\n考虑从一个文件读取数据并输出到另一个文件的过程：\n\n- 通过许多I/O系统调用选取两个文件。\n- 打开输入文件并创建输出文件。这个过程可能遇到输入文件不存在等错误，处理这些错误情况需要其它系统调用。\n- 进入循环读取输入文件并写到输出文件。这个过程也可能遇到错误。\n- 复制完文件。程序关闭两个文件（视为系统调用），控制台提示消息等。\n\n![image-20260211122047526](./pictures/image-20260211122047526.png)\n\n通常，根据**应用编程接口（Application Programming Interface，API）** 来设计程序。\n\n1. Windows API\n\n   以Handle为核心，风格严谨（繁琐），参数极多。直接与Windows 内核（NT内核）通信，原生支持GUI API。\n\n2. POSIX标准API（Linux/Unix/macOS）\n\n   **Portable Operating System Interface**。一套标准，确保代码在不同的Unix系统间可移植。简洁，“万物皆文件”。POSIX线程（Pthreads）是其处理并发的标准\n\n3. Java虚拟机API（Java API/JDK）\n\n   Java不直接让用户接触硬件，而是提供了一层包装。当用户调用Java API时，JVM会根据当前系统自动转换成Win32或POSIX调用。\n\n大多数程序设计语言都会提供**系统调用接口（system-call interface）**，就是对系统调用的再封装。\n\n通常每个系统调用都有一个相关数字，以建立一个索引列表。\n\n![image-20260211122448958](./pictures/image-20260211122448958.png)\n\n系统调用和函数调用很像，所以在参数传递上几乎一样，唯一不同的是：\n\n当参数比寄存器能支持的数目多，只能通过**栈传参**。\n\n如果是函数调用，函数会使用被处理好的栈指针，愉快地执行。如果是内核，这么做可能会不安全，例如栈指针被恶意指向内核关键数据导致操作系统成砖。\n\n内核有独立的内核栈，系统调用发生时会让栈指针指向内核栈某块区域，确保地址的合法性。\n\n或者内核用**高强度检查函数**逐地址写入数据，每个地址都要满足条件才能被搬入内核的缓冲区。\n\n![image-20260211130215897](./pictures/image-20260211130215897.png)\n\n## 2.4系统调用类型\n\n- **进程控制（process control）**\n  - 结束、中止\n  - 加载、执行\n  - 创建进程、终止进程\n  - 获取进程属性、设置进程属性\n  - 等待时间\n  - 等待事件、信号事件\n  - 分配和释放内存\n- **文件管理（file manipulation）**\n  - 创建文件、删除文件\n  - 打开、关闭\n  - 读、写、重新定位\n  - 获取文件属性、设置文件属性设备管理\n- **设备管理（device manipulation）**\n  - 请求设备、释放设备\n  - 读、写、重新定位\n  - 获取设备属性、设置设备属性\n  - 逻辑附加或分离设备\n- **信息维护（information maintenance）**\n  - 获取时间或日期、设置时间或日期\n  - 获取系统数据、设置系统数据\n  - 获取进程、文件或设备属性\n  - 设置进程、文件或设备属性\n- **通信（communication）**\n  - 创建、删除通信连接\n    发送、接收消息\n    传送状态信息\n    附加或分离远程设备\n- **保护（protection）**\n\n### 2.4.1进程控制\n\n执行程序应能**正常**或**异常**停止执行。对于后者，会将错误信息转储到磁盘（即使内核崩溃了，也有办法做到）。可用**调试器（debugger）** 确定问题原因。\n\n此后操作系统会把控制交还命令解释程序，它可能根据错误等级进行下一步操作。\n\n我们通常用命令解释程序去**加载**和**执行**另一个程序（发生在shell本身不支持的指令上）：\n\n- 这个过程shell调用系统调用`fork()`，得到新子进程。\n- 新子进程随后系统调用`exec()`获得独立内存空间。\n- 新子进程执行指令。\n- shell调用`wait()`直到新子进程结束。\n\n> [!note]\n>\n> 你可以在指令末尾加`&`避免shell系统调用`wait()`方便你执行下一个指令。但是此时毙掉shell还是会让子进程殉情。\n>\n> 我们再在指令前加`nohup`使shell不会对这个子进程发送`SIGHUP`。\n>\n> 此时如果在`wait()`时毙掉shell，会让子进程被1号进程（`systemd`或`init`）收养。\n\n系统调用示例：\n\n| 类型     | Windows                        | UNIX       |\n| -------- | ------------------------------ | ---------- |\n| 进程控制 | CreateProcess()                | fork()     |\n|          | ExitProcess()                  | exit()     |\n|          | WaitForSingleObject()          | wait()     |\n| 文件管理 | CreateFile()                   | open()     |\n|          | ReadFile()                     | read()     |\n|          | WriteFile()                    | write()    |\n|          | CloseHandle()                  | close()    |\n| 设备管理 | SetConsoleMode()               | ioctl()    |\n|          | ReadConsole()                  | read()     |\n|          | WriteConsole()                 | write()    |\n| 信息维护 | GerCurrentProcessID()          | getpid()   |\n|          | SetTimer()                     | alarm()    |\n|          | Sleep()                        | sleep()    |\n| 通信     | CreatePipe()                   | pipe()     |\n|          | CreateFileMapping()            | shm_open() |\n|          | MapViewOfFile()                | mmap()     |\n| 保护     | SetFileSecurity()              | chmod()    |\n|          | InitializeSecurityDescriptor() | umask()    |\n|          | SetSecurityDescriptorGroup()   | chown()    |\n\n### 2.4.2文件管理\n\n我们会在后续章节详细讨论。\n\n> [!note]\n>\n> 调用`create()`生成文件的过程在底层发生了什么？\n>\n> 调用`create("test.txt", 0644)`时：\n>\n> 1. 参数准备。\n> 2. 执行`syscall`指令。\n> 3. CPU跳到`entry_SYSCALL_64`。内核查表找到`sys_open`，进而调用内核内部函数`do_sys_open()`。\n>\n> Linux通过**VFS**这一层抽象：\n>\n> - 内核找到这个文件要创建在哪个目录下并检查每一级目录的权限。\n> - 内核会在内存中创建一个新的`struct inode`结构体，记录文件的所有者、权限、创建时间等。\n>\n> 磁盘数据结构：\n>\n> - EXT4文件系统会在磁盘的**Inode Bitmap**（位图）里找一个空闲的位，标记为**已占用**。\n> - 内核修改父目录的数据内容，因为目录也是一种文件。\n> - 为了应对创建到一半文件系统崩溃，EXT4会先在磁盘的日志区写下请求，创建成功后再标记完成。\n>\n> 数据送到硬件：\n>\n> 1. 内核把写请求放进一个队列，并进行**调度优化**。\n> 2. 磁盘驱动程序将这些块地址转换成硬件指令。\n> 3. **SSD**：通过闪存控制器改变Cell的电荷状态。\n> 4. **HDD**：磁头通过电磁感应改变磁盘表面的磁极。\n\n### 2.4.3设备管理\n\n操作系统控制的各种资源（内存、磁盘驱动、所需文件等）可看作设备。多用户系统要**请求设备**，用完后**释放设备**。\n\n### 2.4.4信息维护\n\n例如大多数操作系统都可以返回**当前时间**、**当前日期**、**用户数**等。\n\n还有一组系统调用帮助调试程序，比如`dump()`。这是有关单步调试的系统调用。\n>\n> \n\n系统调用也可以获取、重置进程信息。我们以后讨论。\n\n### 2.4.5通信\n\n进程间通信的常用模型有**消息传递模型**和**共享内存模型**。\n\n我们也可以用一些应用上的分类：\n\n- **管道**：\n\n  你可能在CSAPP中实现过`ls | grep txt`命令的实现，这个`|`代表管道通信，会将第一个指令的输出作为第二个指令的输入。本质是维护一个内存页的缓冲区。\n\n- **消息队列**：\n\n  涉及持久化链表，不太懂。\n\n- **共享内存**：\n\n  内核在物理内存中开辟若干个页。\n\n  两个进程的虚拟地址指向同一个物理页。\n\n- **信号**：\n\n  每个进程的`task_struct`里都有一个`pending`位图。\n\n  当A向B发信号，内核只是把B进程位图中对应的那一位从`0`拨成`1`。\n\n  当进程B从内核态返回用户态的瞬间，内核会检查这个位图。\n\n  如果发现有信号，内核会强行修改B的指令指针（RIP/EIP），让它跳到信号处理函数执行，执行完再跳回原处。\n\n- **套接字通信**：\n\n  本地的通信是**在内核中通过双向缓冲区交换数据**，性能远高于网络套接字。\n\n  网络Socket几乎是另一回事，或许该在计算机网络再深入了解。\n\n### 2.4.6保护\n\n比如访问权限等。\n\n`sudo`切换用户权限也可以理解为一种保护。\n\n## 2.5系统程序\n\n**系统程序**为程序开发和执行提供了一个方便的环境，可分为以下几类：\n\n- **文件管理**：\n\n  `mkdir`，`rm`等...\n\n- **状态信息**：\n\n  日期、时间、内存、甚至注册表等...\n\n- **文件修改**：\n\n  创建、修改、查找和文本转换文件等...\n\n- **程序语言支持**：\n\n  Linux内核就是C编写的。高级程序语言连带着编译器、链接器、调试器提供给用户。\n\n  背后有一套设计哲学：高级程序语言实则通用化了不同软硬件设计，例如不同的CPU支持的机器码可能不一样，但映射得到的高级语言是一样的。操作系统本身是软件，所以是程序语言承载了操作系统而不是反之。这很有一种设计美感，再试想高级程序语言也不是最原子的，我认为最通用的操作应当是图灵机的操作。\n\n- **程序加载与执行**：\n\n  系统要提供把程序部署到内存的**重定位程序**，还要提供编程语言的调试程序。\n\n- **通信**：\n\n  有关创建虚拟连接的机制。\n\n- **后台服务**：\n\n  比如你打开任务管理器就能看到WPS催命一样贴心地准备方便你打开它的服务。\n\n操作系统还会提供很多应用程序，比如Firefox经常焊死在很多Linux系统上。\n\n## 2.6操作系统的设计与实现\n\n### 2.6.1设计目标\n\n**用户目标**：便于使用、易于学习和使用、可靠、安全和快速。\n\n**系统目标**：易于设计、实现和维护，也应灵活、可靠、正确且高效。\n\n### 2.6.2机制与策略\n\n**机制**决定如何做，**策略**决定做什么。\n\n前者可以是操作系统的一个组件，后者可以是这个组件怎么运行。\n\n### 2.6.3实现\n\n采用高级语言编写应用程序利于硬件移植，但是会带来速度的降低和存储的增加，然而这部分降低远远不如数据结构和算法的进步。\n\n此外根据组成中学习的知识，只有小部分代码（时间开销高的部分）对高性能是关键的，这部分会用更精细的汇编代码替换。\n\n## 2.7操作系统的结构\n\n### 2.7.1简单结构\n\n这是一个利用最小空间而提供最多功能的系统。\n\n![image-20260214110747760](./pictures/image-20260214110747760.png)\n\nUNIX由**内核**和**系统程序**组成。内核又分为一系列接口和驱动程序。\n\n内核通过系统调用，可提供文件系统、CPU调度、内存管理和其它操作系统功能。\n\n![image-20260214111728913](./pictures/image-20260214111728913.png)\n\n### 2.7.2分层方法\n\n**分层法（layered approach）**。\n\n![image-20260214112020178](./pictures/image-20260214112020178.png)\n\n简化了构造和调试，因为高层的错误不会因为低层而发生。\n\n分层法的难点是合理定义各层，比如备份存储驱动需要等待I/O完成并且CPU还要进行调度，前者位于的层次要在后者之下。\n\n分层法的另一问题是效率稍差。\n\n现在，设计采用功能更多而数量更少的分层。\n\n### 2.7.3微内核\n\n内核：（Linux，BSD，Windows，macOS）\n\n它把所有的核心功能——进程管理、内存管理、文件系统、设备驱动、网络协议栈——全部塞进同一个巨大的内核空间里。\n\n由于大家都在同一个地址空间，所以通信成本极低。\n\n然而如果发生了一个空指针错误，整个内核都会崩溃（蓝屏来咯）。\n\n------\n\n微内核：（QNX，Minix，HarmonyOS，Zircon）\n\n只保留最必不可少的功能——**IPC（进程间通信）**、基础调度和低级内存管理。其他所有功能（驱动、文件系统、协议栈）都被踢出内核。相应地便于扩展操作系统。\n\n通信成本大。如果文件系统要读磁盘，它必须通过内核发送一条IPC消息给磁盘驱动。这涉及到频繁的上下文切换和内存拷贝。\n\n内核和其它组件高度隔离。\n\n### 2.7.4模块\n\n可能目前操作系统设计的最佳方法是**可加载的内核模块（loadable kernel module）**，内核有一组核心组件，无论在启动或运行时，内核都可通过模块链入额外服务。\n\n新增额外服务的时候，可在内核运行时动态实现而不需要重新编译内核。\n\n![image-20260214121550237](./pictures/image-20260214121550237.png)\n\n### 2.7.5混合系统\n\nLinux和Solaris都是单片的，因为单一地址空间可以提供非常高效性能，而它们也是模块化的。\n\n#### 2.7.5.1Mac OS X\n\n![image-20260214121836669](./pictures/image-20260214121836669.png)\n\n#### 2.7.5.2iOS\n\n![image-20260214121905090](./pictures/image-20260214121905090.png)\n\n#### 2.7.5.3Android\n\n![image-20260214121935126](./pictures/image-20260214121935126.png)\n\n## 2.8操作系统的调试\n\n### 2.8.1故障分析\n\n进程发生故障时，大多数OS将错误信息写入**日志文件（log file）**。OS还会进行**核心转储（core dump）**，把进程内存捕获并保存到文件以便分析。\n\n> [!note]\n>\n> 亲身体验一下这个过程：\n>\n> 在终端执行\n>\n> ```cmd\n> ulimit -c unlimited\n> sudo sysctl -w kernel.core_pattern=core.%p\n> ```\n>\n> 以解除Core文件生成限制并确保Core文件生成在当前目录下。\n>\n> 在`test.c`写下\n>\n> ```c\n> #include <stdio.h>\n> void fragile_function(int *p) {\n>     *p = 100;\n> }\n> int main() {\n>     int *ptr = NULL; \n>     fragile_function(ptr);\n>     return 0;\n> }\n> ```\n>\n> 执行\n>\n> ```cmd\n> gcc -g test.c -o crash\n> ./crash\n> ```\n>\n> 这里`-g`确保gdb调试时可以看到源代码。\n>\n> 可能会提示\n>\n> ```cmd\n> 段错误（核心已转储）\n> # 或者\n> Segmentation fault (core dumped)\n> ```\n>\n> 当前目录下会有一个形如`core.xxxx`的文件，执行\n>\n> ```cmd\n> gdb ./crash core.6570\n> ```\n>\n> 你可以参考这些指令调试：\n>\n> - `bt`：查看调用栈。\n> - `f 0`：跳到崩溃那一层的上下文。\n> - `list`：查看崩溃附近的源代码。\n> - `p p`：查看指针`p`的值。\n\n> **Kernighan法则**\n> 调试难度是编写代码的两倍。因此，根据定义，如果你写的代码非常巧妙，那么没有人足够聪明来调试它。\n\n### 2.8.2性能优化\n\n为了监视系统性能而计算和显示系统行为的度量，有些操作系统可以通过**生成系统行为跟踪列表（trace listing）** 来做到。\n\n在Linux上可以使用`strace`或`gdb`调试。\n\n还可以利用专门的交互工具显示系统组件状态来寻找瓶颈，例如UNIX的`top`命令。\n\n**Windows任务管理器（Windows Task Manager）** 几乎可以做到显示所有系统状态，而且它实现了易于用户观察的GUI。\n\n### 2.8.3DTrace\n\nDTrace工具可以动态探测正在运行的系统，包括用户进程和内核。\n\n通过D编程语言，可查询这些探测，以确定有关内核、系统状态和进程活动的大量信息。\n\n例如，下图显示了一个应用程序执行系统调用`ioctl()`，以及内核为实现这一系统调用进行的函数调用。以“U”结束的行为在用户态下执行，而以“K”结束的行为在内核态下执行。\n\n![image-20260215153647330](./pictures/image-20260215153647330.png)\n\n> [!note]\n>\n> 在Windows11系统使用Dtrace。\n>\n> 调试Dtrace让我力竭了，我们改为调试Ubuntu的bpftrace。\n>\n> 简单安装：\n>\n> ```bash\n> sudo apt update\n> sudo apt install bpftrace\n> ```\n>\n> 简单介绍一些bpftrace的使用：\n>\n> **DSL（Domain specific language）** 的核心逻辑可以概括为：\n>\n> `Probe/Filter/{Action}`，其中`/Filter/`是可选项。\n>\n> - `Probe`：探针。当指定的探针发生什么事（被调用）的时候，执行`Action`，可以用`sudo bpftrace -l`查询可用探针。\n>\n> - `/Filter/`：过滤器。\n>\n>   - `/pid == 1234/`：只看进程号为1234的。\n>   - `/comm == "myprog"/`：只看命令名为`myprog`的进程。\n>   - `/uid == 1000/`：只看用户号为1000的。\n>\n> - `{Action}`：代码写在`{}`里面，和C语言很相似。\n>\n>   - 打印信息：\n>\n>     `printf("格式化字符串", 参数...)`：和C语言几乎一样，如`printf("PID %d opened %s\\n", pid, str(args->filename));`\n>\n>     `time("%H:%M:%S ")`：在输出前加上当前时间戳。\n>\n>     **`join(args->argv)`**：将字符串数组（如命令行参数）连接起来打印。\n>\n>   - 变量：\n>\n>     内置变量（只读）：由系统提供：`pid`,`tid`,`uid`,`gid`,`comm`,`cpu`,`nsecs`。\n>\n>     临时变量（以`$`开头）：仅在当前Action内有效，如`$x = 1;`。\n>\n>     全局变量（以`@`开头，即Map）：在整个脚本运行期间有效，跨探针共享，如`@start[tid] = nsecs;`。\n>\n>   - 聚合函数：\n>\n>     | 函数         | 用途                       | 示例                              |\n>     | ------------ | -------------------------- | --------------------------------- |\n>     | `count()`    | 简单计数                   | `@[comm] = count();`              |\n>     | `sum(val)`   | 求和                       | `@[comm] = sum(args->count);`     |\n>     | `avg(val)`   | 求平均值                   | `@[comm] = avg(nsecs - $start);`  |\n>     | `hist(val)`  | 生成2的幂次直方图          | `@[comm] = hist(nsecs - $start);` |\n>     | `stats(val)` | 同时显示次数、平均值、总和 | `@[comm] = stats(args->size);`    |\n>\n>   - 流程控制与辅助函数：\n>\n>     简单的逻辑判断：`if (条件) { ... } else { ... }`，如`if (pid == 123) { exit(); }`\n>\n>     `exit()`：停止脚本。\n>\n>     `str(pointer)`：将内核里的地址转为可读字符串。\n>\n>     `ustack`/`stack`：打印用户态/内核态的调用栈（回溯），如`printf("Caller: %s\\n", ustack);`\n>\n>   - 例：计算文件读取的耗时：\n>\n>     我们要用到两个探针：一个记录开始时间，一个计算差值。\n>\n>     ```c\n>     /* 1. 进入系统调用时，记录当前纳秒 */\n>     tracepoint:syscalls:sys_enter_read \n>     /comm == "myprog"/ \n>     {\n>         @start[tid] = nsecs; \n>     }\n>     \n>     /* 2. 系统调用返回时，计算差值并清理临时记录 */\n>     tracepoint:syscalls:sys_exit_read \n>     /@start[tid]/ \n>     {\n>         $duration = nsecs - @start[tid];\n>         printf("Read took %d ns\\n", $duration);\n>         delete(@start[tid]); // 记得清理，否则内存会爆\n>     }\n>     ```\n>\n>   - 安全限制：\n>\n>     禁止循环。\n>\n>     栈限制：局部变量不能太大。\n>\n>     内存访问：只能通过`str()`或`kaddr()`等受控方式读取内存。\n\n调试工具应能调试系统任何部分、不影响系统的可靠性和只有极小的性能影响。而DTrace满足这些要求。\n\n或许**断点调试**也能检查系统状态，但它会对多用户操作系统内核带来不利影响。\n\nDTrace的组成包括**编译器**、**框架**、框架内的**探头提供者**及**探头使用者**：\n\n- 探头提供者创建探头，内核结构用于跟踪提供者创建的所有探头。这些探头在哈希表通过名称来哈希，并通过唯一探头标识来索引。\n- 当启用一个探头时，所要探测区域的一些代码会被改写，即先调用`dtrace_probe (probe_identifier)`，然后继续进行代码的原来操作。\n- 不同的提供者创建不同类型的探头。例如，内核系统调用探头的工作方式不同于用户进程探头的，也不同于I/O探头的。\n- DTrace有一个在内核内运行的编译器，可生成字节码。这种代码是“安全”（没有循环，只有明确要求才能修改内核状态等）的。**只有具有DTrace“特权”的用户(或“根”用户)才可使用DTrace**，因为它可以检索私有的内核数据（并且根据要求可以修改数据）。所生成的代码运行在内核中，并启用探头。它也能启用处于用户态的探头使用者，以及启用这两者之间的通信。\n- DTrace探头使用者是对探头及其结果感兴趣的代码。使用者申请由提供者创建的探头。当探头激活后，它就发出由内核管理的数据。在内核中，由于激活了探头，会执行称为**启用控制块（Enabling Control Block，ECB）**的动作。如果多个使用者对同一探头感兴趣，那么这个探头可引起多个ECB执行。每个ECB包含一个谓词(“if语句”)，可筛选出对应ECB。否则，会执行ECB的动作列表，如探头的执行点的某个变量的值。通过收集这些数据，可以得到用户或内核动作的一个完整图像。再者，从用户空间与内核中激活的探头，可以显示用户级动作如何引起内核级的响应。\n- 当探头使用者终止，会移去ECB。当探头没有ECB，会移去该探头。这涉及改写代码以移去`dtrace_probe()`调用，并恢复原来的代码。因此，在创建探头前和删除探头后，系统完全一样，仿佛没有发生探测。\n- DTrace设法确保探头不使用太多内存或CPU计算，以致损害正在运行的系统。**探头执行的CPU时间也要加以监控**。如果超过限制，则会终止使用者及其他出错探头。每个CPU都要分配缓冲区，以**避免竞争和数据丢失**。\n\n## 2.9操作系统的生成\n\n对于某个特定的计算机场所，应配置和生成操作系统。\n\n操作系统的发行通常采用**磁盘**、**CD-ROM**、**DVD-ROM**或**ISO镜像**。\n\n| 时代   | 媒介          | 容量        | 特点                                       |\n| ------ | ------------- | ----------- | ------------------------------------------ |\n| 1950s  | 打孔卡/纸带   | 几十字节/张 | 极其笨重。                                 |\n| 1970s  | 磁带 (Tape)   | 若干MB      | 顺序读写。                                 |\n| 1980s  | 软盘 (Floppy) | 1.44MB      | 分段发行。早期的Windows3.1需要十几张软盘。 |\n| 1990s  | 光盘 (CD/DVD) | 700MB/4.7GB | ISO镜像诞生。甚至塞进各种驱动和库。        |\n| 2010s+ | USB/网络      | 8GB+/无限   | 主流。                                     |\n\n生成系统会使用一个特殊程序**SYSGEN**，它会确定以下信息：\n\n- **CPU**：决定指令集等。\n- **启动盘**格式化方法：比如如何分区。\n- **可用内存**：可以对内存位置一个个引用直到非法地址确认。\n- **可用设备**：设备号、设备终端号、设备类型等。\n- **操作系统选项**：确定参数等，比如缓冲区大小、CPU调度算法、支持进程最大数等。\n\n之后CPU重新编译操作系统或者利用已有的库链接到操作系统。不同做法会影响系统的大小和通用性。\n\n## 2.10系统引导\n\n加载内核以启动计算机的过程称为系统**引导（booting）**。\n\n大多数计算机系统都有一小块代码，称之为**引导程序（bootstrap program）** 能定位内核并加载到内存以开始执行。有时引导程序会调用更复杂的引导程序再加载内核。\n\n之前的实验中体验过这个过程：CPU收到重置事件时**指令寄存器会加载到预先的内存位置加载初始引导程序**。\n\n操作系统通常保存在ROM：\n\n- 改动引导程序代码需要改动ROM芯片，所以有些系统采用**可擦可编程只读存储器（Erasable Programmable Read-Only Memory，EPROM）**。\n- 执行比RAM中慢，所以有时候会复制到RAM中以便执行更快。\n- 相对较贵。\n\n对大型操作系统或经常改变的系统，引导程序存放在**固件（可以是ROM）**上，而操作系统存放在**磁盘**上。\n\n在这种情况下，引导程序会先进行诊断，然后从磁盘固定位置（如第0块）读取整块信息到内存，最后执行**引导块（boot block）** 的代码。存储在引导块的程序可能足以加载整个操作系统到内存，并开始执行。\n\n更典型地，它只是简单的代码（因为它要存放在单一的磁盘块上），并且只知道磁盘的地址以及引导程序其余部分的长度。\n\n整个引导程序在加载后，就可遍历文件系统以寻找操作系统内核，将其加载到内存中，并开始执行。只有到这时，才说系统是在**运行（running）**。\n\n> [!note]\n>\n> GRUB是一个开源的例子，用于引导Linux系统。所有磁盘的引导程序和操作系统本身，通过向磁盘写入新的版本，就可以很容易地改变。具有**引导分区**的磁盘称为**引导盘（boot disk）**或**系统盘（system disk）**。' 
                      },
                      { id: 'operating_system-3', 
                        title: '3、进程', 
                        desc: '', 
                        content: '# 3.进程\n\n为了对各自程序提供更严的控制和更好的划分，**进程（process）** 概念产生。\n\n## 3.1进程概念\n\n**作业**与**进程**两个概念几乎可以互换使用。\n\n### 3.1.1进程\n\n除了程序代码，进程还包括当前活动，比如**程序计数器（PC）**、寄存器内容、堆栈等。\n\n![image-20260218171155160](./pictures/image-20260218171155160.png)\n\n进程本身也可以作为环境，比如**Java虚拟机（Java Virtual Machine，JVM）**。\n\n### 3.1.2进程状态\n\n每个进程可能处于：\n\n- **new**：进程正在创建。\n- **running**：指令正在执行。\n- **waiting**：进程等待发生某个事件。\n- **ready**：进程等待分配处理器。\n- **terminated**：进程已经完成执行。\n\n一个核上只有一个进程运行。\n\n![image-20260218172109977](./pictures/image-20260218172109977.png)\n\n### 3.1.3进程控制块\n\n操作系统内的每个进程表示，采用**进程控制块（Process Control Block，PCB）**，包含与进程有关的信息：\n\n- **进程状态（process state）**：3.1.2的五种状态。\n- **程序计数器（program counter）**：将要执行的下个指令的地址。\n- **CPU寄存器（CPU register）**：由计算机体系结构决定。切换进程时会切换寄存器的值，我们会在**上下文切换**仔细探讨相关问题。\n- **CPU调度信息（CPU-scheduling information）**：包括进程优先级、调度队列的指针和其他调度参数，我们会在第五章讨论**进程调度**。\n- **内存管理信息（memory-management information）**：包括基地址和界限寄存器的值、页表或段表，我们会在第八章讨论**内存系统**。\n- **记账信息（accounting information）**：包括CPU时间、实际使用时间、时间期限、记账数据、作业或进程数量等。\n- **I/O状态信息（I/O status information）**：包括分配给进程的I/O设备列表、打开文件列表等。\n\n![image-20260218211020103](./pictures/image-20260218211020103.png)\n\n### 3.1.4线程\n\n以往或刚刚介绍的进程概念表明每个进程是只能进行单个执行**线程（thread）** 的程序。扩展进程概念，以便一次能够执行多个线程。\n\n我们会在第四章详细讨论**线程**。\n\n> [!note]\n>\n> Linux操作系统的进程控制块采用`<linux/sched.h>`里的结构体`task_struct`表示。这个结构体疑似有点复杂了，其占用物理内存可以达到`1.7KB`。\n>\n> 它较基础的成员分类包括：\n>\n> ```c\n> long state;                  /* state of the process */\n> struct sched_entity se;      /* scheduling information */\n> struct task_struct *parent;  /* this process\'s parent */\n> struct list_head children;   /* this process\'s children */\n> struct files_struct *files;  /* list of open files */\n> struct mm_struct *mm;        /* address space of this process */\n> ```\n>\n> 内核采用一个指针`current`指向当前系统正在执行的进程。\n>\n> ![image-20260218214123898](./pictures/image-20260218214123898.png)\n\n## 3.2进程调度\n\n**进程调度器（process scheduler）** 选择一个可用进程到CPU上执行。\n\n### 3.2.1调度队列\n\n进程在进入系统时，会被加到**作业队列（job queue）**。\n\n驻留在内存中的、就绪的、等待运行的进程保存在**就绪队列（ready queue）** 上，这是一个由链表实现的结构，如下图：\n\n![image-20260218223911567](./pictures/image-20260218223911567.png)\n\n当从中找需要被唤醒的进程，只需顺着链表头依次找。\n\n此外每个I/O设备都有一个等待对应I/O设备的进程列表被称为**设备队列（device queue）**。\n\n进程调度可以用**队列图（queueing diagram）** 表示：\n\n![image-20260218224552629](./pictures/image-20260218224552629.png)\n\n### 3.2.2调度程序\n\n提交的多余的进程会被保存到**大容量存储设备（通常为磁盘）** 的缓冲池。\n\n**长期调度程序（long-term scheduler）/作业调度程序（job scheduler）** 从缓冲池中选择进程，加到内存以便执行。\n\n**短期调度程序（short-term scheduler）或CPU调度程序（CPU scheduler）** 从准备执行的进程中选择进程分配CPU。\n\n后者相对前者需要极短的调度时间（通常在100ms以内），前者的调度时间要和进程离开系统的时间相当。\n\n通常进程可分为**I/O密集型进程（I/O-bound process）**和**CPU密集型进程（CPU-bound process）**，前者主要占用I/O设备队列，后者主要占用就绪队列，需要长期调度程序合理调配。\n\n有些操作系统会引入**中期调度程序（medium-term scheduler）**，会将进程从内存（或CPU竞争）中移出，从而降低多道程序调度。相关的方案被称为**交换（swap）**，我们会在第八章详细讨论。\n\n### 3.2.3上下文切换\n\n当中断发生时，系统需要保存当前运行在CPU上的进程的**上下文**，以便在处理后能够恢复上下文，即先挂起进程，再恢复进程。\n\n进程上下文采用进程PCB表示。通常，通过执行**状态保存（state save）**，**保存CPU当前状态（包括内核模式和用户模式）**；之后，**状态恢复（state restore）** 重新开始运行。\n\n切换CPU到另一个进程需要保存当前进程状态和恢复另一个进程的状态，这个任务称为**上下文切换（context switch）**：\n\n- 当进行上下文切换时，内核会将旧进程状态保存在其PCB中，然后加载经调度而要执行的新进程的上下文。\n- 上下文切换的时间是纯粹的开销，因为在切换时系统并没有做任何有用工作。\n- 上下文切换的速度因机器不同而有所不同，它依赖于内存速度、必须复制的寄存器数量、是否有特殊指令（如加载或存储所有寄存器的单个指令）。典型速度为几毫秒。\n- 上下文切换的时间与硬件支持密切相关。例如，有的处理器（如Sun UltraSPARC）提供了多个寄存器组，上下文切换只需简单改变当前寄存器组的指针。\n- 如果活动进程数量超过寄存器的组数，那么系统需要像以前一样在寄存器与内存之间进行数据复制。而且，操作系统越复杂，上下文切换所要做的就越多。\n- 高级的内存管理技术在每次上下文切换时，所需切换的数据会更多。例如，在使用下一个进程的地址空间之前，需要保存当前进程的地址空间。如何保存地址空间，需要做什么才能保存等，取决于操作系统的内存管理方法。\n\n## 3.3进程运行\n\n操作系统必须提供机制创建进程和终止进程。\n\n### 3.3.1进程创建\n\n进程创建可以形成**进程树（process tree）**。每个进程都会用**进程标识符（process identifier，pid）** 识别。\n\nLinux中：\n\n- `init`的`pid`总是1，作为所有用户进程的根进程或父进程。\n  - `kthreadd`的`pid`总是2，负责创建额外进程以便执行内核任务。\n  - `sshd`是SSH服务的守护进程，负责处理远程登录连接。\n  - `login`负责管理直接登录到系统的客户端。\n  - ...\n\n子进程会从父进程或操作系统那里直接获得资源（CPU时间、内存、文件、I/O设备等）。\n\n![image-20260219134500264](./pictures/image-20260219134500264.png)\n\n`ps`指令可以得到一个进程列表。\n\n```bash\n# 查看所有进程\nps aux\n# 查找某个进程\nps aux | grep sshd\n# 按CPU占用排序\nps aux --sort=-%cpu | head -10\n# 按内存占用排序\nps aux --sort=-%mem | head -10\n# 显示进程树\nps auxf\npstree -p\n# 显示某用户的进程\nps -u username\n# 查看某PID的详细信息\nps -p 1 -f\n# 不同风格\nps aux # BSD风格\nps -ef # Unix风格\n\n## 输出字段解释\nUSER       PID  %CPU  %MEM    VSZ   RSS  TTY   STAT  START   TIME  COMMAND\nroot         1   0.0   0.1  12345  6789  ?     Ss    10:00   0:01  /sbin/init\n```\n\n当进程创建新进程时，可有两种执行可能:\n\n- 父进程与子进程并发执行。\n- 父进程等待，直到某个或全部子进程执行完。\n\n新进程的地址空间也有两种可能：\n\n- 子进程是父进程的复制品（它具有与父进程同样的程序和数据）。\n- 子进程加载另一个新程序。\n\n> [!note]\n>\n> 详见下面的程序\n>\n> ```c\n> #include <stdio.h>\n> #include <unistd.h>\n> int main() {\n>     pid_t pid = fork();\n>     if (pid == 0) {\n>         printf("%d\\n", pid);    // 输出: 0\n>         printf("%d\\n", getpid());    // 输出: 实际PID, 不会是0\n>         printf("%d\\n", getppid());    // 输出: 父进程PID\n>     }\n>     else {\n>         printf("%d\\n", pid);    // 输出: 子进程PID\n>     }\n>     return 0;\n> }\n> ```\n>\n> 这个程序是**并发执行**、**子进程复制品**的可能。`fork()`的时候发生了什么，会让两个进程执行相同的代码段？\n>\n> 调用`fork()`后，内核会为子进程创建一个新的`task_struct`，并复制父进程的几乎所有信息（除了PID），注意**程序计数器（PC/RIP）也被复制了**，所以两者都指向`fork()`返回后的下一条指令。\n>\n> `fork()`并不会立刻复制所有内存，而是：\n>\n> ```\n> 父进程页表──┐\n>        	   ├──→ 同一块物理内存（只读共享）\n> 子进程页表──┘\n> \n> 某进程尝试写入时：\n> └── 触发缺页异常\n>     └── 内核此时才真正复制那一页内存\n>         ├── 父进程继续用原来的页\n>         └── 子进程得到新复制的页\n> ```\n>\n> 此外内核修改了子进程得到`fork()`的返回值（为0）以区分父子进程。\n>\n> ---\n>\n> 这个程序是**等待执行**、**子进程加载新程序**的可能：\n>\n> ```c\n> #include <stdio.h>\n> #include <unistd.h>\n> int main() {\n>     pid_t pid = fork();\n>     if (pid == 0) {\n>         execl("/bin/ls", "ls", "-l", NULL);\n>         perror("exec failed");\n>         exit(1);\n>     }\n>     else {\n>         wait(NULL);\n>         printf("finished\\n");\n>     }\n> }\n> ```\n>\n> `exec()`时：\n>\n> ```\n> 子进程调用 exec("/bin/ls", ...)\n>         │\n>         ▼\n> 内核丢弃当前内存空间（代码段、数据段、堆、栈全部清空）\n>         │\n>         ▼\n> 从磁盘加载新程序的 ELF 文件\n>         │\n>         ▼\n> 重新建立内存映射：\n>   ├── 代码段 → 映射新程序的 .text\n>   ├── 数据段 → 映射新程序的 .data / .bss\n>   └── 栈     → 重新分配，压入 argc / argv / 环境变量\n>         │\n>         ▼\n> RIP（程序计数器）指向新程序的入口点 _start\n>         │\n>         ▼\n> 开始执行新程序（PID不变）\n> ```\n>\n> 所以`perror()`不会被执行，因为进程已经被替换。父进程会通过`wait()`继续运行并监控子进程状态。\n>\n> 顺带一提：\n>\n> `exec()`是一系列系统调用，最底层都是`execve()`：\n>\n> ```c\n> execl("/bin/ls", "ls", "-l", NULL);    // 参数列表\n> execv("/bin/ls", argv[]);              // 参数数组\n> execle("/bin/ls", "ls", NULL, envp[]); // 带环境变量\n> execvp("ls", argv[]);                  // 自动搜索PATH\n> execvpe("ls", argv[], envp[]);         // 搜索PATH+环境变量\n> ```\n>\n> ![image-20260219143148444](./pictures/image-20260219143148444.png)\n\n有关WindowsAPI的进程创建不太想讲了，我有点头痛。\n\n### 3.3.2进程终止\n\n当进程完成执行最后语句并通过`exit()`请求操作系统删除自身时，进程终止。此时进程返回状态值到父进程（通过`wait()`）。操作系统释放所有进程资源。\n\n父进程终止子进程的原因包括：\n\n- 子进程使用了超过它所分配的资源。\n- 分配给子进程的任务不再需要。\n- 父进程正在退出，而且操作系统不允许孤儿进程继续执行。\n\n父进程终止时，它所有子进程也会终止，这被称为**级联终止（cascade termination）**。\n\n> [!note]\n>\n> 当父进程先于子进程终止，子进程就变成了**孤儿进程（orphan process）**。\n>\n> Linux内核会自动将孤儿进程的父进程重新设置为`PID=1`的`init/systemd`。\n>\n> 子进程退出后，内核会保留它的`task_struct`，等待父进程调用`wait()`来读取退出状态，这段时间子进程就是**僵尸进程（zombie process）**。\n>\n> 在`ps`输出中可以看到僵尸进程：\n> \n>    ~~~bash\n>    ps aux | grep \'Z\'\n> ~~~\n>    \n\n## 3.4进程间通信\n\n如果一个进程不能影响其他进程或受其他进程影响，那么该进程是**独立**的。\n\n如果一个进程能影响其他进程或受其他进程所影响，那么该进程是**协作**的。\n\n提供环境允许进程协作，具有许多理由：\n\n- **信息共享（information sharing）**：多个用户可能对同样的信息感兴趣。\n- **计算加速（computation speedup）**：如果希望一个特定任务快速运行，那么应将它分成子任务，而每个子任务可以与其他子任务一起并行执行。这要求计算机有多个处理核。\n- **模块化（modularity）**：可能需要按模块化方式构造系统，如第2章所讨论的，可将系统功能分成独立的进程或线程。\n- **方便（convenience）**：即使单个用户也可能同时执行许多任务。\n\n协作进程需要有一种**进程间通信（InterProcess Communication，IPC）** 机制，以允许进程相互交换数据与信息。\n\n进程间通信有两种基本模型：\n\n- **共享内存（shared memory）**：\n\n  共享内存模型会建立起一块供协作进程共享的内存区域，进程通过向此共享区域读出或写入数据来交换信息。\n\n- **消息传递（message passing）**：\n\n  消息传递模型通过在协作进程间交换消息来实现通信。\n\n![image-20260219155055939](./pictures/image-20260219155055939.png)\n\n研究表明在多核系统（现在普遍是多核系统）上消息传递的性能更优，这是由另一者的高速缓存一致性问题导致的。\n\n### 3.4.1共享内存系统\n\n共享内存系统依赖缓冲区，可分为**无界缓冲区（unbounded-buffer）**和**有界缓冲区（bounded-buffer）**，讨论后者：\n\n共享buffer的实现采用一个循环数组和两个逻辑指针：`in`和`out`。`in`指向缓冲区的下一个空位；`out`指向缓冲区的第一个满位。当`in==out`，缓冲区为空；当`(in+1)%buffer_SIZE==out`，缓冲区为满。\n\n以下为一种示例：\n\n```c\nwhile (true) {\n    /* produce an item in next _produced */\n    while (((in + 1) % BUFFER_SIZE) == out);\n    buffer[in] = next_produced;\n    in = (in + 1) % BUFFER_SIZE;\n}\n```\n\n```c\nitem next_consumed;\nwhile (true) {\n	while (in == out);\n	next.consumed = buffer[out];\n	out = (out + 1) % BUFFER_SIZE;\n	/* consume the item in next_consumed*/\n}\n```\n\n### 3.4.2消息传递系统\n\n消息传递提供一种机制，以便进程实现通信和同步。\n\n消息传递工具提供至少两种操作：\n\n`send(message) receive(message)`\n\n教材在逻辑上将消息传递分类为：\n\n- 直接或间接的通信\n- 同步或异步的通信\n- 自动或显式的缓冲\n\n#### 3.4.2.1命名\n\n**直接通信（direct communication）**：\n\n- `send(P, message)`：向进程`P`发送`message`。\n- `receive(Q, message)`：进程`Q`接收`message`。\n\nLinux采用这种通信，例如：\n\n```c\nkill(p, SIGTERM);\n```\n\n接收方通过信号处理函数被动接收：\n\n```c\nvoid handler(int sig) {\n    printf("receive SIGTERM");\n    exit(0);\n}\nsignal(SIGTERM, handler);\n```\n\n> [!note]\n>\n> `kill`本质上类似于：\n>\n> ```c\n> void send_signal(task_struct *target, int sig) {\n>     sigaddset(&target->pending, sig);\n>     wake_up_process(target);\n> }\n> ```\n>\n> 在目标进程的`sigset_t pending`里添加一个信号，目标进程可能在以下时机检测处理信号：\n>\n> - 系统调用返回用户态之前。\n> - 中断处理完返回用户态之前。\n> - 进程被唤醒时（从睡眠状态恢复）。\n>\n> 接着内核需要保存寄存器状态、信号信息、执行完`handler`后跳到的返回地址到栈上。\n>\n> 内核略动手脚修改**PC**和栈指针。\n>\n> 返回用户态后，CPU就直接执行`handler`了。\n>\n> 执行完后，将跳到的返回地址指向一段特殊代码，它可能是：\n>\n> ```asm\n> __kernel_rt_sigreturn:\n>     mov rax, 15        ; syscall number for rt_sigreturn\n>     syscall            ; call sigreturn\n> ```\n>\n> `sigreturn`系统调用在内核中做的事：\n>\n> ```c\n> void sigreturn() {\n>     sigcontext *ctx = (sigcontext *)current->sp;\n>     regs->rip = ctx->rip;      // PC\n>     regs->rsp = ctx->rsp;      // SP\n>     regs->rax = ctx->rax;      // other\n>     // ...\n>     // sigprocmask\n>     current->blocked = ctx->oldmask;\n> }\n> ```\n\n直接通信还可以是：\n\n- `send(P, message)`：向进程`P`发送`message`。\n- `receive(id, message)`：`id`进程接收`message`。\n\n**间接通信（indirect communication）**：通过共享的消息队列让多个进程通信，不需要知道对方身份，例如POSIX所做的：\n\n```c\n// POSIX message queue\nmqd_t mq = mq_open("/myqueue", O_CREAT | O_WRONLY, 0666, NULL);\n\n// process A\nmq_send(mq, message, strlen(message), 0);\n\n// process B\nmq_receive(mq, buffer, MAX_SIZE, NULL);\n```\n\n#### 3.4.2.2同步\n\n**同步（synchronous）** 或**异步（asynchronous）** 的在与它们是**阻塞（blocking）**或**非阻塞（nonblocking）**的。\n\n- **阻塞发送（blocking send）**：发送进程阻塞，直到消息由接收进程或邮箱所接收。\n- **非阻塞发送（nonblocking send）**：发送进程发送消息，并且恢复操作。\n- **阻塞接收（blocking receive）**：接收进程阻塞，直到有消息可用。\n- **非阻塞接收（nonblocking reveive）**：接收进程收到一个有效消息或空消息。\n\n#### 3.4.2.3缓存\n\n队列实现有三种方法：\n\n- **零容量（zero capacity）**：队列的最大长度为0；意为链路中不能有任何消息处于等待。发送方应阻塞，直到接收方收到消息。\n- **有限容量（bounded capacity）**：如果链路已满，发送者应阻塞，直到队列空间有可用的位置。\n- **无限容量（unbounded capacity）**：发送方从不阻塞。\n\n## 3.5IPC系统例子\n\n### 3.5.1例子：POSIX共享内存\n\n进程必须通过系统调用`shm_open()`创建共享内存对象：\n\n发送方：\n\n```c\n#include <stdio.h>\n#include <stlib.h>\n#include <string.h>\n#include <fcntl.h>\n#include <sys/shm.h>\n#include <sys/stat.h>\n/* the size (in bytes) of shared memory object */\nconst int SIZE = 4096;\n/* name of the shared memory object */\nconst char *name = "/OS";\n/* strings writted to shared memory */\nconst char *message_0 = "Hello";\nconst char *message_1 = "World!";\nint main() {\n    /* create the shared memory object */\n    int shm_fd = shm.open(name, O_CREAT | O_RDRW, 0666);\n    /* configure the size of the shared memory object */\n    ftruncate(shm_fd, SIZE);\n    /* memory map the shared memory object */\n    void *ptr = mmap(0, SIZE, PROT_WRITE, MAP_SHARED, shm_fd, 0);\n    /* write to the shared memory object */\n    sprintf(ptr, "%s", message_0);\n    ptr += strlen(message_0);\n    sprintf(ptr, "%s", message_1);\n    ptr += strlen(message_1);\n    return 0;\n}\n```\n\n接收方：\n\n```c\n#include <stdio.h>\n#include <stlib.h>\n#include <fcntl.h>\n#include <sys/shm.h>\n#include <sys/stat.h>\n/* the size (in bytes) of shared memory object */\nconst int SIZE = 4096;\n/* name of the shared memory object */\nconst char *name = "/OS";\n/* shared memory file descriptor */\nint main() {\n    /* open the shared memory object */\n    shm_fd = shm.open(name, O_RDONLY, 0666);\n    /* memory map the shared memory object */\n    void *ptr = mmap(0, SIZE, PROT_READ, MAP_SHARED, shm_fd, 0);\n    printf("%s", (char * )ptr);\n    /* remove the shared memory object */\n    shm.unlink(name);\n    return 0;\n}\n```\n\n有关`shm_fd`的参数：\n\n- `name`：必须以`/`开头，不能再有`/`，对应`/dev/shm/name`文件。\n- `oflag`：`O_CREAT`：不存在则创建；`O_EXCL`：配合`O_CREAT`，若已存在则报错；`O_RDONLY`：只读打开；`O_RDWR`：读写打开；`O_TRUNC`：已存在则清空内容，大小置0。\n- `mode`：和文件权限一样。\n\n有关`mmap()`的参数：\n\n- `addr`：映射的起始虚拟地址，传为`NULL`让内核自动选择地址。\n\n- `length`：映射的字节数，不能超过文件大小，实际映射大小会向上对齐到页大小。\n\n- `prot`：内存保护标志\n\n  | prot         | 含义     |\n  | ------------ | -------- |\n  | `PROT_READ`  | 可读     |\n  | `PROT_WRITE` | 可写     |\n  | `PROT_EXEC`  | 可执行   |\n  | `PROT_NONE`  | 不可访问 |\n\n  不能超过`shm_open`时指定的权限。\n\n- `flags`：映射标志\n\n  | flags           | 含义                           |\n  | --------------- | ------------------------------ |\n  | `MAP_SHARED`    | 修改对其他进程可见，写回文件   |\n  | `MAP_PRIVATE`   | 写时复制，修改不影响其他进程   |\n  | `MAP_ANONYMOUS` | 不关联文件，fd传-1（匿名映射） |\n  | `MAP_FIXED`     | 强制使用addr指定的地址         |\n  | `MAP_LOCKED`    | 锁定内存，不被换出到swap       |\n  | `MAP_POPULATE`  | 预先建立页表（避免后续缺页）   |\n\n  `MAP_SHARED`和`MAP_PRIVATE`必须选一个，不能同时用。\n\n- `fd`：文件描述符\n\n- `offset`：文件偏移，即从文件的哪个位置开始映射：\n\n  **offset必须是页大小的整数倍**。\n\n### 3.5.2例子：Mach\n\n略。\n\n### 3.5.3例子：Windows\n\n略。\n\n## 3.6客户机/服务器通信\n\n### 3.6.1套接字\n\n**套接字（socket）**为通信的断点，每对网络通信的进程都需要使用一对**socket**。\n\n每个**socket**由一个IP地址和一个端口号组成，通常socket通过服务器监听指定端口等待客户请求，服务器收到请求后，完成与客户的连接。\n\n有关端口：\n\n0~1023由**IANA（Internet Assigned Numbers Authority）** 统一分配，需要root权限才能监听：\n\n| 端口  | 协议    | 服务             |\n| ----- | ------- | ---------------- |\n| 20/21 | TCP     | FTP              |\n| 22    | TCP     | SSH              |\n| 23    | TCP     | Telnet           |\n| 25    | TCP     | SMTP（邮件发送） |\n| 53    | UDP/TCP | DNS              |\n| 80    | TCP     | HTTP             |\n| 443   | TCP     | HTTPS            |\n\n1024~49151是注册端口，应用程序常用，不需要root权限，向IANA注册但不强制：\n\n| 端口  | 服务                |\n| ----- | ------------------- |\n| 3306  | MySQL               |\n| 5432  | PostgreSQL          |\n| 6379  | Redis               |\n| 8080  | HTTP备用/开发服务器 |\n| 27017 | MongoDB             |\n\n49152~65535是客户端发起连接时，操作系统自动分配的临时端口。\n\nsocket的使用有些复杂，而且这一块接口示例在书本上是用java写的，让我难以下手，略。\n\nsocket的底层通常是是内核用`struct socket`和`struct sock`抽象出来的通信端点，通过fd暴露给用户态；数据发送时从用户buffer拷贝到内核发送队列，经过TCP/IP协议栈逐层封装后由DMA写入网卡。\n\n数据接收时网卡DMA写入Ring Buffer，软中断触发协议栈逐层解析，最终放入接收队列唤醒进程。整个过程的核心是`sk_buff`结构在各层间流转，通过移动指针而非拷贝数据来实现高效的协议栈处理。\n\n## 3.6.2远程过程调用\n\n**RPC（Remote Procedure Call）**对于通过网络连接系统之间的过程调用进行了抽象。RPC通信交换的消息具有明确结构，包含**执行函数的一个标识符**以及**传递给函数的一些参数**。另一服务会将执行的结果传递回到请求者。\n\n一个RPC过程就是客户调用位于远程主机的过程一样：\n\n- 客户端提供**存根（stub）** 隐藏通信细节并定位服务器的端口并**封装（marshal）** 参数。\n\n  - stub是一段自动生成的代码，用于把调用转成网络请求发出去。\n\n  - marshal是把数据转化为字节流的过程，可能还会包括过程id，指定过程调用id。\n\n    不同的序列化格式：\n\n    | 格式        | 特点                             |\n    | ----------- | -------------------------------- |\n    | JSON        | 可读性好，体积大                 |\n    | XML         | 可读性好，体积更大               |\n    | Protobuf    | 二进制，体积小，速度快（Google） |\n    | Thrift      | 二进制（Facebook）               |\n    | MessagePack | 二进制版JSON                     |\n\n    \n\n- 存根通过消息传递向服务器发送一个消息。\n\n- 服务器的类似存根收到这个消息并调用服务器。如果必要，可以返回值给客户机。\n\n以下是Python的例子：\n\n```python\n# server.py\nimport socket\nimport json\n\ndef add(a, b):\n    return a + b\n\ndef greet(name):\n    return f"Hello, {name}!"\n\n# ── RPC framework（Server Stub）────────────────\nREGISTRY = {\n    "add": add,\n    "greet": greet,\n}\n\ndef handle(request_bytes):\n    # Deserialization\n    request = json.loads(request_bytes)\n    func_name = request["func"]\n    args = request["args"]\n    kwargs = request["kwargs"]\n\n    # Find and call functions\n    func = REGISTRY.get(func_name)\n    if func is None:\n        return json.dumps({"error": f"function {func_name} doesn\'t exist"})\n\n    try:\n        result = func(*args, **kwargs)\n        return json.dumps({"result": result})\n    except Exception as e:\n        return json.dumps({"error": str(e)})\n\n# ── Network eavesdropping ─────────────────────────────────\nserver = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\nserver.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\nserver.bind(("localhost", 9999))\nserver.listen(5)\nprint("The RPC Server starts and listens on port 9999....")\n\nwhile True:\n    conn, addr = server.accept()\n    data = conn.recv(4096)\n    response = handle(data)\n    conn.send(response.encode())\n    conn.close()\n```\n\n```python\n# client.py\nimport socket\nimport json\n\n# ── RPC framework（Client Stub）────────────────\ndef rpc_call(func_name, *args, **kwargs):\n    # Serialization request\n    request = json.dumps({\n        "func": func_name,\n        "args": args,\n        "kwargs": kwargs\n    })\n\n    # Network transmission\n    client = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    client.connect(("localhost", 9999))\n    client.send(request.encode())\n    response_bytes = client.recv(4096)\n    client.close()\n\n    # Deserialization response\n    response = json.loads(response_bytes)\n    if "error" in response:\n        raise Exception(response["error"])\n    return response["result"]\n\n# ── generate Stub ────────\ndef add(a, b):\n    return rpc_call("add", a, b)\n\ndef greet(name):\n    return rpc_call("greet", name)\n\n# ── user code ──────────\nif __name__ == "__main__":\n    result = add(3, 4)\n    print(f"add(3, 4) = {result}")\n\n    msg = greet("Claude")\n    print(f"greet(\'Claude\') = {msg}")\n```\n\n**麻烦1**：数据封装显然会有**大端小端**的麻烦。\n\n**XDR（eXternal Data Representation）**是Sun Microsystems定义的一种**数据序列化标准**，专门为RPC设计。其在序列化层实现：\n\n- 所有数据统一用大端序。\n- 所有基本类型对齐到4字节边界。\n- 字符串末尾补齐到4字节倍数。\n\n**麻烦2**：由于莫名网络错误或者本地调用出事，RPC可能执行失败或**多次重复执行**。\n\n解决这个麻烦重要的是让服务端**只执行一次**，毕竟不能让支付宝多扣你钱。\n\n具体做法会在计算机网络再细讲，有很多解决思路。\n\n**麻烦3**：双方都没有对方的完全信息，因为它们不共享内存。\n\n可以按固定端口，或者在固定端口的基础上通过额外一次RPC分配端口。\n\n![image-20260221220005034](./pictures/image-20260221220005034.png)\n\n### 3.6.3管道\n\n#### 3.6.3.1普通管道\n\n普通管道是单向的，只能用于父子进程。\n\nUNIX系统上普通管道通过`pipe(int fd[])`创建管道，`fd[0]`为管道的读出端，`fd[1]`为管道的写入端。访问管道可以采用`read()`和`write()`。\n\n![image-20260221223645910](./pictures/image-20260221223645910.png)\n\n```c\n#include <sys/types.h>\n#include <stdio.h>\n#include <string.h>\n#include <unistd.h>\n#define BUFFER_SIZE 25\n#define READ_END 0\n#define WRITE_END 1\nint main() {\n    char write_msg[BUFFER_SIZE] = "Greetings";\n    char read_msg[BUFFER_SIZE];\n    int fd[2];\n    pid_t pid;\n    /* create the pipe */\n    pipe(fd);\n    pid = fork();\n    /* parent process */\n    if (pid > 0) {\n        close(fd[READ_END]);\n        write(fd[WRITE_END], write_msg, strlen(write_msg) + 1);\n        close(fd[WRITE_END]);\n    }\n    /* child process */\n    else {\n        close(fd[WRITE_END]);\n        read(fd[READ_END], read_msg, BUFFER_SIZE);\n        printf("%s", read_msg);\n        close(fd[READ_END]);\n    }\n    return 0;\n}\n```\n\n注意：`fork()`后父子进程各持有管道读写两端，引用计数都变成2。必须关闭不用的那一端，是因为管道的EOF信号依赖写端引用计数归零——如果子进程还持有写端，`read()`永远不会收到EOF（会认为输入方还会写），造成死锁。\n\n#### 3.6.3.2命名管道\n\n命名管道是双向的，可用于多个进程通信，且在被删除前一直存在，对于不同系统间通信，还是需要使用socket。\n\nUNIX系统上通过调用`mkfifo()`可以创建命名管道`FIFO`，可通过系统调用像操作磁盘文件一样操作`FIFO`。\n\n可以用命令行或者代码创建一个命名管道。\n\n```bash\nmkfifo /tmp/mypipe\n\nls -la /tmp/mypipe\n# might alert:\n# prw-r--r-- 1 user group 0 Feb 22 10:00 /tmp/mypipe\n# ▲\n# p means it is a pipe file\n```\n\n```c\n#include <sys/types.h>\n#include <sys/stat.h>\n\nmkfifo("/tmp/mypipe", 0666);\n```\n\n示例：\n\n```c\n// writer.c\n#include <stdio.h>\n#include <fcntl.h>\n#include <string.h>\n#include <sys/stat.h>\n#include <unistd.h>\nint main() {\n    mkfifo("/tmp/mypipe", 0666);\n    int fd = open("/tmp/mypipe", O_WRONLY);\n    char *msg = "Hello from writer!";\n    write(fd, msg, strlen(msg) + 1);\n    close(fd);\n    return 0;\n}\n```\n\n```c\n// reader.c\n#include <stdio.h>\n#include <fcntl.h>\n#include <sys/stat.h>\n#include <unistd.h>\n#define BUFFER_SIZE 64\nint main() {\n    int fd = open("/tmp/mypipe", O_RDONLY);\n    char buffer[BUFFER_SIZE];\n    read(fd, buffer, BUFFER_SIZE);\n    close(fd);\n    unlink("/tmp/mypipe");\n    return 0;\n}\n```\n\n> 命名管道的数据只存在内核内存中，数据被读走就消失、天然阻塞同步、性能更高，大小永远为0。\n\n\n' 
                      },
                      { id: 'operating_system-4', 
                        title: '4、多线程编程', 
                        desc: '', 
                        content: '# 4.多线程编程\n\n## 4.1概述\n\n每个线程是CPU使用的一个基本单元，它包括线程ID、程序计数器、寄存器组和堆栈。它与同一进程的其它线程共享代码段、数据段和其它操作系统资源。\n\n![image-20260222205710155](./pictures/image-20260222205710155.png)\n\n### 4.1.1动机\n\n单个进程可能处理多方面的需求，而一个Web服务器可能处理多个客户请求。而频繁建立进程很耗时间和资源。\n\n在Linux种采用了一个内核线程以便管理系统空闲内存的数量。\n\n![image-20260222211755837](./pictures/image-20260222211755837.png)\n\n### 4.1.2优点\n\n- **响应性**：避免部分阻塞或冗长操作的影响从而增加对用户的相应程度。\n- **资源共享**。\n- **经济**：线程切换往往比进程创建快。\n- **可伸缩性**：多核运行。\n\n## 4.2多核编程\n\n![image-20260222220045940](./pictures/image-20260222220045940.png)\n\n### 4.2.1编程挑战\n\n- **识别任务**：独立或并发的任务。\n- **平衡**：涉及均衡负载问题。\n- **数据分割**：任务访问和操作的数据划分以便运行在单独的核上。\n- **数据依赖**：会在第六章**同步**探讨。\n- **测试与调试**：困难。\n\n### 4.2.2并行类型\n\n**数据并行（data parallelism）** 注重将不同数据分布于多个计算核上，并在每个核上执行相同操作。\n\n**任务并行（task parallelism）** 将任务分配到多个计算核。\n\n## 4.3多线程模型\n\n### 4.3.1多对一模型\n\n将多个用户级线程映射到一个内核线程上。\n\n线程的创建、调度、切换全部在用户空间的线程库中完成，内核完全不知道有多个线程存在。\n\n内核看到的是一个普通进程，线程库在用户空间模拟了线程的行为（比如切换线程）：\n\n```\n线程库维护：\n├── 每个用户线程的 TCB（线程控制块）\n│     ├── 寄存器状态\n│     ├── 栈\n│     └── 线程状态（运行/就绪/阻塞）\n│\n└── 用户态调度器\n      └── 决定哪个用户线程运行\n```\n\n这使得：\n\n- **线程切换开销极小**：只需要切换寄存器和栈。\n- **可以创建大量线程**：只需要线程库维护TCB而不是复杂的数据结构。\n\n> Go语言的goroutine就是这个思路。\n\n当然，这使得进程只能利用一个核。\n\n### 4.3.2一对一模型\n\n将每个用户级线程映射到一个内核线程上。\n\n真正的多核并行，由内核统一调度。\n\n- 由于内核线程的创建开销，使得该模型的创建开销大。\n\n- 线程切换必须进内核，切换开销大。\n\n- 数量受系统限制\n\n  ```bash\n  cat /proc/sys/kernel/threads-max # 系统总线程数上限\n  ulimit -u # 当前用户线程数上限\n  ulimit -s # 查看栈大小限制\n  ```\n\n- 当线程共享同一个地址空间，会有同步问题。\n\n### 4.3.3多对多模型\n\n多路复用多个用户级线程到同样数量或更少数量的内核线程。\n\n通常内核线程数量更少，不在这里详细介绍，\n\nGo是多对多模型最成功的实现，其调度器称为GMP模型。\n\n## 4.4线程库\n\n**线程库（thread library）** 为程序员提供创建和管理线程的API。\n\n目前使用的三种主要线程库：\n\n- **POSIX Pthreads**：POSIX标准的扩展，可以提供用户级或内核级的库。\n- **Windows**：Windows操作系统的内核级线程库。\n- **Java**：通常采用Windows API实现，在UNIX和Linux中采用Pthreads实现。\n\n**异步线程**：父进程创建子进程后会恢复自身执行。线程之间很少有数据共享。\n\n**同步线程**：只有在所有子进程结束后才会恢复执行。涉及线程之间的大量数据的共享。\n\n我们会用同步线程策略涉及多线程程序计算\n$$\n\\sum_{i=0}^Ni\n$$\n\n### 4.4.1Pthreads\n\n参考文档：\n\n[](https://pubs.opengroup.org/onlinepubs/9699919799/basedefs/pthread.h.html)\n\n[pthreads(7) - Linux manual page](https://man7.org/linux/man-pages/man7/pthreads.7.html)\n\n查询具体使用方法：\n\n```bash\nman pthread_create\nman pthread_mutex_lock\nman pthread_cond_wait\n...\n```\n\n```c\n#include <pthread.h>\n#include <stdio.h>\n\n/* this data is shared by the thread(s) */\nint sum;\n/* threads call this function */\nvoid *runner (void *param);\n\nint main(int argc, char *argv[]) {\n	/* the thread identifier */\n	pthread_t tid;\n	/* set of thread attributes */\n	pthread_attr_t attr;\n	if (argc != 2) {\n		fprintf(stderr, "usage: a.out <integer value>\\n");\n		return -1;\n	}\n	if (atoi(argv[1]) < 0) {\n		fprintf(stderr, "%d must be >= 0\\n", atoi(argv[1]));\n		return -1;\n	}\n	/* get the default attributes */\n	pthread_attr_init(&attr);\n	/* create the thread */\n	pthread_create(&tid, &attr, runner, argv[1]);\n	/* wait for the thread to exit */\n	pthread_join(tid, NULL);\n	printf("sum = %d\\n", sum);\n}\n\n/* The thread will begin control in this function */\nvoid *runner(void *param) {\n	int i, upper = atoi(param);\n	sum = 0;\n	for (i = 1; i <= upper; i++) sum += i;\n	pthread_exit(0);\n}\n```\n\n### 4.4.2Windows线程\n\n略。\n\n### 4.4.3Java线程\n\n略。\n\n## 4.5隐式多线程\n\n**隐式线程（implicit threading）** 就是将多线程的创建与管理交给编译器和运行时库来完成。是一种应用层的编程模式，Windows是少数在内核层面提供线程池API的系统。\n\n### 4.5.1线程池\n\n**线程池（thread pool）** 的主要思想是：在进程开始时创建一定数量的线程，并加到池中以等待工作。当服务器收到请求时，它会唤醒池内的一个线程，并将需要服务的请求传递给它。一旦线程完成了任务，它会返回到池中再等待工作。如果池内没有可用线程，那么服务器会等待，直到有空线程为止。\n\n- 用现有线程服务请求比等待创建一个线程更快。\n- 线程池限制了任何时候可用线程的数量。这对那些不能支持大量并发线程的系统非常重要。\n- 将要执行任务从创建任务的机制中分离出来，允许我们采用不同策略运行任务。例如，任务可以被安排在某一个时间延迟后执行，或定期执行。\n\n> [!note]\n>\n> 使用`Pthreads`手写线程池：\n>\n> 可能用到的头文件：\n>\n> ```c\n> #include <pthread.h>\n> #include <errno.h>\n> #include <stdio.h>\n> #include <stdlib.h>\n> #include <string.h>\n> #include <unistd.h>\n> ```\n>\n> 定义**任务（Task）** 结构体：\n>\n> ```c\n> typedef struct Task {\n>     void (*function)(void *arg);          // Task function pointer\n>     void *arg;                            // Task parameters\n>     struct Task *next;                    // Next node of the linked list\n> } Task;\n> ```\n>\n> 定义**线程池（Thread pool）** 结构体：\n>\n> ```c\n> typedef struct {\n>     /* Worker thread */\n>     pthread_t *threads;                   // Worker thread array\n>     int thread_count;                     // Number of threads\n> \n>     /* Tasks queue */\n>     Task *head;                           // Queue head (take task)\n>     Task *tail;                           // Queue tail (add task)\n>     int queue_size;                       // Current queue size\n>     int queue_capacity;                   // Queue capacity (0 = unlimited)\n> \n>     /* Synchronization primitives */\n>     pthread_mutex_t lock;                 // Mutexes protecting queues\n>     pthread_cond_t not_empty;             // Queue non-empty condition variable\n>     pthread_cond_t not_full;              // Queue not full condition variable\n> \n>     /* State */\n>     int shutdown;                         // Shutdown flag (0 = running, 1 = shutdown)\n>     int active_count;                     // Number of active threads executing tasks\n> } ThreadPool;\n> ```\n>\n> 实现内部循环用于负责从队列取任务并执行：\n>\n> ```c\n> static void *worker_thread(void *arg) {\n>     ThreadPool *pool = (ThreadPool *)arg;\n> \n>     while (1) {\n>         pthread_mutex_lock(&pool->lock);\n> \n>         /* Waiting conditions: The queue is empty and not closed */\n>         while (pool->queue_size == 0 && !pool->shutdown) {\n>             pthread_cond_wait(&pool->not_empty, &pool->lock);\n>         }\n> \n>         /* Closed and queue empty: Exit thread */\n>         if (pool->shutdown && pool->queue_size == 0) {\n>             pthread_mutex_unlock(&pool->lock);\n>             pthread_exit(NULL);\n>         }\n> \n>         Task *task = pool->head;\n>         pool->head = task->next;\n>         if (pool->head == NULL) {\n>             pool->tail = NULL;\n>         }\n>         pool->queue_size--;\n>         pool->active_count++;\n> \n>         /* Empty spaces in the queue */\n>         pthread_cond_signal(&pool->not_full);\n>         pthread_mutex_unlock(&pool->lock);\n> \n>         /* ── Execute tasks outside the lock without blocking other threads from retrieving tasks ── */\n>         task->function(task->arg);\n>         free(task);\n> \n>         /* Task finished */\n>         pthread_mutex_lock(&pool->lock);\n>         pool->active_count--;\n> \n>         /* If the queue is empty and there are no active threads, it means that all tasks have been completed */\n>         if (pool->queue_size == 0 && pool->active_count == 0) {\n>             pthread_cond_broadcast(&pool->not_empty);\n>         }\n>         pthread_mutex_unlock(&pool->lock);\n>     }\n> \n>     return NULL;\n> }\n> ```\n>\n> 要实现的API：\n>\n> ```c\n> /**\n>  * Create a thread pool\n>  * @param thread_count   Number of worker threads (must be > 0)\n>  * @param queue_capacity Task queue capacity (0 = unlimited)\n>  * @return Pointer to the created thread pool, or NULL on failure\n>  */\n> ThreadPool *threadpool_create(int thread_count, int queue_capacity);\n> \n> /**\n>  * Submit a task to the thread pool\n>  * @param pool     Pointer to the thread pool\n>  * @param function Task function pointer\n>  * @param arg      Task parameters\n>  * @return 0 on success, -1 on failure (e.g., pool is NULL, function is NULL, or pool is shutdown)\n>  */\n> int threadpool_submit(ThreadPool *pool, void (*function)(void *), void *arg);\n> \n> /**\n>  * Wait for all submitted tasks to complete\n>  * @param pool Pointer to the thread pool\n>  */\n> void threadpool_wait(ThreadPool *pool);\n> \n> /**\n>  * Destroy the thread pool\n>  * @param pool     Pointer to the thread pool\n>  * @param graceful If non-zero, wait for all tasks to complete before destroying; if zero, discard pending tasks immediately\n>  */\n> void threadpool_destroy(ThreadPool *pool, int graceful);\n> ```\n>\n> 进程池的创建：\n>\n> `thread_count`是可并行处理任务的线程数量。\n>\n> `queue_capacity`是队列容量，即最多能缓存多少个等待执行的任务。如果设为`0`，代表无限容量。\n>\n> ```c\n> ThreadPool *threadpool_create(int thread_count, int queue_capacity) {\n>     if (thread_count <= 0) {\n>         fprintf(stderr, "[threadpool] thread_count must > 0\\n");\n>         return NULL;\n>     }\n> \n>     ThreadPool *pool = calloc(1, sizeof(ThreadPool));\n>     if (!pool) {\n>         perror("[threadpool] calloc pool");\n>         return NULL;\n>     }\n> \n>     pool->threads = calloc(thread_count, sizeof(pthread_t));\n>     if (!pool->threads) {\n>         perror("[threadpool] calloc threads");\n>         free(pool);\n>         return NULL;\n>     }\n> \n>     pool->thread_count = thread_count;\n>     pool->queue_capacity = (queue_capacity > 0) ? queue_capacity : 0; /* 0 = inf */\n>     pool->shutdown = 0;\n>     pool->active_count = 0;\n>     pool->queue_size = 0;\n>     pool->head = NULL;\n>     pool->tail = NULL;\n> \n>     if (pthread_mutex_init(&pool->lock, NULL) != 0 ||\n>         pthread_cond_init(&pool->not_empty, NULL) != 0 ||\n>         pthread_cond_init(&pool->not_full,  NULL) != 0) {\n>         perror("[threadpool] pthread init");\n>         free(pool->threads);\n>         free(pool);\n>         return NULL;\n>     }\n> \n>     /* Create threads */\n>     for (int i = 0; i < thread_count; i++) {\n>         if (pthread_create(&pool->threads[i], NULL, worker_thread, pool) != 0) {\n>             fprintf(stderr, "[threadpool] create thread %d failed\\n", i);\n>             pool->shutdown = 1;\n>             pthread_cond_broadcast(&pool->not_empty);\n>             for (int j = 0; j < i; j++) {\n>                 pthread_join(pool->threads[j], NULL);\n>             }\n>             pthread_mutex_destroy(&pool->lock);\n>             pthread_cond_destroy(&pool->not_empty);\n>             pthread_cond_destroy(&pool->not_full);\n>             free(pool->threads);\n>             free(pool);\n>             return NULL;\n>         }\n>     }\n> \n>     printf("[threadpool] create %d threads successfully, capacity = %d\\n",\n>            thread_count,\n>            queue_capacity);\n>     return pool;\n> }\n> ```\n>\n> 提交任务到进程池：\n>\n> 本质是在`pool->task`添加新任务。\n>\n> ```c\n> int threadpool_submit(ThreadPool *pool, void (*function)(void *), void *arg) {\n>     if (!pool || !function) return -1;\n> \n>     Task *task = malloc(sizeof(Task));\n>     if (!task) {\n>         perror("[threadpool] malloc task");\n>         return -1;\n>     }\n>     task->function = function;\n>     task->arg = arg;\n>     task->next = NULL;\n> \n>     pthread_mutex_lock(&pool->lock);\n> \n>     if (pool->shutdown) {\n>         pthread_mutex_unlock(&pool->lock);\n>         free(task);\n>         fprintf(stderr, "[threadpool] pool is shutdown\\n");\n>         return -1;\n>     }\n> \n>     /* If the queue is full, the submitter will be blocked */\n>     while (pool->queue_capacity > 0 &&\n>            pool->queue_size >= pool->queue_capacity &&\n>            !pool->shutdown) {\n>         pthread_cond_wait(&pool->not_full, &pool->lock);\n>     }\n> \n>     if (pool->shutdown) {\n>         pthread_mutex_unlock(&pool->lock);\n>         free(task);\n>         return -1;\n>     }\n> \n>     if (pool->tail == NULL) {\n>         pool->head = pool->tail = task;\n>     } else {\n>         pool->tail->next = task;\n>         pool->tail = task;\n>     }\n>     pool->queue_size++;\n> \n>     pthread_cond_signal(&pool->not_empty);\n>     pthread_mutex_unlock(&pool->lock);\n> \n>     return 0;\n> }\n> ```\n>\n> 等待进程池任务全部执行完毕：\n>\n> ```c\n> void threadpool_wait(ThreadPool *pool) {\n>     if (!pool) return;\n> \n>     pthread_mutex_lock(&pool->lock);\n>     /* Waiting conditions: The queue is empty and there are no active threads */\n>     while (pool->queue_size > 0 || pool->active_count > 0) {\n>         pthread_cond_wait(&pool->not_empty, &pool->lock);\n>     }\n>     pthread_mutex_unlock(&pool->lock);\n> }\n> ```\n>\n> 进程池销毁：\n>\n> ```c\n> void threadpool_destroy(ThreadPool *pool, int graceful) {\n>     if (!pool) return;\n> \n>     pthread_mutex_lock(&pool->lock);\n> \n>     if (pool->shutdown) {\n>         pthread_mutex_unlock(&pool->lock);\n>         return;\n>     }\n> \n>     if (graceful) {\n>         while (pool->queue_size > 0 || pool->active_count > 0) {\n>             pthread_cond_wait(&pool->not_empty, &pool->lock);\n>         }\n>     } else {\n>         Task *cur = pool->head;\n>         while (cur) {\n>             Task *next = cur->next;\n>             free(cur);\n>             cur = next;\n>         }\n>         pool->head = pool->tail = NULL;\n>         pool->queue_size = 0;\n>     }\n> \n>     pool->shutdown = 1;\n>     pthread_cond_broadcast(&pool->not_empty);\n>     pthread_cond_broadcast(&pool->not_full);\n>     pthread_mutex_unlock(&pool->lock);\n> \n>     for (int i = 0; i < pool->thread_count; i++) {\n>         pthread_join(pool->threads[i], NULL);\n>     }\n> \n>     pthread_mutex_destroy(&pool->lock);\n>     pthread_cond_destroy(&pool->not_empty);\n>     pthread_cond_destroy(&pool->not_full);\n>     free(pool->threads);\n>     free(pool);\n> \n>     printf("[threadpool] destroyed\\n");\n> }\n> ```\n>\n> 以下展示了**线程池**、**直接申请线程**和单线程计算\n> $$\n> \\sum_{i=1}^{999999}\n> $$\n> 的测试代码，调用：\n>\n> ```bash\n> gcc -Wall -o test threadpool.c test.c -pthread\n> ```\n>\n> > 这里没有使用任何优化参数，否则第三种做法太容易被编译器优化掉。\n> >\n> > 第二种做法适当减小了进程数，否则屡次访问内核会导致大量的时间开销。\n>\n> ```c\n> #include <stdio.h>\n> #include <stdlib.h>\n> #include <unistd.h>\n> #include <pthread.h>\n> #include <time.h>\n> #include "threadpool.h"\n> \n> static pthread_mutex_t counter_lock = PTHREAD_MUTEX_INITIALIZER;\n> static int total_completed = 0;\n> \n> struct range {\n>     int start;\n>     int end;\n>     long long *ans;\n> };\n> \n> void task(void *arg) {\n>     struct range *p = (struct range *)arg;\n>     long long sum = 0;\n>     for (long long i = p->start; i < p->end; i++) sum += i;\n> \n>     pthread_mutex_lock(&counter_lock);\n>     total_completed++;\n>     *(p->ans) += sum;\n>     pthread_mutex_unlock(&counter_lock);\n> \n>     free(arg);\n> }\n> \n> void test(int N) {\n>     const int TASK_COUNT = 10000;\n>     const int TASK_SIZE = N / TASK_COUNT;\n>     total_completed = 0;\n>     long long ans = 0;\n> \n>     ThreadPool *pool = threadpool_create(8, 0);\n> \n>     printf("Submit %d tasks, thread count = 8\\n", TASK_COUNT);\n> \n>     for (int i = 0; i < TASK_COUNT; i++) {\n>         struct range *p = malloc(sizeof(struct range));\n>         p->start = i * TASK_SIZE;\n>         p->end = (i + 1) * TASK_SIZE;\n>         p->ans = &ans;\n>         threadpool_submit(pool, task, p);\n>     }\n> \n>     threadpool_wait(pool);\n>     printf("Completed tasks: %d / %d\\n", total_completed, TASK_COUNT);\n>     \n>     threadpool_destroy(pool, 1);\n> \n>     printf("Expected answer: %lld\\nActual answer: %lld\\n", ((long long)N * ((long long)N - 1ll)) / 2, ans);\n> }\n> \n> void test_without_pool(int N) {\n>     const int TASK_COUNT = 500;\n>     const int TASK_SIZE = N / TASK_COUNT;\n>     total_completed = 0;\n>     long long ans = 0;\n> \n>     pthread_t *threads = malloc(sizeof(pthread_t) * TASK_COUNT);\n> \n>     printf("Directly creating %d threads...\\n", TASK_COUNT);\n> \n>     for (int i = 0; i < TASK_COUNT; i++) {\n>         struct range *p = malloc(sizeof(struct range));\n>         p->start = i * TASK_SIZE;\n>         p->end = (i + 1) * TASK_SIZE;\n>         p->ans = &ans;\n> \n>         if (pthread_create(&threads[i], NULL, (void *(*)(void *))task, p) != 0) {\n>             perror("Failed to create thread");\n>             break;\n>         }\n>     }\n> \n>     for (int i = 0; i < TASK_COUNT; i++) {\n>         pthread_join(threads[i], NULL);\n>     }\n> \n>     printf("Completed tasks: %d / %d\\n", total_completed, TASK_COUNT);\n>     \n>     free(threads);\n> \n>     printf("Expected answer: %lld\\nActual answer: %lld\\n", ((long long)N * ((long long)N - 1ll)) / 2, ans);\n> }\n> \n> void simple_cal(int N) {\n>     long long ans = 0;\n>     for (long long i = 0; i < N; i++) ans += i;\n>     printf("Expected answer: %lld\\nActual answer: %lld\\n", ((long long)N * ((long long)N - 1ll)) / 2, ans);\n> }\n> \n> int main() {\n>     clock_t a = clock();\n>     test(1000000000);\n>     printf("Time taken: %ld milliseconds\\n", (clock() - a) * 1000 / CLOCKS_PER_SEC);\n>     a = clock();\n>     test_without_pool(1000000000);\n>     printf("Time taken: %ld milliseconds\\n", (clock() - a) * 1000 / CLOCKS_PER_SEC);\n>     a = clock();\n>     simple_cal(1000000000);\n>     printf("Time taken: %ld milliseconds\\n", (clock() - a) * 1000 / CLOCKS_PER_SEC);\n>     return 0;\n> }\n> ```\n>\n> 一种可能的输出是：\n>\n> ```bash\n> [threadpool] create 8 threads successfully, capacity = 0\n> Submit 10000 tasks, thread count = 8\n> Completed tasks: 10000 / 10000\n> [threadpool] destroyed\n> Expected answer: 499999999500000000\n> Actual answer: 499999999500000000\n> Time taken: 1381 milliseconds\n> Directly creating 500 threads...\n> Completed tasks: 500 / 500\n> Expected answer: 499999999500000000\n> Actual answer: 499999999500000000\n> Time taken: 2284 milliseconds\n> Expected answer: 499999999500000000\n> Actual answer: 499999999500000000\n> Time taken: 1979 milliseconds\n> ```\n\n### 4.5.2OpenMP\n\nOpenMP为一组编译指令和API，用于编写C、C++、Fortran等语言的程序，它支持共享内存环境下的并行编程。OpenMP识别**并行区域（parallel region）**，即可并行运行的代码块。\n\n编译时需`-fopenmp`选项。\n\n所谓parallel region是由以下类型指令生成的：\n\n- `parallel`：创建线程团队\n\n  ```c\n  #pragma omp parallel num_threads(4)\n  {\n      int tid = omp_get_thread_num();\n      int total = omp_get_num_threads();\n      printf("threads %d / %d\\n", tid, total);\n  }\n  // Each thread executes the code within the curly braces\n  ```\n\n- `parallel for`：并行化循环\n\n  ```c\n  #pragma omp parallel for\n  for (int i = 0; i < N; i++) {\n      a[i] = b[i] + c[i];\n  }\n  // Automatically assign loop iterations to each thread\n  ```\n\n- 不同调度策略：\n\n  `static`：迭代平均分配，编译时确定\n\n  `dynamic`：线程执行完当前块再动态领取下一块\n\n  `guided`：块大小从大到小动态分配\n\n  ```c\n  #pragma omp parallel for schedule(dynamic, 10)\n  for (int i = 0; i < N; i++) {\n      heavy_compute(i);\n  }\n  // Specify scheduling method\n  ```\n\n- `reduction`：并行归约\n\n  `reduction(+:var)`：加法，初始值0\n\n  `reduction(*:var)`：乘法，初始值1\n\n  `reduction(max:var)`：取最大值\n\n  `reduction(min:var)`：取最小值\n\n  `reduction(&:var)`：按位与\n\n  `reduction(|:var)`：按位或\n\n  ```c\n  int sum = 0;\n  \n  // This will lead to data competition\n  #pragma omp parallel for\n  for (int i = 0; i < N; i++) {\n      sum += a[i];\n  }\n  \n  // Correct\n  #pragma omp parallel for reduction(+:sum)\n  for (int i = 0; i < N; i++) {\n      sum += a[i];\n  }\n  ```\n\n- 同步控制：\n\n  - `sections`：不同线程执行不同任务\n\n    ```c\n    #pragma omp parallel sections\n    {\n        #pragma omp section\n        {\n            task1();\n        }\n    \n        #pragma omp section\n        {\n            task2();\n        }\n    \n        #pragma omp section\n        {\n            task3();\n        }\n    }\n    ```\n\n  - `critical`：互斥锁\n\n    ```c\n    #pragma omp parallel for\n    for (int i = 0; i < N; i++) {\n        #pragma omp critical\n        {\n            // Only one thread executes this at a time\n            sthComplicated();\n        }\n    }\n    ```\n\n  - `atomic`：原子操作\n\n    ```c\n    int counter = 0;\n    \n    #pragma omp parallel for\n    for (int i = 0; i < N; i++) {\n        #pragma omp atomic\n        counter++;\n    }\n    ```\n\n  - `barrier`：手动同步屏障\n\n    ```c\n    #pragma omp parallel\n    {\n        phase1_work();\n    \n        #pragma omp barrier\n    \n        phase2_work();\n    }\n    ```\n\n  - `single`：只由某个线程执行，带有隐形屏障\n\n    `master(masked)`：主线程执行\n\n    ```c\n    #pragma omp parallel\n    {\n        #pragma omp single\n        {\n            // A certain thread executes\n            printf("Hello\\n");\n        }\n    \n        #pragma omp master\n        {\n            // Main thread executes\n            log_progress();\n        }\n    }\n    ```\n\n- 作用域：\n\n  代码块以外的变量默认为共享的：\n\n  ```c\n  #pragma omp parallel for \\\n      shared(x)    \\   // All threads share the same\n      private(y)   \\   // Each thread has its own copy\n      firstprivate(y)  // Each thread has a copy, and it is initialized to the original value\n  {\n      y = x + omp_get_thread_num();\n  }\n  ```\n\n### 4.5.3大中央调度\n\n**大中央调度（Grand Central Dispatch，GCD）** 是Apple Mac OS X和iOS操作系统的一种技术，为C语言、API和运行时库的一组扩展，它允许应用程序开发人员将某些代码区段并行运行。\n\n因为适用面比较少，就不过多介绍。\n\n### 4.5.4其他方法\n\nJava、Go、Rust语言都提供了原生并发编程的API。\n\n相关的还有**MPI（Message Passing Interface）** 用于**多台服务器（集群）** 之间的并行。\n\n**CUDA（NVIDIA），OpenCL**显卡的暴力美学\n\n**TBB（Intel Threading Building Blocks）** Intel下基于C++的接口。\n\n## 4.6多线程问题\n\n### 4.6.1系统调用fork()和exec()\n\n如果某个线程调用`fork()`，新进程会包含所有线程还是仅一个线程？\n\n历史上：在早期的**Solaris**系统和某些版本的**Mach**内核中，曾经提供过两种版本的`fork()`：\n\n- `fork1()`：只复制当前线程。\n- `forkall()`：复制进程中所有的线程。\n\n后者可能导致：\n\n- **网络连接**：如果10个线程正在处理10个不同的TCP连接，复制后，新进程里的10个线程该如何处理那些属于旧进程的文件描述符？\n- **逻辑矛盾**：如果某个线程在`fork`瞬间正处于`if`判断中间，复制过去后，它可能处于一种违反程序逻辑的状态。\n\n---\n\n如果一个线程调用`exec()`，那么`exec()`参数指定的程序将会取代整个进程，包括所有线程。\n\n### 4.6.2信号处理\n\n**UNIX信号（signal）** 用于通知进程某个特定事件已经发生。\n\n- 信号是由特定事件的发生而产生的。\n- 信号被传递给某个进程。\n- 信号一旦收到就应处理。\n\n信号处理程序可以分为：\n\n- 缺省的信号处理程序。\n- 用户定义的信号处理程序。\n\n每个信号都有**缺省信号处理程序（default signal handler）**，内核会默认执行**终止进程**并**生成Core Dump**。除非用户编写**用户定义信号处理程序（user-defined signal handler）**。\n\n多线程情况下的信号处理比较麻烦：\n\n- 硬件异常信号如`SIGSEGV`（越界）、`SIGFPE`（除零），内核会将其发送到**触发该指令的那个特定线程**。如果该线程没有捕获信号，整个进程（所有线程）都会被杀掉。\n- 外部/软件信号如`SIGINT`（Ctrl+C）、`SIGTERM`、`kill()`发送的信号。内核会将信号发送给**进程**。内核会在进程中挑选一个**没有屏蔽该信号**的线程来处理它。如果所有线程都没屏蔽，通常是主线程或第一个被选中的线程。\n\n### 4.6.3线程撤销\n\n**线程撤销（thread cancellation）** 是在线程完成之前终止线程。\n\n需要撤销的线程，通常称为**目标线程（target thread）**：\n\n- **异步撤销**：一个线程立即终止目标线程。\n- **延迟撤销**：目标线程不断检查它是否应终止，这允许目标线程有机会有序终止自己。\n\n我们应该极力避免异步撤销。\n\n下面是线程撤销的接口示例：\n\n```c\npthread_t tid;\npthread_create(&tid, NULL, worker, NULL);\n\n// Send cancellation request\npthread_cancel(tid);\n\n// Wait for thread exiting\npthread_join(tid, NULL);\n\n// Whether accept cancellation request\npthread_setcancelstate(PTHREAD_CANCEL_ENABLE, NULL);\npthread_setcancelstate(PTHREAD_CANCEL_DISABLE, NULL);\n\n// Two ways for cancellation\npthread_setcanceltype(PTHREAD_CANCEL_DEFERRED, NULL);\npthread_setcanceltype(PTHREAD_CANCEL_ASYNCHRONOUS, NULL);\n```\n\n延迟撤销中线程只在**取消点**处响应撤销请求，pthreads规定了很多函数是天然的取消点：\n\n```c\n├── sleep() / usleep() / nanosleep()\n├── read() / write()\n├── wait() / waitpid()\n├── pthread_cond_wait()\n├── pthread_testcancel()\n├── pthread_join()\n├── connect() / accept()\n└── open() / close()\n```\n\n线程被撤销时，需要释放资源，通过**清理处理器**实现，以下是示例：\n\n```c\nvoid cleanup(void *arg) {\n    free(arg);\n}\n\nvoid *worker(void *arg) {\n    char *buf = malloc(1024);\n    \n    /* push sequence defines the clean sequence */\n    pthread_cleanup_push(cleanup, buf);\n    \n    /* cancellation point */\n    sleep(10);\n\n    /* cancel and clean */\n    pthread_cleanup_pop(1);\n\n    return NULL;\n}\n```\n\n多个清理处理器按**后进先出**顺序执行。\n\n### 4.6.4线程本地存储\n\n同一进程的线程共享进程的数据，而当某个线程需要它自己的数据时，就需要**线程本地存储（Thread-Local Storage，TLS）**。\n\n下面是一个实验性程序：\n\n```c\n#include <stdio.h>\n#include <omp.h>\n#include <pthread.h>\n#include <stdlib.h>\n#define N 10\nint sum = 0;\nvoid* task(void *arg) {\n    int p = *(int *)arg;\n    for(int i = p; i < p + 10; ++i) {\n        sum += i;\n    }\n    printf("I am thread %d, sum = %d\\n", p / 10, sum);\n    return NULL;\n}\nint main() {\n    pthread_t* threads = malloc(N * sizeof(pthread_t));\n    int* val = malloc(N * sizeof(int));\n    val[0] = 0;\n    for(int i = 0; i < N; ++i) {\n        if (i) val[i] = val[i - 1] + 10;\n        pthread_create(&threads[i], NULL, task, &val[i]);\n    }\n    for(int i = 0; i < N; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n    printf("%d", sum);\n    return 0;\n}\n```\n\n有两种方法实现TLS：\n\n- 编译器原生支持`__thread`：\n\n  ```c\n  #include <stdio.h>\n  #include <omp.h>\n  #include <pthread.h>\n  #include <stdlib.h>\n  #define N 10\n  __thread int sum = 0;\n  void* task(void *arg) {\n      int p = *(int *)arg;\n      for(int i = p; i < p + 10; ++i) {\n          sum += i;\n      }\n      printf("I am thread %d, sum = %d, %p\\n", p / 10, sum, &sum);\n      return NULL;\n  }\n  int main() {\n      pthread_t* threads = malloc(N * sizeof(pthread_t));\n      int* val = malloc(N * sizeof(int));\n      val[0] = 0;\n      for(int i = 0; i < N; ++i) {\n          if (i) val[i] = val[i - 1] + 10;\n          pthread_create(&threads[i], NULL, task, &val[i]);\n      }\n      for(int i = 0; i < N; ++i) {\n          pthread_join(threads[i], NULL);\n      }\n      printf("%d", sum);\n      return 0;\n  }\n  ```\n\n  我们特意输出了每个线程的`&sum`，可以发现是不同的。\n\n- 通过专门的API动态管理：\n\n  （暂时没想到一个好的修改法，姑且了解用法）\n\n  ```c\n  #include <stdio.h>\n  #include <omp.h>\n  #include <pthread.h>\n  #include <stdlib.h>\n  #define N 10\n  pthread_key_t key;\n  int sum = 0;\n  void destructor(void *value) {\n      //\n  }\n  void* task(void *arg) {\n      int p = *(int *)arg;\n      for(int i = p; i < p + 10; ++i) {\n          sum += i;\n      }\n      int *_sum = &sum;\n      pthread_setspecific(key, _sum);\n      printf("attention: %d\\n", *(int*)pthread_getspecific(key));\n      printf("I am thread %d, sum = %d, %p\\n", p / 10, sum, &sum);\n      return NULL;\n  }\n  int main() {\n      pthread_key_create(&key, destructor);\n      pthread_t* threads = malloc(N * sizeof(pthread_t));\n      int* val = malloc(N * sizeof(int));\n      val[0] = 0;\n      for(int i = 0; i < N; ++i) {\n          if (i) val[i] = val[i - 1] + 10;\n          pthread_create(&threads[i], NULL, task, &val[i]);\n      }\n      for(int i = 0; i < N; ++i) {\n          pthread_join(threads[i], NULL);\n      }\n      return 0;\n  }\n  ```\n\n### 4.6.5调度程序激活\n\n许多系统在实现多对多或双层模型时，在用户和内核线程之间增加一个中间数据结构，即**轻量级进程（LightWeight Process，LWP）**。\n\n![image-20260226213740865](./pictures/image-20260226213740865.png)\n\n用户线程库与内核之间的一种通信方案称为**调度器激活（scheduler activation）**：内核提供一组LWP给应用程序，而应用程序可以调度用户线程到任何一个可用LWP。\n\n内核会将有关特定事件通知应用程序，这个步骤称为**回调（upcall）**，由线程库通过**回调处理程序（upcall handler）** 来处理。\n\n## 4.7操作系统例子\n\n### 4.7.1Windows线程\n\nWindows使用**一对一映射**。\n\n线程的主要数据结构包括:\n\n- **ETHREAD**：执行线程块：线程所属进程的指针、线程控制开始的程序的地址及对应KTHREAD的指针等\n- **KTHREAD**：内核线程块：线程的调度和同步信息。另外，KTHREAD也包括内核堆栈（以供线程在内核模式下运行）和TEB的指针。\n- **TEB**：线程环境块：除了许多其他域外，还包括线程标识符、用户模式堆栈以及用于线程本地存储的数组等。\n\nETHREAD和KTHREAD完全位于内核空间，这意味着只有内核可以访问它们。TEB是个用户空间数据结构，以供线程在用户模式下运行时访问\n\n![image-20260226215215198](./pictures/image-20260226215215198.png)\n\n### 4.7.2Linux线程\n\n其实pthreads和`fork()`的底层都是`clone()`。\n\n在调用`clone()`时，需要传递一组标志，以便确定父任务与子任务如何共享。\n\n| 标志            | 含义             |\n| --------------- | ---------------- |\n| `CLONE_FS`      | 共享文件系统信息 |\n| `CLONE_VM`      | 共享相同内存空间 |\n| `CLONE_SIGHAND` | 共享信号处理程序 |\n| `CLONE_FILES`   | 共享一组打开文件 |\n\n如果将上述所有标志传递给`clone()`，那么父任务和子任务将共享相同几乎所有信息，采用这种方式相当于本章所述的**线程创建**。\n\n如果当调用`clone()`时没有设置这些标志，那么不会发生任何共享，进而类似于系统调用`fork()`的功能。\n\n\n' 
                      },
                      { id: 'operating_system-5', 
                        title: '5、层次化存储', 
                        desc: '', 
                        content: '' 
                      },
                      { id: 'operating_system-6', 
                        title: '6、并行处理器：从客户端到云', 
                        desc: '', 
                        content: '' 
                      },
                      { id: 'operating_system-7', 
                        title: '实验指导', 
                        desc: '', 
                        content: '' 
                      }
                  ]
                },
                { id: 'Introduction to Computational Theory', title: '计算理论导引', icon: 'fas fa-warning', desc: '<p>计算复杂性理论导引。</p><p>抖M专属，图灵机爱好者狂喜。</p>',
                  chapters: [
                      { id: 'Introduction to Computational Theory-1', 
                        title: '1、计算理论', 
                        desc: '', 
                        content: '# 第1章 计算理论\n\n## 1.1图灵机\n\n一台$k$-带图灵机（**TM**）$\\mathbb M$有$k$-条带子。第一条带子称为**输入带**，用来存放输入数据，是只读带。其余$k-1$条带子是工作带 ，可读可写。一条带子被分成了潜在无穷多个格子，每个格子内可以存放一个符号，用$0,1,2,\\dots$标注格子的地址。每条带子有一个**读写头**，它指向带子上的某一个，该时刻读写头只能对这一格里的符号进行读或改写。\n\n> [!NOTE]\n>\n> **定义1.1**：一台$k$-带图灵机是一个三元组$(\\Gamma,Q,\\delta)$，其中\n>\n> 1. $\\Gamma$是有限符号集，至少包含$0、1、\\square、\\triangleright$；\n> 2. $Q$是有限状态集，必须包含起始状态$q_{start}$和终止状态$q_{halt}$；\n> 3. $\\delta:Q\\times\\Gamma^k\\to Q\\times\\Gamma^{k-1}\\times\\{L,S,R\\}^k$是迁移函数。\n\n**初始化**：\n\n1. $\\triangleright$预置在每条带子最左端格子里，图灵机不对第$0$格作修改，也不在其它格子写入$\\triangleright$。\n2. 所有工作带格子均放着$\\square$，表示无用信息。\n3. 输入带除了输入符号串的格子外全放着$\\square$。\n\n图灵机始于$q_{start}$，终于$q_{halt}$。\n\n**迁移函数**$\\delta$：$\\delta(q,a_1,\\dots,a_k)=(q\',a_2\',\\dots,a_k\',A_1,\\dots,A_k)$等价于$(q,a_1,\\dots,a_k)\\to(q\',a_2\',\\dots,a_k\',A_1,\\dots,A_k)$。\n\n后者被称为一条**指令**。\n\n$A_i\\in\\{L,S,R\\}$表示第$i$个读写头的移动。\n\n执行一次指令，图灵机完成了**一步计算**。\n\n规定$\\delta(q_{halt},a_1,a_2,\\dots,a_k)=(q_{halt},a_2,\\dots,a_k,S,\\dots,S)$。当机器进入停机状态$q_{halt}$时，机器不再进行任何计算。\n\n$\\mathbb{M}(x)$表示图灵机$\\mathbb M$的输入带预置了输入$x$。\n\n在计算的任何时刻$t$，$\\mathbb M(x)$的**格局**$\\sigma_t$是一个$2k-$元组$(q,\\kappa_2,\\dots,\\kappa_k,h_1,\\dots,h_k)$，它的含义与指令中后半部分类似：$\\kappa_i$表示时刻$t$时$k-1$条工作带的内容（非$\\square$的符号串），$h_i$表示时刻$t$时$k$个读写头位置。\n\n$\\mathbb M(x)$的**初始格局**是$(q_{start},\\epsilon,\\dots,\\epsilon,0,\\dots,0)$，是唯一的。\n\n$\\mathbb M(x)$的**终止格局**是状态为$q_{halt}$的格局。\n\n一步计算可以写作$\\sigma_t\\to\\sigma_{t+1}$，对于格局迁移序列$\\sigma_0\\to\\sigma_1\\to\\dots\\to\\sigma_t\\to\\dots$，若该计算终止，记为$\\mathbb M(x)\\downarrow$，否则记为$\\mathbb M(x)\\uparrow$。若计算终止于$\\sigma_T$，则$\\sigma_0\\to\\sigma_1\\to\\dots\\to\\sigma_T$表示其**计算路径**，计算路径长度被称为该计算的**计算步数**或**计算时间**。\n\n**时间函数**$T:\\\\mathbb{N}\\to\\\\mathbb{N}$，通常地，是从串的长度$n$到计算时间的一个上界的映射。\n\n一个函数$f:\\\\{0,1\\\\}^\\*\\to\\\\{0,1\\\\}^\\*$是一个**问题**。$\\mathbb M(x)=y$表示$\\mathbb M(x)\\downarrow$且计算终止时输出带上的内容是$y$，称$y$是$\\mathbb M(x)$的**计算结果**。若对任意输入$x\\in\\\\{0,1\\\\}^\\*$，有$\\mathbb M(x)=f(x)$，称$\\mathbb M$**计算**$f$或$\\mathbb M$**解决问题**$f$。\n\n**判定问题**是一个函数$d:\\\\{0,1\\\\}^\\*\\to\\\\{0,1\\\\}$，若$\\mathbb M$解决$d$，也称$\\mathbb M$**判定**$d$。称$\\\\{0,1\\\\}^\\*$的一个子集$L$为**语言**。\n\n若图灵机$\\mathbb M$判定$L$的**特征函数**\n$$\nL(x)=\\begin{cases}1,&若x\\in L\\\\\\\\0,&若x\\notin L\\end{cases}\n$$\n称$\\mathbb M$**接受语言**$L$，或称$L$为**可判定的**。\n\n> [!NOTE]\n>\n> **定义1.2**：一个判定问题$A\\subseteq\\\\{0,1\\\\}^\\*$的补问题$\\overline{A}$定义为$\\\\{0,1\\\\}^\\*\\backslash A$\n\n> [!CAUTION]\n>\n> 教材与本笔记中，如果一个数学表达式求值结果不是整数，自动**向上取整**。用$\\llcorner n\\lrcorner$表示数的二进制形式。\n\n称一个函数是**图灵机可计算的**或**图灵机可解的**，当且仅当有一台图灵机计算它。\n\n## 1.2时间可构造性\n\n设$T(n):\\\\mathbb{N}\\to\\\\mathbb{N}$为时间函数且$L\\subseteq\\\\{0,1\\\\}^*$为可判定问题。若存在判定$L$的图灵机$\\mathbb M$和常数$c>0$，对任意输入$x$，$\\mathbb M$在$cT(|x|)$步内停机，则称$L$在$\\textbf{TIME}(T(n))$中。\n\n一般地，$\\textbf{TIME}(T(n))$依赖于所用模型，如图灵机的带数。\n\n我们假定所关注的图灵机必须将输入完整地读一遍，也就是$T(n)\\ge n$。\n\n> [!NOTE]\n>\n> **定义1.3**：若有图灵机在$O(T(n))$时间内计算函数$1^n\\mapsto\\llcorner T(n)\\lrcorner$，称$T(n)$是**时间可构造的**。\n\n根据线性加速定理，我们可以给出下一个定义：\n\n> [!NOTE]\n>\n> **定义1.4**：若有图灵机在输入$1^n$上准确地计算了$T(n)$步后停机，称$T(n)$是**完全时间可构造的**。\n\n设$\\mathbb M=(Q_0,\\Gamma_0,\\to_0)$为一行为不规则的$k_0$-带图灵机，$\\mathbb T=(Q_1,\\Gamma_1,\\to_1)$是一$k_1$-带时钟图灵机，将它们复合：\n\n- $Q=Q_0\\times Q_1$，对于所有$q\\in Q_0$引入$(q,q_{halt}^1)=q_{halt}$，$q\\in Q_1$引入$(q_{halt}^0,q)=q_{halt}$。\n- $\\Gamma=\\Gamma_0\\times\\Gamma_1$。\n- $\\to=\\to_0\\times\\to_1$。\n\n效果相当于$\\mathbb T$对$\\mathbb M$的计算掐表，强迫后者在规定时间内停机。我们称$\\mathbb T$是**时钟图灵机**，复合后的图灵机是$\\mathbb M$和$\\mathbb T$的**硬连接**。\n\n## 1.3通用图灵机\n\n**事实**：无法设计一套编码系统，使得本质上相同的图灵机有相同的编码。\n\n**原因**：无法设计一个算法测试两台图灵机是否相等。\n\n> [!CAUTION]\n>\n> $\\llcorner\\mathbb M\\lrcorner$表示图灵机$\\mathbb M$的二进制编码，$\\mathbb M_\\alpha$表示二进制编码为$\\alpha$的图灵机。\n\n对图灵机的有效枚举\n$$\n\\mathbb M_0,\\mathbb M_1,\\dots,\\mathbb M_i,\\dots\n$$\n称$i$为图灵机$\\mathbb M_i$的**下标**或**哥德尔编码**。\n\n对**图灵机可计算**函数的枚举\n$$\n\\phi_0,\\phi_1,\\dots,\\phi_i,\\dots\n$$\n其中\n$$\n\\phi_i(x)\\overset{\\text{def}}{=}\\begin{cases}y,&若\\mathbb M_i(x)=y\\\\\\\\\\uparrow,&若\\mathbb M_i(x)\\uparrow\\end{cases}\n$$\n$\\phi_i(x)$在输入$x$上无定义，记为$\\phi_i(x)\\uparrow$，当且仅当$\\mathbb M_i(x)\\uparrow$。$\\phi_i(x)\\downarrow$，当且仅当$\\mathbb M_i(x)\\downarrow$。\n\n> [!NOTE]\n>\n> **定理1.1（枚举定理）**：存在**通用图灵机**$\\mathbb U$，对任意$\\alpha,x\\in\\\\{0,1\\\\}^\\*$，等式$\\mathbb U(\\alpha,x)\\simeq\\mathbb M_\\alpha(x)$成立。\n\n上面$\\simeq$的定义是两边要么同时有定义且相等要么都无定义。\n\n> [!NOTE]\n>\n> **定理1.2**：存在通用图灵机$\\mathbb U$和多项式$c$。对任意长度为$n$的输入串$x$，若$\\mathbb M_\\alpha(x)$在$T(n)$步内停机，则$\\mathbb U(\\alpha,x)$在$c(|\\alpha|)T(n)\\log T(n)$步内停机。\n\n下面我们尽可能通俗地证明：\n\n为了方便，设定图灵机的工作带是左右无限延伸的。\n\n设$\\mathbb M_\\alpha$的工作带数为$k$，由于$k$可能很大，所以我们这么规定$\\mathbb U$：\n\n- $\\mathbb U$的第一条工作带是主工作带，储存$\\mathbb M_\\alpha$的所有工作带上的内容，第二条带用来存储中间结果和提高数据移动效率。\n- 我们把$\\mathbb M_\\alpha$的每条带内容依次放入主工作带，并用分隔符分开。主工作带上的每个单元格要么是分隔符，要么是$s_{i,j}$，表示第$i$个磁带上第$j$个单元格内容，且读写头**不在**这个单元格，要么是$s_{i,j}\'$，表示第$i$个磁带上第$j$个单元格内容，且读写头**在**这个单元格。\n\n$\\mathbb M_\\alpha$的一步计算，我们会扫描主工作带，找出每条带的读写头位置，据此查表（第二条带），得到迁移函数下一步会怎么做。\n\n再扫描一遍带，在对应带区间写入修改的符号，然后在每个带区段内移动带头标记。\n\n最坏情况下的一步计算，如果某段头已经在最左格了，再往左移动（记得证明开始的设定）。\n\n此时一种做法是把该段左边的所有段都向左移动一格，这个操作会移动$O(T(|x|))$个符号。\n\n所以在最坏情况下，$\\mathbb U$模拟$\\mathbb M_\\alpha$所需的时间为$O(T(|x|)^2)$。\n\n---\n\n但是我们可以采取一种独到的数据结构模拟：\n\n我们将$\\mathbb U$分块，具体来说是从中心向左右扩散，块的大小依次为$1,2,4,\\dots,2^{\\log(T(n))}$，中心区间只包含地址是$0$的那个格子。形如：\n$$\n\\dots L_2L_1L_00R_0R_1R_2\\dots\\\\\n|L_i|=|R_i|=2^{i+1}\n$$\n块中引入缓冲符号$\\times$，我们希望$\\times$尽量均匀地分布在主工作带上，这样可以通过覆盖$\\times$进行小范围的移动，避免涉及到整层。\n\n为了让缓冲符号均匀分布，我们要保证以下三守恒：\n\n1. 每一个区间要么是满的（区间里面全是有效符号），要么是空的（区间里全是$\\times$ ），要么是半满的（区间里恰有一半是$\\times$ ）；\n2. 区间$L_i$和$R_i$的有效符号之和恒为$2^{i+1}$个。也就是说，要么$L_i$满$R_i$空，要么$L_i$空$R_i$满，要么$L_i$和$R_i$都是半满；\n3. $0$号位永不是$\\times$。\n\n初始化时，可以视所有$R$区间均是满的，而所有$L$区间均是空的。\n\n在模拟$\\mathbb M_\\alpha$的带头移动时，不妨考虑这层上的内容左移一格，右半边如下操作：\n\n1. 把$0$号位的值挪到第二条带上；\n2. 向右扫描，直到遇见第一个不为空的区间$R_i$（半满或满），把该区间的从左向右$2^i$个有效值挪到第二条带上；\n3. 返回$0$号位，并在$0$号位，$R_0,R_1,\\dots,R_{i-1}$， 这些区间中分别按顺序写入$1,1,2,\\dots,2^{i-1}$个来自于$R_i$区间的值。\n\n最后区间$R_0,R_1,\\dots,R_{i-1}$都由空变为了半满，而区间$R_i$少了一半。\n\n接下来左半边的操作：\n\n1. 把区间$L_{i-1},\\dots,L_0$所有的值挪到第二条带上。它们一定是满的；\n2. 在区间$L_i,\\dots,L_1$按顺序分别写入上一步中的$2^i，2^{i-1},\\dots,2$个值；\n3. 在区间$L_0$写入$0$号位原始的值。\n\n最后区间$L_{i-1},\\dots,L_0$都由满变为了半满，而区间$L_i$增加了一半。\n\n至于右移的情况，镜像即可。\n\n我们考虑最坏的情况：一次带子的左移涉及到了$R_i$ ，此后$R_0$至$R_{i-1}$都为半满，带子继续一个劲地左移，要移动$1+2+4+\\dots+2^{i-1}=2^i-1$次清空$R_0$至$R_{i-1}$的所有内容，再下一次左移才会再次涉及到$R_i$。也就是说，两次涉及到区间$R_i$的移动的间隔至少为$2^i$。\n\n带子的移动至多为$T$次，那么对区间$R_i$的操作不超过$\\frac{T}{2^i}$次。最远对区间$R_i$进行操作时，$\\mathbb U$需要扫描$L_i$至$R_i$的范围常数次，耗时$O(|\\alpha|^c 2^i)$。而$i\\in[1,\\log(T(n))]$，那么$\\mathbb U$的计算时间是\n$$\nO(\\sum_{i=1}^{\\log T(n)}\\frac{T(n)}{2^i}|\\alpha|^c2^i)=O(|\\alpha|^cT(n)\\log T(n)).\n$$\n\n---\n\n接下来引入一个概念，若一台图灵机在任意时刻读写头的位置不依赖于输入的内容，而只依赖于输入的长度和该时刻已经进行的计算步数，称其为**健忘图灵机**。\n\n> [!NOTE]\n>\n> **推论1.1**：设$T(n)$是时间可构造的，$L$可在$T(n)$时间内被一台图灵机判定。一定存在常数$C$和在$CT(n)\\log T(n)$时间内判定$L$的健忘图灵机。\n\n很容易构造一种$CT(n)^2$判定$L$的健忘图灵机：读写头反复顺序扫描带子，每次寻找下一个数据最多花费$O(T(n))$的时间。\n\n一种不严格的$CT(n)\\log T(n)$的构造是：将带子按$2^0,2^1,2^2,\\dots,2^n$分块，想象一个二进制自增计数器，我们每次扫描都会访问$2^0$分块，每$2$次访问$2^1$分块，每$4$次访问$2^2$分块，$\\dots$，每$2^n$次访问$2^n$分块。\n\n每次取到需要的数据，就把它往较小一层的分块的一个数据交换位置。\n$$\nT\'=\\sum_{i=0}^{L}(2^i块被扫描次数\\times 单次扫描时间开销)=\\sum_{i=0}^{L}(\\frac{T(n)}{2^i}\\times2^i)=T(n)L\n$$\n因为$T(n)$最多用到$T(n)$个格子，所以我们开的块不需要太多，只需要\n$$\nL=O(\\log(T(n)))\n$$\n\n$$\nT\'=O(T(n)\\log T(n))\n$$\n\n> [!NOTE]\n>\n> **推论1.2**：设$f\\in\\textbf{TIME}(T(n))$。有一台双读写带图灵机在$O(T(n)\\log T(n))$时间内计算$f$。有一台单独写带的图灵机在$O(T(n)^2)$时间内计算$f$。\n\n将$\\mathbb U$的输入带和主工作带合二为一。如果只有一条读写带，数据移动需要$O(T(n)^2)$的时间。\n\n## 1.4对角线方法\n\n技术上，对角线方法必须用到通用图灵机。\n\n考虑如下判定问题：\n$$\n\\text{UC}(\\alpha)=\\begin{cases}0,&若\\mathbb M_\\alpha(\\alpha)=1\\\\\\\\1,&若\\mathbb M_\\alpha(\\alpha)\\ne1 (包括\\mathbb M_\\alpha(\\alpha)不会停机)\\end{cases}\n$$\n假定$\\text{UC}$可由$\\mathbb{UC}$判定，就有$\\mathbb{UC}(\\llcorner\\mathbb{UC}\\lrcorner)=0$当且仅当$\\mathbb{UC}(\\llcorner\\mathbb{UC}\\lrcorner)=1$，矛盾。\n\n---\n\n定义函数\n$$\n\\text H(\\alpha,x)=\\begin{cases}1,&若\\mathbb M_\\alpha(x)\\downarrow\\\\\\\\0,&若\\mathbb M_\\alpha(x)\\uparrow\\end{cases}\n$$\n如果$\\text H$是可计算的，那么我们可以判定任一问题对于任意输入是否会停机。\n\n假设$\\mathbb M$可以计算$\\text{H}$，那么对于任意$\\alpha$，都有\n$$\n\\mathbb M(\\alpha,\\alpha)=\\text H(\\alpha,\\alpha)=\\begin{cases}1,&若\\mathbb M_\\alpha(\\alpha)\\downarrow\\\\\\\\0,&若\\mathbb M_\\alpha(\\alpha)\\uparrow\\end{cases}\n$$\n那么存在图灵机$\\mathbb N$可以判定$\\text{UC}$\n$$\n\\mathbb N(\\alpha)=\\begin{cases}0,&若\\mathbb M(\\alpha,\\alpha)=1且\\mathbb M_\\alpha(\\alpha)=1\\\\\\\\1,&\\text{else}\\end{cases}\n$$\n矛盾。\n\n也就是**停机问题**不可判定。\n\n## 1.6加速定理\n\n加速定理说明了**不存在最优的算法**。\n\n加速定理的证明及其推论有点困难，我们只证明**线性加速定理**。\n\n> [!NOTE]\n>\n> **定理1.6（线性加速）**：设图灵机$\\mathbb M$在$T(n)$步内判定$L$。对任意$\\epsilon>0$，存在图灵机$\\mathbb M\'$，$\\mathbb M\'$能在$\\epsilon T(n)+n+2$步内判定$L$。\n\n我们试构造$\\mathbb M\'$：\n\n- $\\mathbb M\'$用$n+2$步将输入转换成长度为$\\frac{n}{m}$的内部符号串（作一个长度为$m$的符号串到长度为$1$的符号串映射），第$i$个内部符号串对应$\\mathbb M$的第$i$个分块。\n- $\\mathbb M\'$用$\\frac{n}{m}$步移动读写头回第$0$格。\n- 模拟$\\mathbb M$的$m$步计算：\n  $\\mathbb M$的$m$步计算只有可能触及块$i$和块$i-1$和块$i+1$，且读写头的最终位置也只可能在块$i$和块$i-1$和块$i+1$。$\\mathbb M\'$，只需要遍历这三个单元格即可，最多的操作数是$5$。\n\n从而$\\mathbb M\'$的计算时间不超过$n+2+\\frac{n}{m}+\\frac{5}{m}T(n)\\le n+2+\\frac{6}{m}T(n)$，令$m=\\frac{6}{\\epsilon}$即可。\n\n当$T(n)$的增长速度严格大于线性函数时，我们有一个更简洁的加速定理：\n\n> [!NOTE]\n>\n> **推论1.3**：设$T(n)=\\omega(n)$，设图灵机$\\mathbb M$在$T(n)$步内判定$L$。对任意$\\epsilon >0$，存在图灵机$\\mathbb M\'$，$\\mathbb M\'$能在$\\epsilon T(n)$步内判定$L$。\n\n## 1.7时间复杂性类\n\n一个**复杂性类**是一个模型无关的问题类。最著名的一个复杂性类是**多项式时间类**，定义如下：\n$$\n\\textbf{P}=\\bigcup_{c\\ge 1}\\textbf{TIME}(n^c)\n$$\n$\\textbf P$的定义不依赖于任何模型。\n\n**指数时间类**：\n$$\n\\textbf{EXP}=\\bigcup_{c\\ge 1}\\textbf{TIME}(2^{n^c})\n$$\n注意我们不能定义为$\\textbf{TIME}(2^{nc})$，如果我们把$\\Theta(2^{nc})$的算法和$\\Theta(n^3)$的算法复合，得到的也是指数算法，但不在$\\textbf{TIME}(2^{nc})$中。\n\n我们用$\\textbf{coT}$表示$\\textbf T$的**补类**，即$\\\\{\\overline{A}|A\\in\\textbf T\\\\}$。\n\n> [!NOTE]\n>\n> **引理1.3**：$\\textbf{coT}\\subseteq\\textbf T$当仅当$\\textbf T\\subseteq\\textbf{coT}$当仅当$\\textbf{coT}=\\textbf T$。\n\n$\\textbf P=\\textbf{coP}$，这是因为$\\textbf P$由确定性图灵机$\\mathbb M$定义，$\\mathbb M$能判定$A$，那么$\\mathbb M\'$只是交换接收状态$q_{acc}$与拒绝状态$q_{rej}$也能判定$\\overline{A}$，由于只改变了结果，判定过程不变，所以两台图灵机判定的问题的时间复杂性相同。\n\n事实上任何由确定性图灵机定义的复杂性类都满足$\\textbf{coT}=\\textbf{T}$。\n\n如果$\\mathbb M$是非确定性图灵机，这个问题会非常有意思。\n\n## 1.8非确定图灵机\n\n一台**非确定图灵机**$\\mathbb N$可以简单地定义为具有两个迁移函数$\\delta_0$，$\\delta_1$，它每时刻毫无章法地选择其中一个迁移函数计算。它常用来解决**存在性问题**。\n\n非确定性图灵机每条计算路径试图构造一个存在性证明，若成功，在输出带上写$1$并停机，该终止格局为**接受格局**；若失败，在输出带上写$1$并停机，该终止格局为**拒绝格局**。\n\n> [!NOTE]\n>\n> **定义1.6**：设$\\mathbb N$为非确定图灵机，当输入$x$时，若$\\mathbb N(x)$有一条计算路径终止于接受格局，称$\\mathbb N$接受$x$，记为$\\mathbb N(x)=1$。若$\\mathbb N(x)$的所有的计算路径都不终止于接受格局，称$\\mathbb N$拒绝$x$，记为$\\mathbb N(x)=0$。\n\n设$L$为一语言，若$x\\in L$当仅当$\\mathbb N(x)=1$，称$\\mathbb N$接受$L$。\n\n设$T:\\mathbb N\\to\\mathbb N$为时间函数。对任意输入$x$，若非确定图灵机$\\mathbb N$的任一计算路径长度都不超过$T(|x|)$，称$T(n)$为$\\mathbb N$的时间函数。设$L\\subseteq\\{0,1\\}^*$。记号$L\\in\\textbf{NTIME}(T(n))$表示存在接受$L$的非确定图灵机$\\mathbb N$和常数$c >0$，$cT(n)$为$\\mathbb N$的时间函数。\n$$\n\\textbf{NP}=\\bigcup_{c\\ge 1}\\textbf{NTIME}(n^c)\\\\\n\\textbf{NEXP}=\\bigcup_{c\\ge 1}\\textbf{NTIME}(2^{n^c})\\\\\n$$\n\n> [!NOTE]\n>\n> **命题1**：$\\textbf P\\subseteq\\textbf{NP}\\subseteq{\\textbf{EXP}}\\subseteq\\textbf{NEXP}$。\n\n第一个蕴含是因为$\\textbf P$可视为解决$\\textbf{NP}$问题的图灵机只使用一个迁移函数的特殊情况。\n\n第二个蕴含是因为解决$\\textbf{EXP}$问题包含不能在多项式时间验证的问题，非确定图灵机对于它们，怎么猜都需要指数时间。\n\n第三个蕴含是和第一个蕴含类似。\n\n非确定图灵机可以有效地被枚举\n$$\n\\mathbb N_0,\\mathbb N_1,\\dots,\\mathbb N_i,\\dots\n$$\n此枚举满足：\n\n- 所有非确定图灵机都出现过。\n- 每个非确定图灵机都出现过无穷多次（为什么？）。\n\n为定义通用非确定图灵机，引入如下定义。\n\n> [!NOTE]\n>\n> **定义1.7**：设$\\mathbb N$为$k$-带（非确定）图灵机，$x$为输入。$\\mathbb N(x)$在第$t$步的**快照**为$k+1$元组\n> $$\n> \\langle q,a_1,\\dots,a_k\\rangle\\in Q\\times\\underbrace{\\Gamma\\times\\dots\\times\\Gamma}_{k}\n> $$\n> 其中，$q$为$t$时刻的机器状态，$a_1,\\dots,a_k$为$t$时刻读写头所指格中的符号。\n\n定义通用非确定图灵机$\\mathbb V$如下：\n\n1. 输入非确定图灵机编码$\\alpha$和$0-1$串$x$。\n2. $\\mathbb V$猜测$\\mathbb N_\\alpha(x)$的一个终止于接受格局的计算路径的快照序列和一个同等长度的$0-1$串，后者表示$\\mathbb N_\\alpha$在计算时做的非确定选择，$0$表示选$\\delta_0$，$1$表示选$\\delta_1$。在猜测快照序列时，$\\mathbb V$只跟踪输入带上的符号而忽略工作带，工作带上的符号通过猜测得到。\n3. 对每一条工作带，$\\mathbb V$验证在猜测阶段对该条工作带上猜测的符号是否正确。$\\mathbb V$使用另一条工作带来记录$\\mathbb N_\\alpha$在该工作带上的实际读写过程。\n4. 若所有验证均成功，$\\mathbb V$停机并接受；若发现错误，$\\mathbb V$停机并拒绝。\n\n$\\mathbb V$的最大优势是它几乎没有额外的时间开销，能在输入图灵机计算时间的一个常数倍里模拟输入图灵机的运行。$\\mathbb V$的缺点是，它不一定终止，没有任何方法阻止它不停猜测。\n\n---\n\n回到**引理1.3**的讨论：\n\n我们不能把证明$\\textbf{P}=\\textbf{coP}$的方法用在$\\textbf{NP}$时间复杂性类上，这是因为：\n\n假设$\\mathbb{M}_{NP}$是一个判定$L \\in \\mathbf{NP}$的$NTM$：\n\n- 如果$w \\in L$，只需一条计算路径在多项式时间内接受。\n- 如果$w \\notin L$，则所有计算路径都必须拒绝（或超时）。\n\n如果我们简单地反转$\\mathbb{M}_{NP}$的接受/拒绝状态得到$\\mathbb{M}\'$：\n\n1. 如果$w \\in L$：$\\mathbb{M}\\\_{NP}$有至少一条接受路径，和很多的拒绝路径。$\\mathbb{M}\'$沿着拒绝路径，会停在原来的$q\\\_{rej}$，但现在被标记为$q\'\\\_{acc}$，所以$\\mathbb{M}\'$接受。\n2. 如果$w \\notin L$：$\\mathbb{M}\\\_{NP}$的所有路径都拒绝。$\\mathbb{M}\'$沿着这些路径，都会停在原来的$q\\\_{rej}$，现在被标记为$q\'\\\_{acc}$。\n\n目前$\\textbf{P}=\\textbf{NP}\\Rightarrow\\textbf{NP}=\\textbf{coNP}$，只是这两个等号都没有确切的证明。\n\n## 1.12时间谱系定理\n\n给定时间函数$f$和$g$，$f\\le g\\Rightarrow\\textbf{TIME}(f(n))\\subseteq\\textbf{TIME}(g(n))$，什么时候这个推论是严格的。\n\n> [!NOTE]\n>\n> **定理1.8（时间谱系定理）**：若$f$和$g$是时间可构造的且$f(n)\\log f(n)=o(g(n))$，则$\\textbf{TIME}(f(n))\\subsetneq\\textbf{TIME}(g(n))$。\n\n显然$\\textbf{TIME}f(n)\\subset\\textbf{TIME}(g(n))$。\n\n我们关心的是$\\textbf{TIME}(g(n))\\nsubseteq\\textbf{TIME}(f(n))$。设$L$由如下定义的图灵机$\\mathbb D$判定：\n\n- 当输入$x$时，让$\\mathbb U(x,x)$计算$g(|x|)$步；若$\\mathbb U(x,x)$在$g(|x|)$步内完成模拟，输出$\\mathbb M_x(x)$的反转$\\overline{\\mathbb M_x(x)}$，否则输出$0$。\n\n此定义中，让$\\mathbb U(x,x)$计算$g(|x|)$步指的是：\n\n- 将图灵机$\\lambda z.\\mathbb U(z,z)$和$g(n)$-时钟图灵机进行硬连接，得到图灵机$\\mathbb U_g$，然后计算$\\mathbb U_g(x)$。\n\n$L\\in\\textbf{TIME}(g(n))$。假设$L\\in\\textbf{TIME}(f(n))$，且$L$由图灵机$\\mathbb M_z$在$f(n)$时间内判定。因为$f(n)\\log f(n)=o(g(n))$，所以通用图灵机总能在$f(|z|)\\log f(|z|)\\le g(|z|)$时间内模拟完$\\mathbb M_z(z)$的计算。因此：\n\n- $\\mathbb D(z)=\\mathbb M_z(z)$，这是因为$\\mathbb D$和$\\mathbb M_z$都判定语言$L$。\n- $\\mathbb D(z)=\\overline{\\mathbb M_z(z)}$，这是因为$\\mathbb D(z)$完成了对$\\mathbb M_z$的模拟后将其结果反转。\n\n> 这个证明的本质是**定理1.2**，即通用图灵机的极限效率决定了这个严格条件。\n\n利用时间谱系定理，定义如下无穷多个复杂性类，它们构成一个严格包含序列：\n$$\n\\begin{align}\n\\textbf{EXP}&=\\bigcup_{c>1}\\textbf{TIME}(2^{n^c})\\\\\\\\\n\\textbf{2EXP}&=\\bigcup_{c>1}\\textbf{TIME}(2^{2^{n^c}})\\\\\\\\\n\\textbf{3EXP}&=\\bigcup_{c>1}\\textbf{TIME}(2^{2^{2^{n^c}}})\\\\\\\\\n&\\vdots\\\\\\\\\n\\textbf{ELEMENTARY}&=\\textbf{EXP}\\cup\\textbf{2EXP}\\cup\\textbf{3EXP}\\cup\\dots\n\\end{align}\n$$\n$\\textbf{ELEMENTARY}$就是**初等函数类**。书中顺带提到了任何初等函数的增长速度都小于$2^{\\cdot^{\\cdot^{\\cdot^{2^{n}}}}}\\rbrace{n}$，后者叫做**塔函数**。\n\n> [!NOTE]\n>\n> **定理1.9（非确定时间谱系定理）**：若$f$和$g$为时间可构造，且$f(n+1)=o(g(n))$，则$\\textbf{NTIME}(f(n))\\subsetneq\\textbf{NTIME}(g(n))$。\n\n证明：\n\n设一个精致的非确定图灵机$\\mathbb Z$，定义为：\n\n1. $\\mathbb Z$的输入带上的读写头和第一条工作带上的读写头同步全速扫描：\n   - 若输入长度是$1$或包含至少一个$0$，$\\mathbb Z$停机并输出$0$。\n   - 第一条工作带读写头第一格写$1$，大部分时间写$0$，偶尔写$1$，设$h_i(\\text{i start from 0})$为第一条工作带上读写头写$1$的格子地址。\n2. 第二条工作带上$\\mathbb Z$枚举所有**非确定图灵机**和一个固定的$h(n)$-时钟图灵机硬连接，$h(n)=2f(n)$。设枚举为$\\mathbb L_i\\text{(i start from 1)}$。当$\\mathbb Z$枚举完$\\mathbb L_i$，依次做：\n   - 暂停扫描。\n   - 利用第一条工作带上的标记将$1^{h_{i-1}+1}$在第三条工作带上构造出来。（可以在上一次构造基础上额外构造$h_{i-1}-h_{i-2}$个$1$实现）\n   - 将编码$\\mathbb L_{i-1}$从第二条工作带上复制到第三条工作带上。\n   - 将第一条工作带和第二条工作带上的读写头移到暂停之前位置。\n   - 恢复扫描。同时$\\mathbb Z$用暴力法计算$\\mathbb L_{i-1}(1^{h_{i-1}+1})$。计算完成时，结果写在第二条工作带上，第一条工作带上写$1$，这个写$1$的格子地址就是$h_i$。之后，$\\mathbb Z$在第二条工作带上枚举$\\mathbb L_{i+1}$。\n3. 设输入是$1^n$，其中$n>1$。当$\\mathbb Z$扫描完输入：\n   - 若$n=h_i$，$\\mathbb Z$接受$1^n$当且仅当$\\mathbb L_{i-1}(1^{h_{i-1}+1})=0$。\n   - 若$h_{i-1}<n<h_i$，$\\mathbb Z$非确定地让$\\mathbb V(\\mathbb L_{i-1},1^{n+1})$计算$g(n)$步（事实上这里计算$h(n)$步就能确保停机，选择$g(n)$是一种刻意）。\n\n设$\\mathbb Z$接受的语言是$L$：\n\n说明$L\\in\\textbf{NTIME}(g(n))$：\n\n前两步的开销都是线性的，即使有暴力计算$\\mathbb L_{i-1}(1^{h_{i-1}+1})$，由定义，这一步的开销也不会超过$h(n)$。第三步的两种情况的开销分别是$O(1)$和$O(g(n))$。\n\n说明$L\notin\\textbf{NTIME}(f(n))$：\n\n如果$L\\in\\textbf{NTIME}(f(n))$，那么必然存在$\\mathbb N=\\mathbb L_i$在$O(f(n))$时间内接受$L$，不妨挑选一个**足够大**的$k$，使得：\n\n1. $\\mathbb N=\\mathbb{L}_{k-1}$。\n\n2. $\\forall n \\ge h_{k-1},f(n+1)<g(n)$。\n\n   > 因为$f(n+1)=o(g(n))$。\n\n**当$h_{k-1}<n<h_k$时：**\n\n对于这个范围内的$n$：\n\n$$1^n\\in L(即\\mathbb{Z}接受1^n)\\Leftrightarrow\\mathbb{Z}非确定地运行\\mathbb{V}(\\mathbb{L}_{k-1},1^{n+1})并在g(n)步内接受$$\n\n> - 由于$\\mathbb N=\\mathbb{L}_{k-1}$的运行时间是$f(n)$，所以$\\mathbb N$在输入$1^{n+1}$上最多运行$f(n+1)$步就会停机。\n> - 因为$k$足够大，使得$f(n+1)<g(n)$，所以$\\mathbb{Z}$的$g(n)$步模拟必定能正确地计算出$\\mathbb N(1^{n+1})$的最终结果。\n\n因此，对于$h_{k-1} < n < h_k$：\n\n$$1^n \\in L \\Leftrightarrow \\mathbb N(1^{n+1})接受\\Leftrightarrow 1^{n+1} \\in L$$\n\n通过对$n$从$h_{k-1}+1$到$h_k-1$进行归纳，可以得到：\n\n$$1^{h_{k-1}+1} \\in L \\Leftrightarrow 1^{h_{k-1}+2} \\in L \\Leftrightarrow \\dots \\Leftrightarrow 1^{h_k-1} \\in L \\Leftrightarrow 1^{h_k} \\in L$$\n\n由此得出：\n$$\n1^{h_{k-1}+1} \\in L \\Leftrightarrow 1^{h_k} \\in L\n$$\n**当$n = h_k$时：**\n\n$$1^{h\\\_k} \\in L(即\\mathbb{Z}接受1^{h\\\_k})\\Leftrightarrow \\mathbb{L}\\\_{k-1}(1^{h\\\_{k-1}+1}) = 0\\Leftrightarrow 1^{h\\\_{k-1}+1}\\notin L$$\n\n> 第$3$步的第一种操作。\n\n由此得出：\n$$\n1^{h_k} \\in L \\Leftrightarrow 1^{h_{k-1}+1} \\notin L\n$$\n于是得到了矛盾，证明了$L\\notin\\textbf{NTIME}(f(n))$。\n\n这个方法称为**迟对角线方法**。\n\n## 1.13间隙定理\n\n> [!NOTE]\n>\n> **定理1.10（间隙定理）**：设$r(x)\\ge x$为可计算全函数。存在可计算全函数$b(x)$使得等式$\\textbf{TIME}(b(x))=\\textbf{TIME}(r(b(x)))$成立。\n\n间隙定理说明：若不对时间函数做任何限制，即使多花指数级的时间也不可能多解决一个问题（说人话就是复杂性类之间不是连续分布的，而是存在**停滞区间**；在这些间隙里，增加时间或空间上限**不会增加可计算的语言集合**）。\n\n这个咱们就不证了。\n\n## 1.14神谕图灵机\n\n一台**神谕图灵机**$\\mathbb M^?$有一条额外的读写带，称为**神谕带**，以及三个额外的状态$q_{query},q_{yes},q_{no}$。一个**神谕**$B$是一个判定问题，即$\\{0,1\\}^*$的一个子集。用$\\mathbb M^B$表示连接了神谕$B$的神谕图灵机$\\mathbb M^?$。$\\mathbb M^?$计算输入$x$时，当在$q_{query}$状态，若神谕带上的字符串$z\\in B$，进入状态$q_{yes}$，否则进入状态$q_{no}$。\n\n$\\textbf P^O$是带神谕$O$的具有多项式时间函数的神谕图灵机可判定的问题类。\n\n$\\textbf{NP}^O$是带神谕$O$的具有多项式时间非确定神谕图灵机可接受的问题类。\n\n$\\textbf{NP}^{O[k]}$代表$\\textbf{NP}^O$的一个子类。一个在$\\textbf{NP}^O$中的问题$L$也在$\\textbf {NP}^{O[k]}$中当且仅当存在多项式时间非确定神谕图灵机$\\mathbb M^?$，$\\mathbb M^O$接受$L$且$\\mathbb M^O$的每次运行过程中问$O$问题的次数不超过$k$。\n\n如果神谕$A$是多项式时间可判定问题，显然$\\textbf P^A=\\textbf P$，因为多项式时间内只能调用多项式次神谕，问题的大小也是多项式的，总时间仍然是多项式的。\n$$\n\\textbf{NP}^\\textbf{NP}=\\bigcup_{A\\in\\textbf{NP}}\\textbf{NP}^A\n$$\n$\\textbf{NP}^\\textbf{NP}=\\textbf{NP}^{SAT}$因为所有$NP$语言的问题都可以在多项式时间内转换成问$SAT$的问题。\n\n$\\textbf{EXP}^\\textbf{EXP}=2-\\textbf{EXP}$。\n\n> [!NOTE]\n>\n> **定义1.14**：若$\\textbf{A}^\\textbf{B}=\\textbf A$，称复杂性类$\\textbf B$对复杂性类$\\textbf A$是低的。\n\n## 1.15归约\n\n> [!note]\n>\n> **定义1.15**：可计算全函数$f:\\\\{0,1\\\\}^\\*\\to\\\\{0,1\\\\}^\\*$是从问题$A$到问题$B$的**m-归约**，记为$A\\le_mB$，若满足：对任意$0-1$串$x$，$x\\in A$当且仅当$f(x)\\in B$.\n\n$A\\le_mB$可理解为“$A$至少与$B$一样容易或至少一样难”。回想1.4节，我们其实做了一个**将不可判定的问题归约到另一个问题而推出另一个问题不可判定的事儿**。\n\n> [!note]\n>\n> **定义1.16**：设$A$和$B$为判定问题。若存在神谕图灵机$\\mathbb M^?$使得$\\mathbb M^B$判定$A$，称$A$**图灵归约**到$B$，记为$A\\le_TB$。\n\n> [!note]\n>\n> **定义1.17**：若从$A$到$B$有一个多项式时间可计算的$m$-归约函数，称$A$可**卡普归约**到$B$，记为$A\\le_KB$。\n\n> [!note]\n>\n> **定义1.18**：若$A\\in\\textbf{P}^B$，称$A$可**库克归约**到$B$，记为$A\\le_CB$。\n\n显然$A\\le_CB\\Leftrightarrow A\\le_C\\overline{B}$，翻转判定结果就好了。\n\n> [!note]\n>\n> **命题3**：若$A\\le_KB\\le_KC$，则$A\\le_KC$。若$A\\le_CB\\le_CC$，则$A\\le_CC$。\n\n第一个很好证明，因为多项式函数的嵌套当然是多项式的。\n\n第二个我们有$A\\in\\textbf P^B$，$B\\in\\textbf P^C$，因为$B$在多项式图灵机$\\mathbb M$调用神谕$C$可以判定的问题里，后者自然可以拿来判定$A$。\n\n> [!note]\n>\n> **引理1.5**：$SAT\\le_K3SAT$。\n\n把语句分成若干个析取式$x_1\\lor x_2\\lor\\dots\\lor x_k$，把它扩展为\n$$\n(x_1\\lor x_2\\lor y_1)\\land(\\neg y_1\\lor x_3\\lor\\neg y_2)\\land\\dots\\land(\\neg y_{k-1}\\lor x_{k-1}\\lor x_k)\n$$\n这样当存在$x_i$为真，总存在一种$y_i$构造使得这个表达式为真；当不存在$x_i$为真，相邻和取式不同时为真。\n\n> [!note]\n>\n> **命题4**：$3SAT\\le_KIS$。\n\n对于每个语句$(x\\lor y\\lor z)$，构造一个含7个结点的团，它们是\n$$\n(\\neg x\\land y\\land z),(x\\land \\neg y\\land z),(x\\land y\\land \\neg z),(\\neg x\\land \\neg y\\land z),(\\neg x\\land y\\land \\neg z),(x\\land \\neg y\\land \\neg z),(\\neg x\\land \\neg y\\land \\neg z)\n$$\n不同团的两结点有边相连当且仅当它们存在冲突。\n\n## 1.16空间复杂性类\n\n设$S:\\mathbb N\\to\\mathbb N$，且$L\\subseteq\\\\{0,1\\\\}^\\*$。若有常数$c$和判定语言$L$的图灵机$\\mathbb M$，当输入$x$时，$\\mathbb M(x)$计算时使用的**工作带**上的格子数不会超过$cS(n)$，那么$L\\in\\textbf{SPACE}(S(n))$。称$S(n)$为$\\mathbb M$的**空间函数**。\n\n我们规定$S(n)\\ge\\log n$。\n\n> 如果$\\mathbb M$从输入带最左端走到最右端，若配置总数$N_{conf}=2^{O(S(n))}<n+1$，则必存在两个不同的位置$i<j$使得机器在到达$i$时与到达$j$时的全局配置相同。从此可构造循环（重复）——机器无法区分后续输入段，从而不能决定依赖于后面输入内容的语言。\n\n> [!NOTE]\n>\n> **定义1.19**：若有图灵机在$O(S(n))$空间内计算函数$1^n\\mapsto\\llcorner S(n)\\lrcorner$，称$S(n)$是**空间可构造的**。\n\n> [!NOTE]\n>\n> **定义1.20**：若有图灵机当输入为$1^n$时准确地使用了工作带上的$S(n)$格后停机，称$S(n)$是**完全空间可构造的**。\n\n给定图灵机$\\mathbb M$和输入$x$，**格局图**$G_{\\mathbb M,x}$的结点是$\\mathbb M(x)$的格局。假定只有唯一的接受格局（$q_{start}$，读写头位置均为$0$，除最后一条工作带上输出$1$，其余均为空）。$C_{start}$表示起始格局，$C_{accept}$表示接受格局。$\\mathbb M$接受$x\\Leftrightarrow$在$G_{\\mathbb M,x}$中有一条从$C_{start}$到$C_{accept}$的路径。$\\mathbb M$接受$x$变成了**可达性问题**。\n\n设$\\mathbb M$的空间函数$S(n)$，状态的编码长度是常数，带子上的内容长度是$O(S(n))$，读写头位置的编码长度是$O(\\log S(n))$。所以格局图$G_{\\mathbb M,x}$的结点大小为$O(S(n))$，结点个数不会超过$2^{O(S(n))}$（为什么？）。\n\n> 根据定义，工作带上使用的格子数不超过$c\\cdot S(n)$。\n>\n> $\\mathbb M$的状态数为$|Q|$。\n>\n> 设工作带的字母表为$\\Gamma$。\n>\n> $k-1$条工作带的总内容组合数是$|\\Gamma|^{(k-1) \\cdot c \\cdot S(n)}= 2^{\\log_2(|\\Gamma|)\\cdot (k-1)\\cdot c\\cdot S(n))} = 2^{O(S(n))}$。\n>\n> 读写头可能的位置组合不超过$(S(n)+1)^{k-1}\\cdot n=O(n\\cdot S(n))$。\n\n---\n\n若有常数$c$和接受$L$的非确定图灵机$\\mathbb N$，无论选择哪条计算路径，$\\mathbb N$所有的工作带上的格子数不超过$cS(n)$，那么$L\\in\\textbf{NSPACE}(S(n))$。\n\n定义几个常用的空间复杂性类及它们的非确定版本：\n$$\n\\begin{align}\n\\textbf{L}&\\stackrel{\\text{def}}{=}\\textbf{SPACE}(\\log(n))\\\\\\\\\n\\textbf{NL}&\\stackrel{\\text{def}}{=}\\textbf{NSPACE}(\\log(n))\\\\\\\\\n\\textbf{PSPACE}&\\stackrel{\\text{def}}{=}\\bigcup_{c>0}\\textbf{SPACE}(n^c)\\\\\\\\\n\\textbf{NPSPACE}&\\stackrel{\\text{def}}{=}\\bigcup_{c>0}\\textbf{NSPACE}(n^c)\\\\\\\\\n\\end{align}\n$$\n以一个例子理解对数空间复杂度，定义$\\textbf L$中的一个问题：\n$$\n\\text{MULP}\\stackrel{\\text{def}}{=}\\{(a,b,c)|a,b,c为二进制数,且a\\cdot b=c\\}\n$$\n用小学乘法就可以在对数空间判定$\\text{MULP}$，只需要大小$|a|+|b|-1$的计数器记录在处理$a\\cdot b$的哪一位，大小为$|c|+1$的计数器，用来存储进位。\n\n> [!NOTE]\n>\n> **定理1.11（空间压缩定理）**：设图灵机$\\mathbb M$在$S(n)$空间判定$L$。对任意$\\epsilon>0$，存在图灵机$\\mathbb M\'$，$\\mathbb M\'$能在$\\epsilon S(n)+1$空间内判定$L$。\n\n这个定理的证明和**线性加速定理**类似，参考第三周作业。\n\n> [!note]\n>\n> **定义1.19**：若有图灵机在$O(S(n))$空间内计算函数$1^n\\mapsto\\llcorner S(n)\\lrcorner$，称$S(n)$是**空间可构造的**。\n\n> [!note]\n>\n> **定义1.20**：若有图灵机当输入为$1^n$时准确地使用了工作带上的$S(n)$格后停机，称$S(n)$是**完全空间可构造的**。\n\n这两个定义是等价的。\n\n先说明$定义1.20\\subseteq定义1.19$：\n\n设$\\mathbb M$在输入$1^n$上使用了$S(n)$格后停机，我们在这些区域内把$1^{S(n)}$转换成$\\llcorner S(n)\\lrcorner$，因为$\\log S(n)<S(n)$，这一定能做到。\n\n再说明$定义1.19\\subseteq定义1.20$：\n\n有一台空间复杂性是$\\epsilon S(n)+1$的图灵机计算$\\llcorner S(n)\\lrcorner$。假设$|\\llcorner S(n)\\lrcorner|+\\epsilon S(n)+1\\le S(n)$，那么我们可以用此图灵机通过连续减一操作准确地标注工作带上$S(n)$个格子。技术上机器每向右移动一格，就把带子上的数字减$1$，当数字减到$0$时，机器正好移动了$S(n)$步，也就准确使用了$S(n)$格。\n\n> [!note]\n>\n> **引理1.6**：对任意格局$C$和$C\'$，$\\varphi_{\\mathbb M,x}(C,C\')=1$当且仅当从格局$C$可一步到达格局$C\'$。表达式$\\varphi_{\\mathbb M,x}(C,C\')$的求值可在$O(|\\varphi_{\\mathbb M,x}|)$时间和对数空间完成。\n\n公式$\\varphi$本质上是在检查$C$和$C\'$是否满足迁移函数$\\delta$的约束，只需要对$C$和$C\'$扫描一遍，用对数空间存储当前扫描的位置，因为一个格局的长度为$O(S(n))$，可以用$\\log S(n)$空间表示扫描到格局的第几位。\n\n> [!NOTE]\n>\n> **命题5**：设$S(n):\\mathbb N\\to\\mathbb N$为空间可构造。有下述包含关系：\n> $$\n> \\textbf{TIME}(S(n))\\subseteq\\textbf{SPACE}(S(n))\\subseteq\\textbf{NSPACE}(S(n))\\subseteq\\textbf{TIME}(2^{O(S(n))})\n> $$\n\n这是因为：\n\n- 图灵机在$S(n)$时间内最多访问$S(n)$格。\n- 确定图灵机是非确定图灵机的特例。\n- 格局图结点个数不超过$2^{O(S(n))}$，相应时间内能构造出格局图。\n\n$\\textbf{NP}\\subseteq\\textbf{PSPACE}$，因为非确定图灵机每条路径可以在多项式完成，不同于时间，空间可以重复使用。\n\n> [!NOTE]\n>\n> **定理1.12（通用图灵机，空间版本）**：存在通用图灵机，当输入空间函数为$S(n)$的图灵机$\\mathbb M$和串$x$，通用图灵机在$cS(|x|)$空间内完成$\\mathbb M(x)$的计算，其中$c$依赖于$\\mathbb M$但不依赖于输入$x$。\n\n因为通用图灵机只需要三条工作带：\n\n- 一条用于记录$\\mathbb M$的工作带内容。\n- 一条实现计数器，记录读写头地址。\n- 一条用于记录当前状态。\n\n所用的空间为$O(S(n)+\\log(S(n))+\\log|Q|)$。\n\n> [!NOTE]\n>\n> **定理1.13（空间谱系定理）**：设空间函数$f,g$为空间可构造，且$f(n)=o(g(n))$。包含关系$\\textbf{SPACE}(f(n))\\subseteq\\textbf{SPACE}(g(n))$是严格的。\n\n证明与**时间谱系定理**类似，本质是**定理1.12**。\n\n构造一个特殊的对角化图灵机$\\mathbb{D}$在$g(n)$空间内模拟$\\mathbb{M}_w$在输入$w$上的运行：\n\n如果$\\mathbb{M}_w$在运行过程中试图使用超过$g(n)$的空间，或者$\\mathbb M_w$步数太长以至于超过$2^{O(g(n))}$，那么$\\mathbb M_w$一定进入了一个死循环而无法停机，$\\mathbb{D}$直接停机并拒绝。\n\n否则如果$\\mathbb{M}_w$接受$w$，那么$\\mathbb{D}$拒绝$w$，反之接受$w$。\n\n显然$\\mathbb{D}$定义的语言$L \\in \\textbf{SPACE}(g(n))$。\n\n假设存在某个在$f(n)$空间运行的机器$\\mathbb{M}_x$判定了$L$，当输入$x$时，$\\mathbb{D}$会模拟$\\mathbb{M}_x(x)$并给出相反的答案。由于$f(n)=o(g(n))$，对于足够大的$n$，$\\mathbb{D}$肯定有足够的空间完成这个模拟并反转结果。\n\n产生了矛盾，说明没有任何$f(n)$空间的机器能解决$\\mathbb{D}$解决的问题。\n\n## 1.17对数空间类\n\n对时间复杂性而言，最小资源类是$\\textbf P$。对空间复杂性而言，最小资源类是$\\textbf L$。\n\n引入一个比较问题的空间复杂性的方法：我们需要满足如下性质的**归约**：若$C$在空间复杂性类$\\textbf K$中并且$B$可归约到$C$，则$B$也在$\\textbf K$中。为此引入下述定义：\n\n> [!NOTE]\n>\n> **定义1.21**：若下述条件满足，称$f:\\\\{0,1\\\\}^\\*\\to\\\\{0,1\\\\}^\\*$为**隐式对数空间可计算**：\n>\n> 1. $\\exists c.\\forall x.|f(x)|\\le c|x|^c$。\n> 2. $\\{\\langle x,i\\rangle|i\\le|f(x)|\\}\\in\\textbf L$。\n> 3. $\\{\\langle x,i\\rangle|f(x)_i=1\\}\\in\\textbf L$。\n\n在输入$x$后，隐式对数空间可计算函数$f$的输出长度有个多项式的界，这就是**条件一**。\n\n> 如果输出长度是指数级的（例如$2^n$），那么要表示输出结果的下标就需要$O(n)$的空间。\n\n如果我们能判定$i \\le |f(x)|$，我们就可以通过对$i$进行二分查找（在$0$到$c|x|^c$之间），精确地找到$|f(x)|$的值，这就是**条件二**。\n\n给定输入$x$和下标$i$，我们要能在对数空间内计算出$f(x)$的第$i$个比特是$0$还是$1$，这就是**条件三**。\n\n> [!NOTE]\n>\n> **定义1.22**：问题$B$可**对数空间归约**到问题$C$，记为$B\\le_L C$，若存在隐式对数空间可计算的从$B$到$C$的归约。\n\n若$B\\le_LC$，我们可推出结论说$B$的空间复杂性不超过$C$的空间复杂性或$C$的空间复杂性至少与$B$的空间复杂性一样，那么对数空间归约应当是传递的。\n\n> [!NOTE]\n>\n> **引理1.7**：若$B\\le_LC$和$C\\le_LD$，则有$B\\le_LD$。\n\n设$f:B\\to C$和$g:C\\to D$为隐式对数空间可计算函数。从$B$到$D$的隐式对数空间可计算函数定义为：输入$x$，计算$f(x)$，再计算$g(f(x))$。\n\n依赖**定义1.21**：\n\n如果$\\mathbb{M}_1$计算 $f(x)$，$\\mathbb{M}_2$计算 $g(y)$。\n\n在对数空间下，不能简单地先运行$\\mathbb{M}_1$把$f(x)$写满输出带，再让$\\mathbb{M}_2$读。因为$f(x)$的长度可能是多项式级的。\n\n隐式计算的解决方案是把$f(x)$当作一个虚拟输入。\n\n- 当$\\mathbb{M}_2$需要读$f(x)$的第$i$位时，它暂停，调用$\\mathbb{M}_1$的“按位计算”子程序（**条件三**）。\n- $\\mathbb{M}_1$算完第$i$位后把结果（$0$或$1$）传回给$\\mathbb{M}_2$。\n- 这样，我们就不需要存储完整的$f(x)$，从而保证了整个复合过程仍然在对数空间$\\mathbf{L}$内。\n\n---\n\n对数归约可用另一类更直观的函数定义。函数$f:\\\\{0,1\\\\}^\\*\\to\\\\{0,1\\\\}^\\*$是**对数空间可计算**当且仅当有一台图灵机计算$f$时使用了工作带上对数个格子，并且这台图灵机除了工作带之外，还有一条**只写输出带**，这条带被写入$f(x)$，读写头每写一次，向右移一格。\n\n> 如果函数$f$是对数空间可计算的，且$\\forall x\\in A\\Leftrightarrow f(x)\\in B$，就说语言$A$可以对数空间归约到语言$B$。\n\n> [!NOTE]\n>\n> **引理1.8**：隐式对数空间可计算函数就是对数空间可计算函数。\n\n1. 对数空间可计算$\\to$隐式对数空间可计算：\n\n如果函数$f$可以被$\\mathbb{M}$计算出来，那么：\n\n- 因为$\\mathbb M$只用了对数格子，所以$\\mathbb M$运行时间为多项式$T(n)$，所以输出长度$|f(x)| \\le T(n)$，满足**条件一**。\n- 给$\\mathbb M$分配$g(n)$的空间，检查$\\mathbb M$会不会产生重复格局（或者说不得不用超过$g(n)$的空间），如果是，则令$g(n)$增加$1$。否则，我们找到了$|f(x)|$。满足**条件二**。\n- 要计算$f(x)$的第$i$位，我们只需让$\\mathbb{M}\'$模拟$\\mathbb{M}$的完整计算过程。$\\mathbb{M}\'$在模拟过程中，只需维护一个对数空间的计数器，在计算到第$i$位时，将该位的值作为自己的接受/拒绝结果。整个模拟过程的额外工作空间仍然是$O(\\log n)$，满足**条件三**。\n\n2. 隐式对数空间可计算$\\to$对数空间可计算：\n\n构造$\\mathbb{M}$来输出整个$f(x)$：\n\n- $\\mathbb M$用对数空间确定$|f(x)|$，这是因为二分查找$|f(x)|$只需要对数次，每次只会用到一组上下界。\n- 再使用$O(\\log n)$工作空间来存储一个计数器$i$，$i$从$1$迭代到$|f(x)|$，在每次迭代中，$\\mathbb{M}$当然可以用对数空间确定$f(x)_i$的值，虽说要确定$|f(x)|$次，但是空间可以复用。\n- 接着每次迭代完，$\\mathbb{M}$将得到的值写入只写输出带。\n\n---\n\n若对所有$A\\in\\textbf L$有$A\\le_LA\'$，称$A\'$是**$L$-难的**。若$A\'\\in\\textbf L$是$L$-难的，称$A\'$是$L$-完全的。\n\n非确定对数空间类$\\textbf{NL}$有个标准的完全问题：\n$$\n\\text{Reachability}=\\{\\langle G,s,t\\rangle|有向图G中从s到t有一条路径\\}\n$$\n\n> [!NOTE]\n>\n> **定理1.14（可达性问题的复杂性）**：Reachability是$NL$-完全的。\n\n设输入图有$n$个结点。从$s$出发，从当前结点$v$猜测一个邻居然后释放$v$所占用的空间，重复$n-1$次，看是否到达$t$。结点的长度是对数的，控制猜测次数（路径长度）的计数器也是对数的，所以Reachability在$\\textbf{NL}$中。\n\n> 编码$n$个结点需要$\\log n$位。\n>\n> 1.16中提到结点个数不会超过$2^{O(S(n))}$，因此$T(n)\\le \\text{结点个数}\\le 2^{O(S(n))}$。\n>\n> 对于$\\mathbf{NL}$类（对数空间$S(n) = O(\\log n)$）。\n>\n> 所以$T(n)\\le O(n)$，记录步数的计数器就是对数的。\n\n设非确定图灵机$\\mathbb N$在对数空间判定$L$。从$L$到Reachability的对数空间归约定义如下：\n$$\nx\\mapsto\\langle G_{\\mathbb N,x},C_{\\text{start}},C_{\\text{accept}}\\rangle\n$$\n格局图$G_{\\mathbb N,x}$可用邻接矩阵表示，矩阵的每个元素可在对数空间计算出（见引理1.6）。$C_{\\text{start}}$和$C_{\\text{accept}}$是固定的0-1串。因此上述归约是一个对数空间归约。\n\n> [!NOTE]\n>\n> **推论1.4**：有向无环图的可达性问题是$NL$-完全的。\n\n可以用下面的归约证明它是$NL$-完全的：\n\n设有向图$G=(V,E)$，结点数为$n$，构造一个新的图$G\'$：\n\n把$G$的每个结点$v$复制$n$份，标记为$(v, 0), (v, 1), \\dots, (v, n-1)$，这里的第二个参数代表在第多少步到达$v$，所以$G\'$的结点集是$V \\times \\\\{0, \\dots, n-1\\\\}$。\n\n如果在原图$G$中有一条边$u \\to v$，那么在$G\'$中，添加$(u, i) \\to (v, i+1)$，技术上：\n\n单个结点的某一位可以用对数空间读取到，枚举所有$u$和$v$，枚举第多少个结点也可以用对数空间做到。就可以用对数空间判定$u$和$v$是否存在边$u\\to v$。\n\n显然这样构造的$G\'$是$DAG$。\n\n因为结点的长度依然是$n$，路径则是$n^2$，好在$\\log n^2=2\\log n$，计数器仍然是$O(\\log n)$的空间，所以这个归约得到一个$n^2$个结点的$\\text{Reachability}$。\n\n## 1.18多项式空间类\n\n多项式空间类（$\\textbf{PSPACE}$）是一个非常大的类，它的难问题是对人类计算能力的极限挑战，人类发明的智力对抗游戏都在这个类里。\n\n> [!CAUTION]\n>\n> 我们已经无奈地接受了一个事实，在这类博弈中，人类是玩不过多项式空间图灵机的。\n\n我们提及一下跳过的QBF问题。\n\n> [!NOTE]\n>\n> **定义1.13**：问题QBF定义为所有永真的量化布尔公式的集合。\n\n一个QBF具有如下形式：\n$$\n\\text{QBF} = Q_1 x_1 Q_2 x_2 \\dots Q_n x_n \\cdot \\varphi(x_1, x_2, \\dots, x_n)\n$$\n\n- $Q_i$是量词，可以是$\\exists$或$\\forall$。\n- $x_i$是布尔变量。\n- $\\varphi$是一个没有量词的布尔公式。\n\n> [!NOTE]\n>\n> **引理1.9**：QBF可在线性空间判定。\n\n这很简单，爆搜就可以了：用线性空间存储爆搜$x_i$的结果，用线性空间计算$\\varphi$。\n\n事实上*Samuel Buss*找到一种算法可以把$\\varphi$对数空间转化为递归深度只有$O(\\log n)$的方法，从而可以用对数空间计算$\\varphi$。\n\n> [!NOTE]\n>\n> **定理1.15（斯托克迈尔-梅耶定理）**：QBF是$\\textbf{PSPACE}$-完全的。\n\n根据上一条引理，只需证明QBF是$\\textbf{PSPACE}-$难的。\n\n设$\\mathbb M$在$S(|x|)$空间判定$L,x\\in\\{0,1\\}^*$。目的是将格局图$G_{\\mathbb M,x}$中一条从$C_{\\text{start}}$到$C_{\\text{accept}}$的路径用量化布尔公式表示。\n\n定义$\\psi_i(C\',C\'\')$为真当且仅当从格局$C\'$到格局$C\'\'$有一条长度不超过$2^i$的路径。\n\n$$\n\\psi_{i+1}(C\', C\'\') = \\exists C \\forall X \\forall Y \\Big[ \\big( (X=C\' \\land Y=C) \\lor (X=C \\land Y=C\'\') \\big) \\to \\psi_i(X, Y) \\Big]\n$$\n$\\psi_0(C,C\')$定义为两格局一步可达。\n\n依赖上式，有\n$$\n|\\psi_{i+1}|=|\\psi_i|+O(S(|x|))\n$$\n\n> 新引入的部分包括：\n>\n> 1. $\\exists C, \\forall X, \\forall Y$：这就涉及到$3 \\times O(S(n))$个布尔变量。\n> 2. 逻辑判断$(X=C\' \\land Y=C) \\dots$：这也涉及到$O(S(n))$个变量的比较\n\n定义$\\varphi_x$为$\\psi_{S(|x|)}$，则$\\varphi_x$中含有$O(S(n))^2$个变量,$|\\varphi_x|=O(S(n)^2)$。\n\n> 严格来说，考虑到每个变量的下标索引需要$O(\\log S(n))$位来表示，总长度通常写为$O(S(n)^2 \\log S(n))$，但这不影响它是多项式长度的结论。\n\n由上一条引理，我们可以在多项式空间计算$\\varphi_x$。按定义，$\\mathbb M(x)=1$当且仅当$\\varphi_x\\in\\text{QBF}$。\n\n因此我们定义了一个从$L$到$\\text{QBF}$的归约。\n\n要输出$\\varphi_x$，只需记住正在输出哪个$\\psi_i$，只需维护一个长度是$\\log S(|x|)$的计数器。\n\n---\n\n> [!note]\n>\n> **定理1.16（萨维奇定理）：**$\\textbf{NSPACE}(S(n))\\subseteq\\textbf{SPACE}(S(n)^2)$，这里$S(n)$为空间可构造函数。\n\n根据**定理1.14**，我们讨论Reachability：\n\n给定一个非确定性图灵机$\\mathbb{M}$和输入$x$，我们想知道是否存在从起始格局$C_{start}$到接受格局$C_{accept}$的路径。\n\n整个格局图的结点总数最多为$M = 2^{O(S(n))}$。如果存在路径，必存在一条长度不超过$M$的路径。\n\n我们定义一个递归函数$Reach(u,v,k)$，判定是否存在一条从格局$u$到格局$v$的路径，且路径长度不超过$2^k$。\n\n- 如果$u$能在$2^k$步内到达$v$，那么必然存在一个中间格局$w$，使得：\n  1. $u$能在$2^{k-1}$步内到达$w$。\n  2. $w$能在$2^{k-1}$步内到达$v$。\n\n确定性图灵机$\\mathbb D$将执行以下递归过程：\n\n```python\nfunction Reach(u, v, k):    \n    # --- 基准情况 (Base Case) ---\n    if k == 0:\n        # 步数不超过 2^0 = 1，即一步可达或就在原地\n        if (u == v) or (u -> v 是合法的一步):\n            return True\n        else:\n            return False\n\n    # --- 递归步骤 (Recursive Step) ---\n    # 我们需要找到一个中间点 w\n    # 注意：因为我们是确定性机器，我们不能猜 w，\n    # 我们必须遍历所有可能的格局 w\n    \n    For w in All_Possible_Configurations:\n        # 尝试验证：路径前半段存在 AND 路径后半段存在\n        if Reach(u, w, k-1) == True AND Reach(w, v, k-1) == True:\n            return True # 找到了一个有效的中间点，说明路径存在\n            \n    # 遍历完所有可能的 w 都没成功\n    return False\n```\n\n为了判定机器是否接受$x$，我们只需调用：\n$$\n\\text{Reach}(C_{start}, C_{accept}, \\log M)\n$$\n\n\n递归栈的最大深度由初始$k$决定，是$O(S(n))$。\n\n在每一层递归`Reach(u, v, k)`中，需要存储：\n\n1. 参数`u`和`v`：这是两个格局。每个格局需要记录纸带内容，大小是$O(S(n))$。\n2. 局部变量`w`：当前循环枚举到的中间点。也是一个格局，大小是$O(S(n))$。\n3. 参数`k`：用于计数，大小是$O(1)$。\n\n所以，每一层搜索占用的空间是$O(S(n))$。\n\n$$\\text{Total Space} = O(S(n)) \\times O(S(n)) = O(S(n)^2)$$\n\n---\n\n> [!note]\n>\n> **推论1.5**：$\\textbf{PSPACE}=\\textbf{NPSPACE}$。\n\n显然$\\textbf{PSPACE}\\subseteq\\textbf{NPSPACE}$。\n\n根据定义，$\\mathbf{NPSPACE} = \\bigcup_{k \\ge 1} \\mathbf{NSPACE}(n^k)$。\n\n对于任意语言$L \\in \\mathbf{NPSPACE}$，存在某个常数$k$，使得$L \\in \\mathbf{NSPACE}(n^k)$。\n\n根据萨维奇定理：$L \\in \\mathbf{SPACE}((n^k)^2) = \\mathbf{SPACE}(n^{2k})$。\n\n由于$n^{2k}$仍然是一个多项式，因此$L \\in \\mathbf{PSPACE}$。\n\n所以$\\mathbf{NPSPACE} \\subseteq \\mathbf{PSPACE}$。\n\n## 1.19对数空间的补封闭性\n\n$\\textbf{NPSPACE}$在补运算下封闭，根据萨维奇定理：\n$$\n\\begin{align}\n\\textbf{coNPSPACE}&=\\overline{\\textbf{NPSPACE}}\\\\\\\\\n&=\\overline{\\textbf{PSPACE}}\\\\\\\\\n&=\\textbf{PSPACE}\\\\\\\\\n&=\\textbf{NPSPACE}\\\\\\\\\n\\end{align}\n$$\n有一些~~非~~人类证明了$\\textbf{NL}$也在补运算下封闭。\n\n> [!note]\n>\n> **定理1.17（伊默尔曼-斯泽勒普森伊定理）**：$\\overline{\\text{Reachability}}\\in\\textbf{NL}$。\n\n设计一对数空间非确定图灵机，$\\mathbb N((G,s,t))=1$当且仅当从$s$到$t$没有路径。\n\n设$G$有$n$个结点。$\\forall i\\in[n-1]$定义：\n\n- $C_i$为从$s$出发$i$步之内到达的结点集合。这里我们认为不移动也可以是一步，所以显然有$C_1\\subseteq C_2\\subseteq\\dots\\subseteq C_{n-1}$。\n- $c_i=|C_i|$。\n\n每个$c_i$长度是对数的（二进制表示），所以可以把固定数目$c_i$放在工作带上。注意不能是所有，否则空间复杂度要乘上一个$O(n)$。每个$C_i$一般含有线性多个结点，所以不能把$C_i$存放在工作带上。考虑下述非确定算法：\n\n1. 设所有$c_i$为0。\n2. 计算$c_1$。\n3. 对所有$i\\in[n-1]$，从$c_i$计算$c_{i+1}$。当成功计算出$c_{i+1}$后，删掉$c_i$。\n4. 从$c_{n-1}$判定是否$t\\notin C_{n-1}$。\n\n第二步可在对数空间完成，至于第三步：\n\n- 对每个不为$s$的结点$v$，若$v\\in C_i$或从某个$C_i$中的结点$u$到$v$有条边，计数器$c_{i+1}$加$1$。\n\n不能把$C_i$存放在工作带上，那么如何判断$v\\in C_i$呢？\n\n- 我们猜某个元素是否属于$C_i$，对于元素$v$，用Reachability的非确定算法验证即可。因为Reachability是$\\textbf{NL}$完全的，所以这一步仍然是对数空间的。验证通过，对计数器加一。\n\n第四步重复上面操作即可。\n\n> [!note]\n>\n> **推论1.6**：$\\textbf {coNL}=\\textbf{NL}$。\n\n因为Reachability是$\\text{NL}$-完全的，所以$\\overline{\\text{Reachability}}$是$\\text{coNL}$-完全的。又$\\overline{\\text{Reachability}}\\in\\textbf{NL}$，所以$\\textbf{coNL}\\subseteq\\textbf{NL}$。于是$\\textbf{coNL}=\\textbf{NL}$。\n\n> [!note]\n>\n> **推论1.7**：$\\textbf{coNSPACE}(S(n))=\\textbf{NSPACE}(S(n))$，这里$S(n)$为空间可构造的。\n\n这是因为所有在$\\textbf{coNSPACE}(S(n))$的问题都可以用形式一致的$\\textbf{NSPACE}(S(n))$问题排除所有不符的结果来得到剩余相符的结果。\n\n> [!note]\n>\n> **命题6**：$\\text{2SAT}$是$\\text{NL}$-完全的。\n\n这是因为$2\\text{SAT}$可以对数空间归约为有向图不可达问题，具体见作业。' 
                      },
                      { id: 'Introduction to Computational Theory-2', 
                        title: '2、难解性', 
                        desc: '', 
                        content: '\n# 第2章 难解性\n\n~~是的，你甚至能学到第二章。~~\n\n没有人真正理解$\\textbf{NP}$类的内在复杂性和结构，但一个合格的计算机科学家应能大致判断一个问题是否是$\\text{NP}$-难的，就像一个合格的计算机科学家能凭直觉判断一个问题是否可计算。\n\n## 2.1可验证性\n\n> [!note]\n>\n> **定理2.1（高效可验证性）**：语言$L\\subseteq\\\\{0,1\\\\}^\\*$在$\\textbf{NP}$中当且仅当存在多项式$p:\\\\mathbf N \\to\\\\mathbf N$和多项式时间图灵机$\\\\mathbb M$满足：对任意$x\\in\\\\{0,1\\\\}^\\*$，下述等价关系成立：\n> $$\n> x\\in L当且仅当\\exists u\\in\\\\{0,1\\\\}^{p(|x|)}.\\\\mathbb M(x,u)=1\n> $$\n> 称$\\\\mathbb M$为$L$的验证器。若$x$和$u$满足$|u|=p(|x|)$和$\\\\mathbb M(x,u)=1$，称$u$为$x\\in L$的**证书**（或**证明**）。\n\n设非确定图灵机$\\mathbb N$在多项式时间$p(n)$接受$L$。假定对任意输入串$x$，$\\mathbb N(x)$的所有计算路径长度均为$p(|x|)$。用通用图灵机对$\\mathbb N(x)$的计算进行模拟，模拟时需要一长度为$p(|x|)$的0-1串，该串表示$\\mathbb N(x)$对迁移函数的选择。\n\n反之，$\\mathbb M$作为$L$的验证器。一台非确定图灵机可以在多项式时间猜测一个长度为$p(|x|)$的证书$u$，然后计算$\\mathbb M(x,u)$。\n\n---\n\n$\\textbf{NP}$是所有具有**多项式长证明**的问题，$\\textbf P$是所有能在**多项式时间找出证明**的问题。\n\n直觉上$\\textbf P\\subseteq\\textbf{NP}$。\n\n## 2.2NP-完全性\n\n> [!note]\n>\n> **定义2.1**：若对任意$A\\in\\textbf{NP}$，均有$A\\le_K B$，称$B$为$\\text{NP}$-难的。若$B$是$\\text{NP}$-难的且$B\\in\\textbf{NP}$，称$B$是$\\text{NP}$-完全的。\n\n搬运一个对卡普归约的理解：\n\n> 譬如说你想证明某个问题$A$是$\\text{NP}$-hard 的, 那么就假定你有求解这个问题对应的语言$L$的**神谕**。为了证明$\\text{NP-hardness}$，你需要通过查询这个神谕来求解$\\text{NP}$中的任何问题, 而你能用的就是一台确定性多项式时间的机器, 所以现在的问题是你允许怎么查询这个神谕：\n>\n> 如果只能调用神谕一次，这就是**Karp reduction**。\n\n设$\\textbf{NPC}$为所有$\\text{NP}$-完全问题类。解决了$\\textbf{NPC}$里的问题也就解决了所有$\\text{NP}$问题。\n\n若要证明一个问题是$\\text{NP}$-完全的，就需要证明所有$\\text{NP}$问题可以归约到该问题。那么我们要先找出一个$\\text{NP}$-完全问题。\n\n> [!note]\n>\n> **定理2.2（NP-完全问题的存在性）**：TMNP$=\\{\\langle\\alpha,x,1^n,1^t\\rangle|\\exists u\\in\\{0,1\\}^n.\\mathbb M_\\alpha(x,u)在t步内输出1\\}$是$\\text{NP}$-完全的。\n\n- $\\alpha$是验证器$\\mathbb{M}_\\alpha$的编码。\n- $x$是要解决的具体问题实例。\n- $1^n$是证书$u$的最大长度。\n- $1^t$是是验证过程的最大步数。\n\n设$L\\in\\textbf{NP}$有一个多项式$q(n)$时间验证器$\\mathbb M$，证书的长度是多项式值$p(n)$。\n$$\nx\\in L\\Leftrightarrow \\exists u\\in\\{0,1\\}^{p(|x|)}.\\mathbb M(x,u)在q(|x|+p(|x|))步内输出1\\Leftrightarrow\\langle\\llcorner\\mathbb M\\lrcorner,x,1^{p(|x|)},1^{q(|x|+p(|x|))}\\rangle\\in TMNP\n$$\n我们需要的从$L$到$TMNP$的**卡普归约**将输入串$x$映射到四元组$\\langle\\llcorner\\mathbb M\\lrcorner,x,1^{p(|x|)},1^{q(|x|+p(|x|))}\\rangle$，归约时间是多项式的。\n\n> 为什么选择$t=|x|+p(|x|)$？\n>\n> 因为这确保了$t$足够让验证器读完$x$并且读完整个证书$u$。\n>\n> 为什么要选择$1^n$和$1^t$？\n>\n> 因为模拟运行$t$步是多项式时间的，它相对于问题规模的“尺度”决定了时间的“尺度”。例如，如果$n$和$t$用二进制表示，那么问题规模就是对数级的，这时运行$t$步相对是指数级的，该问题就会变成$\\textbf{NEXPTIME}$-完全的。\n>\n> 我们会在后面对这个现象有更深刻的体会。\n\n有了这个证明，就有$L\\in\\textbf{NPC}\\Leftrightarrow TMNP\\le_KL\\in\\textbf{NP}$。\n\n## 2.3库克-莱文定理\n\n> [!note]\n>\n> **定理2.3（库克-莱文定理）**：可满足性问题$SAT$是$\\text{NP}$-完全的。\n\n将判定一个$\\text{NP}$-问题的验证器$\\mathbb M$在输入$x$和证书$u$上的计算$\\mathbb M(x,u)$用布尔公式$\\psi_{\\mathbb M,x}(u,y,z)$表示。\n\n归约是对数空间的，因而是多项式空间的。\n\n其中公式$\\psi_{\\mathbb{M}, x}(u, y, z)$是一个巨大的逻辑判断，它的变量被分为三组，分别代表计算过程的不同要素：\n\n| 变量组 | 含义          | 作用                                                 |\n| ------ | ------------- | ---------------------------------------------------- |\n| $u$    | 证书变量      | 代表证书$u$的每一次迁移函数的选择。                  |\n| $y$    | 时间/位置变量 | 代表计算过程中的时刻和读写头位置。                   |\n| $z$    | 状态/内容变量 | 代表在某一时刻、某一读写头，图灵机的状态和磁带内容。 |\n\n$\\psi$做的就是，用逻辑语言写下**所有规则**，强制要求这些变量$u, y, z$的取值必须共同满足$\\mathbb{M}$的有效计算历史。\n\n具体来说：\n\n取$t=q(|x|+p(|x|))$，构造一个$t\\times t$的表格，第$i$行第$j$列的格子存储时刻$i$位于位置$j$的状态与内容。\n\n定义\n$$\nX_{i,j,k}=\\begin{cases}1,&如果时刻i、位置j的状态或内容是k，则为真\\\\\\\\0,&其它\\end{cases}.\n$$\n构造$\\psi_{\\mathbb M,x}(u,y,z)$是下面四个部分的合取:\n$$\n\\forall a,b\\in\\Gamma,c,d\\in Q,a\\ne b,c\\ne d,\\neg(X_{i,j,a}=1\\land X_{i,j,b}=1\\lor X_{i,j,c}=1\\land X_{i,j,d}=1)\n$$\n\n$$\n(X_{0,1,q_{start}}=1)\\land(\\forall j,X_{0,j,x_j}=1)\\land(\\forall j,X_{0,j,u_{j-|x|}}=1)\n$$\n\n$$\n\\forall i>0,j,((X_{i,j,k}=1\\land X_{i,j,l}=1)\\to(\\exists e,r,\\delta,(X_{i,j,e}=1\\land X_{i,j,r}=1\\land\\delta((e,r))=(k,l))))\n$$\n\n$$\n\\exists i\\le t,j,X_{i,j,q_{halt}}=1\n$$\n\n第一个：每个格子至多有一个状态和内容信息。\n\n第二个：初始时刻一定包含开始状态并包含$x$和$u$。\n\n第三个：初始时刻以外有信息的每个格子都存在上一个时刻某个格子通过迁移函数的转移。\n\n第四个：$t$步内一定会停机。\n\n由于$k$所属的符号集$\\Gamma$和状态集$Q$大小是常数，所以$X_{i,j,k}$的变量数为$O(t^2)$是多项式级的。\n\n而构造表格的过程只需要维护时间、空间、状态和内容的计数器，存储这些计数器只需要$O(\\log(t))=O(\\log(|x|))$空间。\n\n由于对数空间归约($\\textbf{L}$)自动蕴含了多项式时间归约($\\textbf{P}$)，因此这个证明满足了所有$\\mathbf{NP}$-完全性的要求。\n\n所以$L \\le_{\\mathbf{L}} \\text{SAT}$，所以$\\text{SAT}$也是$\\mathbf{NP}$-完全的。\n\n---\n\n设$\\text{Ctf}(x)$为满足$\\mathbb M(x,u)=1$的证书集合，$\\text{Tas}(\\psi_{\\mathbb M,x}(u,y,z))$为满足$\\psi_{\\mathbb M,x}(u,y,z)=1$的证书集合，这里$\\psi_{\\mathbb M,x}(u,y,z)=1$的证书是使$\\psi_{\\mathbb M,x}(u,y,z)=1$为真的真值指派。根据$\\mathbb M(x,u)$计算的唯一性，归约$\\psi_{\\\\mathbb M,\\\\_}$是从$\\text{Ctf}(x)$到$\\text{Tas}(\\\_{\\mathbb M,x}(u,y,z))$的双射，其逆函数也是多项式时间可计算的。称满足这些性质的多项式时间归约为**莱文归约**。\n\n搜索问题之间的归约必须是莱文归约。\n\n我的理解是：$\\textbf{NP}$问题的莱文归约就是把它归约为合取范式的**搜索验证**，即若第一位的真值$0$不符合条件，则第一位赋为$1$，然后枚举第二位的真值...这个真值指派可以莱文归约为原问题的证书。\n\n---\n\n$A\\le_K^1B$表示从$A$到$B$有个**单射**卡普归约。\n\n$A\\cong_pB$表示从$A$到$B$有个**双射**卡普归约，若$A\\cong_pB$，称$A$和$B$为**多项式同构的**。\n\n若从$A$到$B$的卡普归约$r$满足：对任意$x$有$|r(x)|>|x|$，称$r$为**严格增长的**。\n\n若一个卡普归约$f$有一个多项式时间可计算的逆函数$f^{-1}$，称$f$为**可逆的**。\n\n可逆的卡普归约$f$的逆函数也是卡普归约，并且$f$和$f^{-1}$都是单射。\n\n以下是卡普的21个NP-完全问题：\n\n$$\n\\begin{align}\n&\\text{SAT}\\le_K\\text{0-1-IntegerProgramming}\\\\\\\\\n&~~~~~~~~\\le_K\\text{Clique}\\\\\\\\\n&~~~~~~~~~~~~~~~\\le_K\\text{SetPacking}\\\\\\\\\n&~~~~~~~~~~~~~~~\\le_K\\text{VertexCover}\\\\\\\\\n&~~~~~~~~~~~~~~~~~~~~~~\\le_K\\text{SetCovering, FeedbackNodeSet, FeedbackArcSet}\\\\\\\\\n&~~~~~~~~~~~~~~~~~~~~~~\\le_K\\text{DirectedHamiltonCircuit}\\\\\\\\\n&~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\le_K\\text{UndirectedHC}\\\\\\\\\n&~~~~~~~~\\le_K\\text{3SAT}\\\\\\\\\n&~~~~~~~~~~~~~~~\\le_K\\text{ChromaticNumber}\\\\\\\\\n&~~~~~~~~~~~~~~~~~~~~~~\\le_K\\text{CliqueCover}\\\\\\\\\n&~~~~~~~~~~~~~~~~~~~~~~\\le_K\\text{ExactCover}\\\\\\\\\n&~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\le_K\\text{HittingSet, SteinerTree, 3DimMatching}\\\\\\\\\n&~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\le_K\\text{Knapsack}\\\\\\\\\n&~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\le_K\\text{JobSequencing}\\\\\\\\\n&~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\le_K\\text{Partition}\\\\\\\\\n&~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\le_K\\text{MaxCut}\\\\\\\\\n\\end{align}\n$$\n\n> [!note]\n>\n> 它们依次是：\n>\n> - 0-1整数规划。\n> - 判断图中是否存在大小为$k$的完全子图。\n>   - 给定一个有限集合$S$及其子集列表，判定是否存在$k$个两两不相交的子集。\n>   - 给定一个无向图$G=(V,E),|V|=N,|E|=M$，问是否存在一个不超过$K$个点的集合$S$，使得$G$中的每条边都至少有一个点在集合$S$中。\n>     - 给定全集$U$，以及一个集合$S$满足$\\bigcup_{A\\in S}A=U$，找到$B\\subseteq S$满足$\\bigcup_{A\\in B}A=U$。\n>     - 给定一个图$G=(V, E)$，找到一个最小的顶点子集$S \\subseteq V$，当我们从图$G$中移除$S$中的所有顶点及其关联的边后，剩余的图无环。\n>     - 给定一个有向图$G=(V,E)$，找到一个最小的边子集$D\\subseteq E$，当我们从图$G$中移除$D$中的所有边及因此孤立的点后，剩余的图无环。\n>     - 判断有向图$G$有没有无重复遍历所有点的有向回路。\n>       - 判断无向图$G$有没有无重复遍历所有点的回路。\n> - 3-SAT。\n>   - 给定一个无向图$G=(V,E)$，将$V$分为$k$个颜色组，每个组形成一个独立集。\n>     - 一个图里面的所有点可否分成$k$个完全子图。\n>     - 给定全集$U$，以及一个集合$S$满足$\\bigcup_{A\\in S}A=U$，找到$B\\subseteq S$满足$B$是$U$的划分。\n>       - 给定一组集合$S_i$，找到一个集合$H$，满足$\\forall i,H\\cap S_i\\ne\\emptyset$，$|H|\\le k$。\n>       - 给定一个带权图$G=(V,E)$，以及$R\\in V$，找到图$G$的一个树$T$，使$T$的顶点集包含$R$，且$T$中所有边的权值总和最小。\n>       - 给定三个不相交的集合$X,Y,Z,|X|=|Y|=|Z|=n$。给定$T\\subseteq X\\times Y \\times Z,|T|=m$。求$T\'\\subseteq T$满足$|T\'|=n$且恰好包含$X,Y,Z$每个元素一次。\n>       - 背包问题\n>         - 给定$n$个工作，每个工作包括它要做的时间、截止时间和迟到惩罚三个参数，判断是否存在顺序使得总惩罚不超过$k$。\n>         - 判断$n$个正整数组成的集合是否可以分成和相等的两部分。\n>           - 给定图$G=(V,E)$，将$V$划分为两个不相交的子集，使得这两个子集之间的边数最大化。\n\n仅作参考，给出$\\text{SAT}\\le_K\\text{Clique}$的构造：\n\n设图$G=(V,E)$，待寻找完全图大小为$k$，定义\n$$\nx_{i,v}=\\begin{cases}1,&完全图的第i个结点是v\\\\\\\\0,&其它\\end{cases}\n$$\n$|x_{i,v}|=|V|^k$是多项式的。\n\n构造的$\\varphi$满足\n$$\n\\forall i,\\bigvee_j^n x_{i,v_j}=1\n$$\n\n$$\n\\forall i,u\\neq v,(\\neg x_{i,u}\\lor\\neg x_{i,v})\n$$\n\n$$\n\\forall v,i\ne j,(\\neg x_{i,v}\\lor\\neg x_{j,v})\n$$\n\n$$\n\\forall u,v,((u,v)\\in E\\to\\exists i\\ne j,(x_{i,u}\\land x_{j,v}))\n$$\n\n第一个：完全图的每个位置至少有一个结点。\n\n第二个：完全图的每个位置至多有一个结点。\n\n第三个：完全图的结点互异。\n\n第四个：完全图的任意两个结点之间必须连边。\n\n> [!note]\n>\n> **定理2.4（伯曼-哈特马尼斯定理）**：若有严格增长的可逆卡普归约$f:A\\to B$和$g:B\\to A$，则$A\\cong_p B$。\n\n对任意串$x$，序列\n$$\nx_0=x,x_1=g^{-1}(x_0),x_2=f^{-1}(x_1),x_3=g^{-1}(x_2),x_4=f^{-1}(x_3),\\dots\n$$\n由$f^{-1},g^{-1}$单调递减，则序列长度不会大于$|x|$。\n\n定义$h:A\\to B$：\n\n1. 若序列终止于某个偶数下标$x_{2i}$，称$x$为$A$-类的，设$h(x)=f(x)$。\n2. 若序列终止于某个奇数下标$x_{2i+1}$，称$x$为$B$-类的，设$h(x)=g^{-1}(x)$。\n\n若$\\exists x_1,x_2,x_1\\ne x_2,h(x_1)=h(x_2)$，则$x_1,x_2$必为不同类的，且$f(x_1)=g^{-1}(x_2)\\Rightarrow g(f(x_1))=x_2$，则$x_1$是$A$-类的，$x_2$也是$A$-类的，矛盾。\n\n所以$h$是单射。\n\n显然$h$是满射，又$h$只调用了$O(|x|)$次$\\{f,g,f^{-1},g^{-1}\\}$，所以$h$是多项式时间可计算的。\n\n因此$A\\cong_pB$。\n\n---\n\n**伯曼-哈特马尼斯猜测**：所有NP-完全问题都是多项式同构的。\n\n> [!note]\n>\n> **命题7**：若伯曼-哈特马尼斯猜测成立，则$\\textbf{NP}\\ne\\textbf{P}$。\n\n设$S\\subseteq\\{0,1\\}^*$，$S^{\\le n}$表示$S$中所有长度不超过$n$的串构成的集合。\n\n若$|S^{\\le n}|=2^{n^{O(1)}}$，称$S$为**稠密**的；若$|S^{\\le n}|=n^{O(1)}$，称$S$为**稀疏**的。\n\n> 通常可以这么理解稠密和稀疏：\n>\n> 如果增加1的问题规模，该问题最多增加多项式的解，那么它是稀疏的，比如：\n> $$\n> L=\\\\{1^n|n是质数\\\\},L\\subseteq 增加一个数,它与之前的数是否互质\n> $$\n> 如果最少增加指数的解，那么它是稠密的，比如：\n> $$\n> L\\subseteq SAT,L\\subseteq 增加一个结点,找出所有包含至少一个回路的图\n> $$\n\n一个稠密的语言不可能与一个稀疏的语言多项式同构，不然设$L$为稠密，$L\'$为稀疏，双射卡普归约函数$r:L\\to L\'$，则$r(L^{\\le n})\\subseteq(L\')^{\\le p(n)}$，前者是指数增长的，后者是多项式增长的，二者的数量级不对等，不能建立双射。\n\nSAT是稠密的，P-问题$\\\\{1^n|n\\in\\\\mathbb N\\\\}$是稀疏的，因此它们不能多项式同构。\n\n若$\\textbf{NP}=\\textbf{P}$，则$\\textbf{NPC}=\\textbf{P}$，即$\\\\{1^n|n\\in\\\\mathbb N\\\\}$也是NP-完全的，这与它们不能多项式同构矛盾。\n\n---\n\n$$\n\\text{THEOREM}=\\{(\\varphi,1^{|\\varphi|^c})|\\varphi有一个长度不超过|\\varphi|^c的\\mathcal A中的证明\\}\n$$\n\n其中$\\mathcal A$是任何熟知的公理系统。\n\n结论是SAT可卡普归约为$\\text{THEOREM}$，所以后者是NP完全的。\n\n## 2.4拉德纳定理\n\n我们好奇$\\textbf{NP}\\setminus\\textbf P$中除了NP完全问题，还有其它NP问题吗。\n\n> [!note]\n>\n> **定理2.5（拉德纳定理）**：若$\\textbf P\\ne\\textbf{NP}$，则$\\textbf P\\cup\\textbf{NPC}\\ne\\textbf{NP}$。\n\n$SAT$是NP-完全的，$2-SAT$是P问题，证明的思路是从$SAT$中删去足够多的元素，使得剩下的集合足够稀疏，使得不是NP完全的又不至于沦为P问题。\n\n对于$\\psi\\in\\text{SAT}$，把$\\psi$变成$\\psi\\land v_1\\land\\dots\\land v_h$，记为$\\psi01^h$，其中$v_1,\\dots,v_h$不出现在$\\psi$里。$\\psi$可满足当且仅当$\\psi 01^h$可满足。\n\n下面容易验证：\n\n- $\\\\{\\psi01^{|\\psi|^c}|\\psi\\in\\text{SAT}\\\\}$是NP-完全的；\n- $\\\\{\\psi01^{2^{|\\psi|}}|\\psi\\in\\text{SAT}\\\\}$是多项式时间可判定的。\n\n> 设$L_1=\\psi01^{|\\psi|^c}$，$N_1=|L_1|$，$L_2=\\psi01^{2^{|\\psi|}}$，$N_2=|L_2|$。\n>\n> 验证器$\\mathbb M_{L_1}$可以在$O(N_1)$时间内定位分隔符$0$并识别出公式$\\psi$，验证$\\psi$的时间是$O(2^{|\\psi|})=O(N^{\\frac1c})$，所以\n> $$\n> \\\\{{\\psi01^{|\\psi|^c}|\\psi\\in\\text{SAT}}\\\\}\\in\\textbf{NP}\n> $$\n> 考虑$f:\\text{SAT}\\to\\\\{\\psi01^{|\\psi|^c}|\\psi\\in\\text{SAT}\\\\}$，$f(\\psi)=\\psi01^{|\\psi|^c}$，这个归约显然是$|\\psi|$的多项式时间，所以有\n> $$\n> \\psi\\in\\text{SAT}\\Leftrightarrow f(\\psi)\\in\\\\{\\psi01^{|\\psi|^c}|\\psi\\in\\text{SAT}\\\\}\n> $$\n> 即\n> $$\n> \\text{SAT}\\le_K\\\\{\\psi01^{|\\psi|^c}|\\psi\\in\\text{SAT}\\\\}\n> $$\n> 所以\n> $$\n> \\\\{\\psi01^{|\\psi|^c}|\\psi\\in\\text{SAT}\\\\}\\in\\textbf{NPC}\n> $$\n> 同样地，验证器$\\mathbb M_{L_2}$验证$\\psi$的时间是$O(2^{|ψ|})=O(2\\log N_2)=O(N_2)$，在庞大的$1$串的影响下，$\\\\{\\psi01^{2^{|ψ|}}|\\psi\\in\\text{SAT}\\\\}\\in\\textbf P$是成立的。\n\n设$h(n)=|\\psi|^{H(|\\psi|)}$，我们必须定义一个增长速度恰当的函数$H$。设\n$$\n\\text{SAT}_H=\\left\\\\{\\psi01^{|\\psi|^{H(|\\psi|)}}|\\psi\\in\\text{SAT}\\right\\\\}\n$$\n并定义\n$$\n\\text{SAT}_H(x)=\\begin{cases}1,&若x\\in\\text{SAT}_H\\\\\\\\0,&若x\\notin\\text{SAT}_H\\end{cases}\n$$\n拉德纳给出的函数$H$定义如下：\n$$\nH(n)=\\begin{cases}&i是满足①和②的最小下标:\\\\\\\\i&①i<\\log\\log n;\\\\\\\\&②对所有满足|x|\\le\\log n的x,\\\\mathbb M_i(x)在i|x|^i步内输出\\text{SAT}_H(x)\\\\\\\\\\log\\log n,&否则\\end{cases}\n$$\n函数$H$满足如下性质：\n\n1. $H$是非递减函数。若$H(n)=\\log\\log n$，则$\\log\\log n\\le H(n+1)$；否则$\\forall i<H(n)$，即$i$不满足$H(n)$相应的性质，则$i$也一定不满足$H(n+1)$相应的性质，则$i<H(n+1)$。\n2. $H$可在多项式时间内计算：\n   - 根据条件①和条件②，被模拟的图灵机个数不超过$\\log\\log n$，长度不超过$\\log n$的串的个数不超过$O(n)$。通用图灵机对每个$\\mathbb M_i(x)$的模拟时间不超过$c(\\log\\log\\log n)C\\log C$，其中$C=(\\log\\log n)(\\log n)^{\\log\\log n}$代表$\\mathbb M_i$的时间函数。显然$c(\\log\\log\\log n)C\\log C=o(n)$。\n   - 判定每个$x$是否$x\\in\\text{SAT}_H$，用暴力法判定$x\\in\\text{SAT}_H$的时间是$O(n)$。\n   - 计算$H$在一个长度不超过$|x|\\le\\log n$的输入上的值，通过递归调用，$T(|x|)\\le T(\\log n)$。\n\n$H(n)$的时间函数$T(n)$满足：\n$$\nT(n)\\le(\\log\\log n)O(n)(o(n)+O(n)+T(\\log n)+O(1))\n$$\n其中$\\log\\log n$来自对$i$的枚举，$O(n)$来自所有$|x|\\le\\log n$的串的个数，即\n$$\nT(n)=o(n^3).\n$$\n假定$\\mathbb M_i$在$cn^c$步判定$\\text{SAT}_H$。取$i\\ge c$，按照定义，对所有足够大的$n$有$H(n)\\le i$，由$H$非递减，存在常数$D$，对所有$n\\ge D$，$H(x)$是常函数$\\Rightarrow\\text{SAT}\\le_K\\text{SAT}_H$。所以$\\text{SAT}_H\\in\\textbf{P}$蕴含$\\textbf{NP}=\\textbf P$，矛盾。所以$H$不会为常函数，$H(\\\\mathbb N)$是无限集。\n\n设$\\text{SAT}_H$是NP-完全的，一定有某个多项式$dn^d$时间内可计算的规约函数$r:\\text{SAT}\\to\\text{SAT}_H$，$\\exists N$，当$|\\psi|>d$和\n$$\n|r(\\varphi)|=|\\psi01^{|\\psi|^{H(|\\psi|)}}|>N\n$$\n时，有$H(|\\psi|)>2d+1$。因此，$|\\psi|^{2d+1}<|\\psi|^{H(|\\psi|)}<|r(\\varphi)|\\le d|\\varphi|^d<|\\psi|\\cdot|\\varphi|^d$。由此推得$|\\psi|<\\sqrt{|\\varphi|}$。\n\n可定义判定$\\text{SAT}$的递归算法$\\text{Sat}(\\varphi)$如下：\n\n1. 计算$r(\\varphi)$，结果将形如$\\psi01^{|\\psi|^{H(|\\psi|)}}$。\n2. 若$|r(\\varphi)|>N$，递归调用$\\text{Sat}(\\psi)$，否则用暴力法判定$\\varphi$的可满足性。\n\n此算法的递归调用深度$k$满足$1\\le|\\varphi|^{2^{-k}}\\le N$，即$k\\le\\log\\log|\\varphi|$，所以$\\text{Sat}$为多项式算法，矛盾。\n\n综上，$\\text{SAT}_H\\notin\\textbf{NPC}$。\n\n## 2.5贝克-吉尔-索罗维定理\n\n> [!note]\n>\n> **定理2.6（贝克-吉尔-索罗维定理)**：存在$A$和$B$使得$\\textbf P^A=\\textbf{NP}^A$且$\\textbf{P}^B\ne\\textbf{NP}^B$。\n\n取$A$为$\\textbf{PSPACE}$-完全问题QBF，因为$\\textbf{PSPACE}=\\textbf{P}^\\textbf{PSPACE}\\subseteq\\textbf{NP}^{\\textbf{PSPACE}}=\\textbf{PSPACE}$，所以$\\textbf{P}^A=\\textbf{NP}^A$。\n\n构造$B_0\\subseteq B_1\\subseteq B_2\\subseteq \\dots$，$n_0<n_1<n_2<\\dots$。设$B_0=\\emptyset$和$n_0=0$，试从$B_i$构造$B_{i+1}$。\n\n1. 确保$n_{i+1}>n_i$,$n_{i+1}$大于构造$B_1,\\dots,B_i$时所询问过的所有问题的长度。\n2. 让$\\mathbb M_i^{B_i}(1^{n_{i+1}})$计算$2^{n_{i+1}-1}$步。\n   1. 若计算未终止，定义$B_{i+1}=B_i$。\n   2. 若接受，定义$B_{i+1}=B_i$。\n   3. 若拒绝，定义$B_{i+1}=B_i\\cup\\{s\\}$，其中$s$是任意一个满足$|s|=n_{i+1}$并且在计算$\\mathbb M_i^{B_i}(1^{n_{i+1}})$时没被当作问题问神谕$B_i$的0-1串。\n\n定义$B=\\bigcup_{i\\in\\\\mathbb N}B_i$,并定义$U_B$为问题$\\{1^n|B包含一个长度为n的0-1串\\}$。\n\n$U_B\\in\\textbf{NP}^B$因为非确定图灵机$\\\\mathbb N^B$只需要猜测一个0-1串再问神谕$B$。\n\n假设$\\mathbb M_i^B$在多项式时间$T(n)$内判定$U_B$。取满足$T(n_i)<2^{n_i-1}$的足够大的$i$。按定义，$\\mathbb M_i^B(1^{n_{i+1}})=0$，当且仅当$B$不含有长度是$n_{i+1}$的0-1串，当且仅当$B_{i+1}$不含有长度是$n_{i+1}$的0-1串，当且仅当$\\mathbb M_i^{B_i}(1^{n_{i+1}})=1$推出$\\mathbb M_i^{B_{i+1}}(1^{n_{i+1}})=1$，进而$\\mathbb M_i^B(1^{n_{i+1}})=1$，矛盾。所以$U_B\\notin\\textbf{P}^B$。' 
                      }
                  ]
                },
                { id: 'quantum information', title: '量子信息论', icon: 'fas fa-universal-access', desc: '<p>属于个人兴趣所作。</p><p>全英笔记。</p>',
                  chapters: [
                      { id: 'quantum information-1', 
                        title: '1、Basics of quantum information', 
                        desc: '', 
                        content: '# Single Systems\n\n## Probabilistic state\n\n**We can represent any probabilistic state through a column vector satisfying two properties:**\n\n1. All entries of the vector are nonnegative real numbers.\n2. The sum of the entries is equal to 1.\n\n**Conversely, any column vector that satisfies these two properties can be taken as a representation of a probabilistic state.**\n\nFor example, assuming that the system we have in mind is a bit, the standard basis vectors are given by\n$$\n|0\\rangle = \\begin{pmatrix} 1 \\\\\\\\ 0 \\end{pmatrix}\\ \\text{and}\\ |1\\rangle = \\begin{pmatrix} 0 \\\\\\\\ 1 \\end{pmatrix}.\n$$\nNotice that any two-dimensional column vector can be expressed as a linear combination of these two vectors. For example,\n$$\n\\begin{pmatrix}\\frac{3}{4} \\\\\\\\ \\frac{1}{4}\\end{pmatrix}=\\frac{3}{4}|0\\rangle+\\frac{1}{4}|1\\rangle\n$$\n\n------\n\n### Function\n\nThere are deterministic operations, where each classical state $a\\in \\Sigma$ is transformed into $f(a)$ for some function $f$ of the form $f:\\Sigma\\rightarrow\\Sigma$.\n\nFor example, if $\\Sigma =\\\\{0,1\\\\}$ , there are four functions of this form, $f_1,f_2,f_3,f_4$ which can be represented by tables of values as follows:\n$$\n\\begin{array}{c|cc}\na & f_1(a) \\\\\\\\\n\\hline\n0 & 0 \\\\\\\\\n1 & 0\n\\end{array}\n\\ \\ \\ \\\n\\begin{array}{c|cc}\na & f_2(a) \\\\\\\\\n\\hline\n0 & 0 \\\\\\\\\n1 & 1\n\\end{array}\n\\ \\ \\ \\\n\\begin{array}{c|cc}\na & f_3(a) \\\\\\\\\n\\hline\n0 & 1 \\\\\\\\\n1 & 0\n\\end{array}\n\\ \\ \\ \\\n\\begin{array}{c|cc}\na & f_4(a) \\\\\\\\\n\\hline\n0 & 1 \\\\\\\\\n1 & 1\n\\end{array}\n$$\nSpecifically, the matrix $M$ that represents a given function $f:\\Sigma\\rightarrow\\Sigma$ is the one that satisfies:\n$$\nM|a\\rangle=|f(a)\\rangle\n$$\nfor every $a\\in\\Sigma$.\n\nFor instance, the matrices $M_1,…,M_4$ corresponding to the functions $f_1,…,f_4$ above are as follows:\n$$\nM_1=\\begin{pmatrix}1\\ \\ 1 \\\\\\\\ 0\\ \\ 0\\end{pmatrix},\\ M_2=\\begin{pmatrix}1\\ \\ 0 \\\\\\\\ 0\\ \\ 1\\end{pmatrix},\\ M_3=\\begin{pmatrix}0\\ \\ 1 \\\\\\\\ 1\\ \\ 0\\end{pmatrix},\\ M_4=\\begin{pmatrix}0\\ \\ 0 \\\\\\\\ 1\\ \\ 1\\end{pmatrix}\n$$\n\n------\n\n### Ket and bra\n\nWe denote by $\\langle a|$ the $row$ vector having a $1$ in the entry corresponding to $a$ and zero for all other entries, for each $a\\in\\Sigma$. This vector is read as "bra $a$."\n\nFor example, if $\\Sigma=\\\\{0,1\\\\}$ ,then\n$$\n\\langle0|=(1\\ \\ \\ 0)\\ \\text{and}\\ \\langle1|=(0\\ \\ \\ 1).\n$$\n\n------\n\n### Matrix\n\nWe obtain a square matrix having a $1$ in the entry corresponding to the $\\text{pair} (b,a)$, meaning that the row of the entry corresponds to the classical state $b$ and the column corresponds to the classical state $a$, with $0$ for all other entries. For example,\n$$\n|0\\rangle\\langle1|=\\begin{pmatrix}1 \\\\\\\\ 0 \\end{pmatrix}(0\\ \\ \\ 1)=\\begin{pmatrix}0\\ \\ \\ 1 \\\\\\\\ 0 \\ \\ \\ 0\\end{pmatrix}.\n$$\nUsing this notation, we may express the matrix $M$ that corresponds to any given function $f:\\Sigma\\rightarrow\\Sigma$ as\n$$\nM=\\sum_{a\\in\\Sigma}{|f(a)\\rangle}\\langle a|.\n$$\n\n------\n\n### Construction of M\n\nIf we again think about vectors as matrices, and this time consider the multiplication $\\langle a||b\\rangle$, we obtain a $1\\times 1$ matrix, which we can think about as a scalar (that is, a number). \n\nFor the sake of tidiness, we write this product as $\\langle a|b\\rangle$ rather than $\\langle a||b\\rangle$. This product satisfies the following simple formula:\n$$\n\\langle a|b \\rangle = \\begin{cases} 1 & a=b \\\\\\\\ 0 & a \\neq b \\end{cases}\n$$\nUsing this observation, together with the fact that matrix multiplication is associative and linear, we obtain\n$$\nM|b\\rangle=(\\sum_{a\\in\\Sigma}|f(a)\\rangle\\langle a|)|b\\rangle=\\sum_{a\\in\\Sigma}|f(a)\\rangle\\langle a|b\\rangle=|f(b)\\rangle\n$$\nfor each $b\\in\\Sigma$, which is precisely what we require of the matrix $M$.\n\n------\n\n## Matrix multiplication and probabilistic operations\n\nFor an arbitrary choice of a classical state set, we can describe the set of all probabilistic operations in mathematical terms as those that are represented by **stochastic matrices**, which are matrices satisfying these two properties:\n\n1. All entries are nonnegative real numbers.\n2. The entries in every column sum to $1$.\n\nSuppose that $X$ is a system having classical state set $\\Sigma$, and $M_1,…,M_n$ are stochastic matrices representing **probabilistic operations** on the system $X$.\n\nAs $M_1$ and $M_2$ are applied  to the probabilistic state represented by a probability vector $u$ sequentially, we obtain the probability vector\n$$\nM_2(M_1u)=(M_2M_1)u\n$$\nNote that the ordering is important here: although matrix multiplication is **associative**, it is not a commutative operation. For example, if\n$$\nM_1=\\begin{pmatrix}1\\ \\ \\ 1 \\\\\\\\ 0\\ \\ \\ 0\\end{pmatrix}\\ \\text{and}\\ M_2=\\begin{pmatrix}0\\ \\ \\ 1 \\\\\\\\ 1\\ \\ \\ 0\\end{pmatrix},\n$$\nthen\n$$\nM_2M_1=\\begin{pmatrix}0\\ \\ \\ 0 \\\\\\\\ 1\\ \\ \\ 1\\end{pmatrix}\\ \\text{and}\\ M_1M_2=\\begin{pmatrix}1\\ \\ \\ 1 \\\\\\\\ 0\\ \\ \\ 0\\end{pmatrix},\n$$\n\n------\n\n## Quantum states\n\nVectors representing **quantum states** are characterized by these two properties:\n\n1. The entries of a quantum state vector are **complex numbers**.\n2. The sum of the **absolute values squared** of the entries of a quantum state vector is $1$.\n\nThe **Euclidean norm** of a column vector\n$$\nv=\\begin{pmatrix}\\alpha_1 \\\\\\\\ \\vdots \\\\\\\\ \\alpha_n\\end{pmatrix}\n$$\nis denoted and defined as follows:\n$$\n||v||=\\sqrt{\\sum_{k=1}^n|\\alpha_k|^2}\n$$\nThe condition that **the sum of the absolute values squared of a quantum state vector** equals $1$is therefore equivalent to that vector **having Euclidean norm** equal to $1$. That is, quantum state vectors are **unit vectors** with respect to the Euclidean norm.\n\n------\n\n### Examples of qubit states\n\n$$\n\\begin{pmatrix}\\frac{1+2i}{3} \\\\\\\\ -\\frac{2}{3}\\end{pmatrix}=\\frac{1+2i}{3}|0\\rangle-\\frac{2}{3}|1\\rangle\n$$\n\nNote that they are linear combinations of the standard basis states $|0\\rangle$ and $|1\\rangle$, and for this reason we often say that they\'re **superpositions** of the states $0$and $1$.\n$$\n|\\frac{1+2i}{3}|^2+|-\\frac{2}{3}|^2=1\n$$\nWithin the context of quantum states, **superposition** and **linear combination** are essentially synonymous.\n\n------\n\n### Plus/Minus state\n\n$$\n|+\\rangle=\\frac{1}{\\sqrt{2}}|0\\rangle+\\frac{1}{\\sqrt{2}}|1\\rangle$$$$\n|-\\rangle=\\frac{1}{\\sqrt{2}}|0\\rangle-\\frac{1}{\\sqrt{2}}|1\\rangle\n$$\n\n------\n\n### Complex conjugate\n\nNotice that, if we have a vector $|\\psi⟩$ whose indices correspond to some classical state set $\\Sigma$ and if $a\\in\\Sigma$ is an element of this classical state set, then the matrix product $\\langle a||\\psi\\rangle$ is equal to the entry of the vector $|\\psi\\rangle$ whose index corresponds to $a$. As we did when $|\\psi\\rangle$ was a standard basis vector, we write $\\langle a|\\psi\\rangle$ rather than $\\langle a||\\psi\\rangle$ for the sake of readability.\n\nFor example, if $\\Sigma=\\\\{0,1\\\\}$ and\n$$\n|\\psi\\rangle=\\frac{1+2i}{3}|0\\rangle-\\frac{2}{3}|1\\rangle=\\begin{pmatrix}\\frac{1+2i}{3}\\\\\\\\-\\frac{2}{3}\\end{pmatrix}\n$$\nthen\n$$\n\\langle 0|\\psi\\rangle=\\frac{1+2i}{3}\\ \\text{and}\\ \\langle1|\\psi\\rangle=-\\frac{2}{3}.\n$$\nthe notation $\\langle\\psi|$ refers to the row vector obtained by taking the **conjugate-transpose** of the column vector $|\\psi\\rangle$\n$$\n\\langle\\psi|=\\frac{1-2i}{3}\\langle0|-\\frac{2}{3}\\langle1|=(\\frac{1-2i}{3}\\ \\ \\ -\\frac{2}{3})\n$$\n\n------\n\n## The probabilities of different classical state measurement\n\nIf a quantum state is measured, each classical state of the system appears with probability equal to the **absolute value squared** of the entry in the quantum state vector corresponding to that classical state. It implies that the probabilities of different classical state measurement outcomes sum to $1$.\n\nMeasuring the state\n$$\n|\\psi\\rangle=\\frac{1+2i}{3}|0\\rangle-\\frac{2}{3}|1\\rangle\n$$\ncauses the two possible outcomes to appear with probabilities as follows:\n$$\n\\text{Pr}(\\text{outcome is }0)=|\\langle0|\\psi\\rangle|^2=|\\frac{1+2i}{3}|^2=\\frac{5}{9}\n$$\nand\n$$\n\\text{Pr}(\\text{outcome is }1)=|\\langle1|\\psi\\rangle|^2=|-\\frac{2}{3}|^2=\\frac{4}{9}\n$$\n\n------\n\n## Unitary operations\n\nA square matrix $U$ having complex number entries is *unitary* if it satisfies the equations\n$$\nUU^{\\dagger} = \\mathbb{I}\\\\\\\\\nU^{\\dagger}U = \\mathbb{I}.\n$$\nHere, $\\mathbb{I}$ is the identity matrix, and $U^{\\dagger}$ is the **conjugate transpose** of $U$, meaning the matrix obtained by transposing $U$ and taking the complex conjugate of each entry.\n$$\nU^\\dagger=\\overline{U^T}\n$$\nand\n$$\nU^{-1}=U^\\dagger.\n$$\nThe condition that $U$ is unitary is equivalent to the condition that multiplication by $U$ does not change the Euclidean norm of any vector. That is, an $n\\times n$ matrix $U$ is unitary if and only if $||U|\\psi\\rangle||=|||\\psi\\rangle||$ for every $n-dimensional$ column vector $|\\psi\\rangle$ with complex number entries.\n\n------\n\n### Examples of unitary operations on qubits\n\n1. **Pauli operations**. The four Pauli matrices are as follows:\n   $$\n   \\mathbb{I}=\\begin{pmatrix}1\\ \\ \\ 0\\\\\\\\0 \\ \\ \\ 1\\end{pmatrix},\\ \\sigma_x=\\begin{pmatrix}0\\ \\ \\ 1\\\\\\\\1 \\ \\ \\ 0\\end{pmatrix},\\ \\sigma_y=\\begin{pmatrix}0\\ -i\\\\\\\\i \\ \\ \\ \\ 0\\end{pmatrix},\\ \\sigma_z=\\begin{pmatrix}1\\ \\ \\ \\ \\ 0\\\\\\\\0 \\ -1\\end{pmatrix}.\n   $$\n   The $X$ operation is also called a **bit flip** or a **NOT operation** because it induces this action on bits:\n   $$\n   X|0\\rangle=|1\\rangle\\ \\text{and}\\ X|1\\rangle=|0\\rangle.\n   $$\n   The $Z$​ operation is also called a **phase flip**, and it has this action:\n   $$\n   Z|0\\rangle=|0\\rangle\\ \\text{and}\\ Z|1\\rangle=-|1\\rangle.\n   $$\n\n2. **Hadamard operation**. The Hadamard operation is described by this matrix:\n   $$\n   H=\\begin{pmatrix}\\frac{1}{\\sqrt{2}}\\ \\ \\ \\ \\ \\frac{1}{\\sqrt{2}} \\\\\\\\ \\frac{1}{\\sqrt{2}}\\ -\\frac{1}{\\sqrt{2}}\\end{pmatrix}.\n   $$\n\n3. **Phase operations**. A phase operation is one described by the matrix:\n   $$\n   P_\\theta=\\begin{pmatrix}1\\ \\ \\ 0\\\\\\\\ 0\\ \\ e^{i\\theta}\\end{pmatrix}\n   $$\n   for any choice of a real number $\\theta$. \n\nHere\'s the action of the Hadamard operation on a few commonly encountered qubit state vectors.\n$$\nH|0\\rangle=\\begin{pmatrix}\\frac{1}{\\sqrt{2}}\\ \\ \\ \\ \\ \\frac{1}{\\sqrt{2}} \\\\\\\\ \\frac{1}{\\sqrt{2}}\\ -\\frac{1}{\\sqrt{2}}\\end{pmatrix}\\begin{pmatrix}1\\\\\\\\0\\end{pmatrix}=\\begin{pmatrix}\\frac{1}{\\sqrt{2}}\\\\\\\\\\frac{1}{\\sqrt{2}}\\end{pmatrix}=|+\\rangle$$$$\nH|1\\rangle=\\begin{pmatrix}\\frac{1}{\\sqrt{2}}\\ \\ \\ \\ \\ \\frac{1}{\\sqrt{2}} \\\\\\\\ \\frac{1}{\\sqrt{2}}\\ -\\frac{1}{\\sqrt{2}}\\end{pmatrix}\\begin{pmatrix}0\\\\\\\\1\\end{pmatrix}=\\begin{pmatrix}\\frac{1}{\\sqrt{2}}\\\\\\\\-\\frac{1}{\\sqrt{2}}\\end{pmatrix}=|-\\rangle$$$$\nH|+\\rangle=\\begin{pmatrix}\\frac{1}{\\sqrt{2}}\\ \\ \\ \\ \\ \\frac{1}{\\sqrt{2}} \\\\\\\\ \\frac{1}{\\sqrt{2}}\\ -\\frac{1}{\\sqrt{2}}\\end{pmatrix}\\begin{pmatrix}\\frac{1}{\\sqrt{2}}\\\\\\\\\\frac{1}{\\sqrt{2}}\\end{pmatrix}=\\begin{pmatrix}1\\\\\\\\0\\end{pmatrix}=|0\\rangle$$$$\nH|-\\rangle=\\begin{pmatrix}\\frac{1}{\\sqrt{2}}\\ \\ \\ \\ \\ \\frac{1}{\\sqrt{2}} \\\\\\\\ \\frac{1}{\\sqrt{2}}\\ -\\frac{1}{\\sqrt{2}}\\end{pmatrix}\\begin{pmatrix}\\frac{1}{\\sqrt{2}}\\\\\\\\-\\frac{1}{\\sqrt{2}}\\end{pmatrix}=\\begin{pmatrix}0\\\\\\\\1\\end{pmatrix}=|1\\rangle\\\\\\\\\n$$\n\n------\n\n### The linearity of matrix multiplication\n\nAlong similar lines, we may compute the result of applying a Hadamard operation to the quantum state vector just obtained:\n$$\n\\begin{align}\n&H \\left( \\frac{1}{\\sqrt{2}}|0\\rangle + \\frac{1+i}{2}|1\\rangle \\right) = \\frac{1}{\\sqrt{2}} H|0\\rangle + \\frac{1+i}{2} H|1\\rangle \\\\\\\\\n&\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ = \\frac{1}{\\sqrt{2}}|+\\rangle + \\frac{1+i}{2}|-\\rangle \\\\\\\\\n&\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ = \\left( \\frac{1}{2}|0\\rangle + \\frac{1}{2}|1\\rangle \\right) + \\left( \\frac{1+i}{2\\sqrt{2}}|0\\rangle - \\frac{1+i}{2\\sqrt{2}}|1\\rangle \\right) \\\\\\\\\n&\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ = \\left( \\frac{1}{2} + \\frac{1+i}{2\\sqrt{2}} \\right)|0\\rangle + \\left( \\frac{1}{2} - \\frac{1+i}{2\\sqrt{2}} \\right)|1\\rangle\n\\end{align}\n$$\n\n------\n\n### Compositions of qubit unitary operations\n\nCompositions of unitary operations are represented by matrix multiplication, just like we had in the probabilistic setting.\n\nFor example, suppose we first apply a Hadamard operation, followed by an $S$ operation, followed by another Hadamard operation. The resulting operation, which we shall name $R$ for the sake of this example, is as follows:\n$$\nR=HSH=\\begin{pmatrix}\\frac{1}{\\sqrt{2}}\\ \\ \\ \\ \\ \\frac{1}{\\sqrt{2}} \\\\\\\\ \\frac{1}{\\sqrt{2}}\\ -\\frac{1}{\\sqrt{2}}\\end{pmatrix}\\begin{pmatrix}1\\ 0\\\\\\\\0\\ i\\end{pmatrix}\\begin{pmatrix}\\frac{1}{\\sqrt{2}}\\ \\ \\ \\ \\ \\frac{1}{\\sqrt{2}} \\\\\\\\ \\frac{1}{\\sqrt{2}}\\ -\\frac{1}{\\sqrt{2}}\\end{pmatrix}=\\begin{pmatrix}\\frac{1+i}{2} \\ \\frac{1-i}{2} \\\\\\\\ \\frac{1-i}{2}\\ \\frac{1+i}{2}\\end{pmatrix}\n$$\nThis unitary operation $R$ is an interesting example. By applying this operation twice, which is equivalent to squaring its matrix representation, we obtain a **NOT** operation:\n$$\nR^2=\\begin{pmatrix}\\frac{1+i}{2} \\ \\frac{1-i}{2} \\\\\\\\ \\frac{1-i}{2}\\ \\frac{1+i}{2}\\end{pmatrix}^2=\\begin{pmatrix}0\\ 1\\\\\\\\1\\ 0\\end{pmatrix}.\n$$\nThat is, $R$ is a **square root of NOT** operation. Such a behavior, where the same operation is applied twice to yield a **NOT** operation, is not possible for a classical operation on a single bit.\n\n------\n\n# Multiple systems\n\n### Classical states via the Cartesian product\n\nNow imagine that the two systems, $X$ and $Y$, are placed side-by-side, with $X$ on the left and $Y$ on the right. If we so choose, we can view these two systems as if they form a single system, which we can denote by $(X,Y)$ or $XY$ depending on our preference.\n\nThe set of **classical states** of $(X,Y)$ is the **Cartesian product** of $\\Sigma$ and $\\Gamma$, which is the set defined as\n$$\n\\Sigma\\times\\Gamma=\\\\{(a,b):a\\in\\Sigma\\ \\text{and}\\ b\\in\\Gamma\\\\}\n$$\nFor more than two systems, the situation generalizes in a natural way. If we suppose that $X_1,…,X_n$ are systems having classical state sets $\\Sigma_1,…,\\Sigma_n$, respectively, for any positive integer $n$, the classical state set of the $n-\\text{tuple}(X_1,…,X_n)$, viewed as a single joint system, is the Cartesian product\n$$\n\\Sigma_1\\times\\dots\\times\\Sigma_n=\\\\{(a_1,\\dots,a_n):a_1\\in\\Sigma_1,\\dots,a_n\\in\\Sigma_n\\\\}\n$$\nIt is often convenient to write a classical state of the form $(a_{n-1},…,a_0)$ as a string $a_{n−1}⋯a_0$ for the sake of brevity, particularly in the very typical situation that the classical state sets $\\Sigma_0,…,\\Sigma_{n−1}$ are associated with sets of **symbols** or **characters**.\n\n------\n\n## Probabilistic states\n\n**A probabilistic state of multiple systems** — viewed collectively as a single system — associates a probability with each element of the Cartesian product of the classical state sets of the individual systems.\n\nThere is a simple **convention** that we follow for doing this, which is to start with whatever orderings are already in place for the individual classical state sets, and then to order the elements of the Cartesian product **alphabetically**.\n\nFor example, according to this convention, the Cartesian product $\\\\{1,2,3\\\\}\\times\\\\{0,1\\\\}$ is ordered like this:\n$$\n(1,0),\\ (1,1),\\ (2,0),\\ (2,1),\\ (3,0),\\ (3,1)\n$$\n\n------\n\n### Independence of two systems\n\nTo define this notion precisely, let us suppose once again that $X$ and $Y$ are systems having classical state sets $\\Sigma$ and $\\Gamma$, respectively. With respect to a given probabilistic state of these systems, they are said to be **independent** if it is the case that\n$$\n\\text{Pr}((X,Y)=(a,b))=\\text{Pr}(X=a)\\text{Pr}(x=b)\n$$\nfor every choice of $a\\in\\Sigma$ and $b\\in\\Gamma$.\n\nTo express this condition in terms of probability vectors, assume that the given probabilistic state of $(X,Y)$ is described by a probability vector, written in the Dirac notation as\n$$\n|\\pi\\rangle=\\sum_{(a,b)\\in\\Sigma\\times\\Gamma}p_{ab}|ab\\rangle.\n$$\nIndependence of X and Y is then equivalent to the existence of two probability vectors\n$$\n|\\phi\\rangle=\\sum_{a\\in\\Sigma}q_a|a\\rangle\\ \\text{and}\\ |\\psi\\rangle=\\sum_{b\\in\\Gamma}r_b|b\\rangle\n$$\nrepresenting the probabilities associated with the classical states of $X$ and $Y$, respectively, such that\n$$\np_{ab}=q_ar_b\n$$\nfor all $a\\in\\Sigma\\ \\text{and}\\ b\\in\\Gamma$.\n\nFor example, the probabilistic state of a pair of bits $(X,Y)$ represented by the vector\n$$\n\\frac{1}{6}|00\\rangle+\\frac{1}{12}|01\\rangle+\\frac{1}{2}|10\\rangle+\\frac{1}{4}|11\\rangle\n$$\nis one in which $X$ and $Y$ are independent. Specifically, the condition required for independence is true for the probability vectors\n$$\n|\\phi\\rangle=\\frac{1}{4}|0\\rangle+\\frac{3}{4}|1\\rangle\\ \\text{and}\\ |\\psi\\rangle=\\frac{2}{3}|0\\rangle+\\frac{1}{3}|1\\rangle\n$$\n\n### Tensor products of vectors\n\nThe condition of independence just described can be expressed succinctly through the notion of a **tensor product**. Although tensor products are a very general notion, and can be defined quite abstractly and applied to a variety of mathematical structures, we can adopt a simple and concrete definition in the case at hand.\n\nGiven two vectors\n$$\n|\\phi\\rangle=\\sum_{a\\in\\Sigma}\\alpha_a|a\\rangle\\ \\text{and}\\ |\\psi\\rangle=\\sum_{b\\in\\Gamma}\\beta_b|b\\rangle\n$$\nthe tensor product $|\\phi\\rangle\\otimes|\\psi\\rangle$ is the vector defined as\n$$\n|\\phi\\rangle\\otimes|\\psi\\rangle=\\sum_{(a,b)\\in\\Sigma\\times\\Gamma}\\alpha_a\\beta_b|ab\\rangle.\n$$\nThe entries of this new vector correspond to the elements of the Cartesian product $\\Sigma\\times\\Gamma$, which are written as strings in the previous equation. Equivalently, the vector $|\\pi\\rangle=|\\phi\\rangle\\otimes|\\psi\\rangle$ is defined by the equation\n$$\n\\langle ab|\\pi\\rangle=\\langle a|\\phi\\rangle\\langle b|\\psi\\rangle\n$$\nbeing true for every $a\\in\\Sigma\\ \\text{and}\\ b\\in\\Gamma$.\n\nAlternative notation for tensor products:\n$$\n|\\phi\\rangle|\\psi\\rangle=|\\phi\\rangle\\otimes|\\psi\\rangle\\\\\n|\\phi\\otimes\\psi\\rangle=|\\phi\\rangle\\otimes|\\psi\\rangle.\n$$\nWhen we use the alphabetical convention for ordering elements of Cartesian products, we obtain the following specification for the tensor product of two column vectors.\n$$\n\\begin{pmatrix}\\alpha_1\\\\\\\\\\vdots\\\\\\\\\\alpha_m\\end{pmatrix}\\otimes\\begin{pmatrix}\\beta_1\\\\\\\\\\vdots\\\\\\\\\\beta_k\\end{pmatrix}=\\begin{pmatrix}\\alpha_1\\beta_1\\\\\\\\\\vdots\\\\\\\\\\alpha_1\\beta_k\\\\\\\\\\alpha_2\\beta_1\\\\\\\\\\vdots\\\\\\\\\\alpha_2\\beta_k\\\\\\\\\\vdots\\\\\\\\\\alpha_m\\beta_1\\\\\\\\\\vdots\\\\\\\\\\alpha_m\\beta_k\\end{pmatrix}\n$$\nAs an important aside, notice the following expression for tensor products of standard basis vectors:\n$$\n|a\\rangle\\oplus|b\\rangle=|a\\rangle|b\\rangle=|ab\\rangle.\n$$\nWe could alternatively write $(a,b)$ as an ordered pair, rather than a string, in which case we obtain $|a\\rangle\\otimes|b\\rangle=|(a,b)\\rangle$. It is, however, more common to omit the parentheses in this situation, instead writing $|a\\rangle\\otimes|b\\rangle=|a,b\\rangle$. \n\nThe tensor product of two vectors has the important property that it is **bilinear**, which means that it is linear in each of the two arguments separately, assuming that the other argument is fixed. This property can be expressed through these equations:\n\n1. Linearity in the first argument:\n   $$\n   (|\\phi_1\\rangle+\\phi_2\\rangle)\\otimes|\\psi\\rangle=|\\phi_1\\rangle\\otimes|\\psi\\rangle+|\\phi_2\\rangle\\otimes|\\psi\\rangle\\\\\\\\\n   (\\alpha|\\phi\\rangle)\\otimes|\\psi\\rangle=\\alpha(|\\phi\\rangle\\otimes|\\psi\\rangle)\n   $$\n\n2. Linearity in the second argument:\n   $$\n   |\\phi\\rangle\\otimes(|\\psi_1\\rangle+\\psi_2\\rangle)=|\\phi\\rangle\\otimes|\\psi_1\\rangle+|\\phi\\rangle\\otimes|\\psi_2\\rangle\\\\\\\\\n   |\\phi\\rangle\\otimes(\\alpha|\\psi\\rangle)=\\alpha(|\\phi\\rangle\\otimes|\\psi\\rangle)\n   $$\n   \n\nConsidering the second equation in each of these pairs of equations, we see that scalars **"float freely"** within tensor products:\n$$\n(\\alpha|\\phi\\rangle)\\otimes|\\psi\\rangle=|\\phi⟩\\otimes(\\alpha|\\psi\\rangle)=\\alpha(|\\phi\\rangle\\otimes|\\psi\\rangle).\n$$\n\n------\n\n### Independence and tensor products for three or more systems\n\nThe definition of the tensor product generalizes in a natural way: the vector\n$$\n|\\psi\\rangle=|\\phi_{n-1}\\rangle\\otimes\\dots\\otimes|\\phi_0\\rangle\n$$\nis defined by the equation\n$$\n\\langle a_{n-1}\\dots a_0|\\psi\\rangle=\\langle a_{n-1}|\\phi_{n-1}\\rangle\\dots\\langle a_{0}|\\phi_{0}\\rangle\n$$\nbeing true for every $a_0\\in\\Sigma_0,\\dots a_{n−1}\\in\\Sigma_{n-1}$.\n\nA different, but equivalent, way to define the tensor product of three or more vectors is recursively in terms of tensor products of two vectors:\n$$\n|\\phi_{n-1}\\rangle\\otimes\\dots\\otimes|\\phi_0\\rangle=|\\phi_{n-1}\\rangle\\otimes(|\\phi_{n-2}\\rangle\\otimes\\dots\\otimes|\\phi_0\\rangle).\n$$\nGeneralizing the observation earlier concerning tensor products of standard basis vectors, for any positive integer $n$ and any classical states $a_0,\\dots,a_{n−1}$, we have\n$$\n|a_{n-1}\\rangle\\otimes\\dots\\otimes|a_0\\rangle=|a_{n-1}\\dots a_0\\rangle.\n$$\n\n---\n\n## Measurements of probabilistic states\n\nBy choosing to view multiple systems together as single systems, we immediately obtain a specification of how measurements must work for multiple systems — provided that **all** of the systems are measured.\n\nFor example, if the probabilistic state of two bits $(X,Y)$ is described by the probability vector\n$$\n\\frac{1}{2}|00\\rangle+\\frac{1}{2}|11\\rangle,\n$$\nthen the outcome $00$ — meaning $00$ for the measurement of $X$ and $0$ for the measurement of $Y$— is obtained with probability $\\frac{1}{2}$ and the outcome $11$ is also obtained with probability $\\frac{1}{2}$. In each case we update the probability vector description of our knowledge accordingly, so that the probabilistic state becomes $|00\\rangle\\ \\text\\ |11\\rangle$, respectively.\n\nLet\'s suppose that $X$ and $Y$ are systems whose classical state sets are $\\Sigma$ and $\\Gamma$, respectively, and that the two systems together are in some probabilistic state. We\'ll consider what happens when we measure just $X$ and do nothing to $Y$.\n\n1. The probability to observe a particular classical state $a\\in\\Sigma$ when just $X$ is measured is\n   $$\n   \\text{Pr}(X=a)=\\sum_{b\\in\\Gamma}\\text{Pr}((X,Y)=(a,b)).\n   $$\n\n2. There may still exist uncertainty about the classical state of Y, depending on the outcome of the measurement:\n   $$\n   \\text{Pr}(Y=b|X=a)=\\frac{\\text{Pr}((X,Y)=(a,b))}{\\text{Pr}(X=a)}\n   $$\n\n3. \n\nThese formulas can be expressed using the Dirac notation as follows.\n\nSuppose that $(X,Y)$ is in some arbitrary probabilistic state:\n$$\n\\sum_{(a,b)\\in\\Sigma\\times\\Gamma}p_{ab}|ab\\rangle=\\sum_{(a,b)\\in\\Sigma\\times\\Gamma}p_{ab}|a\\rangle\\otimes|b\\rangle=\\sum_{a\\in\\Sigma}|a\\rangle\\otimes(\\sum_{b\\in\\Gamma}p_{ab}|b\\rangle)\n$$\n\n1. The probability that a measurement of $X$ yields an outcome $a\\in\\Sigma$ is\n   $$\n   \\text{Pr}(X=a)=\\sum_{b\\in\\Gamma}p_{ab}.\n   $$\n\n2. Conditioned on the outcome $a\\in\\Sigma$, the probabilistic state of $Y$ becomes\n   $$\n   \\frac{\\sum_{b\\in\\Gamma}p_{ab}|b\\rangle}{\\sum_{c\\in\\Gamma}p_{ac}}.\n   $$\n\nFor a specific example, suppose that classical state set of $X$ is $\\Sigma=\\\\{0,1\\\\}$, the classical state set of $Y$ is $\\Gamma=\\\\{1,2,3\\\\}$, and the probabilistic state of $(X,Y)$ is\n$$\n|\\psi\\rangle=\\frac{1}{2}|0,1\\rangle+\\frac{1}{12}|0,3\\rangle+\\frac{1}{12}|1,1\\rangle+\\frac{1}{6}|1,2\\rangle+\\frac{1}{6}|1,3\\rangle\n$$\nOur goal will be to determine the probabilities of the two possible outcomes ($0$ and $1$), and to calculate what the resulting probabilistic state of $Y$ is for the two outcomes, assuming the system $X$ is measured.\n\nUsing the **bilinearity** of the tensor product, and specifically the fact that it is linear in the **second** argument, we may rewrite the vector $|\\psi\\rangle$ as follows:\n$$\n|\\psi\\rangle=|0\\rangle\\otimes(\\frac{1}{2}|1\\rangle+\\frac{1}{12}|3\\rangle)+|1\\rangle\\otimes(\\frac{1}{12}|1\\rangle+\\frac{1}{6}|2\\rangle+\\frac{1}{6}|3\\rangle).\n$$\nHaving expressed our probability vector in this way, the effects of measuring the first system become easy to analyze. The probabilities of the two outcomes can be obtained by summing the probabilities in parentheses.\n$$\n\\text{Pr}(X=0)=\\frac{1}{2}+\\frac{1}{12}=\\frac{7}{12}.\n$$\nThus, conditioned on $X$ being $0$, the probabilistic state of $Y$ becomes\n$$\n\\frac{\\frac{1}{2}|1\\rangle+\\frac{1}{12}|3\\rangle}{\\frac{7}{12}}=\\frac{6}{7}|1\\rangle+\\frac{1}{7}|3\\rangle\n$$\n\n---\n\n## Operations on probabilistic states\n\nReturning to the typical set-up where we have two systems $X$ and $Y$, let us consider classical operations on the compound system $(X,Y)$. We\'ve concluded that any such operation is represented by a stochastic matrix whose rows and columns are indexed by the Cartesian product $\\Sigma\\times\\Gamma$.\n\nFor example, suppose that $X$ and $Y$ are bits, and consider an operation with the following description.\n\n> Operation\n>\n> If $X=1$, then perform a NOT operation on $Y$.\n> Otherwise do nothing.\n\nThis is a **deterministic operation** known as a **controlled-NOT** operation, where $X$ is the **control** bit that determines whether or not a NOT operation should be applied to the **target** bit $Y$. \n\nHere is the matrix representation of this operation:\n$$\n\\begin{pmatrix}1\\ \\ 0\\ \\ 0\\ \\ 0\\\\\\\\0\\ \\ 1\\ \\ 0\\ \\ 0\\\\\\\\0\\ \\ 0\\ \\ 0\\ \\ 1\\\\\\\\0\\ \\ 0\\ \\ 1\\ \\ 0\\end{pmatrix}\n$$\nIts action on standard basis states is as follows.\n$$\n|00\\rangle\\mapsto|00\\rangle$$$$\n|01\\rangle\\mapsto|01\\rangle$$$$\n|10\\rangle\\mapsto|11\\rangle$$$$\n|11\\rangle\\mapsto|10\\rangle\n$$\nAnother example is the operation having this description:\n\n> Operation\n>\n> Perform one of the following two operations, each with probability $\\frac{1}{2}$:\n>\n> 1. Set $Y$ to be equal to $X$.\n> 2. Set $X$ to be equal to $Y$.\n\nThe matrix representation of this operation is as follows:\n$$\n\\begin{pmatrix}1\\ \\ \\frac{1}{2}\\ \\ \\frac{1}{2}\\ \\ 0\\\\\\\\0\\ \\ \\ 0\\ \\ \\ 0\\ \\ \\ 0\\\\\\\\0\\ \\ \\ 0\\ \\ \\ 0\\ \\ \\ 0\\\\\\\\0\\ \\ \\frac{1}{2}\\ \\ \\frac{1}{2}\\ \\ 1\\end{pmatrix}=\\frac{1}{2}\\begin{pmatrix}1\\ \\ 1\\ \\ 0\\ \\ 0\\\\\\\\0\\ \\ 0\\ \\ 0\\ \\ 0\\\\\\\\0\\ \\ 0\\ \\ 0\\ \\ 0\\\\\\\\0\\ \\ 0\\ \\ 1\\ \\ 1\\end{pmatrix}+\\frac{1}{2}\\begin{pmatrix}1\\ \\ 0\\ \\ 1\\ \\ 0\\\\\\\\0\\ \\ 0\\ \\ 0\\ \\ 0\\\\\\\\0\\ \\ 0\\ \\ 0\\ \\ 0\\\\\\\\0\\ \\ 1\\ \\ 0\\ \\ 1\\end{pmatrix}\n$$\nThe action of this operation on standard basis vectors is as follows:\n$$\n|00\\rangle\\mapsto|00\\rangle$$$$\n|01\\rangle\\mapsto\\frac{1}{2}|00\\rangle+\\frac{1}{2}|11\\rangle$$$$\n|10\\rangle\\mapsto\\frac{1}{2}|00\\rangle+\\frac{1}{2}|11\\rangle$$$$\n|11\\rangle\\mapsto|11\\rangle\n$$\n\n---\n\n### Tensor products of matrices\n\nLet us say that the operation on $X$ is represented by the matrix $M$ and the operation on $Y$ is represented by the matrix $N$.\n\nThe tensor product $M\\otimes N$ of the matrices\n$$\nM=\\sum_{a,b\\in\\Sigma}\\alpha_{ab}|a\\rangle\\langle b|\n$$\nand\n$$\nN=\\sum_{c,d\\in\\Gamma}\\beta_{cd}|c\\rangle\\langle d|\n$$\nis the matrix\n$$\nM\\otimes N=\\sum_{a,b\\in\\Sigma}\\sum_{c,d\\in\\Gamma}\\alpha_{ab}\\beta_{cd}|ac\\rangle\\langle bd|\n$$\nEquivalently, the tensor product of $M$ and $N$ is defined by the equation\n$$\n\\langle ac|M\\otimes N|bd\\rangle=\\langle a|M|b\\rangle\\langle c|N|d\\rangle\n$$\nbeing true for every selection of $a,b\\in\\Sigma\\ \\text{and}\\  c,d\\in\\Gamma$.\n\nAn alternative, but equivalent, way to describe $M⊗N$ is that it is the unique matrix that satisfies the equation\n$$\n(M\\otimes N)(|\\phi\\rangle\\otimes|\\psi\\rangle)=(M|\\phi\\rangle)\\otimes(N|\\psi\\rangle)\n$$\nfor every possible choice of vectors $|\\phi\\rangle$ and $|\\psi\\rangle$, assuming that the indices of $|\\phi\\rangle$ correspond to the elements of $\\Sigma$ and the indices of $|\\psi\\rangle$ correspond to $\\Gamma$.\n\nIf $M_0,\\dots,M_{n−1}$ are matrices whose indices correspond to classical state sets $\\Sigma_0,…,\\Sigma_{n−1}$, then the tensor product $M_{n−1}\\otimes⋯\\otimes M_0$ is defined by the condition that\n$$\n\\langle a_{n-1}\\dots a_0|M_{n-1}\\otimes\\dots\\otimes M_0|b_{n-1}\\dots b_0\\rangle=\\langle a_{n-1}|M_{n-1}|b_{n-1}\\rangle\\dots\\langle a_0|M_0|b_0\\rangle\n$$\nfor every choice of classical states $a_0,b_0\\in\\Sigma_0,…,a_{n−1},b_{n−1}\\in\\Sigma_{n-1}$.\n\nThe tensor product of matrices is **multiplicative**.\n\n---\n\n## Quantum states\n\nQuantum states of multiple systems are represented by column vectors having **complex number entries** and **Euclidean norm equal to ** $1$,  just like quantum states of single systems.\n\nIn the multiple system case, the entries of these vectors are placed in correspondence with the **Cartesian product** of the classical state sets associated with each of the individual systems, because that\'s the classical state set of the compound system.\n\nFor instance, if $X$ and $Y$ are qubits, then the classical state set of the pair of qubits $(X,Y)$, viewed collectively as a single system, is the Cartesian product $\\\\{0,1\\\\}\\times\\\\{0,1\\\\}$. By representing pairs of binary values as binary strings of length two, we associate this Cartesian product set with the set $\\\\{00,01,10,11\\\\}$. The following vectors are therefore all examples of quantum state vectors of the pair $(X,Y)$:\n$$\n\\frac{1}{\\sqrt{2}}|00\\rangle-\\frac{1}{\\sqrt{6}}|01\\rangle+\\frac{i}{\\sqrt{6}}|10\\rangle+\\frac{1}{\\sqrt{6}}|11\\rangle,\\ \\frac{3}{5}|00\\rangle-\\frac{4}{5}|11\\rangle,\\ \\text{and}\\ |01\\rangle.\n$$\nHere, we have various forms expressing the state vectors of multiple system:\n$$\n|ab\\rangle=|a\\rangle|b\\rangle=|a\\rangle\\otimes|b\\rangle=|a\\rangle_{X}|b\\rangle_{Y}\n$$\nor we may also write quantum state vectors explicitly as column vectors:\n$$\n\\begin{pmatrix}\\frac{1}{\\sqrt{2}}\\\\\\\\-\\frac{1}{\\sqrt{6}}\\\\\\\\\\frac{i}{\\sqrt{6}}\\\\\\\\\\frac{1}{\\sqrt{6}}\\end{pmatrix}.\n$$\n\n---\n\n### Tensor products of quantum state vectors\n\nWhen a pair of systems $(X,Y)$ is in a product state $|\\phi\\rangle\\otimes|\\psi\\rangle$, we may interpret this as meaning that $X$ is in the quantum state $|\\phi\\rangle$, $Y$ is in the quantum state $|\\psi\\rangle$, and the states of the two systems have nothing to do with one another.\n\nThe fact that the tensor product vector $|\\phi\\rangle\\otimes|\\psi\\rangle$ is indeed a quantum state vector is consistent with the Euclidean norm being *multiplicative* with respect to tensor products:\n$$\n\\begin{align}\n\\||\\phi\\rangle\\otimes|\\psi\\rangle\\|&=\\sqrt{\\sum_{(a,b)\\in\\Sigma\\times\\Gamma}|\\langle ab|\\phi\\otimes\\psi\\rangle|^2}\\\\\\\\\n&=\\sqrt{\\sum_{a\\in\\Sigma}\\sum_{b\\in\\Gamma}|\\langle a|\\phi\\rangle\\langle b|\\psi\\rangle|^2}\\\\\\\\\n&=\\sqrt{(\\sum_{a\\in\\Sigma}|\\langle a|\\phi\\rangle|^2)(\\sum_{b\\in\\Gamma}|\\langle b|\\psi\\rangle|^2)}\\\\\\\\\n&=\\||\\phi\\rangle\\|\\||\\psi\\rangle\\|\\\\\\\\\n&=1.\n\\end{align}\n$$\n\n---\n\n### Entangled states\n\nNot all quantum state vectors of multiple systems are product states. For example, the quantum state vector\n$$\n\\frac{1}{\\sqrt{2}}|00\\rangle+\\frac{1}{\\sqrt{2}}|11\\rangle\n$$\nof two qubits is not a product state\n\nThus, the quantum state vector represents a **correlation** between two systems, and specifically we say that the systems are **entangled**.\n\nEntanglement can be complicated. For quantum state vectors, however, **entanglement is equivalent to correlation**: any quantum state vector that is not a product state represents an entangled state.\n\nIn contrast, the quantum state vector\n$$\n\\frac{1}{2}|00\\rangle+\\frac{i}{2}|01\\rangle-\\frac{1}{2}|10\\rangle-\\frac{i}{2}|11\\rangle\n$$\nis an example of a product state, because:\n$$\n\\frac{1}{2}|00\\rangle+\\frac{i}{2}|01\\rangle-\\frac{1}{2}|10\\rangle-\\frac{i}{2}|11\\rangle=(\\frac{1}{\\sqrt{2}}|0\\rangle-\\frac{1}{\\sqrt{2}}|1\\rangle)\\otimes(\\frac{1}{\\sqrt{2}}|0\\rangle+\\frac{i}{\\sqrt{2}}|1\\rangle).\n$$\n\n---\n\n### Bell states\n\nWe\'ll now take a look as some important examples of multiple-qubit quantum states, beginning with the *Bell states*. These are the following four two-qubit states:\n$$\n|\\phi^+\\rangle=\\frac{1}{\\sqrt{2}}|00\\rangle+\\frac{1}{\\sqrt{2}}|11\\rangle$$$$\n|\\phi^-\\rangle=\\frac{1}{\\sqrt{2}}|00\\rangle-\\frac{1}{\\sqrt{2}}|11\\rangle$$$$\n|\\psi^+\\rangle=\\frac{1}{\\sqrt{2}}|01\\rangle+\\frac{1}{\\sqrt{2}}|10\\rangle$$$$\n|\\psi^-\\rangle=\\frac{1}{\\sqrt{2}}|01\\rangle-\\frac{1}{\\sqrt{2}}|10\\rangle$$\n$$\nall four of the Bell states represent entanglement between two qubits.\n\nThe collection of all four Bell states\n$$\n\\\\{|\\phi^+\\rangle,|\\phi^-\\rangle,|\\psi^+\\rangle,|\\psi^-\\rangle\\\\}\n$$\nis known as the **Bell basis**. True to its name, this is a basis; any quantum state vector of two qubits, or indeed any complex vector at all having entries corresponding to the four classical states of two bits, can be expressed as a linear combination of the four Bell states.\n\n---\n\n### GHZ and W states\n\nNext we will consider two interesting examples of states of three qubits. The first example is the **GHZ state**:\n$$\n\\frac{1}{\\sqrt{2}}|000\\rangle+\\frac{1}{\\sqrt{2}}|111\\rangle.\n$$\nThe second example is the so-called **W state**:\n$$\n\\frac{1}{\\sqrt{3}}|001\\rangle+\\frac{1}{\\sqrt{3}}|010\\rangle+\\frac{1}{\\sqrt{3}}|100\\rangle.\n$$\nNeither of these states is a product state.\n\n---\n\n### Additional examples\n\nThe examples of quantum states of multiple systems we\'ve seen so far are states of two or three qubits, but we can also consider quantum states of multiple systems having different classical state sets.\n\nHere\'s an example of a quantum state of three systems, $X$, $Y$, and $Z$, that all share the same classical state set $\\\\{0,1,2\\\\}$:\n$$\n\\frac{|012\\rangle-|021\\rangle+|120\\rangle-|102\\rangle+|201\\rangle-|210\\rangle}{\\sqrt{6}}.\n$$\nSystems having the classical state set $\\\\{0,1,2\\\\}$ are often called **trits** or (assuming that they can be in a quantum state) **qutrits**.\n\n---\n\n## Measurements of quantum states\n\nLet us suppose that $X_0,…,X_{n−1}$ are systems having classical state sets $\\Sigma_0,…,\\Sigma_{n−1}$, respectively. We may then view $(X_{n−1},…,X_0)$ collectively as a single system whose classical state set is the Cartesian product $\\Sigma_{n−1}\\times⋯\\times\\Sigma_0$. If a quantum state of this system is represented by the quantum state vector $|\\psi\\rangle$, and all of the systems are measured, then each possible outcome $(a_{n−1},…,a_0)\\in\\Sigma_{n−1}\\times⋯\\times\\Sigma_0$ appears with probability $|\\langle a_{n−1}⋯a_0|\\psi\\rangle|^2$.\n\n---\n\n### Partial measurements\n\nNow let us consider the situation in which we have multiple systems in some quantum state, and we measure a proper subset of the systems.\n\nIn general, a quantum state vector of $(X,Y)$ takes the form\n$$\n|\\psi\\rangle=\\sum_{(a,b)\\in\\Sigma\\times\\Gamma}\\alpha_{ab}|ab\\rangle,\n$$\nwhere $\\\\{\\alpha_{ab}:(a,b)\\in\\Sigma\\times\\Gamma\\\\}$ is a collection of complex numbers satisfying\n$$\n\\sum_{(a,b)\\in\\Sigma\\times\\Gamma}|\\alpha_{ab}|^2=1\n$$\nwhich is equivalent to $|\\psi\\rangle$ being a unit vector.\n\nIf we suppose instead that just the first system $X$ is measured, the probability for each outcome $a\\in\\Sigma$ to appear must therefore be equal to\n$$\n\\sum_{b\\in\\Gamma}|\\langle ab|\\psi\\rangle|^2=\\sum_{b\\in\\Gamma}|\\alpha_{ab}|^2.\n$$\nThis is consistent with what we already saw in the probabilistic setting, as well as our current understanding of physics: the probability for each outcome to appear when $X$ is measured can\'t possibly depend on whether or not $Y$ was also measured, as that would allow for faster-than-light communication. *(Or the information will be transmit in a moment.)*\n\nHaving obtained a particular outcome $a\\in\\Sigma$ of a standard basis measurement of $X$, we naturally expect that the quantum state of $X$ changes so that it is equal to $|a\\rangle$, just like we had for single systems. But what happens to the quantum state of $Y$?\n\nWe can first express the vector $|\\psi\\rangle$ as\n$$\n|\\psi\\rangle=\\sum_{a\\in\\Sigma}|a\\rangle\\otimes|\\phi_a\\rangle,\n$$\nwhere\n$$\n|\\phi_a\\rangle=\\sum_{b\\in\\Gamma}\\alpha_{ab}|b\\rangle\n$$\nfor each $a\\in\\Sigma$. Here we\'re following the same methodology as in the probabilistic case, of isolating the standard basis states of the system being measured. The probability for the standard basis measurement of $X$ to give each outcome $a$ is as follows:\n$$\n\\sum_{b\\in\\Gamma}|\\alpha_{ab}|^2=\\||\\phi_{a}\\rangle\\|^2.\n$$\nAnd, as a result of the standard basis measurement of $X$ giving the outcome $a$, the quantum state of the pair $(X,Y)$ together becomes\n$$\n|a\\rangle\\otimes\\frac{|\\phi_a\\rangle}{\\||\\phi_a\\rangle\\|}.\n$$\nThat is, the state "collapses" like in the single-system case, but only as far as is required for the state to be consistent with the measurement of $X$ having produced the outcome $a$.\n\nInformally speaking, $|a\\rangle\\otimes|\\phi_a\\rangle$ represents the component of $|\\psi\\rangle$ that is consistent with the a measurement of $X$ resulting in the outcome $a$. We then **normalize** this vector — by dividing it by its Euclidean norm, which is equal to $\\||\\phi_a\\rangle\\|$ — to obtain a valid quantum state vector having Euclidean norm equal to $1$.\n\nAs an example, consider the state of two qubits $(X,Y)$ from the beginning of the section:\n$$\n|\\psi\\rangle=\\frac{1}{\\sqrt{2}}|00\\rangle-\\frac{1}{\\sqrt{6}}|01\\rangle+\\frac{i}{\\sqrt{6}}|10\\rangle+\\frac{1}{\\sqrt{6}}|11\\rangle\n$$\nTo understand what happens when the first system $X$ is measured, we begin by writing\n$$\n|\\psi\\rangle=|0\\rangle\\otimes(\\frac{1}{\\sqrt{2}}|0\\rangle-\\frac{1}{\\sqrt{6}}|1\\rangle)+|1\\rangle\\otimes(\\frac{i}{\\sqrt{6}}|0\\rangle+\\frac{1}{\\sqrt{6}}|1\\rangle).\n$$\nBased on the description above, that the probability for the measurement to result in the outcome $0$ is\n$$\n\\|\\frac{1}{\\sqrt{2}}|0\\rangle-\\frac{1}{\\sqrt{6}}|1\\rangle\\|^2=\\frac{1}{2}+\\frac{1}{6}=\\frac{2}{3},\n$$\nin which case the state of $(X,Y)$ becomes\n$$\n|0\\rangle\\otimes\\frac{\\frac{1}{\\sqrt{2}}|0\\rangle-\\frac{1}{\\sqrt{6}}|1\\rangle}{\\sqrt{\\frac{2}{3}}}=|0\\rangle\\otimes(\\frac{\\sqrt{3}}{2}|0\\rangle-\\frac{1}{2}|1\\rangle);\n$$\nand the probability for the measurement to result in the outcome $1$ is\n$$\n\\|\\frac{i}{\\sqrt{6}}|0\\rangle+\\frac{1}{\\sqrt{6}}|1\\rangle\\|^2=\\frac{1}{6}+\\frac{1}{6}=\\frac{1}{3}\n$$\nin which case the state of $(X,Y)$ becomes\n$$\n|1\\rangle\\otimes\\frac{\\frac{i}{\\sqrt{6}}|0\\rangle+\\frac{1}{\\sqrt{6}}|1\\rangle}{\\sqrt{\\frac{1}{3}}}=|1\\rangle\\otimes(\\frac{i}{\\sqrt{2}}|0\\rangle+\\frac{1}{\\sqrt{2}}|1\\rangle)\n$$\nThe same technique, used in a symmetric way, describes what happens if the second system $Y$ is measured rather than the first. This time we rewrite the vector $|\\psi\\rangle$ as\n$$\n|\\psi\\rangle=(\\frac{1}{\\sqrt{2}}|0\\rangle+\\frac{i}{\\sqrt{6}}|1\\rangle)\\otimes|0\\rangle+(-\\frac{1}{\\sqrt{6}}|0\\rangle+\\frac{1}{\\sqrt{6}}|1\\rangle)\\otimes|1\\rangle\n$$\nThe probability that the measurement of $Y$ gives the outcome $0$ is\n$$\n\\|\\frac{1}{\\sqrt{2}}|0\\rangle+\\frac{i}{\\sqrt{6}}|1\\rangle\\|^2=\\frac{1}{2}+\\frac{1}{6}=\\frac{2}{3}\n$$\nin which case the state of $(X,Y)$ becomes\n$$\n\\frac{\\frac{1}{\\sqrt{2}}|0\\rangle+\\frac{i}{\\sqrt{6}}|1\\rangle}{\\sqrt{\\frac{2}{3}}}\\otimes|0\\rangle=(\\frac{\\sqrt{3}}{2}|0\\rangle+\\frac{i}{2}|1\\rangle)\\otimes|0\\rangle;\n$$\nand the probability that the measurement outcome is $1$ is\n$$\n\\|-\\frac{1}{\\sqrt{6}}|0\\rangle+\\frac{1}{\\sqrt{6}}|1\\rangle\\|^2=\\frac{1}{6}+\\frac{1}{6}=\\frac{1}{3},\n$$\nin which case the state of $(X,Y)$ becomes\n$$\n\\frac{-\\frac{1}{\\sqrt{6}}|0\\rangle+\\frac{1}{\\sqrt{6}}|1\\rangle}{\\frac{1}{\\sqrt{3}}}\\otimes|1\\rangle=(-\\frac{1}{\\sqrt{2}}|0\\rangle+\\frac{1}{\\sqrt{2}}|1\\rangle)\\otimes|1\\rangle.\n$$\n\n---\n\n## Unitary operations\n\nIn principle, any **unitary matrix** whose rows and columns correspond to the classical states of a system represents a valid quantum operation on that system. This, of course, remains true for compound systems, whose classical state sets happen to be Cartesian products of the classical state sets of the individual systems.\n\nFor example, let us suppose that $\\Sigma=\\\\{1,2,3\\\\}$ and $\\Gamma=\\\\{0,1\\\\}$, and recall that the standard convention for ordering the elements of the Cartesian product $\\\\{1,2,3\\\\}\\times\\\\{0,1\\\\}$ is this:\n$$\n(1,0),  (1,1),  (2,0),  (2,1),  (3,0),  (3,1).\n$$\nHere\'s an example of a unitary matrix representing an operation on $(X,Y)$:\n$$\nU=\\begin{pmatrix}\n&\\frac{1}{2}&\\frac{1}{2}&\\frac{1}{2}&0&0&\\frac{1}{2}\\\\\\\\\n&\\frac{1}{2}&\\frac{i}{2}&-\\frac{1}{2}&0&0&-\\frac{i}{2}\\\\\\\\\n&\\frac{1}{2}&-\\frac{1}{2}&\\frac{1}{2}&0&0&-\\frac{1}{2}\\\\\\\\\n&0&0&0&\\frac{1}{\\sqrt{2}}&\\frac{1}{\\sqrt{2}}&0\\\\\\\\\n&\\frac{1}{2}&-\\frac{i}{2}&-\\frac{1}{2}&0&0&\\frac{i}{2}\\\\\\\\\n&0&0&0&-\\frac{1}{\\sqrt{2}}&\\frac{1}{\\sqrt{2}}&0\\\\\\\\\n\\end{pmatrix}\n$$\nTo check that $U$ is unitary, it suffices to compute and check that $U^†U=I$, for instance. Alternatively, we can check that the rows (or the columns) are orthonormal, which is made simpler in this case given the particular form of the matrix $U$.\n\nThe action of $U$ on the standard basis vector $|1,1\\rangle$, for instance, is\n$$\nU|1,1\\rangle=\\frac{1}{2}|1,0\\rangle+\\frac{i}{2}|1,1\\rangle-\\frac{1}{2}|2,0\\rangle-\\frac{i}{2}|3,0\\rangle,\n$$\nwhich we can see by examining the second column of $U$ considering our ordering of the set $\\\\{1,2,3\\\\}\\times\\\\{0,1\\\\}$.\n\n### Unitary operations performed independently on individual systems\n\nThe combined action of a collection of unitary operations applied independently to a collection of systems is represented by the **tensor product** of the unitary matrices.\n\nIf $X_0,…,X_{n−1}$ are quantum systems, $U_0,…,U_{n−1}$ are unitary matrices representing operations on these systems, and the operations are performed independently on the systems, the combined action on $(X_{n−1},…,X_0)$ is represented by the matrix $U_{n−1}\\otimes⋯\\otimes U_0$. We can prove that $U_{n−1}\\otimes⋯\\otimes U_0$ is unitary.\n\nTo say that we perform the operation represented by $U$ just on the system $X$ implies that we do nothing to $Y$, meaning that we independently perform $U$ on $X$ and the **identity operation** on $Y$. That is, "doing nothing" to $Y$ is equivalent to performing the identity operation on $Y$, which is represented by the identity matrix $\\mathbb{I}_Y$.\n\nThe operation on $(X,Y)$ that is obtained when we perform $U$ on $X$ and do nothing to $Y$ is therefore represented by the unitary matrix\n$$\nU\\otimes\\mathbb I_Y.\n$$\nFor example, if $X$ and $Y$ are qubits, performing a Hadamard operation on $X$ and doing nothing to $Y$ is equivalent to performing the operation\n$$\nH\\otimes\\mathbb I_Y=\\begin{pmatrix}\\frac{1}{\\sqrt{2}}&\\frac{1}{\\sqrt{2}}\\\\\\\\\\frac{1}{\\sqrt{2}}&-\\frac{1}{\\sqrt{2}}\\end{pmatrix}\\otimes\\begin{pmatrix}1&0\\\\\\\\0&1\\end{pmatrix}=\\begin{pmatrix}\\frac{1}{\\sqrt{2}}&0&\\frac{1}{\\sqrt{2}}&0\\\\\\\\0&\\frac{1}{\\sqrt{2}}&0&\\frac{1}{\\sqrt{2}}\\\\\\\\\\frac{1}{\\sqrt{2}}&0&-\\frac{1}{\\sqrt{2}}&0\\\\\\\\0&\\frac{1}{\\sqrt{2}}&0&-\\frac{1}{\\sqrt{2}}\\end{pmatrix}\n$$\non the joint system $(X,Y)$.\n\n---\n\n### The swap operation\n\nNot every unitary operation on a collection of systems can be written as a tensor product of unitary operations like this, just as not every quantum state vector of these systems is a product state.\n\nThe **swap** operation on the pair $(X,Y)$ is the operation that exchanges the contents of the two systems, but otherwise leaves the systems alone — so that $X$ remains on the left and $Y$ remains on the right. We\'ll denote this operation as $SWAP$, and it operates like this for every choice of classical states $a,b\\in\\Sigma$:\n$$\n\\mathbf{SWAP}|a\\rangle|b\\rangle=|b\\rangle|a\\rangle.\n$$\nOne way to write the matrix associated with this operation using the Dirac notation is as follows:\n$$\n\\mathbf{SWAP}=\\sum_{c,d\\in\\Sigma}|c\\rangle\\langle d|\\otimes|d\\rangle\\langle c|.\n$$\nAs a simple example, when $X$ and $Y$ are qubits, we find that\n$$\n\\mathbf{SWAP}=\\begin{pmatrix}1&0&0&0\\\\\\\\0&0&1&0\\\\\\\\0&1&0&0\\\\\\\\0&0&0&1\\end{pmatrix}.\n$$\n\n---\n\n### Controlled-unitary operations\n\nNow let us suppose that $Q$ is a qubit and $R$ is an arbitrary system, having whatever classical state set we wish. For every unitary operation $U$ acting on the system $R$, a **controlled-U** operation is a unitary operation on the pair $(Q,R)$ defined as follows:\n$$\nCU=|0\\rangle\\langle0|\\otimes I_R+|1\\rangle\\langle 1|\\otimes U.\n$$\nIf instead we take $R$ to be two qubits, and we take $U$ to be the **swap operation** between these two qubits, we obtain this operation:\n$$\n\\mathbf{CSWAP}=\\begin{pmatrix}1&0&0&0&0&0&0&0\\\\\\\\0&1&0&0&0&0&0&0\\\\\\\\0&0&1&0&0&0&0&0\\\\\\\\0&0&0&1&0&0&0&0\\\\\\\\0&0&0&0&1&0&0&0\\\\\\\\0&0&0&0&0&0&1&0\\\\\\\\0&0&0&0&0&1&0&0\\\\\\\\0&0&0&0&0&0&0&1\\end{pmatrix}.\n$$\nThis operation is also known as a **Fredkin operation**, or more commonly, a **Fredkin gate**, Its action on standard basis states can be described as follows:\n$$\n\\mathbf{CSWAP}|0bc\\rangle=|0bc\\rangle\\\\\\\\\n\\mathbf{CSWAP}|1bc\\rangle=|1cb\\rangle.\n$$\nFinally, a **controlled-controlled-NOT operation**, which we may denote as $CCX$ is called a **Toffoli operation** or **Toffoli gate**. Its matrix representation looks like this:\n$$\n\\mathbf{CCX}=\\begin{pmatrix}1&0&0&0&0&0&0&0\\\\\\\\0&1&0&0&0&0&0&0\\\\\\\\0&0&1&0&0&0&0&0\\\\\\\\0&0&0&1&0&0&0&0\\\\\\\\0&0&0&0&1&0&0&0\\\\\\\\0&0&0&0&0&1&0&0\\\\\\\\0&0&0&0&0&0&0&1\\\\\\\\0&0&0&0&0&0&1&0\\end{pmatrix}.\n$$\nWe may alternatively express it using the Dirac notation as follows:\n$$\nCCX=(|00\\rangle\\langle 00|+|01\\rangle\\langle 01|+|10\\rangle\\langle 10|)\\otimes I+|11\\rangle\\langle 11|\\otimes X.\n$$\n\n---\n\n# Quantum Circuits\n\nIn the **quantum circuit model**, **wires represent qubits** and **gates represent operations** on these qubits. We\'ll focus for now on operations we\'ve encountered so far, namely **unitary operations** and **standard basis measurements**. As we learn about other sorts of quantum operations and measurements, we can enhance our model accordingly.\n\nHere\'s a simple example of a quantum circuit:\n\n```\nX————H——S——H——T——\n```\n\n$$\nTHSH=\\begin{pmatrix}\\frac{1+i}{2}&\\frac{1-i}{2}\\\\\\\\\\frac{1}{\\sqrt{2}}&\\frac{i}{\\sqrt{2}}\\end{pmatrix}\n$$\n\nFor example, if we apply the operation $THSH$ to the state $|0\\rangle$, we obtain the state $\\frac{1+i}{2}|0\\rangle+\\frac{1}{\\sqrt{2}}|1\\rangle$.\n\nHere\'s another example of a quantum circuit, this time with two qubits:\n\n(Before this, remember ordering qubits from **bottom-to-top** is equivalent to ordering them **left-to-right**.)\n\n```\nY————H——·——\n        |\nX———————+——\n```\n\nNothing happening is equivalent to the identity operation being performed. The dotted rectangle in the figure above therefore represents this operation:\n$$\n\\mathbb{I}\\otimes H=\\begin{pmatrix}\\frac{1}{\\sqrt{2}}&\\frac{1}{\\sqrt{2}}&0&0\\\\\\\\\\frac{1}{\\sqrt{2}}&-\\frac{1}{\\sqrt{2}}&0&0\\\\\\\\0&0&\\frac{1}{\\sqrt{2}}&\\frac{1}{\\sqrt{2}}\\\\\\\\0&0&\\frac{1}{\\sqrt{2}}&-\\frac{1}{\\sqrt{2}}\\end{pmatrix}.\n$$\nGiven that we order the qubits as $(X,Y)$, with $X$ being on the bottom and $Y$ being on the top of our circuit, the matrix representation of the **controlled-NOT gate** is this:\n$$\n\\begin{pmatrix}1&0&0&0\\\\\\\\0&0&0&1\\\\\\\\0&0&1&0\\\\\\\\0&1&0&0\\end{pmatrix}.\n$$\nThe unitary operation implemented by the entire circuit, which we\'ll give the name $U$, is the composition of the operations:\n$$\nU=\\begin{pmatrix}1&0&0&0\\\\\\\\0&0&0&1\\\\\\\\0&0&1&0\\\\\\\\0&1&0&0\\end{pmatrix}\\otimes\\begin{pmatrix}\\frac{1}{\\sqrt{2}}&\\frac{1}{\\sqrt{2}}&0&0\\\\\\\\\\frac{1}{\\sqrt{2}}&-\\frac{1}{\\sqrt{2}}&0&0\\\\\\\\0&0&\\frac{1}{\\sqrt{2}}&\\frac{1}{\\sqrt{2}}\\\\\\\\0&0&\\frac{1}{\\sqrt{2}}&-\\frac{1}{\\sqrt{2}}\\end{pmatrix}=\\begin{pmatrix}\\frac{1}{\\sqrt{2}}&\\frac{1}{\\sqrt{2}}&0&0\\\\\\\\0&0&\\frac{1}{\\sqrt{2}}&-\\frac{1}{\\sqrt{2}}\\\\\\\\0&0&\\frac{1}{\\sqrt{2}}&\\frac{1}{\\sqrt{2}}\\\\\\\\\\frac{1}{\\sqrt{2}}&-\\frac{1}{\\sqrt{2}}&0&0\\end{pmatrix}\n$$\nHere are some examples of symbols used to denote gates that commonly appear in circuit diagrams:\n\n- **Single-qubit gates** are generally shown as squares with a letter indicating which operation it is, like this:\n\n  ```\n  ——X—— ——Y—— ——Z——\n  ——H—— ——S—— ——T——\n  ```\n\n- **Not gates (or equivalently, $X$​ gates)** are also sometimes denoted by a circle around a plus sign:\n\n  ```\n  ——+——\n  ```\n\n- **Swap gates** are denoted as follows:\n\n  ```\n  ——x——\n    |\n  ——x——\n  ```\n\n- **Controlled-gates**. For instance, controlled-NOT gates, controlled-controlled-NOT (or Toffoli) gates, and controlled-swap (Fredkin) gates are denoted like this:\n\n  ```\n  ——·——    ——·——    ——·——\n    |        |        |\n  ——+——    ——·——    ——x——\n             |        |\n           ——+——    ——x——\n  ```\n\n- **Arbitrary unitary operations on multiple qubits may be viewed as gates**. For instance, here is a depiction of an (unspecified) unitary operation $U$ as a gate, along with a controlled version of this gate:\n\n  ```\n  ————         ————                  ————————·————————\n  ————         ————                          |\n  ————    U    ————                  ————         ————\n  ————         ————                  ————    U    ————\n  ————         ————                  ————         ————\n  ```\n\n  \n\n## Inner products and projections\n\n### Inner products\n\nRecall that when we use the Dirac notation to refer to an arbitrary column vector as a **ket**, such as\n$$\n|\\psi\\rangle=\\begin{pmatrix}\\alpha_1\\\\\\\\\\alpha_2\\\\\\\\\\vdots\\\\\\\\\\alpha_n\\end{pmatrix},\n$$\nthe corresponding **bra** vector is the **conjugate transpose** of this vector:\n$$\n\\langle\\psi|=(|\\psi\\rangle)^†=(\\overline{\\alpha_1}\\ \\overline{\\alpha_2}\\ \\dots\\ \\overline{\\alpha_n}).\n$$\nAlternatively, if we have some classical state set $\\Sigma$ in mind, and we express a column vector as a **ket**, such as\n$$\n|\\psi\\rangle=\\sum_{a\\in\\Sigma}\\alpha_a|a\\rangle,\n$$\nthen the corresponding **row (or bra)** vector is the conjugate transpose\n$$\n\\langle\\psi|=\\sum_{a\\in\\Sigma}\\overline{\\alpha_a}\\langle a|.\n$$\nSpecifically, if we have two column vectors\n$$\n|\\psi\\rangle=\\begin{pmatrix}\\alpha_1\\\\\\\\\\alpha_2\\\\\\\\\\vdots\\\\\\\\\\alpha_n\\end{pmatrix}\\ \\text{and}\\ |\\phi\\rangle=\\begin{pmatrix}\\beta_1\\\\\\\\\\beta_2\\\\\\\\\\vdots\\\\\\\\\\beta_n\\end{pmatrix},\n$$\nthen\n$$\n\\langle\\psi|\\phi\\rangle=(\\overline{\\alpha_1}\\ \\overline{\\alpha_2}\\ \\dots\\ \\overline{\\alpha_n})\\begin{pmatrix}\\beta_1\\\\\\\\\\beta_2\\\\\\\\\\vdots\\\\\\\\\\beta_n\\end{pmatrix}=\\overline{\\alpha_1}\\beta_1+\\dots+\\overline{\\alpha_n}\\beta_n.\n$$\nThe value $\\langle\\psi|\\phi\\rangle$ is called the **inner product** between the vectors $|\\psi\\rangle$ and $|\\phi\\rangle$.\n\nLet us now collect together some basic facts about inner products of vectors.\n\n1. **Relationship to the Euclidean norm**.\n   The inner product of any vector with itself is\n   $$\n   \\langle\\psi|\\psi\\rangle=\\sum_{a\\in\\Sigma}\\overline{\\alpha_a}\\alpha_a=\\sum_{a\\in\\Sigma}|\\alpha_a|^2=\\||\\psi\\rangle\\|^2.\n   $$\n   Thus, the Euclidean norm of a vector may alternatively be expressed as\n   $$\n   \\||\\psi\\rangle\\|=\\sqrt{\\langle\\psi|\\psi\\rangle}.\n   $$\n   \n2. **Conjugate symmetry**.\n   For any two vectors we have\n   $$\n   \\overline{\\langle\\psi|\\phi\\rangle}=\\langle\\phi|\\psi\\rangle.\n   $$\n\n3. **Linearity in the second argument (and conjugate linearity in the first)**\n\n   If we define a new vector \n   $$\n   |\\phi\\rangle=\\alpha_1|\\phi_1\\rangle+\\alpha_2|\\phi_2\\rangle\n   $$\n   then\n   $$\n   \\langle\\psi|\\phi\\rangle=\\langle\\psi|(\\alpha_1|\\phi_1\\rangle+\\alpha_2|\\phi_2\\rangle)=\\alpha_1\\langle\\psi|\\phi_1\\rangle+\\alpha_2\\langle\\psi|\\phi_2\\rangle.\n   $$\n\n4. **The Cauchy–Schwarz inequality**.\n   For every choice of vectors $|\\phi\\rangle$ and $|\\psi\\rangle$​ having the same number of entries, we have\n   $$\n   |\\langle\\psi|\\phi\\rangle|\\le\\||\\psi\\rangle\\|\\||\\phi\\rangle\\|.\n   $$\n\n---\n\n### Orthogonal and orthonormal sets\n\nTwo vectors are said to be **orthogonal** if their inner product is zero:\n$$\n\\langle\\psi|\\phi\\rangle=0.\n$$\nA set of vectors $\\\\{|\\psi_1\\rangle,…,|\\psi_m\\rangle\\\\}$ is called an **orthogonal set** if every vector in the set is orthogonal to every other vector in the set.\n\nA set of vectors $\\\\{|\\psi_1\\rangle,…,|\\psi_m\\rangle\\\\}$ is called an **orthonormal set** if it is an **orthogonal set** and, in addition, every vector in the set is a unit vector.\n\nFinally, a set $\\\\{|\\psi_1\\rangle,…,|\\psi_m\\rangle\\\\}$ is an **orthonormal basis** if, in addition to being an orthonormal set, it forms a basis.\n\n---\n\n### Projections and projective measurements\n\nA square matrix $\\Pi$ is called a **projection** if it satisfies two properties:\n\n1. $\\Pi=\\Pi^†$.\n2. $\\Pi^2=\\Pi$.\n\nMatrices that satisfy the first condition are called **Hermitian matrices**, and matrices that satisfy the second condition are called **idempotent matrices**.\n\n> As a word of caution, the word **projection** is sometimes used to refer to any matrix that satisfies just the second condition but not necessarily the first, and when this is done the term **orthogonal projection** is typically used to refer to matrices satisfying both properties. \n>\n> In the context of quantum information and computation, however, the terms **projection** and **projection matrix** more typically refer to matrices satisfying both conditions.\n\nGenerally, if $\\\\{|\\psi_1\\rangle,…,|\\psi_m\\rangle\\\\}$ is any orthonormal set of vectors, then the matrix\n$$\n\\Pi=\\sum_{k=1}^m|\\psi_k\\rangle\\langle\\psi_k|\n$$\nis a projection.\n\nIn fact, this exhausts all of the possibilities: **every** projection $\\Pi$ can be written in the form below for some choice of an orthonormal set $\\\\{|\\psi_1\\rangle,…,|\\psi_m\\rangle\\\\}$.\n\n---\n\n### Projective measurements\n\nGenerally, for any finite and nonempty set $\\Sigma$, if we have a collection of projection matrices\n$$\n\\\\{\\Pi_a:a\\in\\Sigma\\\\}\n$$\nthat satisfies the condition\n$$\n\\sum_{a\\in\\Sigma}\\Pi_a=\\mathbb{I},\n$$\nthen this collection describes a projective measurement whose possible outcomes coincide with the set $\\Sigma$:\n\n1. For each $a\\in\\Sigma$, the outcome of the measurement is $a$ with probability equal to\n   $$\n   \\text{Pr}(\\text{outcome is }a)=\\|\\Pi_a|\\psi\\rangle\\|^2.\n   $$\n\n2. For whichever outcome $a$ the measurement produces, the state of $X$​ becomes\n   $$\n   \\frac{\\Pi_a|\\psi\\rangle}{\\|\\Pi_a|\\psi\\rangle\\|}.\n   $$\n\nTo be precise, let us suppose that we have two systems $(X,Y)$ in a quantum state $|\\psi\\rangle$, and a projective measurement described by a collection $\\\\{\\Pi_a:a\\in\\Sigma\\\\}$ is performed on the system $X$, while nothing is done to $Y$. Doing this is then equivalent to performing the projective measurement described by the collection\n$$\n\\\\{\\Pi_a\\otimes\\mathbb{I}:a\\in\\Sigma\\\\}\n$$\non the joint system $(X,Y)$. Each measurement outcome $a$ results with probability\n$$\n\\|(\\Pi_a\\otimes\\mathbb{I})|\\psi\\rangle\\|^2,\n$$\nand conditioned on the result $a$ appearing, the state of the joint system $(X,Y)$ becomes\n$$\n\\frac{(\\Pi_a\\otimes\\mathbb{I})|\\psi\\rangle}{\\|(\\Pi_a\\otimes\\mathbb{I})|\\psi\\rangle\\|}.\n$$\n\n---\n\n### Implementing projective measurements\n\nLet us suppose that $X$ is a system and $\\\\{\\Pi_0,…,\\Pi_{m−1}\\\\}$ is a projective measurement on $X$. We can easily generalize this discussion to projective measurements having different sets of outcomes, but in the interest of convenience and simplicity we will assume the set of possible outcomes for our measurement is $\\\\{0,…,m−1\\\\}$.\n\nLet us note explicitly that $m$ is not necessarily equal to the number of classical states of $X$ — we\'ll let $n$ be the number of classical states of $X$, which means that each matrix $\\Pi_k$ is an $n\\times n$ projection matrix.\n\nBecause we assume that $\\\\{\\Pi_0…,\\Pi_{m−1}\\\\}$ represents a projective measurement, it is necessarily the case that\n$$\n\\sum_{k=0}^{m-1}\\Pi_k=\\mathbb{I}_n.\n$$\nLet\'s perform the projective measurement on $X$ by using only **unitary operations** and **standard basis measurements**.\n\nWe will make use of an extra workspace system $Y$ to do this, and specifically we\'ll take the classical state set of $Y$ to be $\\\\{0,…,m−1\\\\}$, which is the same as the set of outcomes of the projective measurement.\n\nThe idea is that we will perform a standard basis measurement on $Y$, and interpret the outcome of this measurement as being equivalent to the outcome of the projective measurement on $X$. We\'ll need to assume that $Y$ is initialized to some fixed state, which we\'ll choose to be $|0\\rangle$.\n\nOf course, in order for a standard basis measurement of $Y$ to tell us anything about $X$, we will need to allow $X$ and $Y$ to interact somehow before measuring $Y$, by performing a unitary operation on the system $(Y,X)$. First consider this matrix:\n$$\nM=\\sum_{k=0}^{m-1}|k\\rangle\\langle0|\\otimes\\Pi_k.\n$$\nExpressed explicitly as a so-called **block matrix**, which is essentially a matrix of matrices that we interpret as a single, larger matrix, $M$ looks like this:\n$$\nM=\\begin{pmatrix}\\Pi_0&0&\\dots&0\\\\\\\\\\Pi_1&0&\\dots&0\\\\\\\\\\vdots&\\vdots&\\ddots&\\vdots\\\\\\\\\\Pi_{m-1}&0&\\dots&0\\\\\\\\\\end{pmatrix}.\n$$\n\n> Here, each $0$ represents an $n\\times n$ matrix filled entirely with zeros, so that the entire matrix $M$ is an $nm\\times nm$ matrix.\n\nIt is the case that the first $n$ columns of $M$ are orthonormal.\n\nTo verify this claim, notice that for each $j\\in\\\\{0,…,n−1\\\\}$, the vector formed by column number $j$ of $M$ is as follows:\n$$\n|\\psi_j\\rangle=M|0,j\\rangle=\\sum_{k=0}^{m-1}|k\\rangle\\otimes\\Pi_k|j\\rangle.\n$$\nNote that here we\'re numbering the columns starting from column $0$. Taking the inner product of column $i$ with column $j$ when $i,j\\in\\\\{0,…,n−1\\\\}$ gives\n$$\n\\begin{align}\n\\langle\\psi_i|\\psi_j\\rangle&=(\\sum_{k=0}^{m-1}|k\\rangle\\otimes\\Pi_k|i\\rangle)^†(\\sum_{l=0}^{m-1}|l\\rangle\\otimes\\Pi_l|j\\rangle)\\\\\\\\\n&=\\sum_{k=1}^{m-1}\\sum_{l=0}^{m-1}\\langle k|l\\rangle\\langle i|\\Pi_k\\Pi_l|j\\rangle\\\\\\\\\n&=\\sum_{k=0}^{m-1}\\langle i|\\Pi_k\\Pi_k|j\\rangle\\\\\\\\\n&=\\sum_{k=0}^{m-1}\\langle i|\\Pi_k|j\\rangle\\\\\\\\\n&=\\langle i|\\mathbb{I}|j\\rangle\\\\\\\\\n&=\\left\\\\{\\begin{aligned}\n1&&i=j\\\\\n0&&i\ne j\n\\end{aligned}\\right.\n\\end{align}\n$$\nwhich is what we needed to show.\n\nFinally we can describe the measurement process: we first perform $U$ on the joint system $(Y,X)$ and then measure $Y$ with respect to a standard basis measurement. For an arbitrary state $|\\phi\\rangle$ of $X$, we obtain the state\n$$\nU(|0\\rangle|\\phi\\rangle)=M(|0\\rangle|\\phi\\rangle)=\\sum_{k=0}^{m-1}|k\\rangle\\otimes\\Pi_k|\\phi\\rangle,\n$$\nwhere the first equality follows from the fact that $U$ and $M$ agree on their first $n$ columns. When we perform a projective measurement on $Y$, we obtain each outcome $k$ with probability\n$$\n\\|\\Pi_k|\\phi\\rangle\\|^2,\n$$\nin which case the state of $(Y,X)$ becomes\n$$\n|k\\rangle\\otimes\\frac{\\Pi_k|\\phi\\rangle}{\\|\\Pi_k|\\phi\\rangle\\|}.\n$$\nThus, $Y$ stores a copy of the measurement outcome and $X$ changes precisely as it would had the projective measurement described by $\\\\{\\Pi_0,…,\\Pi_{m−1}\\\\}$ been performed directly on $X$.\n\n---\n\n## Limitations on quantum information\n\n### Irrelevance of global phases\n\nSuppose that there exists a complex number $\\alpha$ on the unit circle meaning $\\alpha=e^{i\\theta}$ , such that $|\\phi\\rangle=\\alpha|\\psi\\rangle$.\n\nThe vectors $|\\psi\\rangle$ and $|\\phi\\rangle$ are then said to **differ by a global phase**. \n\nAs the system is in the state $|\\psi\\rangle$, the probability of measuring any given classical state $a$ is\n$$\n|\\langle a|\\psi\\rangle|^2.\n$$\nMeanwhile, $|\\alpha|=1$ , so\n$$\n|\\langle a|\\psi\\rangle|^2=|\\langle\\alpha|\\phi\\rangle|^2.\n$$\nThat means two quantum state vectors that differ by a global phase are considered to be **equivalent**, and are effectively viewed as **being the same state**.\n\nIn particular, performing a **Hadamard operation** and then **measuring** yields outcome probabilities as follows:\n$$\n|\\langle0|H|+\\rangle|^2=1\\\\\n|\\langle0|H|-\\rangle|^2=0\\\\\n|\\langle1|H|+\\rangle|^2=0\\\\\n|\\langle1|H|-\\rangle|^2=1.\n$$\n\n---\n\n### No-cloning theorem\n\nLet $\\Sigma$ be a classical state set having at least two elements, and let $X$ and $Y$ be systems sharing the same classical state set $\\Sigma$. There does **not** exist a quantum state $|\\phi\\rangle$ of $Y$ and a unitary operation $U$ on the pair $(X,Y)$ such that\n$$\nU(|\\psi\\rangle\\otimes|\\phi\\rangle)=|\\psi\\rangle\\otimes|\\psi\\rangle\n$$\nfor every state $|\\psi\\rangle$ of $X$.\n\nThe proof of this theorem is actually quite simple: it boils down to the observation that the mapping\n$$\n|\\psi\\rangle\\otimes|\\phi\\rangle↦|\\psi\\rangle\\otimes|\\psi\\rangle\n$$\nis not linear in $|\\psi\\rangle$.\n\n---\n\n### Non-orthogonal states cannot be perfectly discriminated\n\nIf we have two quantum states $|\\psi\\rangle$ and $|\\phi\\rangle$ that are not orthogonal, then it\'s **impossible** to discriminate them perfectly.' 
                      },
                      { id: 'quantum information-2', 
                        title: '2、Fundamentals of quantum algorithms', 
                        desc: '', 
                        content: '# Quantum query algorithms\n\n## The query model of computation\n\n### Description of the model\n\nWe\'re going to be working exclusively with binary strings in this lesson, as opposed to strings containing different symbols, so let\'s write $\\Sigma=\\\\{0,1\\\\}$ hereafter to refer to the binary alphabet for convenience.\n\nAll of the input will be represented by a function taking the form\n$$\nf:\\Sigma^n\\to\\Sigma^m\n$$\nfor two positive integers $n$ and $m$.\n\nTo say that a computation makes a **query** means that some string $x\\in\\Sigma^n$ is selected, and then the string $f(x)\\in\\Sigma^m$ is made available to the computation by the oracle.\n\nFinally, the way that we\'ll measure efficiency of query algorithms is simple: we\'ll count the **number of queries** they require.\n\n---\n\n### Examples of query problems\n\n- **Or**\n\n  Input：$f:\\Sigma^n\\to\\Sigma$\n\n  Output：$\\begin{align}&1\\text{ if there exists a string }x\\in\\Sigma^n\\text{ for which }f(x)=1\\\\\\\\&0\\text{ if there is no such string}\\end{align}$\n- **Parity**\n\n  Input：$f:\\Sigma^n\\to\\Sigma$\n\n  Output：$\\begin{align}&0\\text{ if }f(x)=1\\text{ for an even number of string }x\\in\\Sigma^n\\\\\\\\&1\\text{ if }f(x)=1\\text{ for an odd number of string }x\\in\\Sigma^n\\end{align}$\n- **Minimum**\n\n  Input：$f:\\Sigma^n\\to\\Sigma^m$\n\n  Output：$\\text{The string }y\\in\\\\{f(x):x\\in\\Sigma^n\\\\}\\text{ that comes first in the lexicographic ordering of }\\Sigma^m$\n\nWe also consider query problems where we have a **promise** on the input.\n\nNo requirements at all are placed on algorithms when they\'re given "don\'t care" inputs.\n\nHere\'s one example of a problem with a promise:\n\n- **Unique search.** The input function takes the form $f:\\Sigma^n\\to\\Sigma$, and we are **promised** that there is exactly one string $z\\in\\Sigma$ for which $f(z)=1$, with $f(x)=0$ for all strings $x≠z$. The task is to find this unique string $z$.\n\n---\n\n### Query gates\n\nThe simplest way to define query gates for classical Boolean circuits is to simply allow them to compute the input function $f$ directly, as the following figure suggests.\n\n```\n  ——————\n  ——————             ——————\n  ——————             ——————\nx ——————      f      ——————  f(x)\n  ——————             ——————\n  ——————             ——————\n  ——————\n```\n\nWhen a **Boolean circuit** is created for a query problem, the input function $f$ is accessed through these gates, and **the number of queries** that the circuit makes is simply **the number of query gates** that appear in the circuit. The input wires of the Boolean circuit itself are initialized to **fixed values**, which should be considered as **part of the algorithm**.\n\n```\n  ——————         ——————\nx ——————         —————— |x⟩\n  ——————         ——————\n           U_f   \n  ——————         ——————\ny ——————         —————— |y⊕f(x)⟩\n  ——————         ——————\n```\n\nHere, our assumption is that $x\\in\\Sigma^n$ and $y\\in\\Sigma^m$ are arbitrary strings.\n\nIntuitively speaking, what the gate $U_f$ does (for any chosen function $f$) is to echo the top input string $x$ and XOR the function value $f(x)$ onto the bottom input string $y$, which is a unitary operation for every choice for the function $f$.\n\n---\n\n## Deutsch\'s algorithm\n\nDeutsch\'s algorithm solves the parity problem for the special case that $n=1$.\n\nTo be precise, the input is represented by a function $f:\\Sigma\\to\\Sigma$ from one bit to one bit. There are four such functions:\n$$\n\\begin{array}{c|cc}\na & f_1(a) \\\\\\\\\n\\hline\n0 & 0 \\\\\\\\\n1 & 0\n\\end{array}\n\\ \\ \\ \\\n\\begin{array}{c|cc}\na & f_2(a) \\\\\\\\\n\\hline\n0 & 0 \\\\\\\\\n1 & 1\n\\end{array}\n\\ \\ \\ \\\n\\begin{array}{c|cc}\na & f_3(a) \\\\\\\\\n\\hline\n0 & 1 \\\\\\\\\n1 & 0\n\\end{array}\n\\ \\ \\ \\\n\\begin{array}{c|cc}\na & f_4(a) \\\\\\\\\n\\hline\n0 & 1 \\\\\\\\\n1 & 1\n\\end{array}\n$$\nThe first and last of these functions are **constant** and the middle two are **balanced**. Deutsch\'s problem is to determine which of these two categories the input function belongs to: **constant or balanced**.\n\n> Deutsch\'s problem\n>\n> Input: a function $f:\\\\{0,1\\\\}\\to\\\\{0,1\\\\}$\n\n> Output: 0 if $f$ is constant, 1 if $f$ is balanced\n\n### Quantum circuit description\n\nDeutsch\'s algorithm solves Deutsch\'s problem using a single query, therefore providing a quantifiable advantage of quantum over classical computations.\n\nHere is a quantum circuit that describes Deutsch\'s algorithm:\n\n```\n                                                             0 if f is constant\n|0⟩ —————— H ——————      —————— H —————— (Measurement) ===\n                    U_f                                      1 if f is balanced\n|1⟩ —————— H ——————      —————————————————————————————————\n\n             |pi_1⟩      |pi_2⟩    |pi_3⟩\n```\n\n### Analysis\n\nThe initial state is $|1\\rangle|0\\rangle$, and the two Hadamard operations on the left-hand side of the circuit transform this state to\n$$\n|\\pi_1\\rangle=|-\\rangle|+\\rangle=\\frac{1}{2}(|0\\rangle-|1\\rangle)|0\\rangle+\\frac{1}{2}(|0\\rangle-|1\\rangle)|1\\rangle.\n$$\n\n> As always, we\'re following Qiskit\'s qubit ordering convention, which puts the top qubit to the right and the bottom qubit to the left.\n\nNext, the $U_f$ gate is performed. According to the definition of the $U_f$ gate, the value of the function $f$ for the classical state of the top/rightmost qubit is XORed onto the bottom/leftmost qubit, which transforms $|\\pi_1\\rangle$ into the state\n$$\n|\\pi_2\\rangle=\\frac{1}{2}(|0\\oplus f(0)\\rangle-|1\\oplus f(0)\\rangle)|0\\rangle+\\frac{1}{2}(|0\\oplus f(1)\\rangle-|1\\oplus f(1)\\rangle)|1\\rangle.\n$$\nWe can alternatively express $|\\pi_2\\rangle$ like this:\n$$\n|\\pi_2\\rangle=|-\\rangle(\\frac{(-1)^{f(0)}|0\\rangle+(-1)^{f(1)}|1\\rangle}{\\sqrt{2}}).\n$$\nWith one final simplification, which is to pull the factor of $(−1)^{f(0)}$ outside of the sum, we obtain this expression of the state $|\\pi_2\\rangle$:\n$$\n|\\pi_2\\rangle=(-1)^{f(0)}|-\\rangle(\\frac{|0\\rangle+(-1)^{f(0)\\oplus f(1)}|1\\rangle}{\\sqrt{2}})\\\\\\\\\n=\\begin{cases} (-1)^{f(0)}|-\\rangle|+\\rangle & \\text{if }f(0)\\oplus f(1)=0 \\\\\\\\ (-1)^{f(0)}|-\\rangle|-\\rangle & \\text{if }f(0)\\oplus f(1)=1 \\end{cases}\n$$\nApplying the final Hadamard gate to the top qubit leaves us with the state\n$$\n|\\pi_3\\rangle=\\begin{cases} (-1)^{f(0)}|-\\rangle|0\\rangle & \\text{if }f(0)\\oplus f(1)=0 \\\\\\\\ (-1)^{f(0)}|-\\rangle|1\\rangle & \\text{if }f(0)\\oplus f(1)=1 \\end{cases},\n$$\nwhich leads to the correct outcome with probability $1$ when the right/topmost qubit is measured.\n\n### Further remarks on the phase kickback\n\nJust know something about\n$$\nU_f(|b\\rangle |a\\rangle)=|b\\oplus f(a)\\rangle|a⟩=(X^{f(a)}|b\\rangle)|a\\rangle.\n$$\n\n### Implementation in Qiskit\n\nLet\'s give an example to show how code works\n\n```python\nimport qiskit\nfrom matplotlib import pyplot as plt\n\ndef deutsch_function(case: int):\n    f = qiskit.QuantumCircuit(2)\n    if case in [2, 3]:\n        f.cx(0, 1)\n    if case in [3, 4]:\n        f.x(1)\n    return f\n\nif __name__ == "__main__":\n    circuit = deutsch_function(3)\n\n    circuit.draw(output="mpl")\n\n    plt.show()\n```\n\nLet\'s put Deutsch\'s algorithm into this code\n\n```python\nimport qiskit\nfrom matplotlib import pyplot as plt\n\ndef deutsch_function(case: int):\n    f = qiskit.QuantumCircuit(2)\n    if case in [2, 3]:\n        f.cx(0, 1)\n    if case in [3, 4]:\n        f.x(1)\n    return f\n\ndef compile_circuit(function: qiskit.QuantumCircuit):\n    # Compiles a circuit for use in Deutsch\'s algorithm.\n \n    n = function.num_qubits - 1\n    qc = qiskit.QuantumCircuit(n + 1, n)\n \n    qc.x(n)\n    qc.h(range(n + 1))\n \n    qc.barrier()\n    qc.compose(function, inplace=True)\n    qc.barrier()\n \n    qc.h(range(n))\n    qc.measure(range(n), range(n))\n \n    return qc\nif __name__ == "__main__":\n    circuit = compile_circuit(deutsch_function(3))\n\n    circuit.draw(output="mpl")\n\n    plt.show()\n```\n\nFinally we do the measurement\n\n```python\nimport qiskit\nfrom qiskit_aer import AerSimulator\nfrom matplotlib import pyplot as plt\n\ndef deutsch_function(case: int):\n    f = qiskit.QuantumCircuit(2)\n    if case in [2, 3]:\n        f.cx(0, 1)\n    if case in [3, 4]:\n        f.x(1)\n    return f\n\ndef compile_circuit(function: qiskit.QuantumCircuit):\n    # Compiles a circuit for use in Deutsch\'s algorithm.\n \n    n = function.num_qubits - 1\n    qc = qiskit.QuantumCircuit(n + 1, n)\n \n    qc.x(n)\n    qc.h(range(n + 1))\n \n    qc.barrier()\n    qc.compose(function, inplace=True)\n    qc.barrier()\n \n    qc.h(range(n))\n    qc.measure(range(n), range(n))\n \n    return qc\n\nif __name__ == "__main__":\n    circuit = compile_circuit(deutsch_function(3))\n    \n    circuit.draw(output="mpl")\n    \n    plt.show()\n\n    result = AerSimulator().run(circuit, shots=1, memory=True).result()\n    measurements = result.get_memory()\n    if measurements[0] == "0":\n        print("constant")\n    else:\n        print("balanced")\n```\n\nand we will get the output `balanced` as expected.\n\n## The Deutsch-Jozsa algorithm\n\n### The Deutsch-Jozsa problem\n\nThe input function for this problem takes the form $f:\\Sigma^n\\to\\Sigma$ for an arbitrary positive integer $n$. Like Deutsch\'s problem, the task is to output $0$ if $f$ is constant and $1$ if $f$ is balanced.\n\n> Deutsch-Jozsa problem\n>\n> Input: a function $f:\\\\{0,1\\\\}^n\\to\\\\{0,1\\\\}$\n\n> Promise: $f$ is either constant or balanced\n\n> Output: $0$ if $f$ is constant, $1$ if $f$ is balanced\n\nThe Deutsch-Jozsa algorithm, with its single query, solves this problem in the following sense: if every one of the $n$ measurement outcomes is $0$, then the function $f$ is constant; and otherwise, if at least one of the measurement outcomes is $1$, then the function $f$ is balanced.\n\n---\n\n#### Algorithm analysis\n\n$$\nH|a\\rangle=\\frac{1}{\\sqrt{2}}|0\\rangle+\\frac{1}{\\sqrt{2}}(-1)^a|1\\rangle=\\frac{1}{\\sqrt{2}}\\sum_{b\\in\\\\{0,1\\\\}}(-1)^{ab}|b\\rangle\n$$\n\nis true for both choices of $a\\in\\Sigma$.\n\nUsing the formula from above, followed by expanding and then simplifying, we can express the action of this combined operation on the standard basis states of $n$ qubits like this:\n$$\nH^{\\otimes n}|x_{n-1}\\dots x_1x_0\\rangle\\\\\\\\\n=\\frac{1}{\\sqrt{2^n}}\\sum_{y_{n-1}\\dots y_0\\in\\Sigma^n}(-1)^{x_{n-1}y_{n-1}+\\dots+x_0y_0}|y_{n-1}\\dots y_0\\rangle.\n$$\nAfter the first layer of Hadamard gates is performed, the state of the $n+1$ qubits is\n$$\n(H|1\\rangle)(H^{\\otimes n}|0\\dots 0\\rangle)=|-\\rangle\\otimes\\frac{1}{\\sqrt{2^n}}\\sum_{x_{n-1}\\dots x_0\\in\\Sigma^n}|x_{n-1}\\dots x_0\\rangle.\n$$\nWhen the $U_f$ operation is performed, this state is transformed into\n$$\n|-\\rangle\\otimes\\frac{1}{\\sqrt{2^n}}\\sum_{x_{n-1}\\dots x_0\\in\\Sigma^n}(-1)^{f(x_{n-1}\\dots x_0)}|x_{n-1}\\dots x_0\\rangle.\n$$\nthrough exactly the same phase kick-back phenomenon that we saw in the analysis of Deutsch\'s algorithm.\n\nThen the second layer of Hadamard gates is performed, which transforms this state into\n$$\n\\begin{align}\n&\\quad\\ |-\\rangle\\otimes H^{\\otimes n}\\frac{1}{\\sqrt{2^n}}\\sum_{x_{n-1}\\dots x_0\\in\\Sigma^n}(-1)^{f(x_{n-1}\\dots x_0)}|x_{n-1}\\dots x_0\\rangle\\\\\\\\\n&=|-\\rangle\\otimes\\frac{1}{\\sqrt{2^n}}\\sum_{x_{n-1}\\dots x_0\\in\\Sigma^n}(-1)^{f(x_{n-1}\\dots x_0)}H^{\\otimes n}|x_{n-1}\\dots x_0\\rangle\\\\\\\\\n&=|-\\rangle\\otimes\\frac{1}{\\sqrt{2^n}}\\sum_{x_{n-1}\\dots x_0\\in\\Sigma^n}(-1)^{f(x_{n-1}\\dots x_0)}\\frac{1}{\\sqrt{2^n}}\\sum_{y_{n-1}\\dots y_0\\in\\Sigma^n}(-1)^{x_{n-1}y_{n-1}+\\dots+x_0y_0}|y_{n-1}\\dots y_0\\rangle\\\\\\\\\n&=|-\\rangle\\otimes\\frac{1}{2^n}\\sum_{x_{n-1}\\dots x_0\\in\\Sigma^n}\\sum_{y_{n-1}\\dots y_0\\in\\Sigma^n}(-1)^{f(x_{n-1}\\dots x_0)+x_{n-1}y_{n-1}+\\dots+x_0y_0}|y_{n-1}\\dots y_0\\rangle\n\\end{align}.\n$$\nFortunately, all we need to know is the probability that every one of the measurement outcomes is $0$ — because that\'s the probability that the algorithm determines that $f$ is constant. This probability has a simple formula.\n$$\n|\\frac{1}{2^n}\\sum_{x_{n-1}\\dots x_0\\in\\Sigma^n}(-1)^{f(x_{n-1}\\dots x_0)}|^2=\\begin{cases} 1 & \\text{if }f\\text{ is constant} \\\\\\\\ 0 & \\text{if }f\\text{ is balanced} \\end{cases}\n$$\n\n---\n\n#### Classical difficulty\n\nAny **deterministic** classical algorithm that correctly solves the Deutsch-Jozsa problem must make exponentially many queries: $2^{n−1}+1$ queries are required in the worst case.\n\nIf we choose $k$ input strings $x_1,\\dots,x_k\\in\\Sigma^n$ uniformly at random, evaluate $f(x_1),\\dots,f(x_k)$, and answer $0$ if the function values are all the same, and $1$ if not, then we\'ll always be correct when $f$ is constant, and wrong in the case that $f$ is balanced with probability just $2^{−k+1}$. If we take $k=11$, for instance, this algorithm will answer correctly with probability greater than $99.99\\%$.\n\nFor this reason, we do still have a rather modest advantage of quantum over classical  algorithms — but it is nevertheless a quantifiable advantage  representing an improvement over Deutsch\'s algorithm.\n\n---\n\n#### Deutsch-Jozsa with Qiskit\n\n```python\nimport numpy as np\nimport qiskit\nfrom qiskit import QuantumCircuit\nfrom qiskit_aer import AerSimulator\nfrom matplotlib import pyplot as plt\n\ndef dj_query(num_qubits):\n    # Create a circuit implementing for a query gate for a random function\n    # satisfying the promise for the Deutsch-Jozsa problem.\n \n    qc = QuantumCircuit(num_qubits + 1)\n \n    if np.random.randint(0, 2):\n        # Flip output qubit with 50% chance\n        qc.x(num_qubits)\n    if np.random.randint(0, 2):\n        # return constant circuit with 50% chance\n        return qc\n \n    # Choose half the possible input strings\n    on_states = np.random.choice(\n        range(2**num_qubits),  # numbers to sample from\n        2**num_qubits // 2,  # number of samples\n        replace=False,  # makes sure states are only sampled once\n    )\n \n    def add_cx(qc, bit_string):\n        for qubit, bit in enumerate(reversed(bit_string)):\n            if bit == "1":\n                qc.x(qubit)\n        return qc\n \n    for state in on_states:\n        qc.barrier()  # Barriers are added to help visualize how the functions are created.\n        qc = add_cx(qc, f"{state:0b}")\n        qc.mcx(list(range(num_qubits)), num_qubits)\n        qc = add_cx(qc, f"{state:0b}")\n \n    qc.barrier()\n \n    return qc\n\ndef compile_circuit(function: QuantumCircuit):\n    # Compiles a circuit for use in the Deutsch-Jozsa algorithm.\n \n    n = function.num_qubits - 1\n    qc = QuantumCircuit(n + 1, n)\n    qc.x(n)\n    qc.h(range(n + 1))\n    qc.compose(function, inplace=True)\n    qc.h(range(n))\n    qc.measure(range(n), range(n))\n    return qc\n\ndef dj_algorithm(function: QuantumCircuit):\n    # Determine if a function is constant or balanced.\n \n    qc = compile_circuit(function)\n \n    result = AerSimulator().run(qc, shots=1, memory=True).result()\n    measurements = result.get_memory()\n    if "1" in measurements[0]:\n        return "balanced"\n    return "constant"\n\nif __name__ == "__main__":\n    circuit = dj_query(3)\n\n    circuit.draw(output="mpl")\n\n    print(dj_algorithm(circuit))\n\n    plt.show()\n```\n\n---\n\n### The Bernstein-Vazirani problem\n\nFirst, let\'s introduce some notation. For any two binary strings $x=x_{n−1}\\dots x_0\\text{ and }y=y_{n−1}\\dots y_0$ of length $n$, we define\n$$\nx·y=\\begin{cases}1&x_{n−1}y_{n-1}+\\dots+x_0y_0\\text{ is odd}\\\\\\\\0&x_{n−1}y_{n-1}+\\dots+x_0y_0\\text{ is even}\\end{cases}.\n$$\nIdentically\n$$\nx·y=x_{n-1}y_{n-1}\\oplus\\dots\\oplus x_0y_0.\n$$\n\n> Bernstein-Vazirani problem\n>\n> Input: a function $f:\\\\{0,1\\\\}^n\\to\\\\{0,1\\\\}$\n\n> Promise: there exists a binary string $s=s_{n−1}\\dots s_0$ for which $f(x)=s⋅x$ for all $x\\in\\Sigma^n$\n\n> Output: the string $s$\n\nThe  Deutsch-Jozsa algorithm can solve it. In the interest of clarity, let\'s refer to the quantum circuit from above, which doesn\'t include the classical post-processing step of computing the OR, as the **Deutsch-Jozsa circuit**.\n\n---\n\n#### Algorithm analysis\n\nUsing the binary dot product, we can alternatively describe the action of $n$ Hadamard gates on the standard basis states of $n$ qubits as follows.\n$$\nH^{\\otimes n}|x\\rangle=\\frac{1}{\\sqrt{2^n}}\\sum_{y\\in\\Sigma^n}(-1)^{x·y}|y\\rangle.\n$$\nTurning to the Deutsch–Jozsa circuit, after the first layer of Hadamard gates is performed, the state of the $n+1$ qubits is\n$$\n|-\\rangle\\otimes\\frac{1}{\\sqrt{2^n}}\\sum_{x\\in\\Sigma^n}|x\\rangle.\n$$\nThe query gate is then performed, which (through the phase kickback phenomenon) transforms the state into\n$$\n|-\\rangle\\otimes\\frac{1}{\\sqrt{2^n}}\\sum_{x\\in\\Sigma^n}(-1)^{f(x)}|x\\rangle.\n$$\nUsing our formula for the action of a layer of Hadamard gates, we see that the second layer of Hadamard gates then transforms this state into\n$$\n|-\\rangle\\otimes\\frac{1}{2^n}\\sum_{x\\in\\Sigma^n}\\sum_{y\\in\\Sigma^n}(-1)^{f(x)+x·y}|y\\rangle.\n$$\nNow we can make some simplifications, in the exponent of $−1$ inside the sum. We\'re promised that $f(x)=s⋅x$ for some string $s=s_{n−1}\\dots s_0$, so we can express the state as\n$$\n|-\\rangle\\otimes\\frac{1}{2^n}\\sum_{x\\in\\Sigma^n}\\sum_{y\\in\\Sigma^n}(-1)^{s·x+x·y}|y\\rangle.\n$$\nObviously, it can also be expressed as\n$$\n|-\\rangle\\otimes\\frac{1}{2^n}\\sum_{x\\in\\Sigma^n}\\sum_{y\\in\\Sigma^n}(-1)^{(s·x)\\oplus(x·y)}|y\\rangle.\n$$\nMeanwhile\n$$\n(s·x)\\oplus(y·x)=(s\\oplus y)·x\n$$\nThe final step is to make use of yet another formula, which works for every binary string $z=z_{n−1}\\dots z_0$.\n$$\n\\frac{1}{2^n}\\sum_{x\\in\\Sigma^n}(-1)^{z·x}=\\begin{cases}1&\\text{if }z=0^n\\\\\\\\0&\\text{if }z\ne 0^n\\end{cases}\n$$\nwhere $0^n$ is the all-zero string of length $n$.\n\nIf we now apply this formula to simplify the state of the circuit prior to the measurements, we obtain\n$$\n|-\\rangle\\otimes\\frac{1}{2^n}\\sum_{x\\in\\Sigma^n}\\sum_{y\\in\\Sigma^n}(-1)^{(s\\oplus y)·x}|y\\rangle=|-\\rangle\\otimes|s\\rangle\n$$\nowing to the fact that $s\\oplus y=0^n$ if and only if $y=s$. Thus, the measurements reveal precisely the string $s$ we\'re looking for.\n\n---\n\n#### Classical difficulty\n\nWhile the Deutsch-Jozsa circuit solves the Bernstein-Vazirani problem with a single query, any classical query algorithm must make at least $n$ queries to solve this problem.\n\n---\n\n#### Bernstein-Vazirani with Qiskit\n\n```python\ndef bv_query(s):\n    # Create a quantum circuit implementing a query gate for the\n    # Bernstein-Vazirani problem.\n \n    qc = qiskit.QuantumCircuit(len(s) + 1)\n    for index, bit in enumerate(reversed(s)):\n        if bit == "1":\n            qc.cx(index, len(s))\n    return qc\n```\n\n```python\ndef bv_algorithm(function: qiskit.QuantumCircuit):\n    qc = compile_circuit(function)\n    result = AerSimulator().run(qc, shots=1, memory=True).result()\n    return result.get_memory()[0]\n```\n\n## Simon\'s algorithm\n\n### Simon\'s problem\n\nThe input function for Simon\'s problem takes the form $f:\\Sigma^n\\to\\Sigma^m$ for positive integers $n$ and $m$. We could restrict our attention to the case $m=n$ in the interest of simplicity, but there\'s little to be gained in making this assumption — Simon\'s algorithm and its analysis are basically the same either way.\n\n> Simon\'s problem\n>\n> Input: a function $f:\\Sigma^n\\to\\Sigma^m$\n\n> Promise: there exists a string $s\\in\\Sigma$ such that $[f(x)=f(y)]\\Leftrightarrow[(x=y)\\lor(x⊕s=y)]$ for all $x,y\\in\\Sigma^n$\n\n> Output: the string $s$\n\n> [!NOTE]\n>\n> Here, $f$ has a very special structure — so most functions won\'t satisfy this promise. \n>\n> It\'s also fitting to acknowledge that this problem isn\'t intended to have practical importance. Rather, it\'s a somewhat artificial problem tailor-made to **be easy for quantum computers** and **hard for classical computers**.\n\n- Case 1: $s=0^n$. If $s$ is the all-zero string, then we can simplify the if and only if statement in the promise so that it reads $[f(x)=f(y)]\\Leftrightarrow [x=y]$. This is equivalent to $f$ being a **one-to-one** function.\n- Case 2: $s\ne 0^n$. If $s$ is not the all-zero string, then the promise being satisfied for this string implies that $f$ is **two-to-one**, meaning that for every possible output string of $f$, there are exactly two input strings that cause $f$ to output that string. Moreover, these two input strings must take the form $w$ and $w\\oplus s$ for some string $w$.\n\nIt\'s important to recognize that there can only be one string $s$ that works if the promise is met, so there\'s always a unique correct answer for functions that satisfy the promise.\n\nHere\'s an example of a function taking the form $f:\\Sigma^3\\to\\Sigma^5$ that satisfies the promise for the string $s=011$.\n$$\nf(000)=10011$$$$\nf(001)=00101$$$$\nf(010)=00101$$$$\nf(011)=10011$$$$\nf(100)=11010$$$$\nf(101)=00001$$$$\nf(110)=00001$$$$\nf(111)=11010$$$$\n$$\nNotice that here how the output strings differ doesn\'t matter as long as they are distinct and satisfy the condition.\n\n---\n\n### Algorithm description\n\n```\n\n|0⟩ —————— H ——————      —————— H —————— (Measurement) ===\n\n|0⟩ —————— H ——————      —————— H ———————(Measurement) ===\n .\n .\n .\n|0⟩ —————— H ——————  U_f —————— H —————— (Measurement) ===\n                                                                    above are Sigma^n\n                                                                    below are Sigma^m\n|0⟩ ———————————————      ———————————————\n\n|0⟩ ———————————————      ———————————————\n .\n .\n .\n|0⟩ —————— H ——————  U_f ———————————————\n```\n\n---\n\n### Analysis\n\nAfter the first layer of Hadamard gates is performed on the top $n$ qubits, the state becomes\n$$\n\\frac{1}{\\sqrt{2^n}}\\sum_{x\\in\\Sigma^n}|0^m\\rangle|x\\rangle.\n$$\nWhen the $U_f$ is performed, the output of the function $f$ is XORed onto the all-zero state of the bottom $m$ qubits, so the state becomes\n$$\n\\frac{1}{\\sqrt{2^n}}\\sum_{x\\in\\Sigma^n}|f(x)\\rangle|x\\rangle.\n$$\nWhen the second layer of Hadamard gates is performed, we obtain the following state by using the same formula for the action of a layer of Hadamard gates as before.\n$$\n\\frac{1}{2^n}\\sum_{x\\in\\Sigma^n}\\sum_{y\\in\\Sigma^n}(-1)^{x·y}|f(x)\\rangle|y\\rangle\n$$\nThe probability $p(y)$ to obtain the string $y$ is equal to\n$$\np(y)=\\|\\frac{1}{2^n}\\sum_{x\\in\\Sigma^n}(-1)^{x·y}|f(x)\\rangle\\|^2.\n$$\nWe\'ll need just a bit more notation and terminology.\n$$\n\\text{range}(f)=\\\\{f(x):x\\in\\Sigma^n\\\\}\\\\\\\\\nf^{-1}(\\\\{z\\\\})=\\\\{x\\in\\Sigma^n:f(x)=z\\\\}\n$$\nThe set $f^{−1}(\\\\{z\\\\})$ is known as the **preimage** of $\\\\{z\\\\}$ under $f$. We can define the preimage under $f$ of any set in place of $\\\\{z\\\\}$ in an analogous way — it\'s the set of all elements that $f$ maps to that set.\n\nUsing this notation, we can split up the sum in our expression for the probabilities above to obtain\n$$\np(y)=\\|\\frac{1}{2^n}\\sum_{z\\in\\text{range}(f)}(\\sum_{x\\in f^{-1}(\\\\{z\\\\})}(-1)^{x·y})|z\\rangle\\|^2.\n$$\nEvery string $x\\in\\Sigma^n$ is represented exactly once by the two summations — we\'re basically just putting these strings into separate buckets depending on which output string $z=f(x)$ they produce when we evaluate the function $f$, and then summing separately over all the buckets.\n\nWe can now evaluate the Euclidean norm squared to obtain\n$$\np(y)=\\frac{1}{2^{2n}}\\sum_{z\\in\\text{range}(f)}|\\sum_{x\\in f^{-1}(\\\\{z\\\\})}(-1)^{x·y}|^2.\n$$\nIf it happens to be the case that $s=0^n$, then $f$ is a one-to-one function and there\'s always just a single element $x\\in f^{−1}(\\\\{z\\\\})$, for every $z\\in\\text{range}⁡(f)$ where we have\n$$\np(y)=\\frac{1}{2^{n}}.\n$$\nIf, on the other hand, $s\ne0^n$, then there are exactly two strings in the set $f^{−1}(\\\\{z\\\\})$. To be precise, if we choose $w\\in f^{−1}(\\\\{z\\\\})$ to be any one of these two strings, then the other string must be $w\\oplus s$ by the promise in Simon\'s problem. That is,\n$$\n\\begin{align}\n|\\sum_{x\\in f^{-1}(\\\\{z\\\\})}(-1)^{x·y}|^2\n&=|(-1)^{w·y}+(-1)^{(w\\oplus s)·y}|^2\\\\\\\\\n&=|(-1)^{w·y}(1+(-1)^{s·y})|^2\\\\\\\\\n&=\\begin{cases}4&y·s=0\\\\\\\\0&y·s=1\\end{cases}\\\\\\\\\n\\end{align}\\\\\\\\\n$$\nand\n$$\np(y)=\\begin{cases}\\frac{1}{2^{n-1}}&y·s=0\\\\\\\\0&y·s=1\\end{cases}.\n$$\nIn words, we obtain a string chosen uniformly at random from the set $\\\\{y\\in\\Sigma^n:y⋅s=0\\\\}$, which contains $2^{n−1}$ strings.\n\n#### Classical post-processing\n\nLet\'s suppose that we run the circuit independently $k$ times, for $k=n+10$. There\'s nothing special about this particular number of iterations — we could take $k$ to be larger (or smaller) depending on the probability of failure we\'re willing to tolerate, as we will see. Choosing $k=n+10$ will ensure that we have greater than a $99.9\\%$ chance of recovering $s$.\n\nBy running the circuit $k$ times, we obtain strings $y^1,\\dots,y^k\\in\\Sigma^n$. To be clear, the superscripts here are part of the names of these strings, not exponents or indexes to their bits, so we have\n$$\ny^1=y_{n-1}^1\\dots y_0^1$$$$\ny^2=y_{n-1}^2\\dots y_0^2$$$$\n\\vdots\\\\\\\\\ny^k=y_{n-1}^k\\dots y_0^k\\\\\\\\\n$$\nWe now form a matrix $M$ having $k$ rows and $n$ columns by taking the bits of these strings as binary-valued entries.\n$$\nM=\n\\begin{pmatrix}\ny_{n-1}^1&\\dots&y_0^1\\\\\\\\\ny_{n-1}^2&\\dots&y_0^2\\\\\\\\\n\\vdots&\\ddots&\\vdots\\\\\\\\\ny_{n-1}^k&\\dots&y_0^k\\\\\\\\\n\\end{pmatrix}\n$$\nNow, we don\'t know what $s$ is at this point — our goal is to find this string. But imagine for a moment that we do know the string $s$, and we form a column vector $v$ from the bits of the string $s=s_{n−1}\\dots s_0$ as follows.\n$$\nv=\\begin{pmatrix}s_{n-1}\\\\\\\\\\vdots\\\\\\\\s_0\\end{pmatrix}\n$$\nIf we perform the matrix-vector multiplication $Mv$ modulo $2$ — meaning that we perform the multiplication as usual and then take the remainder of the entries of the result after dividing by $2$ — we obtain the all-zero vector.\n$$\nMv=\\begin{pmatrix}y^1·s\\\\\\\\y^2·s\\\\\\\\\\vdots\\\\\\\\y^k·s\\end{pmatrix}=\\begin{pmatrix}0\\\\\\\\0\\\\\\\\\\vdots\\\\\\\\0\\end{pmatrix}\n$$\nIf we set $k=n+r$ for an arbitrary choice of a positive integer $r$, the probability that the vectors corresponding to $0^n$ and $s$ are alone in the null space of $M$ is at least $1−2^{−r}$.\n\n#### Classical difficulty\n\nHow many queries does a *classical* query algorithm need to solve Simon\'s problem? The answer is: a lot, in general.\n\nIf we have any probabilistic query algorithm, and that algorithm makes fewer than $2^{n/2}−1$ queries, which is a number of queries that\'s *exponential* in $n$, then that algorithm will fail to solve Simon\'s problem with probability at least $1/2$.\n\nSometimes, proving impossibility results like this can be very challenging, but this one isn\'t too difficult to prove through an elementary probabilistic analysis. Here, however, we\'ll only briefly examine the basic intuition behind it.\n\n### Simon\'s problem with Qiskit\n\n```python\nimport qiskit\nfrom qiskit import QuantumCircuit\nfrom qiskit_aer import AerSimulator\nfrom matplotlib import pyplot as plt\nfrom sympy import Matrix, GF\n\ndef get_f(n: int, s: str) -> QuantumCircuit:\n    \'\'\'\n    construct U_f\n    Remind:\n    constructions listed below are just for n=3 s=\'011\'\n    \'\'\'\n    f = QuantumCircuit(2 * n, n)\n    f.barrier()\n    f.cx(2, 4)\n    f.cx(0, 3)\n    f.cx(1, 3)\n    f.barrier()\n    return f\n\ndef compile_circuit(n: int) -> QuantumCircuit:\n    f = get_f(n, \'011\')\n    qc = QuantumCircuit(2 * n, n)\n    qc.h(range(n))\n    qc.compose(f, inplace=True)\n    qc.h(range(n))\n    qc.measure(range(n), range(n))\n    return qc\n\ndef algorithm(function: qiskit.QuantumCircuit) -> dict:\n    result = AerSimulator().run(function, shots=100, memory=True).result()\n    return result.get_counts()\n\ndef gauss(samples):\n    \'\'\'\n    Gaussian elimination\n    \'\'\'\n    n = len(samples[0])\n    mat = Matrix([[int(b) for b in s] for s in samples])\n    mat = mat.rref(iszerofunc=lambda x: x % 2 == 0, simplify=True)[0]\n    M = Matrix([[int(b) for b in s] for s in samples])\n    nullspace = M.nullspace(GF(2))\n    if len(nullspace) == 1:\n        v = [int(x) % 2 for x in nullspace[0]]\n        return \'\'.join(map(str, v))\n    else:\n        print("dimensions of zero space = ", len(nullspace))\n        return None\n\nif __name__ == "__main__":\n    circuit = compile_circuit(3)\n    circuit.draw(output="mpl")\n    res = algorithm(circuit)\n    samples = []\n    for i in res.keys():\n        samples.append(i)\n    print(gauss(samples))\n    plt.show()\n```\n\n# Quantum algorithmic foundations\n\n## Factoring and computing GCDs\n\n> Integer factorization\n>\n> Input: an integer $N\\ge2$\n> Output: the prime factorization of $N$\n\nUp to the ordering of the prime factors, there is only one prime factorization for each positive integer $N\\ge 2$, which is a fact known as the **fundamental theorem of arithmetic**.\n\nFor even larger values of $N$, things become impossibly difficult, at least as far as we know.\n\nTake\n$$\nRSA1024=13506641086599522334960321627880596993888147560566702752448514385152651060485953383394$$$$0287150571909441798207282164471551373680419703964191743046496589274256239341020864383202110372958$$$$7257623585096431105640735015081875106765946292055636855294752135008528794163773285339061097505443$$$$34999811150056977236890927563\n$$\nfor example.\n\nThe fastest known algorithm for factoring large integers is known as the **number field sieve**. As an example of this algorithm\'s use, the RSA challenge number RSA250, which has 250 decimal digits (or 829 bits when written in binary), was factored using the number field sieve in 2020. The computation required thousands of CPU core-years, distributed across tens of thousands of machines around the world. Here we can appreciate this effort by checking the solution.\n$$\nRSA250 = 214032465024074496126442307283933356300861471514475501779775492088141802344714013664334$$$$5519095804679610992851872470914587687396261921557363047454770520805119056493106687691590019759405$$$$693457452230589325976697471681738069364894699871578494975937497937\\\\\\\\\n=6413528947707158027879019017$$$$0577389084825014742943447208116859632024532344630238623598752668347708737661925585694639798853367$$$$* 333720275949781565562260106053551142279407603447675546667845209870238417292100370802574486732968$$$$81877565718986258036932062711\n$$\nThe security of the RSA public-key cryptosystem is based on the computational difficulty of integer factoring, in the sense that an efficient algorithm for integer factoring would break it.\n\n---\n\n> Greatest common divisor (GCD)\n>\n> Input: nonnegative integers $N$ and $M$, at least one of which is positive\n\n> Output: the greatest common divisor of $N$ and $M$\n\nCould there be a fast algorithm for integer factorization that we just haven\'t discovered yet, allowing large numbers like RSA1024 to be factored in the blink of an eye? The answer is yes. One could be discovered tomorrow — but don\'t hold your breath. Generations of mathematicians and computer scientists have searched, and factoring numbers like RSA1024 remains beyond our reach.\n\n---\n\n## Measuring computational cost\n\n### Encodings and input length\n\nThrough binary strings, we can *encode* a variety of interesting objects that the problems we\'re interested in solving might concern, such as **numbers**, **vectors**, **matrices**, and **graphs**, as well as lists of these and other objects.\n\nFor example, to encode nonnegative integers, we can use **binary notation**.\n$$\n0\\to000$$$$\n1\\to001$$$$\n2\\to010$$$$\n3\\to011$$$$\n\\vdots\n$$\nOther types of inputs, such as vectors and matrices, or more complicated objects like descriptions of molecules, can also be encoded as binary strings. Just like we have for nonnegative integers, a variety of different encoding schemes can be selected or invented. For whatever scheme we come up with to encode inputs to a given problem, we interpret the **length** of an input string as representing the size of the problem instance being solved.\n\nFor example, the number of bits required to express a nonnegative integer $N$ in binary notation, which is sometimes denoted $lg⁡(N)$, is given by the following formula.\n$$\n\\lg(N)=\\begin{cases}1&N=0\\\\\\\\1+\\lfloor{\\log_2(N)}\\rfloor&N\\ge 1\\end{cases}\n$$\nAssuming that we use binary notation to encode the input to the integer factoring problem, the **input length** for the number $N$ is therefore $\\lg⁡(N)$. Note, in particular, that the length (or size) of the input $N$ is not $N$ itself; when $N$ is large we don\'t need nearly this many bits to express $N$ in binary notation.\n\nListed below are some principles:\n\n- Computations that solve interesting problems are viewed abstractly as transformations from binary string inputs to binary string outputs.\n- The details of how objects are encoded as binary strings must necessarily be important to these computations at some level.\n- Usually, though, we don\'t worry all that much about these details when we\'re analyzing computational cost, so that we can avoid getting into details of secondary importance. \n- The basic reasoning is that we expect the computational cost of converting back and forth between "reasonable" encoding schemes to be insignificant compared with the cost of solving the actual problem. In those situations in which this is not the case, the details can (and should) be clarified.\n\n---\n\n### Elementary operations\n\nNow let\'s consider the computation itself.\n\nThe way that we\'ll measure computational cost is to count the number of **elementary operations** that each computation requires.\n\n#### Universal gate sets\n\nHere\'s one standard choice, which we shall adopt as the **default** gate set for quantum circuits:\n\n- Single-qubit unitary gates from this list: $X$, $Y$, $Z$, $H$, $S$, $S^†$, $T$, and $T^†$.\n- Controlled-NOT gates\n- Single-qubit standard basis measurements\n\n---\n\n#### The principle of deferred measurement\n\nAny standard basis measurement performed on a qubit $q_{main}$ can be equivalently replaced by the following sequence of operations, deferring the measurement until the end of the circuit:\n\n1. Add an auxiliary bit $q_{aux}$ and initialize it to $|0\\rangle$.\n2. Use a CX gate on $q_{main}$.\n3. Perform a standard basis measurement on the auxiliary bit $q_{aux}$.\n\n---\n\n### Circuit size and depth\n\n#### Circuit size\n\nA circuit\'s size represents the number of elementary operations it requires — or, in other words, its **computational cost**. We write $\\text{size}⁡(C)$ to refer to the size of a given circuit $C$.\n\n#### Time, cost, and circuit depth\n\nThe notion of computational cost, as the number of elementary operations required to perform a computation, is intended to be an abstract proxy for the time required to implement a computation.\n\nA different way to measure the efficiency of circuits is by their depth. This is the **minimum** number of layers of gates needed within the circuit, where the gates within each layer operate on different wires.\n\nEquivalently, the depth of a circuit is the **maximum** number of gates encountered on any path from an input wire to an output wire. \n\nCircuit depth is one way to formalize the running time of parallel computations. It\'s an advanced topic, and there exist very sophisticated circuit constructions known to minimize the depth required for certain computations.\n\n#### Assigning costs to different gates\n\nOne final note concerning circuit size and computational cost is that it is possible to assign different costs to gates, rather than viewing every gate as contributing equally to the total cost.\n\nWhile all of these options(how difficult they are to implement, etc) are sensible in different contexts, for this lesson we\'ll keep things simple and stick with circuit size as a representation of computational cost.\n\n---\n\n### Cost as a function of input length\n\nWe represent the costs of algorithms as **functions** of the input length.\n\n#### Families of circuits\n\nWe represent the computational cost of an algorithm by a function $t$, defined so that $t(n)$ is the number of gates in the circuit that implements the algorithm for $n$ bit inputs. \n\nIn more formal terms, an algorithm in the Boolean circuit model is described by a sequence of circuits $\\\\{C_1,C_2,C_3,\\dots\\\\}$, where $C_n$ solves whatever problem we\'re talking about for $n$-bit inputs (or, more generally, for inputs whose size is parameterized in some way by $n$), and the function $t$ representing the cost of this algorithm is defined as\n$$\nt(n)=\\text{size}(C_n).\n$$\nFor quantum circuits the situation is similar, where larger and larger circuits are needed to accommodate longer and longer input strings.\n\n#### Example: integer addition\n\n> Integer addition\n>\n> Input: integers $N$ and $M$\n\n> Output: $N+M$\n\nWe\'ll allow for any number of leading zeros in these encodings, and\n$$\n0\\le N,M\\le 2^n-1.\n$$\n**Half adder**: Two bits operated with an AND gate and a XOR gate.\n\n```\n       ----------\n------·  --------  XOR ------\n      | |\n      --|--------\n--------·          AND ------\n         -------- \n```\n\n**Full adder**: Two bits operated with two Half adder and an OR gate.\n\n```\n                        ·----------·\n------------------------|          |------------------------------\n      ·----------·      |Half adder|                          ·--·\n------|          |------|          |--------------------------|OR|\n      |Half adder|      ·----------·            ·-------------|  |\n------|          |------------------------------·             ·--·\n      ·----------·\n```\n\nThis requires 21 gates in total: 2 AND gates, 2 XOR gates (each requiring 7 gates to implement), one OR gate, and 4 FANOUT gates.\n\nIn general, this requires\n$$\n21(n-1)+10=21n-11\n$$\ngates.\n\n#### Asymptotic notation\n\nWe typically use **Big-O** notation when analyzing algorithms\n\nFormally speaking, if we have two functions $g(n)$ and $h(n)$, we write that $g(n)=O(h(n))$ if there exists a positive real number $c>0$ and a positive integer $n_0$ such that\n$$\ng(n)\\le c·h(n)\n$$\nfor all $n≥n_0$. Typically $h(n)$ is chosen to be as simple an expression as possible, so that the notation can be used to reveal the limiting behavior of a function in simple terms. For example, $17n^3−257n^2+65537=O(n^3)$.\n\nThis notation can be extended to functions having multiple arguments in a fairly straightforward way.\n\nFor instance, if we have two functions $g(n,m)$ and $h(n,m)$ defined on positive integers $n$ and $m$, we write that $g(n,m)=O(h(n,m))$ if there exists a positive real number $c>0$ and a positive integer $k_0$ such that\n$$\ng(n,m)\\le c·h(n,m)\n$$\nwhenever $n+m\\ge k_0$.\n\n#### More examples\n\n> Integer multiplication\n>\n> Input: integers $N$ and $M$\n\n> Output: $NM$\n\nWe can come up with circuits having size $O(n^2)$.\n\nThe Schönhage-Strassen multiplication algorithm is at cost $O(n\\lg⁡(n)\\lg⁡(\\lg⁡(n)))$. The intricacy of this method causes a lot of overhead, however, making it only practical for numbers having tens of thousands of bits.\n\n> Integer division\n>\n> Input: integers $N$ and $M≠0$\n\n> Output: integers $q$ and $r$ satisfying $0\\le r<|M|$ and $N=qM+r$\n\nWe can still come up with circuits having size $O(nm)$.\n\nEuclid\'s algorithm for computing the GCD of an $n$-bit number $N$ and an $m$-bit number $M$ requires Boolean circuits of size $O(nm)$.\n\nThere are asymptotically faster GCD algorithms — including ones requiring $O(n(\\lg⁡(n))^2\\lg⁡(\\lg⁡(n)))$ elementary operations to compute the GCD of two $n$-bit numbers.\n\n> Integer modular exponentiation\n>\n> Input: integers $N$, $K$, and $M$ with $K\\ge 0$ and $M\\ge 1$\n\n> Output: $N^K(\\text{mod } M)$\n\nIf $N$ has $n$ bits, $M$ has $m$ bits, and $K$ has $k$ bits, this problem can be solved by Boolean circuits having size $O(km^2+nm)$. This is not at all obvious. The solution is using the **power algorithm**, which makes use of the binary representation of $K$ to perform the entire computation modulo M.\n\n---\n\n#### Cost of integer factorization\n\nOne simple approach to factoring is **trial division**. This requires $O(2^{\\frac{n}{2}})$ iterations in the worst case.\n\nFor the sake of each iteration costing $O(n^2)$ elementary operations, we end up with circuits of size $O(n^22^{\\frac{n}{2}})$, which is **exponential** in the input size $n$.\n\nThe number field sieve mentioned earlier, is generally believed (but not rigorously proven) to require\n$$\n2^{O(n^{\\frac{1}{3}}(\\lg(n))^\\frac{2}{3})}\n$$\nelementary operations.\n\n---\n\n#### Polynomial versus exponential cost\n\nAs a rough, first-order approximation, **algorithms having polynomial cost** are abstractly viewed as representing **efficient** algorithms.\n\nIn contrast, known classical algorithms for integer factoring have *exponential* cost. Sometimes the cost of the number field sieve is described as *sub-exponential* because $n$ is raised to the power $1/3$ in the exponent, but in complexity theory it is more typical to reserve this term for algorithms whose cost is\n$$\nO(2^{n^\\epsilon})\n$$\nfor every $\\epsilon>0$.\n\nThe **NP-complete** problems are a class of problems not known to (and widely conjectured not to) have polynomial-cost algorithms. A circuit-based formulation of the **exponential-time hypothesis** posits something even stronger, which is that no NP-complete problem can have a sub-exponential cost algorithm.\n\nAs we consider advantages of quantum computing over classical computing, our eyes are generally turned first toward **exponential** advantages, or at least **super-polynomial** advantages — ideally finding polynomial-cost quantum algorithms for problems not known to have polynomial-cost classical algorithms. Theoretical advantages on this order have the greatest chances to lead to actual practical advantages — but identifying such advantages is an extremely difficult challenge. Only a few examples are currently known, but the search continues.\n\n---\n\n#### A hidden cost of circuit computation\n\nWhat happens if there are prohibitive computational costs associated with the patterns in the circuits themselves? For instance, the description of each member $C_n$ in a circuit family could, in principle, be determined by some extremely difficult to compute function of $n$.\n\nThe answer is that this is indeed a problem — and so we must place additional restrictions on families of circuits beyond having polynomial cost in order for them to truly represent efficient algorithms. The property of *uniformity* for circuits does this by stipulating that, in various precise formulations, it must be computationally easy to obtain the description of each circuit in a family.\n\n---\n\n## Classical computations on quantum computers\n\nWe\'ll now turn our attention to implementing classical algorithms on quantum computers. We\'ll see that any computation that can be performed with a classical Boolean circuit can also be performed by a quantum circuit with a similar asymptotic computational cost.\n\n---\n\n### Simulating Boolean circuits with quantum circuits\n\nBoolean circuits are composed of AND, OR, NOT, and FANOUT gates. To simulate Boolean circuits with quantum circuits, we\'ll begin by showing how each of these four gates can be simulated by quantum gates.\n\nWe\'ll only need NOT gates, controlled-NOT gates, and Toffoli gates to do this, which are all deterministic operations in addition to being unitary.\n\n---\n\n#### Toffoli gates\n\nToffoli gates are essentially query gates for the AND function.\n\nToffoli gates are not included in the default gate set discussed earlier in the lesson, but it is possible to construct a Toffoli gate from $H$, $T$, $T^†$, and CNOT gates as follows.\n\n```python\ndef toffoli_gate() -> QuantumCircuit:\n    f = QuantumCircuit(3, 3)\n    \'\'\'\n    The simplest implementation of f.mcx([0,1],2)\n    \'\'\'\n    f.h(2)\n    f.cx(1, 2)\n    f.tdg(2)\n    f.cx(0, 2)\n    f.t(2)\n    f.cx(1, 2)\n    f.tdg(2)\n    f.cx(0, 2)\n    f.t([1, 2])\n    f.cx(0, 1)\n    f.t(0)\n    f.tdg(1)\n    f.h(2)\n    f.cx(0, 1)\n    f.measure(range(3), range(3))\n    return f\n```\n\n---\n\n#### Simulating Boolean gates with Toffoli, controlled-NOT, and NOT gates\n\nA single Toffoli gate, used in conjunction with a few NOT gates, can implement an AND and OR gate, and FANOUT gates can easily be implemented using controlled-NOT gates.\n\n```python\ndef and_gate() -> QuantumCircuit:\n    f = QuantumCircuit(3, 3)\n    f.compose(toffoli_gate(), inplace=True)\n    f.measure(range(3), range(3))\n    return f\n\ndef or_gate() -> QuantumCircuit:\n    f = QuantumCircuit(3, 3)\n    f.x([0, 1])\n    f.compose(toffoli_gate(), inplace=True)\n    f.x(2)\n    return f\n\ndef fanout_gate() -> QuantumCircuit:\n    f = QuantumCircuit(2, 2)\n    f.cx(0, 1)\n    return f\n```\n\nThe remaining Boolean gate, the NOT gate, is included in our default set of quantum gates, so we don\'t require a simulation for this one.\n\n---\n\n#### Gate by gate simulation of Boolean circuits\n\nNow suppose that we have an ordinary Boolean circuit named $C$, composed of **AND**, **OR**, **NOT**, and **FANOUT** gates, and having $n$ input bits and $m$ of output bits.\nLet $t=size⁡(C)$ be the number of gates in $C$, and let\'s give the name $f$ to the function that $C$ computes, which takes the form\n$$\nf=\\Sigma^n\\to\\Sigma^m\n$$\nfor $\\Sigma=\\\\{0,1\\\\}$.\n\nNow consider what happens when we go one at a time through the AND, OR, and FANOUT gates of $C$ replacing each one by the corresponding simulation described above, including the addition of the required workspace qubits. Let\'s name the resulting circuit $R$, and let\'s order the qubits of $R$ so that the $n$ input bits of $C$ correspond to the top $n$ qubits of $R$ and the workspace qubits are on the bottom.\n\n```\n  ------·-----------·                   ------·-----------------·\n  ------|           |------             ------|                 |------\nx ------|     C     |------ f(x)    |x> ------|                 |------ |f(x)>\n  ------|  t gates  |------             ------|                 |------\n  ------·-----------·                   ------|        R        |\n                                              |                 |\n                                        ------|                 |\n                                        ------|    O(t) gates   |------\n                                        ------|                 |------\n                                  |0^k> ------|                 |------ |g(x)>\n                                        ------|                 |------\n                                        ------|                 |------\n                                        ------·-----------------·\n```\n\n**Reversibility**\n\nClassical Circuits $C$: Typically contain irreversible gates like AND and OR (information loss). For example, knowing $A \\land B=0$ does not uniquely determine the original values of $A$ and $B$. \n\nQuantum Circuits $R$: Must be unitary, meaning it must be reversible (information cannot be lost).\n\nEach replaced classical gate requires an additional qubit to store intermediate computation results, thus ensuring the entire operation is reversible.\nHere, the sum of additional qubits is $k$.\n\n---\n\nInput bits (top $n$ qubits): Corresponding to the $n$ inputs $x$ of the original Boolean circuit $C$. \n\nWorkspace bits (bottom $k$ qubits): The additional $k$ auxiliary qubits, typically initialized to $|0\\ranglele$.\n\nOriginal output $f(x)$: Corresponding to $m$ outputs of $C$. These $m$ bits are placed at the top of this text and contain the main computational results we need.\n\nLeftover Qubits $g(x)$: These are the remaining $n+k-m$ qubits that store the garbage output $g(x)$, which is the intermediate computational result that must be retained to ensure the **reversibility** of $R$. The function $g: \\Sigma^n \\to \\Sigma^{n+k-m}$ describes the state of these remaining qubits.\n\n---\n\n### Cleaning up the garbage\n\nThis is not good enough if we want to perform classical computations as subroutines within larger quantum computations, because those garbage qubits will cause problems. The phenomenon of **interference** is critically important to quantum algorithms, and garbage qubits can ruin the interference patterns needed to make quantum algorithms work.\n\n**Method**:\nUse $m$ CNOT gates to copy the output $f(x)$, and use $R^†$ to clean up the garbage.\n\nNote that the workspace qubits are needed to make this process work, but they are returned to their initial states once the combined circuit is executed. This allows these qubits to be **reused** as workspace qubits for other purposes.\n\nThere are also known strategies to reduce the number of workspace qubits required (which come at a cost of making the circuits larger), but we won\'t discuss those strategies here.\n\n----\n\n#### Implementing invertible functions\n\nSuppose that the function $f$ takes the form $f:\\Sigma^n\\to\\Sigma^n$, and also suppose that there exists a function $f^{−1}$ such that $f^{−1}(f(x))=x$ for every $x\\in\\Sigma^n$ (which is necessarily unique when it exists). This means that the operation that transforms $|x\\rangle$ into $|f(x)\\rangle$ for every $x\\in\\Sigma^n$ is unitary, so we might hope to build a quantum circuit that implements the unitary operation defined by\n$$\nU|x\\rangle=|f(x)\\rangle\n$$\nfor every $x\\in\\Sigma^n$.\n\nEvery $f$ satisfying the definition is called **invertible**. And they don\'t need $|0^k\\rangle$ to restore garbage.\n\n---\n\nHere is an example of quantum transformation of typical bool circuit.\n\n```python\n\'\'\'\nconstruct a circuit:\nf: n -> m ({p,q,r} -> {x,y})\nx = NOT((p AND q) OR r)\ny = p OR q\nn = 3\nm = 2\nk = 1\n\'\'\'\ncircuit = QuantumCircuit(6, 6)\n# p  q  r  x y k\ncircuit.x([0,2]) # p=1, r=1\ncircuit.barrier()\ncircuit.compose(or_gate(), [0,1,4], inplace=True)  # y = p OR q\ncircuit.barrier()\ncircuit.compose(and_gate(), [0,1,5], inplace=True)  # k = p AND q\ncircuit.barrier()\ncircuit.x([2, 5])\ncircuit.barrier()\ncircuit.compose(and_gate(), [5,2,3], inplace=True)  # x = (p OR q) AND r\ncircuit.barrier()\ncircuit.x([2, 5])\ncircuit.barrier()\ncircuit.compose(and_gate(), [0,1,5], inplace=True)  # k = p AND q\ncircuit.barrier()\ncircuit.measure(range(6),range(6))  # measure all qubits\nres = AerSimulator().run(circuit, shots=8, memory=True).result()\nprint(res.get_memory())\n\ncircuit.draw(output="mpl")\n\nplt.show()\n```\n\n## Phase estimation and factoring\n\n### The phase estimation problem\n\n We\'ll begin with a short discussion of the **spectral theorem** from linear algebra, and then move on to a statement of the phase estimation problem itself.\n\n#### Spectral theorem\n\nIt is an important fact from linear algebra that states the matrices of **normal matrices**.\n\n##### Normal matrices\n\nA square matrix $M$ with complex number entries is said to be a **normal** matrix if $MM^†=M^†M$.\n\nSpecially, for unitary matrix $U$:\n$$\nUU^†=\\mathbb I=U^†U,\n$$\nfor hermitian matrices $H$:\n$$\nHH^†=H^2=H^†H.\n$$\n\n##### Theorem statement\n\nHere\'s a statement of the spectral theorem.\n\n> **Theorem**\n>\n> Spectral theorem:  Let $M$ be a normal $N\\times N$ complex matrix. There exists an orthonormal basis of $N$-dimensional complex vectors $\\\\{|\\psi_1 \\langle   ,\\dots,|\\psi_N\\rangle\\\\}$ along with complex numbers $\\lambda_1,\\dots,\\lambda_N$ such that\n> $$\n> M=\\lambda_1|\\psi_1\\rangle \\langle   \\psi_1|+\\dots+\\lambda_N|\\psi_N\\rangle \\langle   \\psi_N|.\n> $$\n\nThe expression of a matrix in the form\n$$\nM=\\sum_{k=1}^N\\lambda_k|\\psi_k\\rangle \\langle   \\psi_k|\n$$\nis called **spectral decomposition**.\n\nIf $M$ is a normal matrix, then\n$$\nM|\\psi_j\\rangle=\\lambda_j|\\psi_j\\rangle\n$$\nmust be true for every $j=1,\\dots,N$.\n\nThat\'s because $\\\\{|\\psi_1\\rangle,\\dots,|\\psi_N\\rangle\\\\}$ is orthonormal:\n$$\nM|\\psi_j\\rangle=(\\sum_{k=1}^N\\lambda_k|\\psi_k\\rangle \\langle   \\psi_k|)|\\psi_j\\rangle=\\sum_{k=1}^N\\lambda_k|\\psi_k\\rangle \\langle   \\psi_k|\\psi_j\\rangle=\\lambda_j|\\psi_j\\rangle\n$$\nThat is, each number $\\lambda_j$ is an **eigenvalue** of $M$ and $|\\psi_j\\rangle$ is an **eigenvector** corresponding to that eigenvalue.\n\n- **Example 1**:\n\n  Let\n  $$\n  \\mathbb I=\\begin{pmatrix}1&0\\\\\\\\0&1\\end{pmatrix}.\n  $$\n  Obviously\n  $$\n  \\lambda_1=1,\\lambda_2=1,|\\psi_1\\rangle=|0\\rangle,|\\psi_2\\rangle=|1\\rangle.\n  $$\n  Indeed, we could choose $\\\\{|\\psi_1\\rangle,|\\psi_2\\rangle\\\\}$ to be **any** orthonormal basis to construct a normal matrix.\n\n  For instance,\n  $$\n  \\mathbb I=|+\\rangle \\langle   +|+|-\\rangle \\langle   -|.\n  $$\n\n- **Example 2**:\n\n  Consider\n  $$\n  H=\\frac{1}{\\sqrt{2}}\\begin{pmatrix}1&1\\\\\\\\1&-1\\end{pmatrix}\n  $$\n  Define\n  $$\n  |\\psi_\\theta\\rangle=\\cos(\\theta)|0\\rangle+\\sin(\\theta)|1\\rangle.\n  $$\n  and we have\n  $$\n  H=|\\psi_{\\pi/8}\\rangle \\langle   \\psi_{\\pi/8}|-|\\psi_{5\\pi/8}\\rangle \\langle   \\psi_{5\\pi/8}|.\n  $$\n\n- \n\nUnitary $U$ has some overwhelming properties\n\nSuppose complex number $\\lambda$ and a non-zero vector $|\\psi\\rangle$ satisfying\n$$\nU|\\psi\\rangle=\\lambda|\\psi\\rangle.\n$$\nand\n$$\n\\||\\psi\\rangle\\|=\\|U|\\psi\\rangle\\|=\\|\\lambda|\\psi\\rangle\\|=|\\lambda|\\||\\psi\\rangle\\|\\Rightarrow |\\lambda|=1\n$$\nThis reveals that eigenvalues of unitary matrices always lie on the **unit circle**.\n$$\n\\mathbb T=\\\\{\\alpha\\in\\mathbb C:|\\alpha|=1\\\\}.\n$$\n\n#### Phase estimation problem stateme**nt**\n\n> **Phase estimation problem**\n>\n> Input: A unitary quantum circuit for an $n$-qubit operation $U$ along with an $n$-qubit quantum state $|\\psi\\rangle$\n\n> Promise: $|\\psi\\rangle$ is an eigenvector of $U$\n\n> Output: an approximation to the number $\\theta\\in[0,1)$ satisfying $U|\\psi\\rangle=e^{2πiθ}|\\psi\\rangle$\n\n### Phase estimation procedure\n\n#### Warm-up: approximating phases with low precision\n\n##### Using the phase kickback' 
                      }
                  ]
                },
                { id: 'percentage', title: '概率论与数理统计A', icon: 'fas fa-tree', desc: '<p>一些小巧思，出于辅导其他同学考试所作。</p><p>可以用作消遣。</p>',
                  chapters: [
                      { id: 'percentage-1', 
                        title: '学习指南', 
                        desc: '', 
                        content: '# 前言\n\n临时整理的，提示瞎写的，习题乱选的.\n\n# 第一章\n\n## 提示\n\n本章节涉及事件、样本空间、离散型概率计算、加法公式、乘法公式...\n\n内容全部包含于**高中数学概率专题**，难度偏低.\n\n期末考试中通常占5~10分.\n\n## 习题\n\n8.在$1500$件产品中有$400$件次品、$1100$件正品.任取$200$件\n\n(1)求恰有90件次品的概率.\n\n(2)求至少有2件次品的概率.\n\n**解答**：(1)可以从超几何分布角度思考，$P=\\frac{\\text C_{400}^{90}\\text C_{1100}^{110}}{\\text C_{1500}^{400}}=长大了我再算$.\n\n(2)$P(至少有2件次品)=1-P(1件次品)-P(0件次品)=1-\\frac{\\text C_{400}^{1}\\text C_{1100}^{199}}{\\text C_{1500}^{400}}-\\frac{\\text C_{400}^{0}\\text C_{1100}^{200}}{\\text C_{1500}^{400}}=不用算出来的啦$.\n\n---\n\n12.$50$只铆钉随机地取来用在$10$个部件上，其中有$3$只铆钉强度太弱.每个部件用$3$只铆钉.若将$3$只强度太弱的铆钉都装在一个部件上，则这个部件强度就太弱.问发生一个部件强度太弱的概率是多少?\n\n**解答**：$P=P(使用包含这3只太弱的铆钉)\\times P(这3只铆钉装在同一个部件上)=\\frac{\\text C_{47}^{27}}{\\text C_{50}^{30}}\\times\\frac{2}{29}\\times\\frac{1}{28}=\\frac{1}{1960}$.\n\n---\n\n14.(1)已知$P(\\overline A)=0.3,P(B)=0.4,P(A\\overline B)=0.5$，求条件概率$P(B|A\\cup\\overline B)$.\n\n(2)已知$P(A)=\\frac{1}{4},P(B|A)=\\frac{1}{3},P(A|B)=\\frac{1}{2}$，求$P(A\\cup B)$.\n\n**解答**：(1)$P(B|A\\cup\\overline B)=\\frac{P(B(A\\cup\\overline B))}{P(A\\cup\\overline B)}=\\frac{P(AB)}{P(A\\cup\\overline B)}=\\frac{P(A)-P(A\\overline B)}{P(A)+P(\\overline B)-P(A\\overline B)}=\\frac{1-0.3-0.5}{1-0.3+1-0.4-0.5}=\\frac{1}{4}$.\n\n(2)$P(A\\cup B)=P(A)+P(B)-P(AB)=P(A)+2P(AB)-P(AB)=P(A)+\\frac{1}{3}P(A)=\\frac{1}{3}$.\n\n---\n\n15.掷两颗骰子，已知两颗骰子点数之和为$7$，求其中有一颗为$1$点的概率.\n\n**解答**：这题太简单了，我们换一道题.\n\n*该题被移动到思考题区域*.\n\n---\n\n25.某人习惯早上六点赶往食堂，这是他抵达时间发生的变化：\n\n| 时间       | 六点半前 | 六点半 | 六点半后 |\n| ---------- | -------- | ------ | -------- |\n| **走路**   | $0.35$   | $0.45$ | $0.20$   |\n| **骑知音** | $0.65$   | $0.20$ | $0.15$   |\n\n某日他抛一枚硬币选择一种出行方式，结果他六点半准时到达食堂，试求他走路去食堂的概率.\n\n**解答**：设事件$A$：走路去食堂，事件$B$：准时到达，则$P(B|A)=0.45,P(B|\\overline{A})=0.20$，\n$$\nP(A|B)=\\frac{P(AB)}{P(B)}=\\frac{P(B|A)P(A)}{P(B|A)P(A)+P(B|\\overline A)P(\\overline A)}=\\frac{9}{13}.\n$$\n\n---\n\n# 第二章\n\n## 提示\n\n本章节涉及离散概率分布、连续概率分布、概率密度函数...\n\n内容由基础微积分知识衔接，难度较高.\n\n期末考试中通常占10~15分，非常恐怖！\n\n## 习题\n\n4.进行重复独立试验，设每次试验成功的概率为$p$，失败的概率为$1-p~(0<p<1)$.\n\n(1)将试验进行到出现一次成功为止，以$X$表示所需的试验次数，求$X$的分布律.\n\n(2)将试验进行到出现$r$次成功为止，以$Y$表示所需的试验次数，求$Y$的分布律.\n\n(3)一篮球运动员的投篮命中率为$45\\%$，以$Z$表示他首次投中时累计已投篮的次数，写出$Z$的分布律，并计算$Z$取偶数的概率.\n\n**解答**：(1)$P(X=k)=(1-p)^{k-1}p,~k=1,2,3,\\dots.$\n\n(2)$P(Y=k)=\\text{C}_{k-1}^{r-1}p^r(1-p)^{k-r},~k=r,r+1,\\dots.$\n\n(3)由(1)$P(Z=k)=0.55^{k-1}\\times 0.45,~k=1,2,3,\\dots$，$\\sum_{k=1}^{\\infty}P(X=2k)=\\frac{11}{31}.$\n\n---\n\n11.尽管在几何教科书中已经讲过仅用圆规和直尺三等分一个任意角是不可能的，但每一年总是有一些**发明者**撰写关于仅用圆规和直尺将角三等分的文章，设某地区每年提写此类文章的篇数$X$服从参数为$6$的泊松分布.求明年没有此类文章的概率.\n\n**解答**：$X\\sim\\pi(6),P(X=0)=e^{-6}=2.5\\times 10^{-3}.$\n\n---\n\n15.保险公司在一天内承保了$5000$张相同年龄、为期一年的寿险保单，每人一份，在合同有效期内若投保人暴毙，则公司需赔付$3$万元，设在一年内，该年龄段的死亡率为$0.0015$，且各投保人是否死亡相互独立，求该公司对于这批投保人的赔付总额不超过$30$万元的概率(利用泊松定理计算).\n\n**解答**：$X\\sim b(5000,0.0015)$， \n$$\nP(X\\le 10)=\\sum_{k=0}^{10}\\text C_{5000}^k0.0015^k(1-0.0015)^{5000-k}.\n$$\n用泊松定理，近似地$X\\sim\\pi(7.5)$，\n$$\nP(X\\le 10)\\approx\\sum_{k=0}^{10}\\frac{7.5^ke^{-7.5}}{k!}=0.8622.\n$$\n\n---\n\n20.设随机变量$X$​的分布函数为\n$$\nF_{X}(x)=\\begin{equation}\\begin{cases}0,&x<1,\\\\\\\\\\ln x,&1\\le x<e,\\\\\\\\1,&x\\ge e.\\\\\\\\\\end{cases}\\end{equation}\n$$\n求概率密度$f_X(x)$.\n\n**解答**：\n$$\nf_X(x)=\\begin{equation}\\begin{cases}\\frac{1}{x},&1<x<e,\\\\\\\\0,&其他.\\end{cases}\\end{equation}\n$$\n\n---\n\n23.某种型号器件的寿命$X$（以h计）具有概率密度\n$$\nf(x)=\\begin{equation}\\begin{cases}\\frac{1000}{x^2},&x>1000,\\\\\\\\0,&其他.\\end{cases}\\end{equation}\n$$\n任选一个，其寿命大于$1500$h的概率为多少？\n\n**解答**：\n$$\np=\\int_{1500}^\\infty\\frac{1000}{x^2}\\ce{d}x=\\frac{2}{3}.\n$$\n\n---\n\n29.一工厂生产的某种元件的寿命$X$（以h计）服从参数为$\\mu=160,\\sigma(\\sigma>0)$的正态分布.若要求$P(120<X\\le 200)\\ge0.80$，允许$\\sigma$最大为多少？\n\n**解答**：$X\\sim N(160,\\sigma^2)$，\n$$\nP(120<X\\le200)=\\Phi(\\frac{40}{\\sigma})-\\Phi(\\frac{-40}{\\sigma})=2\\Phi(\\frac{40}{\\sigma})-1\\ge0.80,\n$$\n即\n$$\n\\Phi(\\frac{40}{\\sigma})\\ge 0.90=\\Phi(1.282)\\Rightarrow\\sigma\\le31.20.\n$$\n\n---\n\n32.设$f(x),g(x)$都是概率密度函数，求证\n$$\nh(x)=\\frac{2}{\\pi}(\\arctan(114514)f(x)+\\arctan(\\frac{1}{114514})g(x))\n$$\n也是一个概率密度函数.\n\n**解答**：懒得写了，反正先说明$h(x)\\ge 0$，再说明$\\int_{-\\infty}^{+\\infty}h(x)\\ce{d}x=1$.\n\n---\n\n34.设随机变量$X$在区间$(0,1)$内服从均匀分布.\n\n(1)求$Y=\\arcsin X$的概率密度.\n\n(2)求$Y=e^{2X}+2e^X+5$的概率密度.\n\n(3)求$Y=e^X-2X$的概率密度，其中$x_1,x_2$分别是$y=e^x-2x~(2-2\\ln 2<y<1)$的两个解.\n\n**解答**：(1)$Y_{min}=\\lim_{X\\to 0^+}\\arcsin X=0,Y_{max}=\\lim_{X\\to 1^-}\\arcsin X=1$，\n\n$f_X(x)\\left|\\frac{\\ce{d}x}{\\ce{d}y}\\right|=\\sqrt{1-x^2}=\\cos y$.\n$$\nf_Y(y)=\\begin{equation}\\begin{cases}\\cos y,&0<y<1\\\\\\\\0,&其他\\end{cases}\\end{equation}\n$$\n(2)$Y_{min}=\\lim_{X\\to 0^+}e^{2X}+2e^X+5=8,Y_{max}=\\lim_{X\\to 1^-}e^{2X}+2e^X+5=e^2+2e+5$，\n\n$f_X(x)\\left|\\frac{\\ce{d}x}{\\ce{d}y}\\right|=\\frac{1}{2e^{2x}+2e^x}=\\frac{1}{2(y-4-\\sqrt{y-4})}$.\n$$\nf_Y(y)=\\begin{equation}\\begin{cases}\\frac{1}{2(y-4-\\sqrt{y-4})},&8<y<e^2+2e+6\\\\\\\\0,&其他\\end{cases}\\end{equation}\n$$\n(3)~~由题意得~~：$Y_{min}\\to 2-2\\ln2,Y_{max}\\to 1$，\n\n$$f\\\_X(x\\\_1)\\left\|\\frac{\\ce{d}x}{\\ce{d}y}\\right\|\\\_{x=x\\\_1}+f\\\_X(x\\\_2)\\left\|\\frac{\\ce{d}x}{\\ce{d}y}\\right\|\\\_{x=x\\\_2}=\\frac{1}{2-e^{x\\\_1}}+\\frac{1}{e^{x\\\_2}-2}.$$\n$$\nf_Y(y)=\\begin{cases}\\frac{1}{2-e^{x_1}}+\\frac{1}{e^{x_2}-2},&2-2\\ln2<y<1\\\\\\\\0,&其他\\end{cases}\n$$\n\n---\n\n# 第三章\n\n## 提示\n\n本章节涉及为第二章的多维化，众所周知升维打击很有毁灭性...\n\n内容来到概率论的高峰，就像双重积分之于高等数学，难度较高.\n\n期末考试中通常占20~25分，非常可怕！\n\n## 习题\n\n3.设随机变量$(X,Y)$的概率密度为\n$$\nf(x,y)=\\begin{equation}\\begin{cases}Ce^{-\\frac{x^2}{2}}e^{-y},&x\\ge0,y\\ge0\\\\\\\\0,&其他\\end{cases}\\end{equation}\n$$\n(1)求$C$.\n\n(2)求$P(X+Y\\le4)$.\n\n**解答**：(1)\n$$\n\\int_{-\\infty}^{+\\infty}\\int_{-\\infty}^{+\\infty}f(x,y)\\ce{d}x\\ce{d}y=C\\int_{0}^{+\\infty}e^{-\\frac{x^2}{2}}\\ce{d}x\\int_{0}^{+\\infty}e^{-y}\\ce{d}y=C\\sqrt{\\frac{\\pi}{2}}=1\\Rightarrow C=\\sqrt{\\frac{2}{\\pi}}.\n$$\n(2)\n$$\n\\begin{align}\nP(X+Y\\le 4)&=\\int_{0}^{4}\\int_0^{4-y}f(x,y)\\ce{d}x\\ce{d}y\\\\\\\\&=\\sqrt{\\frac{2}{\\pi}}\\int_{0}^{4}\\int_0^{4-y}e^{-\\frac{x^2}{2}}e^{-y}\\ce{d}x\\ce{d}y\\\\\\\\&=\n\\sqrt{\\frac{2}{\\pi}}\\int_{0}^{4}e^{-\\frac{x^2}{2}}\\ce{d}x\\int_0^{4-y}e^{-y}\\ce{d}y\\\\\\\\&=\\sqrt{\\frac{2}{\\pi}}\\int_{0}^{4}e^{-\\frac{x^2}{2}}(1-e^{-4+x})\\ce{d}x\\\\\\\\\n&=\\sqrt{\\frac{2}{\\pi}}((2\\Phi(4)-1)-2e^{-\\frac{7}{2}}(\\Phi(3)+\\Phi(1)-1))\\\\\\\\\n&\\approx0.9486\n\\end{align}\n$$\n\n---\n\n4.设$X,Y$相互独立，其概率密度分别为\n$$\nf_X(x)=\\begin{equation}\\begin{cases}\\lambda_1e^{-\\lambda_1x},&x>0\\\\\\\\0,&其他,\\end{cases}\\end{equation}\n$$\n\n$$\nf_Y(y)=\\begin{equation}\\begin{cases}\\lambda_2e^{-\\lambda_2y},&y>0\\\\\\\\0,&其他,\\end{cases}\\end{equation}\n$$\n\n求$P(X<Y)$.\n\n**解答**：\n$$\n\\begin{align}\nP(X<Y)&=\\int_{-\\infty}^{+\\infty}\\int_{-\\infty}^{y}f(x,y)\\ce{d}x\\ce{d}y\\\\\\\\\n&=\\int_{0}^{+\\infty}\\int_{0}^{y}f_X(x)f_Y(y)\\ce{d}x\\ce{d}y\\\\\\\\\n&=\\lambda_1\\lambda_2\\int_{0}^{+\\infty}e^{-\\lambda_2y}\\ce{d}y\\int_{0}^{y}e^{-\\lambda_1x}\\ce{d}x\\\\\\\\\n&=\\frac{\\lambda_1}{\\lambda_1+\\lambda_2}\n\\end{align}\n$$\n\n---\n\n9.设二维随机变量$(X,Y)$的概率密度为\n$$\nf(x,y)=\\begin{equation}\\begin{cases}cx^2y,&x^2\\le y\\le 1\\\\\\\\0,&其他.\\end{cases}\\end{equation}\n$$\n(1)求$c$.\n\n(2)求$F(x,y)$.\n\n(3)求边缘概率密度.\n\n**解答**：(1)\n$$\n\\int_{-1}^1\\int_{x^2}^1f(x,y)\\ce{d}y\\ce{d}x=\\int_{-1}^1\\int_{x^2}^1cx^2y\\ce{d}y\\ce{d}x=\\frac{4c}{21}=1\\Rightarrow c=\\frac{21}{4}.\n$$\n(2)\n$$\n\\begin{align}\nF(x,y)&=\\int_{-\\infty}^{x}\\int_{-\\infty}^{y}f(u,v)\\ce{d}u\\ce{d}v\\\\\\\\\n&=...\\\\\\\\\n&=\\begin{cases}\n0,&y<0或0\\le y<1,x<-\\sqrt{y}或y\\ge1,x<-1\\\\\\\\\n\\frac{7}{8}x^3 y^2-\\frac{3}{8}x^7+\\frac{1}{2}y^{\\frac{7}{2}},&0\\le y<1,-\\sqrt{y}\\le x<\\sqrt{y}\\\\\\\\y^{\\frac{7}{2}},&0\\le y<1,x\\ge\\sqrt{y}\\\\\\\\\n\\frac{7}{8}x^3-\\frac{3}{8}x^7+\\frac{1}{2},&y\\ge 1,-1\\le x<1\\\\\\\\\n1,&y\\ge1,x\\ge1\n\\end{cases}\n\\end{align}\n$$\n(3)\n\n$$\nf_X(x)=\\int_{-\\infty}^{\\infty}f(x,y)\\ce{d}y=\\begin{equation}\\begin{cases}\\frac{21}{8}x^2(1-x^4),&-1\\le x\\le 1\\\\\\\\0,&其他.\\end{cases}\\end{equation}\n$$\n\n$$\nf_Y(y)=\\int_{-\\infty}^{\\infty}f(x,y)\\ce{d}x=\\begin{equation}\\begin{cases}\\frac{7}{2}y^{\\frac{5}{2}},&0\\le y\\le 1\\\\\\\\0,&其他.\\end{cases}\\end{equation}\n$$\n\n---\n\n13.设二维随机变量$(X,Y)$的概率密度为\n$$\nf(x,y)=\\begin{equation}\\begin{cases}cx^2y,&x^2\\le y\\le 1\\\\\\\\0,&其他.\\end{cases}\\end{equation}\n$$\n(1)求条件概率密度$f_{X|Y}(x|y)$.\n\n(2)求条件概率密度$f_{Y|X}(y|x)$.\n\n(3)求条件概率$P\\\\{Y\\ge\\frac{1}{4}|X=\\frac{1}{2}\\\\},P\\\\{Y\\ge\\frac{3}{4}|X=\\frac{1}{2}\\\\},P\\\\{Y\\ge\\frac{3}{4}|X\\ge\\frac{1}{2}\\\\}$.\n\n**解答**：(1)\n$$\nf_{X|Y}(x|y)=\\begin{equation}\\begin{cases}\\frac{f(x,y)}{f_Y(y)}=\\frac{3}{2}x^2y^{-\\frac{3}{2}}&x^2\\le y\\le 1\\\\\\\\0,&其他.\\end{cases}\\end{equation}\n$$\n(2)\n$$\nf_{Y|X}(y|x)=\\begin{equation}\\begin{cases}\\frac{f(x,y)}{f_X(x)}=\\frac{2y}{1-x^4}&x^2\\le y\\le 1\\\\\\\\0,&其他.\\end{cases}\\end{equation}\n$$\n(3)\n$$\nP\\\\{Y\\ge\\frac{1}{4}|X=\\frac{1}{2}\\\\}=\\int_{\\frac{1}{4}}^1f_{Y|X}(y|x=\\frac{1}{2})\\ce{d}y=1.\n$$\n\n$$\nP\\\\{Y\\ge\\frac{3}{4}|X=\\frac{1}{2}\\\\}=\\int_{\\frac{3}{4}}^1f_{Y|X}(y|x=\\frac{1}{2})\\ce{d}y=\\frac{7}{15}.\n$$\n\n$$\nP\\\\{Y\\ge\\frac{3}{4}|X\\ge\\frac{1}{2}\\\\}=\\frac{P(Y\\ge\\frac{3}{4}\\land X\\ge\\frac{1}{2})}{P(X\\ge\\frac{1}{2})}=\\frac{\\int_{\\frac{3}{4}}^1\\int_{\\frac{1}{2}}^{\\sqrt{y}}f(x,y)\\ce{d}x\\ce{d}y}{\\int_{\\frac{1}{4}}^1\\int_{\\frac{1}{2}}^{\\sqrt{y}}f(x,y)\\ce{d}x\\ce{d}y}=自己算.\n$$\n\n---\n\n21.设二维随机变量$(X,Y)$的概率密度为\n$$\nf(x,y)=\\begin{equation}\\begin{cases}x+y,&0<x<1,0<y<1\\\\\\\\0,&其他.\\end{cases}\\end{equation}\n$$\n(1)求$f_{X+Y}(z)$.\n\n(2)求$f_{XY}(z)$.\n\n(3)求$f_{Xe^Y}(z)$.\n\n**解答**：(1)(2)第一种解法：计算$F_Z(z)=P(g(X,Y)\\le z)=\\iint_{g(x,y)\\le z}f(x,y)\\ce{d}x\\ce{d}y$，再求导.\n\n第二种解法：如果$g(X,Y)=Z$可以显示表达出$Y=h(X,Z)$，有$f_Z(z)=\\int_{-\\infty}^{\\infty}f(x,h(x,z))\\left|\\frac{\\partial y}{\\partial z}\\right|\\ce{d}x$，反之则反之.\n\n(3)\n$$\nxe^y=z\\Rightarrow y=\\ln z-\\ln x$$$$\nf_Z(z)=\\frac{\\int_{-\\infty}^\\infty(x-\\ln x+\\ln z)}{z}\\ce{d}x=\\begin{equation}\\begin{cases}\\frac{1}{z}\\int_{\\frac{z}{e}}^{z}(x-\\ln x+\\ln z)\\ce{d}x,&0<z\\le 1\\\\\\\\\\frac{1}{z}\\int_{\\frac{z}{e}}^{1}(x-\\ln x+\\ln z)\\ce{d}x,&1<z\\le e\\\\\\\\0,&其他.\\end{cases}\\end{equation}\n$$\n即\n$$\nf_Z(z)=\\begin{equation}\\begin{cases}\\frac{1}{2}z(1-\\frac{1}{e^2})+(1-\\frac{2}{e}),&0<z\\le 1\\\\\\\\\\frac{3}{2z}+\\frac{\\ln z}{z}-\\frac{z}{2e^2}-\\frac{2}{e},&1<z\\le e\\\\\\\\0,&其他.\\end{cases}\\end{equation}\n$$\n\n---\n\n26.设随机变量$X$，$Y$相互独立，它们的概率密度均为\n$$\nf(x)=\\begin{cases}e^{-x},&x>0,\\\\\\\\0,&其他.\\end{cases}\n$$\n求$Z=\\frac{Y}{X}$的概率密度.\n\n**解答**：因为相互独立，所以$f(x,y)=f_X(x)f_Y(y)$.\n$$\nf_X(x)=\\begin{cases}e^{-x},&x>0,\\\\\\\\0,&其他.\\end{cases}\n$$\n\n$$\nf_Y(y)=\\begin{cases}e^{-y},&y>0,\\\\\\\\0,&其他.\\end{cases}\n$$\n\n$$\nf(x,y)=\\begin{cases}e^{-x-y},&x>0,y>0,\\\\\\\\0,&其他.\\end{cases}\n$$\n\n$z>0$时,\n$$\nf_Z(z)=\\int_{-\\infty}^{\\infty}f(x,zx)\\left|\\frac{\\partial y}{\\partial z}\\right|\\ce{d}x=\\int_0^\\infty xe^{-x(z+1)}\\ce{d}x=\\frac{1}{(z+1)^2}.\n$$\n$z\\le 0$时，\n$$\nf_Z(z)=0.\n$$\n\n---\n\n29.设随机变量$(X,Y)$​的概率密度为\n$$\nf(x,y)=\\begin{cases}be^{-(x+y)},&0<x<1,0<y<\\infty,\\\\\\\\0,&其他.\\end{cases}\n$$\n(1)确定常数$b$.\n\n(2)求边缘概率密度$f_X(x),f_Y(y)$.\n\n(3)求函数$U=\\max\\\\{X,Y\\\\}$的分布函数.\n\n**解答**：(1)\n$$\n\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}f(x,y)\\ce{d}x\\ce{d}y=\\int_0^\\infty\\int_0^1be^{-(x+y)}\\ce{d}x\\ce{d}y=b(1-\\frac{1}{e})=1\\Rightarrow\\\\\\\\\nb=\\frac{1}{1-\\frac{1}{e}}=\\frac{e}{e-1}.\n$$\n(2)\n$$\nf_X(x)=\\int_{-\\infty}^\\infty f(x,y)\\ce{d}y=\\begin{cases}\\frac{e}{e-1}\\int_0^{\\infty}e^{-x}e^{-y}\\ce{d}y=\\frac{e^{-x}}{1-e^{-1}},&0<x<1,\\\\\\\\0,&其他.\\end{cases}\n$$\n\n$$\nf_Y(y)=\\int_{-\\infty}^\\infty f(x,y)\\ce{d}x=\\begin{cases}\\frac{e}{e-1}\\int_0^{1}e^{-x}e^{-y}\\ce{d}y=e^{-y},&y>0,\\\\\\\\0,&其他.\\end{cases}\n$$\n\n(3)\n\n 因为$F_U(u)=P(u\\le U)=P(u\\le\\max(X,Y))=P(u\\le X,u\\le Y)$，又$f(x,y)=f_X(x)f_Y(y)$成立，所以$X,Y$相互独立，所以$P(u\\le X,u\\le Y)=P(u\\le X)P(u\\le Y)=F_X(u)F_Y(u)$.\n$$\nF_X(u)=\\begin{cases}0,&u<0,\\\\\\\\\\frac{1-e^{-u}}{1-e^{-1}},&0\\le u<1,\\\\\\\\1,&u\\ge 1.\\end{cases}\n$$\n\n$$\nF_Y(u)=\\begin{cases}0,&u<0,\\\\\\\\1-e^{-u},&u\\ge 0.\\end{cases}\n$$\n\n$$\nF_U(u)=\\begin{cases}0,&u<0,\\\\\\\\\\frac{(1-e^{-u})^2}{1-e^{-1}},&0\\le u<1,\\\\\\\\1-e^{-u},&u\\ge 1.\\end{cases}\n$$\n\n---\n\n# 第四章\n\n## 提示\n\n本章节涉及离散随机变量和连续随机变量的三围：均值、方差、标准差...\n\n这门课程计算的高峰止于这一章。\n\n期末考试中通常占30~35分，非常可怕！\n\n## 习题\n\n4.(1)设随机变量$X$的分布律为$P\\\\{X=(-1)^{j+1}\\frac{3^j}{j}\\\\}=\\frac{2}{3^j},j=1,2,\\dots$，说明$X$的数学期望不存在.\n\n**解答**：(1)\n$$\nE(X)=\\sum_{j=1}^\\infty(-1)^{j+1}\\frac{3^j}{j}P\\\\{X=(-1)^{j+1}\\frac{3^j}{j}\\\\}=2\\sum_{j=1}^\\infty\\frac{(-1)^{j+1}}{j}\n$$\n不绝对收敛(调和级数不收敛)，期望不存在.\n\n---\n\n6.(1)设$X\\sim\\pi(\\lambda)$，求$E(\\frac{1}{X+1})$.\n\n**解答**：(1)\n$$\nP\\\\{X=k\\\\}=\\frac{\\lambda^ke^{-\\lambda}}{k!}.$$$$\nE(\\frac{1}{X+1})=\\sum_{k=0}^\\infty\\frac{1}{k+1}P\\\\{X=k\\\\}=\\frac{e^{-\\lambda}}{\\lambda}\\sum_{j=1}^\\infty\\frac{\\lambda^j}{j!}=\\frac{e^{-\\lambda}}{\\lambda}(e^\\lambda-1)=\\frac{1}{\\lambda}(1-e^{-\\lambda})\n$$\n此题旨在帮助各位回忆泰勒公式.\n\n---\n\n7.(1)设随机变量$X_i,i=1,2,\\dots,n$相互独立，且$X_i\\sim U(0,1)$，分别求$U=\\max\\\\{X_1,X_2,\\dots,X_n\\\\}$和$V=\\min\\\\{X_1,X_2,\\dots,X_n\\\\}$的数学期望.\n\n**解答**：(1)$X_i$的分布函数为\n$$\nF(x)=\\begin{cases}0,&x<0,\\\\\\\\x,&0\\le x<1,\\\\\\\\1,&x\\ge 1.\\end{cases}\n$$\n\n$$\n\\begin{align}\nF_U(u)&=P(U\\le u)=P(X_1\\le u,X_2\\le u,\\dots,X_n\\le u)=F(u)^n\\\\\\\\\n&=\\begin{cases}0,&u<0,\\\\\\\\u^n,&0\\le u<1,\\\\\\\\1,&u\\ge 1.\\end{cases}\n\\end{align}\n$$\n\n$$\nf_U(u)=\\begin{cases}nu^{n-1},&0<u<1,\\\\\\\\0,&其他.\\end{cases}\n$$\n\n$$\nE(U)=\\int_{-\\infty}^{\\infty}uf_U(u)\\ce du=\\frac{n}{n+1}.\n$$\n\n$$\n\\begin{align}\nF_V(v)&=P(V\\le v)=1-P(V>v)=1-P(X_i>v)^n\\\\\\\\\n&=\\begin{cases}0,&v<0,\\\\\\\\1-(1-v)^n,&0\\le v<1,\\\\\\\\1,&v\\ge 1.\\end{cases}\\\\\\\\\n\\end{align}\n$$\n\n$$\nf_V(v)=\\begin{cases}n(1-v)^{n-1},&0<v<1,\\\\\\\\0,&其他.\\end{cases}\n$$\n\n$$\nE(V)=\\frac{1}{n+1}.\n$$\n\n---\n\n9.(1)设随机变量$(X,Y)$服从在$y=x^2$与$y=\\sqrt{x}$围成的区域均匀分布，求$E(X)$，$E(Y)$，$E(X^2+Y^2)$，$E(\\frac{Y^2}{X})$，$E(X^Y)$，$D(XY)$，$\\text{Cov}(X,Y)$，$\\rho_{XY}$.\n\n**解答**：(1)计算区域$S$面积：\n$$\nS=\\int\\\_0^1\\int\\\_{x^2}^{\\sqrt x}\\ce{d}y\\ce{d}x=(\\frac{2}{3}x^{\\frac{3}{2}}-\\frac{1}{3}x^3)\\bigg|\\\_0^1=\\frac{1}{3}\n$$\n概率密度函数：\n$$\nf(x,y)=\\begin{cases}3,&(x,y)\\in S\\\\\\\\0,&其他.\\end{cases}\n$$\n接下来求期望都可以用这个公式：\n$$\nE(g(X,Y))=\\int_{-\\infty}^\\infty\\int_{-\\infty}^\\infty g(x,y)f(x,y)\\ce{d}x\\ce{d}y\n$$\n\n$$\nE(X)=\\iint_S3x\\ce{d}x\\ce{d}y=3\\int_{0}^{1}x\\left(\\int_{x^2}^{\\sqrt{x}}\\ce dy\\right)\\ce dx=3\\int_{0}^{1}x(\\sqrt{x}-x^2)\\ce dx=\\frac{9}{20}\n$$\n\n由对称性，$E(Y)=E(X)=\\frac{9}{20}$.\n$$\nE(X^2+Y^2)=2E(X^2)=\\frac{18}{35}\n$$\n\n$$\nE(\\frac{Y^2}{X})=\\frac{1}{2}\n$$\n\n$$\nE(X^Y)=\\int_0^1\\frac{x^{\\sqrt{x}}-x^{x^2}}{\\ln x}\\ce dx\\approx0.245989\n$$\n\n$$\nE(XY)=\\frac{1}{4}\n$$\n\n$$\nE(X^2Y^2)=\\frac{1}{9}\n$$\n\n$$\nD(XY)=E(X^2Y^2)-[E(XY)]^2=\\frac{7}{144}\n$$\n\n$$\n\\text{Cov}(X,Y)=E[(X-E(X))(Y-E(Y))]=E(XY)-E(X)E(Y)=\\frac{19}{400}\n$$\n\n$$\nD(X)=D(Y)=E(X^2)-[E(X)]^2=\\frac{153}{2800}\n$$\n\n$$\n\\rho_{XY}=\\frac{\\text{Cov}(X,Y)}{\\sqrt{D(X)D(Y)}}=\\frac{133}{153}\n$$\n\n---\n\n10.(1)设$X\\sim N(0,\\sigma^2)$，$Y\\sim N(0,\\sigma^2)$，$X$和$Y$相互独立，求$E(\\sqrt{X^2+Y^2})$.\n\n(2)上一问基础上，若$X$和$Y$不相互独立，已知它们的相关系数为$\\rho$，你能推导出\n$$\nf(x,y) = \\frac{1}{2\\pi\\sigma^2\\sqrt{1-\\rho^2}} \\exp\\left[\\frac{2\\rho xy-x^2-y^2}{2(1-\\rho^2)\\sigma^2}\\right]\n$$\n吗？\n\n**解答**：(1)\n$$\nf(x,y)=\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{x^2}{2\\sigma^2}}\\cdot \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{y^2}{2\\sigma^2}}=\\frac{1}{2\\pi\\sigma^2}e^{-\\frac{x^2+y^2}{2\\sigma^2}}\n$$\n\n$$\n\\begin{align}\nE(\\sqrt{X^2+Y^2})&=\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}\\sqrt{x^2+y^2}\\frac{1}{2\\pi\\sigma^2}e^{-\\frac{x^2+y^2}{2\\sigma^2}}\\ce dx\\ce dy\\\\\\\\\n&=\\int_0^{2\\pi}\\ce{d}\\theta\\int_0^{\\infty}\\frac{r}{2\\pi\\sigma^2}e^{-\\frac{r^2}{2\\sigma^2}}r\\ce dr\\\\\\\\\n&=\\sigma\\sqrt\\frac{\\pi}{2}\n\\end{align}\n$$\n\n(2)\n\n设$Z_1,Z_2$是相互独立的随机变量，且都服从标准正态分布$N(0,1)$.\n$$\nf(z_1, z_2) = \\frac{1}{2\\pi} \\exp\\left( -\\frac{z_1^2 + z_2^2}{2} \\right)\n$$\n令\n$$\nX=\\sigma Z_1,Y=\\sigma(\\rho Z_1+\\sqrt{1-\\rho^2}Z_2)\n$$\n显然$X\\sim N(0,\\sigma^2)$，验证$Y$：\n$$\nE(Y)=0$$$$D(Y)=D(\\sigma\\rho Z_1)+D(\\sigma\\sqrt{1-\\rho^2}Z_2)+\\text{Cov}(\\sigma^2\\rho\\sqrt{1-\\rho^2}Z_1Z_2)=\\sigma^2\n$$\n$Y$又是服从正态分布的变量的叠加，所以$Y\\sim N(0,\\sigma^2)$成立.\n$$\n\\rho_{XY}=\\frac{\\text{Cov}(X,Y)}{\\sigma^2}=\\frac{E(XY)}{\\sigma^2}=\\frac{\\sigma^2 E(\\rho Z_1^2 + \\sqrt{1-\\rho^2} Z_1 Z_2)}{\\sigma^2}=\\rho\n$$\n现在需要从$(Z_1,Z_2)$映射到$(X,Y)$：\n$$\nZ_1=\\frac{X}{\\sigma},Z_2=\\frac{Y-\\rho X}{\\sigma\\sqrt{1-\\rho^2}}\n$$\n\n$$\n\\begin{align}\nf(x,y)&=f(z_1,z_2)\\cdot\\left|\\frac{\\partial(z_1,z_2)}{\\partial(x,y)}\\right|\\\\\\\\\n&=\\frac{1}{2\\pi} \\exp\\left( -\\frac{z_1^2 + z_2^2}{2} \\right)\\cdot\\left|\\begin{matrix}\\frac{1}{\\sigma}&0\\\\\\\\-\\frac{\\rho}{\\sigma\\sqrt{1-\\rho^2}}&\\frac{1}{\\sigma\\sqrt{1-\\rho^2}}\\end{matrix}\\right|\\\\\\\\\n&=\\frac{1}{2\\pi\\sigma^2\\sqrt{1-\\rho^2}} \\exp\\left[\\frac{2\\rho xy-x^2-y^2}{2(1-\\rho^2)\\sigma^2}\\right]\n\\end{align}\n$$\n\n---\n\n34.(1)设随机变量$(X,Y)$服从二维正态分布，且$D(X)=\\sigma_X^2$，$D(Y)=\\sigma_Y^2$，求$a$的值使$X-aY$和$X+aY$相互独立.\n\n**解答**：(1)\n$$\n\\begin{align}\n\\text{Cov}(X-aY,X+aY)&=E[(W-E(W))(V-E(V)]\\\\\\\\\n&=E(WV)-E(W)E(V)\\\\\\\\\n&=E(X^2-a^2Y^2)-(E(X)-aE(Y))(E(X)+aE(Y))\\\\\\\\\n&=E(X^2)-a^2E(Y^2)-E(X)^2+a^2E(Y)^2\\\\\\\\\n&=D(X)-a^2D(Y)\\\\\\\\\n&=0\\Rightarrow a=\\frac{\\sigma_X}{\\sigma_Y}\n\\end{align}\n$$\n\n---\n\n36.(1)已知正常男性成人血液中,每一毫升所含白细胞数的均值是$7300$，均方差是$700$.利用切比雪夫不等式估计每毫升含白细胞数在$5200\\sim9400$的概率$p$.\n\n**解答**：(1)$E(X)=7300$，$\\sqrt{D(X)}=700$.\n$$\n\\begin{align}\np&=P\\\\{5200<X<9400\\\\}\\\\\\\\\n&=P\\\\{|X-7300|<2100\\\\}\n\\end{align}\n$$\n由\n$$\nP\\\\{|X-E(X)|\\ge b\\\\}\\le\\frac{D(X)}{b^2}\n$$\n有\n$$\np\\ge1-\\frac{D(X)}{2100^2}=\\frac{8}{9}\n$$\n\n---\n\n# 第五六七八章\n\n## 提示\n\n本章节涉及大数定律、中心极限定理、样本抽样分布、参数估计、假设检验...\n\n在基础的概率论数理统计中，难度比较低.\n\n从这里概率论进入背大于算的阶段了.\n\n期末考试中通常占40~50分.\n\n## 习题\n\n这部分习题都是针对实际问题的应用，做法几乎都是一个模板，非常无聊，违背了“好玩”的初衷，所以本指南到此为止.' 
                      }
                  ]
                }
            ],
            questions: [
                {
                    id: '1', title: '西克曼骰子', preview: '修改两个骰子各自点数的分布可能导致相同的和的期望...', difficulty: 'Hard', category: 'Probability', 
                    content: '掷两颗骰子，如果它们是标准的六面骰，那么你很容易计算出它们**和**的概率分布：\n>\n| 点数     | 2              | 3              | 4              | 5              | 6              | 7              | 8              | 9              | 10             | 11             | 12             |\n| -------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- |\n| **概率** | $\\frac{1}{36}$ | $\\frac{2}{36}$ | $\\frac{3}{36}$ | $\\frac{4}{36}$ | $\\frac{5}{36}$ | $\\frac{6}{36}$ | $\\frac{5}{36}$ | $\\frac{4}{36}$ | $\\frac{3}{36}$ | $\\frac{2}{36}$ | $\\frac{1}{36}$ |\n>\n但是聪明的你发现，如果修改两个六面骰点数分别为\n>\n- $\\\\{1, 2, 2, 3, 3, 4\\\\}$.\n- $\\\\{1, 3, 4, 5, 6, 8\\\\}$.\n>\n它们点数和的概率分布和上面的分布等同！\n>\n---\n>\n假设一个标准$n$面骰子是一个$n$，其面用整数$[1,n]$标记，使掷出每个数字的概率为$\\frac{1}{n}$.对于$n=6$，投掷这种骰子的生成函数是$x+x^2+x^3+x^4+x^5+x^6$.该多项式与其自身的乘积就是投掷一对骰子的生成函数：$x^2+2x^3+3x^4+4x^5+5x^6+6x^7+5x^8+4x^9+3x^{10}+2x^{11}+x^{12}$.\n>\n定义$n$**次单位根**$=\\\\{z|z^n=1\\land z\\in\\\\mathbb C\\\\}$，**$n$次本原单位根**$=\\\\{z|\\text{ord}(z)=n\\\\}$，这里旨在说明本原单位根是阶为$n$的单位根.\n>\n定义**分圆多项式$\\Phi_n(x)$**$=(x-\\epsilon_1)(x-\\epsilon_2)\\dots(x-\\epsilon_{\\phi(n)})$，其中$\\epsilon_i$表示第$i$个$n$次本原单位根，$\\varphi(n)$是$n$次本原单位根的个数.\n>\n如$n=4$：$4次单位根=\\\\{1,i,-1,-i\\\\}$，$4次本原单位根=\\\\{i,-i\\\\}$，$\\Phi_4(x)=(x-i)(x+i)=x^2+1$.\n>\n众所周知：\n$$\nx^n-1=\\prod_{d|n}\\Phi_d(x).\n$$\n又有\n$$\n\\frac{x^n-1}{x-1}=\\sum_{i=0}^{n-1}x^i=1+x+\\dots+x^{n-1}.\n$$\n因此，我们推导出单个$n$面规范骰子的生成函数为\n$$\nx+x^2+\\dots+x^n=\\frac{x}{x-1}\\prod_{d|n}\\Phi_d(x)\n$$\n对于六面标准骰子，就有\n$$\nx+x^2+x^3+x^4+x^5+x^6=\\frac{x}{x-1}\\Phi_1(x)\\Phi_2(x)\\Phi_3(x)\\Phi_6(x)=$$$$\n\\frac{x}{x-1}(x-1)(x+1)(x^2+x+1)(x^2-x+1)=x(x+1)(x^2+x+1)(x^2-x+1).\n$$\n投掷两个骰子的生成函数是每个因子的两个副本的乘积.我们想将它们分割成两个点数不是传统排列的**合规**骰子.这里的**合规**是指骰子的系数都是非负数且总和为$6$，仅存在一种这样的情况：\n>\n$$x(x+1)(x^2+x+1)=x+2x^2+2x^3+x^4$$\n>\n和\n>\n$$x(x+1)(x^2+x+1)(x^2-x+1)^2=x+x^3+x^4+x^5+x^6+x^8$$.\n>\n最终我们推出了一对概率分布一样的骰子.\n\n'
                },
                {
                    id: '2', title: '随机鸭子分布问题1', preview: '在圆、球内随机选取鸭子，它们能被落于指定图形的概率是...', difficulty: 'Medium', category: 'Probability', 
                    content: '在一个单位圆$O$内，随机选取$n$个点，这里随机的定义是：对于任意$O$中面积为$S$的区域，选取的点落于这个区域的概率是$S$.求存在一条直径能将这$n$个点划为同一个半圆内的概率$P$.当然，这个问题同样不考虑点落于直径上的情况.\n>\n显然对于$n=1,n=2$，都有$P=1$.\n>\n对于$n=3$，有$P=\\frac{3}{4}$，可以这样分析：\n>\n在任何$n=2$的情况下增加一个点，如果原先两个点对应的半径是$OA$和$OB$，那么新增加的点只要不落于$OA$和$OB$反方向夹角以内的区域即可.这个夹角显然服从在$0°$到$180°$的均匀分布，所以新增加的点不落于这个区域的概率是\n$$\nP=1-\\frac{\\frac{0°+180°}{2}}{360°}=\\frac{3}{4}.\n$$\n对于$n$更大的情况采取另一个思路：\n>\n考虑每个点对应的半径$OP_i$，固定这个点使其它所有点落于$OP_i$顺时针$180°$的半圆内的概率是\n$$\nP_i=\\left(\\frac{1}{2}\\right)^{n-1}.\n$$\n注意$P_i$是彼此互斥的，又没有遗漏的事件，所以\n$$\nP=\\sum_{i=1}^n P_i=\\frac{n}{2^{n-1}}.\n$$\n接下来，把问题扩展到三维世界：\n>\n在单位球$O$的球面上随机选取$n$个点，这里随机的定义是：对于任意$O$面上面积为$S$的区域，选取的点落于这个区域的概率是$S$.求这些点围成的凸多面体包含球心的概率$P\'$.当然，这个问题同样不考虑球心落于线段或平面上的情况.此外这里凸多面体的定义是：枚举任意三点构成的子平面，剔除那些能被已有的子平面完全围住的子平面，剩下的子平面围成的多面体.\n>\n其实本题就是问使$n$个点都落于同一个半球的概率.\n>\n考虑第$i$个点和球心连成的直线，这条直线与球交于$A_iA_{-i}$，作这条直线过球心的法平面，当新增第$k$个法平面，会切割原有的$k$个不相交的区域，所以对于$n$个法平面，会把球面分割为\n$$\n2+\\sum_{i=1}^n2(i-1)=n^2-n+2\\\\\n$$\n个区域.\n>\n对于每个区域，总可以确定唯一一个数对\n$$\n\\langle \\gamma_1,\\gamma_2,\\dots,\\gamma_n\\rangle,\\gamma_i\\in\\{A_i,A_{-i}\\}\n$$\n代表$n$个点的选择使得这$n$个点落于同一个半球，所以合法方案数就等于区域个数.\n>\n因此\n$$\nP\'=\\frac{n^2-n+2}{2^n}.\n$$'
                },
                {
                    id: '3', title: '"量子力学"的美', preview: '通常自己创造条件不会对解题有帮助，除非...', difficulty: 'Medium', category: 'Probability', 
                    content: '你有幸参与到**电锯惊魂**的电影拍摄.众所周知，竖锯很喜欢给犯下罪过的人类玩一些小游戏，大抵是因为计组没考好于斩杀线中被老师捞了起来被视为了一种罪过，现在你最好赢得下面的小游戏（能提高$0.01\\%$的获胜概率都是好的），否则竖锯会给你一块小蛋糕和一个电锯，你得选择坐在其中一个上面吃另一个.\n>\n设$T\\subseteq\\\\mathbb R$，随机取$a,b\\in T$，令$a\\ne b$，现在给出$a$的值，询问$b$比$a$更大或更小？\n>\n我们尚不知道$T\\subseteq\\\\mathbb R$有什么深意，此外好像没有多余信息.\n\n直觉告诉我们只能瞎猜，而且猜中的概率是$50\\\\%$，但我们可以这样做：\n>\n为方便表达，我们令$a< b$，题目修改为给出其中一个数的值，询问另一个数比这个数更大或更小？\n>\n在心中预设一个数$x\\in T$，采取策略：\n>\n- 如果$x$小于给出的数，那么猜另一个数比它更小.\n- 如果$x$大于给出的数，那么猜另一个数比它更大.\n>\n分析：\n>\n- 如果$x$落于小于$a$的区间，那么我们有$50\\%$的概率猜对.\n- 如果$x$落于大于$b$的区间，那么我们有$50\\%$的概率猜对.\n- 如果$x\\in(a,b)$，那么我们一定能猜对.\n>\n乍一看我们猜中的概率比$50\\%$高，看来你有救的期望大于0.那么奥秘出在哪里呢？\n>\n设事件$A$表示猜对：\n$$\nP(A|x<a)=P(A|x>b)=0.5$$$$\nP(A|a<x<b)=1$$$$\nP(A)=P(A\\land x<a)+P(A\\land x>b)+P(A\\land a<x<b)\n$$\n而：\n$$\nP(A\\land x<a)=0.5P(x<a)$$$$\nP(A\\land x>b)=0.5P(x>b)$$$$\nP(A\\land a<x<b)=P(a<x<b)$$$$\n$$\n所以：\n$$\nP(A)=0.5P(x<a)+0.5P(x>b)+P(a<x<b)\n$$\n$x$视为在$T$上均匀分布，概率密度函数满足：\n$$\nf(x)=\\begin{cases}\\frac{1}{T_{\\max}-T_{\\min}},&T_{\\min}\\le x\\le T_{\\max}\\\\\\\\0,&其他\\end{cases}\n$$\n计算上述概率：\n$$\nP(x<a)=\\int_{T_{\\min}}^af(x)\\ce{d} x=\\frac{a-T_{\\min}}{T_{\\max}-T_{\\min}}$$$$\nP(x>b)=\\int_{b}^{T_{\\max}}f(x)\\ce{d} x=\\frac{T_{\\max}-b}{T_{\\max}-T_{\\min}}$$$$\nP(a<x<b)=\\int_{a}^bf(x)\\ce{d} x=\\frac{b-a}{T_{\\max}-T_{\\min}}$$$$\nP(A)=\\frac{1}{2}+\\frac{b-a}{2(T_{\\max}-T_{\\min})}\n$$\n$a$和$b$也是随机选取的，注意这里规定$a<b$，$a$视为两个随机变量的较小量，$b$的分布依赖$a$，它们的​的概率密度函数有所不同：\n$$\nf_a(x)=\\begin{cases}\\frac{2(T_{\\max}-T_{\\min}-x)}{T_{\\max}^2-T_{\\min}^2},&T_{\\min}\\le x\\le T_{\\max}\\\\\\\\0,&其他\\end{cases}$$$$\nf_b(x)=\\begin{cases}\\frac{1}{T_{\\max}-a},&a\\le x\\le T_{\\max}\\\\\\\\0,&其他\\end{cases}\n$$\n所以：\n$$\nE(a)=\\int_{T_{\\min}}^{T_{max}}{x}{f_a(x)}\\ce{d}x=\\frac{T_{max}+2T_{min}}{3}$$$$\nE(b|a)=\\int_{a}^{T_{max}}xf_b(x)\\ce{d}x=\\frac{T_{\\max}+a}{2}$$$$\nE(b)=E(E(b|a))=\\frac{T_{\\max}+E(a)}{2}$$$$\nE(b-a)=E(b)-E(a)=\\frac{T_\\max-E(a)}{2}=\\frac{T_\\max-T_\\min}{3}\n$$\n于是：\n$$\nE(P(A))=\\frac{1}{2}+\\frac{1}{6}=\\frac{2}{3}\\\\\\\\\n$$\n如果$T=\\\\mathbb R$，因为在$\\\\mathbb R$上不存在均匀分布，我倾向于认为$\\frac{b-a}{T_\\max-T_\\min}\\to0$，$P(A)\\to\\frac{1}{2}$.'
                },
                {
                    id: '4', title: '随机鸭子分布问题2', preview: '在圆内随机选取鸭子，它们围成面积是...', difficulty: 'Hard', category: 'Probability', 
                    content: '在单位圆$O$中**随机**选取三个点$P,Q,R$，这里随机的定义是：对于任意$O$中面积为$S$的区域，选取的点落于这个区域的概率是$S$.\n>\n(1)三个点可能共线，但发生概率为$0$，我们不予考虑。当三个点不共线，计算$E(S_{\\Delta PQR})$.\n>\n(2)作$P,Q,R$彼此相连的直线.记过$P$的两条直线$QP,RP$与圆弧分别交于$A,B$，记$PA,PB,\\overset{\\LARGE{\\frown}}{AB}$围成的区域面积为$S_1$，同理得到$S_2,S_3$，计算$E(S_1+S_2+S_3)$.\n>\n(3)多选取一个点$T$，求$P,Q,R,T$构成的平面凸包是四边形的概率$P\\\_\\\\_$.\n>\n**解答**：(1)选取到圆心的距离$r$，考虑三个点距离圆心最远的点落于内圆半径为$r$，外圆半径为$r+\\ce{d}r$的圆环的概率\n$$\n\\begin{align}P_1&=\\frac{\\pi r^2}{\\pi\\times1^2}\\cdot\\frac{\\pi r^2}{\\pi\\times1^2}\\cdot\\frac{2\\pi r\\ce{d}r}{\\pi\\times1^2}\\cdot 3\\\\\\\\\n&=6r^5\\ce{d}r\\end{align}.\n$$\n这里还需要乘以$3$，是因为每个点都可以作为距离圆心最远的点.\n>\n这样做可以视为固定距离圆心最远的点于半径为$r$的小圆处，在小圆内随机选取另外两个点.不妨以这个被固定的点为原点建立极坐标，使得小圆内的点可以被表示为$(x,\\theta)$，且$x\\in(0,2r\\sin\\theta),\\theta\\in(0,\\pi)$.\n>\n不妨记这两个点为$(x_1,\\theta_1),(x_2,\\theta_2)$，显然有\n$$\nS_{\\Delta PQR}=\\frac{1}{2}x_1x_2\\sin(|\\theta_1-\\theta_2|)\n$$\n这里是局部期望\n$$\n\\begin{align}\nE\'(S_{\\Delta PQR})&=\\int_0^\\pi\\int_0^{2r\\sin\\theta_2}\\int_0^\\pi\\int_0^{2r\\sin\\theta_1}\\frac{1}{2}x_1x_2\\sin(|\\theta_1-\\theta_2|)\\frac{x_1\\ce{d}x_1\\ce{d}\\theta_1}{\\pi r^2}\\frac{x_2\\ce{d}x_2\\ce{d}\\theta_2}{\\pi r^2}\\\\\\\\\n&=\\frac{1}{2\\pi^2 r^4}\\int_0^\\pi\\int_0^{2r\\sin\\theta_2}\\int_0^\\pi\\int_0^{2r\\sin\\theta_1}x_1^2x_2^2\\sin(|\\theta_1-\\theta_2|)\\ce{d}x_1\\ce{d}\\theta_1\\ce{d}x_2\\ce{d}\\theta_2\\\\\\\\\n&=\\frac{1}{2\\pi^2 r^4}\\int_0^\\pi\\int_0^\\pi\\sin(|\\theta_1-\\theta_2|)\\ce{d}\\theta_1\\ce{d}\\theta_2\\int_0^{2r\\sin\\theta_2}x_2^2\\ce{d}x_2\\int_0^{2r\\sin\\theta_1}x_1^2\\ce{d}x_1\\\\\\\\\n&=\\frac{1}{2\\pi^2 r^4}\\int_0^\\pi\\int_0^\\pi\\frac{8r^3\\sin^3\\theta_1}{3}\\frac{8r^3\\sin^3\\theta_2}{3}\\sin(|\\theta_1-\\theta_2|)\\ce{d}\\theta_1\\ce{d}\\theta_2\\\\\\\\\n&=\\frac{32}{9\\pi^2 r^4}\\int_0^\\pi\\int_0^\\pi r^6\\sin^3\\theta_1\\sin^3\\theta_2\\sin(|\\theta_1-\\theta_2|)\\ce{d}\\theta_1\\ce{d}\\theta_2\\\\\\\\\n&=\\frac{64}{9\\pi^2 r^4}\\int_0^\\pi\\int_0^{\\theta_2}-r^6\\sin^3\\theta_1\\sin^3\\theta_2\\sin(\\theta_1-\\theta_2)\\ce{d}\\theta_1\\ce{d}\\theta_2\\\\\\\\\n&=\\frac{64r^2}{9\\pi^2}\\int_0^\\pi\\int_0^{\\theta_2}-(\\sin^4\\theta_1\\sin^3\\theta_2\\cos\\theta_2-\\sin^3\\theta_1\\sin^4\\theta_2\\cos\\theta_1)\\ce{d}\\theta_1\\ce{d}\\theta_2\\\\\\\\\n&=\\frac{64r^2}{9\\pi^2}(-\\int_0^\\pi\\sin^3\\theta_2\\cos\\theta_2\\ce{d}\\theta_2\\int_0^{\\theta_2}\\sin^4\\theta_1\\ce{d}\\theta_1+\\int_0^\\pi\\sin^4\\theta_2\\ce{d}\\theta_2\\int_0^{\\theta_2}\\sin^3\\theta_1\\cos\\theta_1\\ce{d}\\theta_1)\\\\\\\\\n&=\\frac{64r^2}{9\\pi^2}\\int_0^\\pi\\frac{\\sin^8\\theta_2}{2}\\ce{d}\\theta_2\\\\\\\\\n&=\\frac{32r^2}{9\\pi^2}\\frac{7\\cdot5\\cdot3\\cdot1}{8\\cdot6\\cdot4\\cdot2}\\pi\\\\\\\\\n&=\\frac{35r^2}{36\\pi}\n\\end{align}.\n$$\n从而\n$$\n\\begin{align}\nE(S_{\\Delta PQR})&=\\int_0^1E\'(S_{\\Delta PQR})P_1\\\\\\\\\n&=\\int_0^1\\frac{35r^7}{6\\pi}\\ce{d}r\\\\\\\\\n&=\\frac{35}{48\\pi}\n\\end{align}.\n$$\n或许采用平面直角坐标系计算$E\'(S_{\\Delta PQR})$也不复杂，若固定点坐标是$(-r,0)$，随机点坐标分别是$(x_1,y_1),(x_2,y_2)$\n$$\n\\begin{align}\nE\'(S_{\\Delta PQR})&=\\int_{-r}^r\\int_{-\\sqrt{r^2-x_1^2}}^{\\sqrt{r^2-x_1^2}}\\int_{-r}^r\\int_{-\\sqrt{r^2-x_2^2}}^{\\sqrt{r^2-x_2^2}}\\frac{|(x_1+r)y_2-(x_2+r)y_1|}{2}\\ce{d}y_2\\ce{d}x_2\\ce{d}y_1\\ce{d}x_1\\\\\\\\\n&=...\\text{好像没想象中简单}\n\\end{align}.\n$$\n(2)(3)放一起讲.\n>\n如果四点构成的平面凸包是四边形，那么选取其中任何三个点，其对应的围成的三角形和与圆弧构成的三个诡异的图形都不会包含第四个点。\n>\n如果四点构成的平面凸包是三角形，那么选取其中任何三个点，若选取到恰好为凸包的三个点，则第四个点落于三角形内，否则第四个点落于诡异的图形内。\n>\n因此\n$$\n\\frac{S_1+S_2+S_3}{S_{\\Delta PQR}}=\\frac{P(T\\in(S_1\\cup S_2\\cup S_3))}{P(T\\in S_{\\Delta PQR})}=3.\n$$\n所以\n$$\nE(S_1+S_2+S_3)=3E(S_{\\Delta PQR})=\\frac{35}{16\\pi}.\n$$\n平面凸包要么是三角形要么是四边形\n$$\nP\\\_\\\\_=1-\\frac{P(T\\in(S\\\_1\\cup S\\\_2\\cup S\\\_3\\cup S\\\_{\\Delta PQR}))}{P(T\\in O)}=1-\\frac{35}{12\\pi^2}.\n$$'
                },
                {
                    id: '5', title: '神秘分布', preview: '科普一些概率分布...', difficulty: 'Hard', category: 'Probability', 
                    content: '设随机变量$X_i$服从**神秘分布$X$**，彼此相互独立.若$E(X)$存在，则记为$\\mu$，若$D(X)$存在，则记为$\\sigma^2$满足\n$$\nX_1+X_2+\\dots+X_n\\overset{d}{=}c_nX+d_n\n$$\n其中\n$$\n\\overset{d}=表示同分布.$$$$\n令\\alpha\\in(0,2],\\\\\\\\\nc_n=n^\\frac{1}{\\alpha},\\\\\\\\\nd_n=\\begin{cases}\\mu(n-n^{\\frac{1}{\\alpha}}),&\\alpha>1,\\\\\\\\0,&\\alpha=1,\\\\\\\\略,&\\alpha<1.\\end{cases}\n$$\n这样的分布$X$称作**稳定分布**，在统计学和机器学习领域有应用，比如**本华·曼德博**发现棉花价格的变化服从稳定分布$\\alpha=1.7$.\n>\n---\n>\n对于$\\alpha=2$，\n$$\nX_1+X_2+\\dots+X_n\\overset{d}{=}\\sqrt{n}X+\\mu(n-\\sqrt{n})\n$$\n对右式求均值和方差，\n$$\nE(\\sqrt{n}X+\\mu(n-\\sqrt{n}))=\\mu(n-\\sqrt{n})+\\sqrt{n}E(X)=n\\mu\n$$\n>\n$$\nD(\\sqrt{n}X+\\mu(n-\\sqrt{n}))=nD(X)=n\\sigma^2\n$$\n>\n事实上此时$X$服从正态分布$N(\\mu,\\sigma^2)$.\n>\n---\n>\n对于$\\alpha=1$​，\n$$\nX_1+X_2+\\dots+X_n\\overset{d}{=}nX\n$$\n有人托梦给我此时$X$服从标准柯西分布：\n$$\nf_X(x)=\\frac{1}{\\pi(1+x^2)}\n$$\n设$X\\sim N(0,1),Y\\sim N(0,1)$，令$Z=\\frac{X}{Y}$.\n$$\nf_Z(z)=\\int_{-\\infty}^{\\infty}f_X(x)f_Y(zx)\\left|\\frac{\\partial y}{\\partial z}\\right|\\ce{d}x=\\frac{1}{2\\pi}\\int_{-\\infty}^\\infty xe^{-\\frac{x^2(z^2+1)}{2}}\\ce{d}x=\\frac{1}{\\pi(1+z^2)}\n$$\n可知标准柯西分布可以由正态分布导出.\n>\n我们引入**特征函数**：\n>\n对于连续随机变量$X$：\n$$\n\\phi_X(t)=E(e^{itX})=\\int_{-\\infty}^{+\\infty}e^{itx}f(x)\\ce dx.\n$$\n一个特征函数$\\phi_X(t)$唯一地决定了随机变量$X$的概率分布，且对于两个独立随机变量$X_1,X_2$，有$\\phi_S(t)=\\phi_{X_1}(t)\\phi_{X_2}(t)$.\n>\n对于$f(x)=\\frac{1}{\\pi(1+x^2)}$，\n$$\n\\phi_X(t)=\\int_{-\\infty}^{+\\infty}e^{itx}\\frac{1}{\\pi(1+x^2)}\\ce dx.\n$$\n我们没学过复变函数，所以上面的结果直接给出：\n$$\n\\phi_X(t)=e^{-|t|}.\n$$\n$X_1+X_2+\\dots+X_n$的特征函数就是$e^{-n|t|}$，与$nX$的特征函数等同.\n>\n值得注意的是：\n$$\n\\int_{-\\infty}^{\\infty}\\frac{|x|}{\\pi(1+x^2)}=\\frac{1}{\\pi}\\ln(1+x^2)|_{0}^\\infty\\to\\infty\n$$\n相应地不难证明$E(X^2)$也不存在，所以标准柯西分布的期望和方差均不存在.\n>\n---\n>\n对于$\\alpha=\\frac{1}{2}$，\n$$\nX_1+X_2+\\dots+X_n\\overset{d}{=}n^2X\n$$\n此时$X$服从**标准$Levy$分布**：\n$$\nf_X(x)=\\begin{cases}\\sqrt{\\frac{1}{2\\pi}}x^{-\\frac{3}{2}}e^{-\\frac{1}{2x}},&x>0,\\\\\\\\0,&其他.\\end{cases}\n$$\n设$X\\sim N(0,1),Y\\sim N(0,1)$，令$Z=\\frac{1}{XY}$.\n$$\nf_Z(z)=\\int_{-\\infty}^{\\infty}f_X(x)f_Y(\\frac{1}{zx})\\left|\\frac{1}{z^2x}\\right|\\ce{d}x=\\frac{1}{\\pi}\\int_{0}^\\infty \\frac{1}{z^2x}e^{-\\frac{x^2+\\frac{1}{z^2x^2}}{2}}\\ce{d}x=\\sqrt{\\frac{1}{2\\pi}}x^{-\\frac{3}{2}}e^{-\\frac{1}{2x}}\n$$\n~~这个计算过程应该是有问题的，我们暂时不管，反正没人看.~~\n>\n不难得到特征函数：\n$$\nϕ_X(t)=\\exp(-|t|^{\\frac{1}{2}}+i\\text{sgn}(t)|t|^{\\frac{1}{2}})\n$$\n$X_1+X_2+\\dots+X_n$的特征函数是$$\\exp(-n|t|^\\frac{1}{2}+ni\\text{sgn}(t)|t|^\\frac{1}{2})$$.\n>\n$n^2X$的特征函数是$$\\phi_{n^2X}(t)=\\exp\\left(-n|t|^\\frac{1}{2}+ni\\operatorname{sgn}(t))|t|^{\\frac{1}{2}}\\right)$$\n>\n因此它们同分布.\n>\n可以证明，标准$Levy$分布的均值和方差也均不存在.\n>\n---\n>\n对于$\\alpha\\notin\\\\{0.5,1,2\\\\}$，相应分布没有初等函数的表示.'
                },
                {
                    id: '6', title: '计算n=100', preview: '简单的数论问题...', difficulty: 'Easy', category: 'Number Theory', 
                    content: '用尽可能少的资源计算\n$$\n\\sum_{i=1}^n\\gcd(i,n)\n$$\n.\n\n直觉告诉我们借助欧几里得的力量很容易写出$O(n\\log n)$的算法解决该题，在一定的数据规模内预处理素数可能会得到更佳的效率.\n\n但我们更容易想到下面效率更好的做法：\n\n记\n$$\nP(n)=\\sum_{i=1}^n\\gcd(i,n).\n$$\n显然：\n$$\n\\gcd(i,n)|n.\n$$\n于是：\n$$\n\\gcd(\\frac{i}{\\gcd(i,n)},\\frac{n}{\\gcd(i,n)})=1.\n$$\n对于每一个因数$d$，满足条件的$i$的个数恰好是$\\varphi(\\frac{n}{d})$，这里$\\varphi$是欧拉函数.\n\n所以：\n$$\nP(n)=\\sum_{d|n}d\\cdot\\varphi(\\frac{n}{d}).\n$$\n这里研究一下$P(n)$的性质，注意到若$\\gcd(n,m)=1$：\n$$\n\\begin{align}P(n)\\cdot P(m)&=\\left(\\sum_{d|n}d\\cdot\\varphi\\left(\\frac{n}{d}\\right)\\right)\\cdot\\left(\\sum_{d|m}d\\cdot\\varphi\\left(\\frac{m}{d}\\right)\\right)\\\\\\\\\n&=\\sum_{d_1|n}\\sum_{d_2|m}d_1d_2\\varphi(\\frac{nm}{d_1d_2})\\\\\\\\\n&=\\sum_{d|(nm)}d\\cdot\\varphi(\\frac{nm}{d})\\\\\\\\\n&=P(nm)\n\\end{align}.\n$$\n把$n$分解为\n$$\np_1^{a_1}p_2^{a_2}\\cdots p_k^{a_k}.\n$$\n$p_i^{a_i}$与$p_j^{a_j}$要么相等要么互质，所以：\n$$\n\\begin{align}P(n)&=\\prod_{i=1}^kP(p_i^{a_i})\\\\\\\\\n&=\\prod_{i=1}^k\\left((a_i+1)p_i^{a_i}-a_i\\cdot p_i^{a_i-1}\\right)\n\\end{align}.\n$$\n这只要求我们对$n$做一个质因数分解，复杂度是接近$O(\\sqrt n)$的.'
                },
                {
                    id: '7', title: '容斥原理', preview: '有点难...', difficulty: 'Medium', category: 'Probability', 
                    content: '对$S=\\{1,2,\\dots,25\\}$随机给出$5$个元素个数相等的划分，也就是第$i$个划分$A_i$满足$|A_i|=5$且$\\bigcap_{i=1}^5A_i=\\emptyset$，$\\bigcup_{i=1}^5A_i=S$，计算$E[\\min(\\min(A_i)]$也就是这$5$个划分各自的最小值构成集合的最小值的期望。\n\n设随机变量$X=\\min\\min(A_i)$也就是这$5$个划分各自的最小值构成集合的最小值。\n\n根据定义：\n$$\nE[X]=\\sum_{k=0}^{20}P(X>k).\n$$\n这可能与我们熟知的期望定义不一样，事实上：\n$$\n\\begin{align}\n\\sum_{k=0}^{20}P(X>k)&=[P(X=1)+P(X=2)+\\dots+P(X=21)]+[P(X=2)+\\dots+P(X=21)]+\\dots+P(X=21)\\\\\\\\\n&=\\sum_{k=1}^{21}kP(X=k)\n\\end{align}.\n$$\n根据容斥原理：\n$$\nP(X>k)=\\sum_{j=0}^{5}(-1)^j\\binom{5}{j}\\frac{\\binom{k}{5j}}{\\binom{25}{5j}}.\n$$\n\n- $\\binom{5}{j}$：从$5$个划分中选出$j$个特定的划分。\n- $\\frac{\\binom{k}{5j}}{\\binom{25}{5j}}$：这$j$个划分（共$5j$个数）完全由$\\{1,2,\\dots,k\\}$构成，这里$k\\le 5j$的时候分子记为$0$。\n\n代入期望公式：\n$$\n\\begin{align}\nE[X]&=\\sum_{k=0}^{20}\\left[\\sum_{j=0}^{5}(-1)^j\\binom{5}{j}\\frac{\\binom{k}{5j}}{\\binom{25}{5j}}\\right]\\\\\\\\\n&=\\sum_{j=0}^{5}(-1)^j\\binom{5}{j}\\frac{1}{\\binom{25}{5j}}\\left[\\sum_{k=0}^{20}\\binom{k}{5j}\\right]\n\\end{align}\n$$\n\n\n由\n$$\n\\sum_{i=r}^{n}\\binom{i}{r}=\\binom{n+1}{r+1}\n$$\n化简得：\n$$\n\\begin{align}\nE[X]&=\\sum_{j=0}^{5}(-1)^j\\binom{5}{j}\\frac{\\binom{25}{5j+1}}{\\binom{25}{5j}}\\\\\\\\\n&=\\sum_{j=0}^{5} (-1)^j\\binom{5}{j}\\frac{25-5j}{5j+1}\n\\end{align}\n$$\n逐项计算：\n$$\n\\begin{align}\nE[X]&=25-\\frac{50}{3}+\\frac{150}{11}-\\frac{25}{4}+\\frac{25}{21}-0\\\\\\\\\n&=\\frac{15625}{924}\n\\end{align}$$'
                }
            ]
        };
        let currentView = 'subjects'; // 状态管理: subjects, chapters, content
        let activeSubject = null;

        const display = document.getElementById('content-display');
        const display_question = document.getElementById('question-display');
        const backBtn = document.getElementById('back-btn-container');
        const backBtnQuestion = document.getElementById('back-btn-container-question');

        function renderSubjects() {
            currentView = 'subjects';
            backBtn.style.display = 'none';
            backBtnQuestion.style.display = 'none';
            let html = '<div class="subject-grid">';
            database.subjects.forEach(sub => {
                html += `
                    <div class="subject-card" onclick="renderChapters('${sub.id}')">
                        <div class="subject-icon"><i class="fas ${sub.icon}"></i></div>
                        <div class="subject-info">
                            <h3>${sub.title}</h3>
                            <p>${sub.desc}</p>
                        </div>
                    </div>`;
            });
            html += '</div>';
            display.innerHTML = html;
            let html_question = '';
            database.questions.forEach(q => {
                html_question += `
                    <div class="question-card" onclick="renderContent('${q.id - 1}', 'Q')">
                        <div class="card-status-accent"></div>
                        <div class="card-body">
                            <div class="card-header">
                                <span class="tag tag-difficulty" data-level="${q.difficulty}">${q.difficulty}</span>
                                <span class="question-id">#${q.id}</span>
                            </div>
                            <h3 class="question-title">${q.title}</h3>
                            <p class="question-preview">${q.preview}</p>
                            <div class="card-footer">
                                <button class="action-btn">去试试 →</button>
                            </div>
                        </div>
                    </div>`;
            });
            display_question.innerHTML = html_question;
        }
        function renderChapters(subjectId) {
            currentView = 'chapters';
            activeSubject = database.subjects.find(s => s.id === subjectId);
            backBtn.style.display = 'block';
            let html = `<div class="chapter-list"><h2 style="margin-bottom:1.5rem; padding-left:10px;">${activeSubject.title}</h2>`;
            activeSubject.chapters.forEach((ch, index) => {
                const displayIdx = (index + 1).toString().padStart(2, '0');
                html += `
                    <div class="chapter-item" onclick="renderContent('${index}', 'S')">
                        <div style="display: flex; align-items: center;">
                            <div class="chapter-info">
                                <span class="chapter-title">${ch.title}</span>
                                <p>${ch.desc}</p>
                            </div>
                        </div>
                        <i class="fas fa-chevron-right" style="font-size: 0.8rem; opacity: 0.3;"></i>
                    </div>`;
            });
            html += '</div>';
            display.innerHTML = html;
        }

        // 渲染笔记内容 (Level 3)
        function renderContent(index, SorQ) {
            if (SorQ === 'S') {
                currentView = 'content';
                const chapter = activeSubject.chapters[index];
                display.innerHTML = `<div class="markdown-body" id="note-render-target"></div>`;
                const target = document.getElementById('note-render-target');
                refreshMarkdown(target, chapter.content);
            } else if (SorQ === 'Q') {
                currentView = 'content-question';
                backBtnQuestion.style.display = 'block';
                const question = database.questions[index];
                display_question.innerHTML = `<div class="markdown-body" id="note-render-target"></div>`;
                const target = document.getElementById('note-render-target');
                refreshMarkdown(target, question.content);
            }
        }

        function refreshMarkdown(containerElement, rawMarkdown) {
            containerElement.innerHTML = marked.parse(rawMarkdown);
            if (window.MathJax && MathJax.typesetPromise) {
                MathJax.typesetPromise([containerElement]);
            }
        }

        function goBack() {
            if (currentView === 'content-question' || currentView === 'chapters') {
                renderSubjects();
            }
            else if (currentView === 'content') {
                renderChapters(activeSubject.id);
            }
        }
        document.addEventListener('DOMContentLoaded', renderSubjects);
    </script>
    <!--负责切换逻辑-->
    <script>
        document.addEventListener('DOMContentLoaded', () => {
            currentView = 'subjects';
            const links = document.querySelectorAll('.nav-links a');
            const sections = {
                notes: document.getElementById('section-notes'),
                downloads: document.getElementById('section-downloads'),
                questions: document.getElementById('section-questions'),
                about: document.getElementById('section-about')
            };

            links.forEach(link => {
                link.addEventListener('click', (e) => {
                    e.preventDefault();
                    const target = link.getAttribute('data-section');
                    links.forEach(l => l.classList.remove('active'));
                    link.classList.add('active');
                    Object.keys(sections).forEach(key => {
                        if (sections[key]) {
                            sections[key].style.display = (key === target) ? 'block' : 'none';
                        }
                    });
                    if (target === 'notes') {
                        renderSubjects();
                    }
                });
            });
            renderSubjects();
        });
    </script>
    <script>
        $m.innerHTML = marked.parse($t.value);
        window.MathJax && MathJax.typeset();
    </script>
</body>
</html>